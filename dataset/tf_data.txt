import json
import tempfile
import pytest
import tensorflow as tf
from tests.integration.utils import ()
test_data = [[]]
test_tensor = tf.constant()
def tf1_model_path():
    def cnn_model_fn():
        X = tf.placeholder(shape=[], dtype=, name=)
        inter1 = tf.layers.dense(inputs=, units=, activation=)
        p = tf.argmax(input=, axis=)
        y = tf.placeholder(tf.float32, shape=[], name=)
        loss = tf.losses.softmax_cross_entropy()
        train_op = tf.train.AdamOptimizer().minimize()
        return {"p":, "loss":, "train_op":, "X":, "y":}
    tf.reset_default_graph()
    cnn_model = cnn_model_fn()
    with tempfile.TemporaryDirectory() as temp_dir:
        with tf.Session() as sess:
            sess.run(tf.global_variables_initializer())
            prediction = sess.run(cnn_model[], {cnn_model[]:})
            inputs = {"X":}
            outputs = {"prediction":}
            tf.saved_model.simple_save(sess, temp_dir, inputs=, outputs=)
        yield temp_dir
def svc():
    from tests.bento_service_examples.tensorflow1_classifier import ()
    Tensorflow1Classifier._bento_service_bundle_path =
    Tensorflow1Classifier._bento_service_bundle_version =
    svc = Tensorflow1Classifier()
    svc.pack()
    return svc
def image():
    with export_service_bundle() as saved_path:
        yield clean_context.enter_context(build_api_server_docker_image())
def host():
    with run_api_server_docker_container(image, enable_microbatch=, timeout=) as host:
        yield host
async def test_tensorflow_1_artifact_with_docker():
    await pytest.assert_request("","",assert_status=,assert_data=,)
from os import getcwd, chdir
from shutil import rmtree
from os.path import exists
from tempfile import mkdtemp
import pytest
import numpy as np
import coremltools as ct
import os
from coremltools._deps import ()
class TestTensorFlow1ConverterExamples:
    def test_convert_from_frozen_graph():
        import tensorflow as tf
        with tf.Graph().as_default() as graph:
            x = tf.placeholder(tf.float32, shape=(), name=)
            y = tf.nn.relu(x, name=)
        mlmodel = ct.convert()
        test_input = np.random.rand() - 0.5
        with tf.compat.v1.Session(graph=) as sess:
            expected_val = sess.run(y, feed_dict={x:})
        results = mlmodel.predict({"input":}, useCPUOnly=)
        np.testing.assert_allclose(results[], expected_val)
    def test_convert_from_frozen_graph_file():
        import tensorflow as tf
        with tf.Graph().as_default() as graph:
            x = tf.placeholder(tf.float32, shape=(), name=)
            y = tf.nn.relu(x, name=)
        save_path = str()
        tf.io.write_graph(graph, save_path, "", as_text=)
        test_input = np.random.rand() - 0.5
        with tf.compat.v1.Session(graph=) as sess:
            expected_val = sess.run(y, feed_dict={x:})
        pb_path = os.path.join()
        mlmodel = ct.convert(pb_path,inputs=[ct.TensorType(name=, shape=())],outputs=[],)
        mlmodel = ct.convert(pb_path,inputs=[ct.TensorType(shape=())],outputs=[],)
        mlmodel = ct.convert(pb_path, outputs=[])
        results = mlmodel.predict({"input":}, useCPUOnly=)
        np.testing.assert_allclose(results[], expected_val)
        mlmodel_path = os.path.join()
        mlmodel.save()
        results = mlmodel.predict({"input":})
        np.testing.assert_allclose(results[], expected_val, atol=)
    def test_convert_from_saved_model_dir():
        test_input = np.random.rand() - 0.5
        import tensorflow as tf
        with tf.compat.v1.Session() as sess:
            x = tf.placeholder(shape=(), dtype=)
            y = tf.nn.relu()
            expected_val = sess.run(y, feed_dict={x:})
        inputs = {"x":}
        outputs = {"y":}
        save_path = str()
        tf.compat.v1.saved_model.simple_save()
        mlmodel = ct.convert()
        input_name = x.name.split(":")[]
        results = mlmodel.predict({input_name:}, useCPUOnly=)
        output_name = y.name.split(":")[]
        np.testing.assert_allclose(results[], expected_val)
    def test_freeze_and_convert_matmul_graph():
        import tensorflow as tf
        graph = tf.Graph()
        with graph.as_default():
            x = tf.placeholder(tf.float32, shape=[], name=)
            W = tf.Variable(tf.truncated_normal([], stddev=))
            b = tf.Variable(tf.ones([]))
            y = tf.matmul() + b
            output_names = []
        import tempfile
        import os
        from tensorflow.python.tools.freeze_graph import freeze_graph
        model_dir = tempfile.mkdtemp()
        graph_def_file = os.path.join()
        checkpoint_file = os.path.join()
        frozen_graph_file = os.path.join()
        with tf.Session(graph=) as sess:
            sess.run(tf.global_variables_initializer())
            tf.train.write_graph(sess.graph, model_dir, graph_def_file, as_text=)
            saver = tf.train.Saver()
            saver.save()
            freeze_graph(input_graph=,input_saver=,input_binary=,input_checkpoint=,output_node_names=",".join(),restore_op_name=,filename_tensor_name="",output_graph=,clear_devices=,initializer_nodes=)
        mlmodel = ct.convert()
        import shutil
        try:
            shutil.rmtree()
        except:
            pass
class TestTensorFlow2ConverterExamples:
    def setup_class():
        self._cwd = getcwd()
        self._temp_dir = mkdtemp()
        chdir()
        import tensorflow as tf
        tf_keras_model = tf.keras.Sequential([tf.keras.layers.Flatten(input_shape=()),tf.keras.layers.Dense(128, activation=),tf.keras.layers.Dense(10, activation=),])
        tf_keras_model.save()
        tf_keras_model.save("", save_format=)
    def teardown_class():
        chdir()
        if exists():
            rmtree()
    def test_convert_tf_keras_h5_file():
        import tensorflow as tf
        x = tf.keras.Input(shape=(), name=)
        y = tf.keras.layers.Dense(16, activation=)()
        keras_model = tf.keras.Model()
        save_dir = str()
        h5_path = os.path.join()
        keras_model.save()
        mlmodel = ct.convert()
        test_input = np.random.rand()
        expected_val = keras_model()
        results = mlmodel.predict({"input":})
        np.testing.assert_allclose(results[], expected_val, rtol=)
    def test_convert_tf_keras_model():
        import tensorflow as tf
        x = tf.keras.Input(shape=(), name=)
        y = tf.keras.layers.Dense(16, activation=)()
        keras_model = tf.keras.Model()
        mlmodel = ct.convert()
        test_input = np.random.rand()
        expected_val = keras_model()
        results = mlmodel.predict({"input":})
        np.testing.assert_allclose(results[], expected_val, rtol=)
    def test_convert_tf_keras_applications_model():
        import tensorflow as tf
        tf_keras_model = tf.keras.applications.MobileNet(weights=, input_shape=())
        input_name = tf_keras_model.inputs[].name.split(":")[]
        output_name = tf_keras_model.outputs[].name.split(":")[]
        tf_graph_output_name = output_name.split()[]
        if dtype == "":
            dtype =
        elif dtype == "":
            dtype =
        else:
            dtype =
        mlmodel = ct.convert(tf_keras_model,inputs=[ct.TensorType(shape=(), dtype=)],outputs=[],)
        mlmodel.save()
    def test_convert_from_saved_model_dir():
        mlmodel = ct.convert()
        mlmodel.save()
    def test_keras_custom_layer_model():
        import tensorflow as tf
        from tensorflow import keras
        from tensorflow.keras import layers
        class CustomDense():
            def __init__(self, units=):
                super().__init__()
                self.units =
            def build():
                self.w = self.add_weight(shape=(input_shape[], self.units),initializer=,trainable=,)
                self.b = self.add_weight(shape=(), initializer=, trainable=)
            def call():
                return tf.matmul() + self.b
        inputs = keras.Input(())
        outputs = CustomDense()()
        model = keras.Model()
        ct.convert()
    def test_concrete_function_conversion():
        import tensorflow as tf
        def gelu_tanh_activation():
            a = (np.sqrt() * (x + 0.044715 * tf.pow()))
            y = 0.5 * (1.0 + tf.tanh())
            return x * y
        conc_func = gelu_tanh_activation.get_concrete_function()
        mlmodel = ct.convert([])
    def test_quickstart_example():
        import tensorflow as tf
        keras_model = tf.keras.applications.MobileNetV2(weights=,input_shape=(),classes=,)
        import urllib.request
        label_url = ""
        class_labels = urllib.request.urlopen().read().splitlines()
        class_labels = class_labels[1:]
        for i, label in enumerate():
            if isinstance():
                class_labels[] = label.decode()
        image_input = ct.ImageType(shape=(),bias=[], scale=)
        classifier_config = ct.ClassifierConfig()
        model = ct.convert(keras_model, inputs=[], classifier_config=,)
        input_name = model.input_description._fd_spec[].name
        model.input_description[] =
        model.output_description[] =
        model.author = ""
        model.license = ""
        model.short_description = ""
        model.version = ""
        from PIL import Image
        import requests
        from io import BytesIO
        img_url = 'https:
        response = requests.get()
        img = Image.open(BytesIO())
        example_image = img.resize(())
        out_dict = model.predict({input_name:})
class TestPyTorchConverterExamples:
    def test_convert_torch_vision_mobilenet_v2():
        import torch
        import torchvision
        model = torchvision.models.mobilenet_v2()
        model.eval()
        example_input = torch.rand()
        traced_model = torch.jit.trace()
        mlmodel = ct.convert(traced_model,inputs=[ct.TensorType(name=, shape=)],)
        save_path = os.path.join(str(), "")
        mlmodel.save()
        if ct.utils._is_macos():
            results = mlmodel.predict({"input":})
            expected = model()
            np.testing.assert_allclose(list(results.values())[], expected.detach().numpy(),atol=, rtol=)
    def test_int64_inputs():
        import torch
        num_tokens =
        embedding_size =
        class TestModule():
            def __init__():
                super().__init__()
                self.embedding = torch.nn.Embedding()
            def forward():
                return self.embedding()
        model = TestModule()
        model.eval()
        example_input = torch.randint(high=, size=(), dtype=)
        traced_model = torch.jit.trace()
        mlmodel = ct.convert(traced_model,inputs=[ct.TensorType(name=,shape=,dtype=example_input.numpy().dtype,)],)
        if ct.utils._is_macos():
            result = mlmodel.predict({"input":})
            expected = model()
            name = list(result.keys())[]
            np.testing.assert_allclose(result[], expected.detach().numpy())
        with pytest.raises(ValueError, match=):
            mlmodel = ct.convert(traced_model,inputs=[ct.TensorType(name=,shape=,dtype=example_input.numpy().dtype,),ct.TensorType(name=,shape=,dtype=example_input.numpy().dtype,),],)
        with pytest.raises(ValueError, match=):
            mlmodel = ct.convert(traced_model,inputs=[ct.TensorType(name=,shape=,dtype=example_input.numpy().dtype,),],outputs=[],)
    def test_fully_dynamic_inputs():
        import torch
        class Model():
            def __init__():
                super().__init__()
                self.index =
            def forward():
                x[:, int(self.index.item())] =
                y = y.unsqueeze()
                return y, x
        model = Model(torch.tensor())
        scripted_model = torch.jit.script()
        mlmodel = ct.convert(scripted_model,inputs=[ct.TensorType("", shape=(ct.RangeDim(), ct.RangeDim())),ct.TensorType("", shape=(ct.RangeDim(), ct.RangeDim()))],)
        if ct.utils._is_macos():
            x, y = torch.rand(), torch.rand()
            torch_res = model()
            results = mlmodel.predict({"x":,"y":})
            np.testing.assert_allclose(torch_res[], results[])
            np.testing.assert_allclose(torch_res[], results[])
            x, y = torch.rand(), torch.rand()
            torch_res = model()
            results = mlmodel.predict({"x":,"y":})
            np.testing.assert_allclose(torch_res[], results[])
            np.testing.assert_allclose(torch_res[], results[])
class TestMILExamples:
    def test_tutorial():
        from coremltools.converters.mil import Builder as mb
        def prog():
            x = mb.relu(x=, name=)
            x = mb.transpose(x=, perm=[], name=)
            x = mb.reduce_mean(x=, axes=[], keep_dims=, name=)
            x = mb.log(x=, name=)
            y = mb.add(x=, y=)
            return x
        import coremltools as ct
        mlmodel = ct.convert()
        if ct.utils._is_macos():
            prediction = mlmodel.predict({"x":,})
class TestFlexibleShape:
    def test_tf2keras_shared_range_dim():
        import tensorflow as tf
        input_dim =
        x1 = tf.keras.Input(shape=(), name=)
        x2 = tf.keras.Input(shape=(), name=)
        y =
        keras_model = tf.keras.Model(inputs=[], outputs=[])
        if use_symbol:
            seq_len_dim = ct.RangeDim(symbol=)
        else:
            seq_len_dim = ct.RangeDim()
        seq1_input = ct.TensorType(name=, shape=())
        seq2_input = ct.TensorType(name=, shape=())
        mlmodel = ct.convert(keras_model,inputs=[])
        batch =
        seq_len =
        test_input_x1 = np.random.rand().astype()
        test_input_x2 = np.random.rand().astype()
        expected_val = keras_model([])
        if ct.utils._is_macos():
            results = mlmodel.predict({"seq1":,"seq2":})
            np.testing.assert_allclose(results[], expected_val,rtol=, atol=)
    def test_tf2keras_incorrect_range_dim():
        import tensorflow as tf
        input_dim =
        x1 = tf.keras.Input(shape=(), name=)
        y =
        keras_model = tf.keras.Model(inputs=[], outputs=[])
        with pytest.raises(ValueError,match=):
            seq1_input = ct.TensorType(name=, shape=())
            mlmodel = ct.convert(keras_model, inputs=[])
    def test_tf2keras_outofbound_range_dim():
        import tensorflow as tf
        input_dim =
        x = tf.keras.Input(shape=(), name=)
        y =
        keras_model = tf.keras.Model(inputs=[], outputs=[])
        if use_symbol:
            seq_len_dim = ct.RangeDim(symbol=, lower_bound=,upper_bound=)
        else:
            seq_len_dim = ct.RangeDim(lower_bound=, upper_bound=)
        seq_input = ct.TensorType(name=, shape=())
        mlmodel = ct.convert(keras_model, inputs=[])
        batch =
        seq_len =
        test_input_x = np.random.rand().astype()
        expected_val = keras_model([])
        if ct.utils._is_macos():
            results = mlmodel.predict({"seq":})
            np.testing.assert_allclose(results[], expected_val,rtol=, atol=)
            with pytest.raises(RuntimeError,match=):
                seq_len =
                test_input_x = np.random.rand().astype()
                results = mlmodel.predict({"seq":})
            with pytest.raises(RuntimeError,match=):
                seq_len =
                test_input_x = np.random.rand().astype()
                results = mlmodel.predict({"seq":})
    def test_torch_range_dim():
        import torch
        num_tokens =
        embedding_size =
        class TestModule():
            def __init__():
                super().__init__()
                self.embedding = torch.nn.Embedding()
            def forward():
                return self.embedding()
        model = TestModule()
        model.eval()
        example_input = torch.randint(high=, size=(),dtype=)
        traced_model = torch.jit.trace()
        if use_symbol:
            seq_len_dim = ct.RangeDim(symbol=)
        else:
            seq_len_dim = ct.RangeDim()
        seq_input = ct.TensorType(name=, shape=(),dtype=)
        mlmodel = ct.convert(traced_model,inputs=[],)
        if ct.utils._is_macos():
            result = mlmodel.predict({"input":})
            expected = model()
            name = list(result.keys())[]
            np.testing.assert_allclose(result[], expected.detach().numpy())
            example_input2 = torch.randint(high=, size=(),dtype=)
            result = mlmodel.predict({"input":})
            expected = model()
            name = list(result.keys())[]
            np.testing.assert_allclose(result[], expected.detach().numpy())
    def test_torch_range_dim_lstm():
        import torch
        import coremltools as ct
        input_size =
        hidden_size =
        class TestNet():
            def __init__():
              super().__init__()
              self.lstm = torch.nn.LSTM()
            def forward():
                output, () = self.lstm(x, ())
                return output, new_hidden_state, new_cell_state
        model = TestNet()
        model.eval()
        seq_len =
        batch =
        input_shape = ()
        rand_input = torch.rand()
        h_shape = ()
        rand_h0 = torch.rand()
        rand_c0 = torch.rand()
        traced_model = torch.jit.trace(model, ())
        ct_seq_len = ct.RangeDim() if variable_length else seq_len
        seq_input = ct.TensorType(shape=(),name=)
        h_input = ct.TensorType(shape=, name=)
        c_input = ct.TensorType(shape=, name=)
        mlmodel = ct.convert(traced_model,inputs=[],)
        if ct.utils._is_macos():
            result = mlmodel.predict({"seq_input":,"h_input":,"c_input":,})
            expected = model()
            names = list(result.keys())
            names.sort()
            np.testing.assert_allclose(result[names[]],expected[].detach().numpy(), atol=)
            np.testing.assert_allclose(result[names[]],expected[].detach().numpy(), atol=)
            np.testing.assert_allclose(result[names[]],expected[].detach().numpy(), atol=)
            if variable_length:
                seq_len =
                input_shape = ()
                rand_input = torch.rand()
                result = mlmodel.predict({"seq_input":,"h_input":,"c_input":,})
                expected = model()
                names = list(result.keys())
                names.sort()
                np.testing.assert_allclose(result[names[]],expected[].detach().numpy(), atol=)
                np.testing.assert_allclose(result[names[]],expected[].detach().numpy(), atol=)
                np.testing.assert_allclose(result[names[]],expected[].detach().numpy(), atol=)
    def test_torch_outofbound_range_dim():
        import torch
        num_tokens =
        embedding_size =
        class TestModule():
            def __init__():
                super().__init__()
                self.embedding = torch.nn.Embedding()
            def forward():
                return self.embedding()
        model = TestModule()
        model.eval()
        example_input = torch.randint(high=, size=(),dtype=)
        traced_model = torch.jit.trace()
        if use_symbol:
            seq_len_dim = ct.RangeDim(symbol=, lower_bound=,upper_bound=)
        else:
            seq_len_dim = ct.RangeDim(lower_bound=, upper_bound=)
        seq_input = ct.TensorType(name=, shape=(),dtype=)
        mlmodel = ct.convert(traced_model,inputs=[],)
        if ct.utils._is_macos():
            result = mlmodel.predict({"input":})
            expected = model()
            name = list(result.keys())[]
            np.testing.assert_allclose(result[], expected.detach().numpy())
            with pytest.raises(RuntimeError,match=):
                example_input2 = torch.randint(high=, size=(),dtype=)
                result = mlmodel.predict({"input":})
            with pytest.raises(RuntimeError,match=):
                example_input2 = torch.randint(high=, size=(),dtype=)
                result = mlmodel.predict({"input":})
    def test_tf2keras_enumerated_shapes():
        import tensorflow as tf
        input_shape = ()
        x = tf.keras.Input(shape=, name=)
        C_out =
        kHkW =
        y = tf.keras.layers.Conv2D(C_out, kHkW, activation=,input_shape=)()
        keras_model = tf.keras.Model(inputs=[], outputs=[])
        shapes = [(), ()]
        enumerated_shapes = ct.EnumeratedShapes(shapes=)
        tensor_input = ct.TensorType(name=, shape=)
        mlmodel = ct.convert(keras_model, inputs=[])
        test_input_x = np.random.rand(*shapes[]).astype()
        expected_val = keras_model([])
        if ct.utils._is_macos():
            results = mlmodel.predict({"input":})
            np.testing.assert_allclose(results[],expected_val, rtol=)
            test_input_x = np.random.rand(*shapes[]).astype()
            results = mlmodel.predict({"input":})
            with pytest.raises(RuntimeError,match=):
                test_input_x = np.random.rand().astype()
                results = mlmodel.predict({"input":})
    def test_torch_enumerated_shapes():
        import torch
        in_channels =
        out_channels =
        kernel_size =
        class TestModule():
            def __init__():
                super().__init__()
                self.conv = torch.nn.Conv2d()
            def forward():
                return self.conv()
        model = TestModule()
        model.eval()
        example_input = torch.randn()
        traced_model = torch.jit.trace()
        shapes = [(), ()]
        enumerated_shapes = ct.EnumeratedShapes(shapes=)
        tensor_input = ct.TensorType(name=, shape=)
        mlmodel = ct.convert(traced_model,inputs=[],)
        if ct.utils._is_macos():
            result = mlmodel.predict({"input":},useCPUOnly=,)
            expected = model()
            name = list(result.keys())[]
            np.testing.assert_allclose(result[], expected.detach().numpy(),rtol=, atol=)
            test_input_x = np.random.rand(*shapes[]).astype()
            results = mlmodel.predict({"input":})
            with pytest.raises(RuntimeError,match=):
                test_input_x = np.random.rand().astype()
                results = mlmodel.predict({"input":})
    def test_tf2_image_enumerated_shapes():
        import tensorflow as tf
        keras_model = tf.keras.applications.MobileNetV2(input_shape=(),classes=,include_top=,)
        input_shapes = ct.EnumeratedShapes(shapes=[(), ()])
        image_input = ct.ImageType(shape=,bias=[], scale=)
        model = ct.convert(keras_model, inputs=[])
        spec = model.get_spec()
    def test_torch_image_enumerated_shapes():
        import torch
        import torchvision
        torch_model = torchvision.models.mobilenet_v2().features
        torch_model.eval()
        example_input = torch.rand()
        traced_model = torch.jit.trace()
        input_shapes = ct.EnumeratedShapes(shapes=[(), ()])
        image_input = ct.ImageType(shape=,bias=[], scale=)
        model = ct.convert(traced_model, inputs=[])
        spec = model.get_spec()
class TestOptionalInput:
    def test_tf2keras_optional_input():
        import tensorflow as tf
        input_dim =
        x1 = tf.keras.Input(shape=(), name=)
        x2 = tf.keras.Input(shape=(), name=)
        y =
        keras_model = tf.keras.Model(inputs=[], outputs=[])
        seq_len_dim = ct.RangeDim()
        default_value = np.ones(()).astype()
        optional_input = ct.TensorType(name=,shape=(),default_value=,)
        required_input = ct.TensorType(name=,shape=(),)
        mlmodel = ct.convert(keras_model,inputs=[])
        batch =
        seq_len =
        test_input_x2 = np.random.rand().astype()
        expected_val = keras_model([])
        if ct.utils._is_macos():
            results = mlmodel.predict({"required_input":})
            np.testing.assert_allclose(results[], expected_val, rtol=)
    def test_torch_optional_input():
        import torch
        num_tokens =
        embedding_size =
        class TestModule():
            def __init__():
                super().__init__()
                self.embedding = torch.nn.Embedding()
            def forward():
                return self.embedding() + y
        model = TestModule()
        model.eval()
        example_input = [torch.randint(high=, size=(), dtype=),torch.rand(),]
        traced_model = torch.jit.trace()
        required_input = ct.TensorType(name=, shape=(ct.RangeDim(),), dtype=)
        default_value = np.array([]).astype()
        optional_input = ct.TensorType(name=, shape=(),default_value=)
        mlmodel = ct.convert(traced_model,inputs=[],)
        if ct.utils._is_macos():
            result = mlmodel.predict({"required_input":})
            torch_default_value = torch.tensor([])
            expected = model(example_input[].detach(), torch_default_value)
            name = list(result.keys())[]
            np.testing.assert_allclose(result[], expected.detach().numpy())
class TestMILConverterExamples:
    def test_convert_tf1_frozen_graph():
        import tensorflow as tf
        with tf.Graph().as_default() as graph:
            x = tf.placeholder(tf.float32, shape=(), name=)
            y = tf.nn.relu(x, name=)
        model = ct.convert(graph, convert_to=)
    def test_convert_tf2_keras():
        import tensorflow as tf
        x = tf.keras.Input(shape=(), name=)
        y = tf.keras.layers.Dense(16, activation=)()
        keras_model = tf.keras.Model()
        model = ct.convert(keras_model, convert_to=)
    def test_convert_torch_traced_model():
        import torch
        from torch import nn
        class Network():
            def __init__():
                super().__init__()
                self.hidden = nn.Linear()
                self.output = nn.Linear()
                self.sigmoid = nn.Sigmoid()
                self.softmax = nn.Softmax(dim=)
            def forward():
                x = self.hidden()
                x = self.sigmoid()
                x = self.output()
                x = self.softmax()
                return x
        torch_model = Network()
        torch_model.eval()
        example_input = torch.rand()
        traced_model = torch.jit.trace()
        model = ct.convert(traced_model,inputs=[ct.TensorType(name=, shape=)],convert_to=)
from __future__ import print_function
import numpy as np
import tensorflow as tf
import speech_data
from speech_data import Source, Target
from tensorflow.python.ops import ctc_ops as ctc
import time
start = int(time.time())
display_step =
test_step =
save_step =
learning_rate =
training_iters =
batch_size =
width = features =
height = max_input_length =
classes = num_characters =
max_word_length =
keep_prob = dropout =
batch = speech_data.mfcc_batch_generator(batch_size, source=, target=)
X, Y = next()
x = inputX = inputs = tf.placeholder(tf.float32, shape=())
inputs = tf.transpose(inputs, [])
inputs = tf.split(axis=, num_or_size_splits=, value=)
num_hidden =
cell = tf.nn.rnn_cell.LSTMCell(num_hidden, state_is_tuple=)
cell = tf.nn.rnn_cell.MultiRNNCell(num_hidden, state_is_tuple=)
state = cell.zero_state(batch_size, dtype=)
if "" == 0:
	outputs = []
	for input_ in inputs:
		input_ = tf.reshape(input_, [])
		output, state = cell()
		outputs.append()
	y_ =
else:
	inputs = [tf.reshape(input_, []) for input_ in inputs]
	outputs, states = tf.nn.rnn(cell, inputs, initial_state=)
target_shape = ()
y = target = tf.placeholder(tf.float32, shape=)
logits = []
costs = []
i =
accuracy =
for i in range():
	output = outputs[]
	uniform = tf.random_uniform([], minval=, maxval=)
	weights = tf.Variable(uniform, name=)
	uniform_bias = tf.random_uniform([], minval=, maxval=)
	bias = tf.Variable(uniform_bias, name=)
	y_ = outputY = tf.matmul(output, weights, name=) + bias
	cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=, labels=y[:, i, :]), name=)
	costs.append()
	logits.append()
	correct_pred = tf.equal(tf.argmax(), tf.argmax(y[:, i], 1))
	accuraci = tf.reduce_mean(tf.cast())
	accuracy +=
targetY = tf.SparseTensor()
logits =
logits3d = tf.stack()
seqLengths = [] * batch_size
cost = tf.reduce_mean(ctc.ctc_loss())
tf.summary.scalar()
tf.summary.scalar()
optimizer = tf.train.AdamOptimizer().minimize()
steps =
session = tf.Session()
try:
	saver = tf.train.Saver(tf.global_variables())
except:
	saver = tf.train.Saver(tf.global_variables())
snapshot =
checkpoint = tf.train.latest_checkpoint(checkpoint_dir=)
if checkpoint:
	try: saver.restore()
	except: print()
try: session.run([tf.global_variables_initializer()])
except: session.run([tf.global_variables_initializer()])
step =
try: summaries = tf.summary.merge_all()
except: summaries = tf.summary.merge_all()
try: summary_writer = tf.summary.FileWriter()
except: summary_writer = tf.summary.FileWriter()
while step < steps:
	batch_xs, batch_ys = next()
	feed_dict = {x:, y:}
	loss, _ = session.run([], feed_dict=)
	if step % display_step == 0:
		seconds = int(time.time()) - start
		feed = {x:, y:}
		acc, summary = session.run([], feed_dict=)
		if str() == "":
			quit()
	if step % save_step == 0 and step > 0:
		saver.save()
	step =
import contextlib
import json
import os
import tempfile
from enum import Enum
from termcolor import colored
from .bert import modeling
from .helper import import_tf, set_logger
__all__ = []
class PoolingStrategy():
    NONE =
    REDUCE_MAX =
    REDUCE_MEAN =
    REDUCE_MEAN_MAX =
    FIRST_TOKEN =
    LAST_TOKEN =
    CLS_TOKEN =
    SEP_TOKEN =
    CLS_POOLED =
    CLASSIFICATION =
    REGRESSION =
    def __str__():
        return self.name
    def from_string():
        try:
            return PoolingStrategy[]
        except KeyError:
            raise ValueError()
def optimize_graph(args, logger=):
    if not logger:
        logger = set_logger(colored(), args.verbose)
    try:
        tf = import_tf(verbose=)
        from tensorflow.python.tools.optimize_for_inference_lib import optimize_for_inference
        config = tf.ConfigProto(device_count={'GPU':}, allow_soft_placement=)
        config_fp = os.path.join()
        init_checkpoint = os.path.join()
        if args.fp16:
        with tf.gfile.GFile() as f:
            bert_config = modeling.BertConfig.from_dict(json.load())
        input_ids = tf.placeholder(tf.int32, (), "")
        input_mask = tf.placeholder(tf.int32, (), "")
        input_type_ids = tf.placeholder(tf.int32, (), "")
        jit_scope =
        with jit_scope():
            input_tensors = []
            model = modeling.BertModel(config=,is_training=,input_ids=,input_mask=,token_type_ids=,use_one_hot_embeddings=,use_position_embeddings=)
            if args.pooling_strategy == PoolingStrategy.CLASSIFICATION:
                hidden_size = model.pooled_output.shape[].value
                output_weights = tf.get_variable("", [],initializer=tf.truncated_normal_initializer(stddev=))
                output_bias = tf.get_variable("", [], initializer=tf.zeros_initializer())
            if args.pooling_strategy == PoolingStrategy.REGRESSION:
                hidden_size = model.pooled_output.shape[].value
                output_weights = tf.get_variable("", [],initializer=tf.truncated_normal_initializer(stddev=))
                output_bias = tf.get_variable("", [], initializer=tf.zeros_initializer())
            tvars = tf.trainable_variables()
            () = modeling.get_assignment_map_from_checkpoint()
            tf.train.init_from_checkpoint()
            minus_mask =, m: x - tf.expand_dims(1.0 - m, axis=) * 1e30
            mul_mask =, m: x * tf.expand_dims(m, axis=)
            masked_reduce_max =, m: tf.reduce_max(minus_mask(), axis=)
            masked_reduce_mean =, m: tf.reduce_sum(mul_mask(), axis=) / (tf.reduce_sum(m, axis=, keepdims=) + 1e-10)
            with tf.variable_scope():
                if len() == 1:
                    encoder_layer = model.all_encoder_layers[args.pooling_layer[]]
                else:
                    all_layers = [model.all_encoder_layers[] for l in args.pooling_layer]
                    encoder_layer = tf.concat()
                input_mask = tf.cast()
                if args.pooling_strategy == PoolingStrategy.REDUCE_MEAN:
                    pooled = masked_reduce_mean()
                elif args.pooling_strategy == PoolingStrategy.REDUCE_MAX:
                    pooled = masked_reduce_max()
                elif args.pooling_strategy == PoolingStrategy.REDUCE_MEAN_MAX:
                    pooled = tf.concat([masked_reduce_mean(),masked_reduce_max()], axis=)
                elif args.pooling_strategy == PoolingStrategy.FIRST_TOKEN or args.pooling_strategy == PoolingStrategy.CLS_TOKEN:
                    pooled = tf.squeeze(encoder_layer[:, :, :], axis=)
                elif args.pooling_strategy == PoolingStrategy.CLS_POOLED:
                    pooled =
                elif args.pooling_strategy == PoolingStrategy.LAST_TOKEN or args.pooling_strategy == PoolingStrategy.SEP_TOKEN:
                    seq_len = tf.cast(tf.reduce_sum(input_mask, axis=), tf.int32)
                    rng = tf.range(0, tf.shape()[])
                    indexes = tf.stack([], 1)
                    pooled = tf.gather_nd()
                elif args.pooling_strategy == PoolingStrategy.NONE:
                    pooled = mul_mask()
                elif args.pooling_strategy == PoolingStrategy.CLASSIFICATION:
                    pooled =
                    logits = tf.matmul(pooled, output_weights, transpose_b=)
                    logits = tf.nn.bias_add()
                    pooled = tf.nn.softmax(logits, axis=)
                elif args.pooling_strategy == PoolingStrategy.REGRESSION:
                    pooled =
                    logits = tf.matmul(pooled, output_weights, transpose_b=)
                    logits = tf.nn.bias_add()
                    pooled = tf.nn.sigmoid()
                else:
                    raise NotImplementedError()
            if args.fp16:
                pooled = tf.cast()
            pooled = tf.identity()
            output_tensors = []
            tmp_g = tf.get_default_graph().as_graph_def()
        with tf.Session(config=) as sess:
            sess.run(tf.global_variables_initializer())
            dtypes = []
            tmp_g = optimize_for_inference(tmp_g,[n.name[:] for n in input_tensors],[n.name[:] for n in output_tensors],[],False)
            tmp_g = convert_variables_to_constants(sess, tmp_g, [n.name[:] for n in output_tensors],use_fp16=)
        tmp_file = tempfile.NamedTemporaryFile("", delete=, dir=).name
        with tf.gfile.GFile() as f:
            f.write(tmp_g.SerializeToString())
        return tmp_file, bert_config
    except Exception:
def convert_variables_to_constants(sess,input_graph_def,output_node_names,variable_names_whitelist=,variable_names_blacklist=,use_fp16=):
    from tensorflow.python.framework.graph_util_impl import extract_sub_graph
    from tensorflow.core.framework import graph_pb2
    from tensorflow.core.framework import node_def_pb2
    from tensorflow.core.framework import attr_value_pb2
    from tensorflow.core.framework import types_pb2
    from tensorflow.python.framework import tensor_util
    def patch_dtype():
        if use_fp16 and () and (input_node.attr[].type ==):
            output_node.attr[].CopyFrom(attr_value_pb2.AttrValue(type=))
    inference_graph = extract_sub_graph()
    variable_names = []
    variable_dict_names = []
    for node in inference_graph.node:
        if node.op in []:
            variable_name =
            if (() or()):
                continue
            variable_dict_names.append()
            if node.op == "":
                variable_names.append(variable_name + "")
            else:
                variable_names.append(variable_name + "")
    if variable_names:
        returned_variables = sess.run()
    else:
        returned_variables = []
    found_variables = dict(zip())
    output_graph_def = graph_pb2.GraphDef()
    how_many_converted =
    for input_node in inference_graph.node:
        output_node = node_def_pb2.NodeDef()
        if input_node.name in found_variables:
            output_node.op =
            output_node.name =
            dtype = input_node.attr[]
            data = found_variables[]
            if use_fp16 and dtype.type == types_pb2.DT_FLOAT:
                output_node.attr[].CopyFrom(attr_value_pb2.AttrValue(tensor=tensor_util.make_tensor_proto(data.astype(),dtype=,shape=)))
            else:
                output_node.attr[].CopyFrom()
                output_node.attr[].CopyFrom(attr_value_pb2.AttrValue(tensor=tensor_util.make_tensor_proto(data, dtype=,shape=)))
            how_many_converted +=
        elif input_node.op == "" and (input_node.input[] in found_variables):
            output_node.op =
            output_node.name =
            output_node.input.extend([input_node.input[]])
            output_node.attr[].CopyFrom(input_node.attr[])
            if "" in input_node.attr:
                output_node.attr[].CopyFrom(input_node.attr[])
        else:
            output_node.CopyFrom()
        patch_dtype()
        patch_dtype()
        patch_dtype()
        patch_dtype()
        patch_dtype()
        if use_fp16 and () and (output_node.attr[].tensor.dtype ==):
            output_node.attr[].CopyFrom(attr_value_pb2.AttrValue(tensor=tensor_util.make_tensor_proto(output_node.attr[].tensor.float_val[],dtype=)))
        output_graph_def.node.extend([])
    output_graph_def.library.CopyFrom()
    return output_graph_def
import tensorflow as tf
import numpy as np
import os
import sys
import collections
import gzip
from cadl import utils
def build_model(txt,batch_size=,sequence_length=,n_layers=,n_cells=,gradient_clip=,learning_rate=):
    vocab = list(set())
    vocab.sort()
    n_chars = len()
    encoder = collections.OrderedDict(zip(vocab, range()))
    decoder = collections.OrderedDict(zip(range(), vocab))
    X = tf.placeholder(tf.int32, [], name=)
    Y = tf.placeholder(tf.int32, [], name=)
    keep_prob = tf.placeholder(tf.float32, name=)
    with tf.variable_scope():
        embedding = tf.get_variable("", [])
        Xs = tf.nn.embedding_lookup()
        Xs = tf.split(axis=, num_or_size_splits=, value=)
        Xs = [tf.squeeze(X_i, []) for X_i in Xs]
    with tf.variable_scope():
        cells = tf.contrib.rnn.MultiRNNCell([tf.contrib.rnn.DropoutWrapper(tf.contrib.rnn.BasicLSTMCell(num_units=, forget_bias=, state_is_tuple=),output_keep_prob=) for _ in range()])
        initial_state = cells.zero_state(tf.shape()[], tf.float32)
        outputs, final_state = tf.contrib.rnn.static_rnn(cells, Xs, initial_state=)
        outputs_flat = tf.reshape(tf.concat(axis=, values=), [])
    with tf.variable_scope():
        W = tf.get_variable("",shape=[],initializer=tf.contrib.layers.xavier_initializer())
        b = tf.get_variable("", shape=[], initializer=tf.constant_initializer())
        logits = tf.matmul() + b
        probs = tf.nn.softmax()
        Y_pred = tf.argmax()
    with tf.variable_scope():
        loss = tf.contrib.legacy_seq2seq.sequence_loss_by_example([], [tf.reshape(tf.concat(axis=, values=), [])], [tf.ones([])])
        cost = tf.reduce_sum() / batch_size
    with tf.name_scope():
        optimizer = tf.train.AdamOptimizer(learning_rate=)
        gradients = []
        clip = tf.constant(gradient_clip, name=)
        for grad, var in optimizer.compute_gradients():
            gradients.append((tf.clip_by_value(), var))
        updates = optimizer.apply_gradients()
    model = {'X':,'Y':,'logits':,'probs':,'Y_pred':,'keep_prob':,'cost':,'updates':,'initial_state':,'final_state':,'decoder':,'encoder':,'vocab_size':}
    return model
def train(txt,batch_size=,sequence_length=,n_cells=,n_layers=,learning_rate=,max_iter=,gradient_clip=,ckpt_name=,keep_prob=):
    g = tf.Graph()
    with tf.Session(graph=) as sess:
        model = build_model(txt=,batch_size=,sequence_length=,n_layers=,n_cells=,gradient_clip=,learning_rate=)
        init_op = tf.group(tf.global_variables_initializer(),tf.local_variables_initializer())
        saver = tf.train.Saver()
        sess.run()
        if os.path.exists() or os.path.exists():
            saver.restore()
        cursor =
        it_i =
        avg_cost =
        while it_i < max_iter:
            Xs, Ys = [], []
            for batch_i in range():
                Xs.append([model[][]for ch in txt[cursor:]])
                Ys.append([model[][]for ch in txt[cursor + 1:]])
                cursor +=
                if () >= len() - sequence_length - 1:
                    cursor = np.random.randint(0, high=)
            feed_dict = {model[]:,model[]:,model[]:}
            out = sess.run([model[], model[]], feed_dict=)
            avg_cost += out[]
            if (it_i + 1) % print_step == 0:
                p = sess.run(model[],feed_dict={model[]:,model[]:})
                if isinstance(txt[], str):
                    amax = []
                    for p_i in p:
                        amax.append(model[][np.argmax()])
                    samp = []
                    for p_i in p:
                        p_i = p_i.astype()
                        p_i = p_i / p_i.sum()
                        idx = np.argmax(np.random.multinomial(1, p_i.ravel()))
                        samp.append(model[][])
                avg_cost =
                save_path = saver.save(sess, ckpt_name, global_step=)
            it_i +=
        return model
def infer(txt,ckpt_name,n_iterations,n_cells=,n_layers=,learning_rate=,max_iter=,gradient_clip=,init_value=[],keep_prob=,sampling=,temperature=):
    g = tf.Graph()
    with tf.Session(graph=) as sess:
        sequence_length = len()
        model = build_model(txt=,batch_size=,sequence_length=,n_layers=,n_cells=,gradient_clip=,learning_rate=)
        init_op = tf.group(tf.global_variables_initializer(),tf.local_variables_initializer())
        saver = tf.train.Saver()
        sess.run()
        saver.restore()
        state = []
        synth = []
        for s_i in model[]:
            state += sess.run([],feed_dict={model[]:,model[]:})
        for i in range():
            feed_dict = {model[]:, model[]:}
            state_updates = []
            for state_i in range():
                feed_dict[model[][].c] = state[]
                feed_dict[model[][].h] = state[]
                state_updates.append(model[][].c)
                state_updates.append(model[][].h)
            p = sess.run(model[], feed_dict=)[]
            if sampling == "":
                p = np.argmax()
            else:
                p = p.astype()
                p = np.log() / temperature
                p = np.exp() / np.sum(np.exp())
                p = np.random.multinomial(1, p.ravel())
                p = np.argmax()
            state = [sess.run(s_i, feed_dict=) for s_i in state_updates]
            synth.append([])
            sys.stdout.flush()
            if model[][] in []:
    return [model[][] for ch in np.concatenate()]
def test_alice(max_iter=):
    utils.download("")
    with gzip.open() as fp:
        txt = fp.read().decode()
    return train(txt, n_layers=, n_cells=, max_iter=)
def test_trump(max_iter=):
    utils.download("")
    with open() as fp:
        txt = fp.read()
def test_wtc():
    from scipy.io.wavfile import write, read
    rate, aud = read()
    txt = np.int8(np.round())
    txt = np.squeeze().tolist()
    train(txt, sequence_length=, n_layers=, n_cells=, max_iter=)
    synthesis = infer(txt,"",8000 * 30,n_layers=,n_cells=,keep_prob=,sampling=)
    snd = np.int16(np.array() / 128.0 * 16384.0)
    write()
if __name__ == "__main__":
    test_alice()
import numpy as np
import os
import matplotlib
matplotlib.use()
import matplotlib.pyplot as plt
import tensorflow as tf
import tensorflow.contrib.layers as tfl
from cadl.utils import imcrop_tosquare
from scipy.misc import imresize
def l1loss():
    return tf.reduce_mean(tf.abs())
def l2loss():
    return tf.reduce_mean(tf.squared_difference())
def lrelu(x, leak=, name=):
    with tf.variable_scope():
        return tf.maximum()
def instance_norm(x, epsilon=):
    with tf.variable_scope():
        mean, var = tf.nn.moments(x, [], keep_dims=)
        scale = tf.get_variable(name=,shape=[x.get_shape()[]],initializer=tf.truncated_normal_initializer(mean=, stddev=))
        offset = tf.get_variable(name=,shape=[x.get_shape()[]],initializer=tf.constant_initializer())
        out = scale * tf.div(x - mean, tf.sqrt()) + offset
        return out
def conv2d(inputs,activation_fn=,normalizer_fn=,scope=,**kwargs):
    with tf.variable_scope():
        h = tfl.conv2d(inputs=,activation_fn=,normalizer_fn=,weights_initializer=tf.truncated_normal_initializer(stddev=),biases_initializer=,**kwargs)
        if normalizer_fn:
            h = normalizer_fn()
        if activation_fn:
            h = activation_fn()
        return h
def conv2d_transpose(inputs,activation_fn=,normalizer_fn=,scope=,**kwargs):
    with tf.variable_scope():
        h = tfl.conv2d_transpose(inputs=,activation_fn=,normalizer_fn=,weights_initializer=tf.truncated_normal_initializer(stddev=),biases_initializer=,**kwargs)
        if normalizer_fn:
            h = normalizer_fn()
        if activation_fn:
            h = activation_fn()
        return h
def residual_block(x, n_channels=, kernel_size=, scope=):
    with tf.variable_scope():
        h = tf.pad(x, [[], [], [], []], "")
        h = conv2d(inputs=,num_outputs=,kernel_size=,padding=,scope=)
        h = tf.pad(h, [[], [], [], []], "")
        h = conv2d(inputs=,num_outputs=,kernel_size=,activation_fn=,padding=,scope=)
        h = tf.add()
    return h
def encoder(x, n_filters=, k_size=, scope=):
    with tf.variable_scope():
        h = tf.pad(x, [[], [], [], []],"")
        h = conv2d(inputs=,num_outputs=,kernel_size=,activation_fn=,stride=,padding=,scope=)
        h = conv2d(inputs=,num_outputs=,kernel_size=,activation_fn=,stride=,scope=)
        h = conv2d(inputs=,num_outputs=,kernel_size=,activation_fn=,stride=,scope=)
    return h
def transform(x, img_size=):
    h =
    if img_size >= 256:
        n_blocks =
    else:
        n_blocks =
    for block_i in range():
        with tf.variable_scope(""):
            h = residual_block()
    return h
def decoder(x, n_filters=, k_size=, scope=):
    with tf.variable_scope():
        h = conv2d_transpose(inputs=,num_outputs=,kernel_size=,activation_fn=,stride=,scope=)
        h = conv2d_transpose(inputs=,num_outputs=,kernel_size=,activation_fn=,stride=,scope=)
        h = tf.pad(h, [[], [], [], []],"")
        h = conv2d(inputs=,num_outputs=,kernel_size=,stride=,padding=,activation_fn=,scope=)
    return h
def generator(x, scope=, reuse=):
    img_size = x.get_shape().as_list()[]
    with tf.variable_scope(scope or "", reuse=):
        h = encoder()
        h = transform()
        h = decoder()
    return h
def discriminator(x, n_filters=, k_size=, scope=, reuse=):
    with tf.variable_scope(scope or "", reuse=):
        h = conv2d(inputs=,num_outputs=,kernel_size=,stride=,normalizer_fn=,scope=)
        h = conv2d(inputs=,num_outputs=,kernel_size=,stride=,scope=)
        h = conv2d(inputs=,num_outputs=,kernel_size=,stride=,scope=)
        h = conv2d(inputs=,num_outputs=,kernel_size=,stride=,scope=)
        h = conv2d(inputs=,num_outputs=,kernel_size=,stride=,activation_fn=,scope=)
        return h
def cycle_gan(img_size=):
    X_real = tf.placeholder(name=, shape=[], dtype=)
    Y_real = tf.placeholder(name=, shape=[], dtype=)
    X_fake_sample = tf.placeholder(name=,shape=[],dtype=)
    Y_fake_sample = tf.placeholder(name=,shape=[],dtype=)
    X_fake = generator(Y_real, scope=)
    Y_fake = generator(X_real, scope=)
    X_cycle = generator(Y_fake, scope=, reuse=)
    Y_cycle = generator(X_fake, scope=, reuse=)
    D_X_real = discriminator(X_real, scope=)
    D_Y_real = discriminator(Y_real, scope=)
    D_X_fake = discriminator(X_fake, scope=, reuse=)
    D_Y_fake = discriminator(Y_fake, scope=, reuse=)
    D_X_fake_sample = discriminator(X_fake_sample, scope=, reuse=)
    D_Y_fake_sample = discriminator(Y_fake_sample, scope=, reuse=)
    l1 =
    loss_cycle_X = l1 * l1loss()
    loss_cycle_Y = l1 * l1loss()
    loss_G_xy = l2loss()
    loss_G_yx = l2loss()
    loss_G =
    loss_D_Y = l2loss() + l2loss()
    loss_D_X = l2loss() + l2loss()
    tf.summary.histogram()
    tf.summary.histogram()
    tf.summary.histogram()
    tf.summary.histogram()
    tf.summary.histogram()
    tf.summary.histogram()
    tf.summary.image("", X_real, max_outputs=)
    tf.summary.image("", Y_real, max_outputs=)
    tf.summary.image("", X_fake, max_outputs=)
    tf.summary.image("", Y_fake, max_outputs=)
    tf.summary.image("", X_cycle, max_outputs=)
    tf.summary.image("", Y_cycle, max_outputs=)
    tf.summary.histogram()
    tf.summary.histogram()
    tf.summary.histogram()
    tf.summary.histogram()
    tf.summary.histogram()
    tf.summary.histogram()
    tf.summary.scalar()
    tf.summary.scalar()
    tf.summary.scalar()
    tf.summary.scalar()
    tf.summary.scalar()
    tf.summary.scalar()
    tf.summary.scalar()
    summaries = tf.summary.merge_all()
    training_vars = tf.trainable_variables()
    D_X_vars = [v for v in training_vars if v.name.startswith()]
    D_Y_vars = [v for v in training_vars if v.name.startswith()]
    G_xy_vars = [v for v in training_vars if v.name.startswith()]
    G_yx_vars = [v for v in training_vars if v.name.startswith()]
    G_vars =
    return locals()
def get_images(path1, path2, img_size=):
    files1 = [os.path.join() for f in os.listdir()]
    files2 = [os.path.join() for f in os.listdir()]
    imgs1 = []
    for f in files1:
        try:
            img = imresize(imcrop_tosquare(plt.imread()), ())
        except:
            continue
        if img.ndim == 3:
            imgs1.append(img[..., :])
        else:
            img = img[]
            imgs1.append(np.concatenate([] * 3, 2))
    imgs1 = np.array() / 127.5 - 1.0
    imgs2 = []
    for f in files2:
        try:
            img = imresize(imcrop_tosquare(plt.imread()), ())
        except:
            continue
        if img.ndim == 3:
            imgs2.append(img[..., :])
        else:
            img = img[]
            imgs2.append(np.concatenate([] * 3, 2))
    imgs2 = np.array() / 127.5 - 1.0
    return imgs1, imgs2
def batch_generator_dataset():
    n_imgs = min(len(), len())
    rand_idxs1 = np.random.permutation(np.arange(len()))[:]
    rand_idxs2 = np.random.permutation(np.arange(len()))[:]
    for idx1, idx2 in zip():
        yield imgs1[[]], imgs2[[]]
def batch_generator_random_crop(X, Y, min_size=, max_size=, n_images=):
    r, c, d =
    Xs, Ys = [], []
    for img_i in range():
        size = np.random.randint()
        max_r =
        max_c =
        this_r = np.random.randint()
        this_c = np.random.randint()
        img = imresize(X[this_r:, this_c:, :],())
        Xs.append()
        img = imresize(Y[this_r:, this_c:, :],())
        Ys.append()
    imgs1, imgs2 = np.array() / 127.5 - 1.0, np.array() / 127.5 - 1.0
    n_imgs = min(len(), len())
    rand_idxs1 = np.random.permutation(np.arange(len()))[:]
    rand_idxs2 = np.random.permutation(np.arange(len()))[:]
    for idx1, idx2 in zip():
        yield imgs1[[]], imgs2[[]]
def train(ds_X,ds_Y,ckpt_path=,learning_rate=,n_epochs=,img_size=):
    if ds_X.ndim == 3:
        batch_generator =
    else:
        batch_generator =
    capacity =
    fake_Xs = capacity * [np.zeros((), dtype=)]
    fake_Ys = capacity * [np.zeros((), dtype=)]
    idx =
    it_i =
    with tf.Graph().as_default(), tf.Session() as sess:
        net = cycle_gan(img_size=)
        D_X = tf.train.AdamOptimizer(learning_rate=).minimize(net[], var_list=net[])
        D_Y = tf.train.AdamOptimizer(learning_rate=).minimize(net[], var_list=net[])
        G = tf.train.AdamOptimizer(learning_rate=).minimize(net[], var_list=net[])
        init_op = tf.group(tf.global_variables_initializer(),tf.local_variables_initializer())
        sess.run()
        saver = tf.train.Saver()
        writer = tf.summary.FileWriter()
        for epoch_i in range():
            for X, Y in batch_generator():
                X_fake, Y_fake = sess.run([net[], net[]],feed_dict={net[]:,net[]:})
                if it_i < capacity:
                    fake_Xs[] =
                    fake_Ys[] =
                    idx = () % capacity
                elif np.random.random() > 0.5:
                    rand_idx = np.random.randint()
                    fake_Xs[], X_fake =, fake_Xs[]
                    fake_Ys[], Y_fake =, fake_Ys[]
                else:
                    pass
                loss_G = sess.run([net[], G],feed_dict={net[]:,net[]:,net[]:,net[]:})[]
                loss_D_Y = sess.run([net[], D_Y],feed_dict={net[]:,net[]:,net[]:})[]
                loss_D_X = sess.run([net[], D_X],feed_dict={net[]:,net[]:,net[]:})[]
                if it_i % 100 == 0:
                    summary = sess.run(net[],feed_dict={net[]:,net[]:,net[]:,net[]:})
                    writer.add_summary()
                it_i +=
            if epoch_i % 50 == 0:
                saver.save(sess,os.path.join(),global_step=)
import matplotlib.pyplot as plt
import tensorflow as tf
from cadl.datasets import MNIST, CIFAR10
from cadl.dataset_utils import create_input_pipeline
from cadl import utils, gif
import numpy as np
def linear():
    w = tf.get_variable("", [x.get_shape()[], n_output],initializer=tf.contrib.layers.xavier_initializer())
    b = tf.get_variable("", [], initializer=tf.constant_initializer())
    return tf.add(tf.matmul(), b)
def encoder(x, rnn, batch_size, state=, n_enc=, reuse=):
    with tf.variable_scope("", reuse=):
        if state is None:
            h_enc, state = rnn(x, rnn.zero_state())
        else:
            h_enc, state = rnn()
    return h_enc, state
def variational_layer(h_enc, noise, n_z=, reuse=):
    with tf.variable_scope("", reuse=):
        with tf.variable_scope("", reuse=):
            h_z_mu = linear()
        with tf.variable_scope("", reuse=):
            h_z_log_sigma = linear()
        z_t = h_z_mu + tf.multiply(tf.exp(), noise)
    return z_t, h_z_mu, h_z_log_sigma
def decoder(z, rnn, batch_size, state=, n_dec=, reuse=):
    with tf.variable_scope("", reuse=):
        if state is None:
            h_dec, state = rnn(z, rnn.zero_state())
        else:
            h_dec, state = rnn()
    return h_dec, state
def create_attention_map(h_dec, reuse=):
    with tf.variable_scope("", reuse=):
        p = linear()
        g_tilde_x, g_tilde_y, log_sigma, log_delta_tilde, log_gamma = tf.split(p, 5, axis=)
    return g_tilde_x, g_tilde_y, log_sigma, log_delta_tilde, log_gamma
def create_filterbank(g_x, g_y, log_sigma_sq, log_delta, A=, B=, C=, N=):
    with tf.name_scope():
        g_x = () / 2 * ()
        g_y = () / 2 * ()
        delta = (max() - 1) / () * tf.exp()
        ns = tf.expand_dims(tf.cast(tf.range(), tf.float32), 0)
        mu_x = tf.reshape(g_x + () * delta, [])
        mu_y = tf.reshape(g_y + () * delta, [])
        sigma_sq = tf.reshape(tf.exp(), [])
        xs = tf.reshape(tf.cast(tf.range(), tf.float32), [])
        ys = tf.reshape(tf.cast(tf.range(), tf.float32), [])
        F_x = tf.exp(-tf.square() / ())
        F_y = tf.exp(-tf.square() / ())
        epsilon =
        F_x = F_x / tf.maximum(tf.reduce_sum(F_x, 2, keep_dims=), epsilon)
        F_y = F_y / tf.maximum(tf.reduce_sum(F_y, 2, keep_dims=), epsilon)
    return F_x, F_y
def filter_image(x, F_x, F_y, log_gamma, A, B, C, N, inverted=):
    with tf.name_scope():
        gamma = tf.exp()
        if inverted:
            F_y = tf.transpose(F_y, perm=[])
            gamma =
            if C == 1:
                glimpse = tf.matmul(F_y,tf.matmul(tf.reshape(x, []), F_x))
            else:
                x = tf.reshape(x, [])
                xs = tf.split(x, C, axis=)
                glimpses = []
                for x_i in xs:
                    glimpses.append(tf.matmul(F_y, tf.matmul(tf.squeeze(x_i, axis=[]), F_x)))
                glimpse = tf.concat([tf.expand_dims() for x_i in glimpses], axis=)
        else:
            F_x = tf.transpose(F_x, perm=[])
            if C == 1:
                glimpse = tf.matmul(F_y,tf.matmul(tf.reshape(x, []), F_x))
            else:
                x = tf.reshape(x, [])
                xs = tf.split(x, C, axis=)
                glimpses = []
                for x_i in xs:
                    glimpses.append(tf.matmul(F_y, tf.matmul(tf.squeeze(x_i, axis=[]), F_x)))
                glimpse = tf.concat([tf.expand_dims() for x_i in glimpses], axis=)
        glimpse = tf.reshape(glimpse,[-1, np.prod(glimpse.get_shape().as_list()[1:])])
        return glimpse * tf.reshape(gamma, [])
def read(x_t,x_hat_t,h_dec_t,read_n=,A=,B=,C=,use_attention=,reuse=):
    with tf.variable_scope("", reuse=):
        if use_attention:
            g_x_tilde, g_y_tilde, log_sigma_sq_tilde, log_delta_tilde, log_gamma_tilde = create_attention_map(h_dec_t, reuse=)
            F_x_tilde, F_y_tilde = create_filterbank(g_x_tilde,g_y_tilde,log_sigma_sq_tilde,log_delta_tilde,N=,A=,B=,C=)
            x_t = filter_image()
            x_hat_t = filter_image()
    return tf.concat([], axis=)
def write(h_dec_t, write_n=, A=, B=, C=, use_attention=, reuse=):
    with tf.variable_scope("", reuse=):
        if use_attention:
            w_t = linear()
            if C == 1:
                w_t = tf.reshape(w_t, [])
            else:
                w_t = tf.reshape(w_t, [])
            g_x_hat, g_y_hat, log_sigma_sq_hat, log_delta_hat, log_gamma_hat = create_attention_map(h_dec_t, reuse=)
            F_x_hat, F_y_hat = create_filterbank(g_x_hat,g_y_hat,log_sigma_sq_hat,log_delta_hat,N=,A=,B=,C=)
            w_t = filter_image(w_t,F_x_hat,F_y_hat,log_gamma_hat,A,B,C,write_n,inverted=)
            return w_t
        else:
            return linear()
def binary_cross_entropy(t, o, eps=):
    return -(t * tf.log() + () * tf.log())
def create_model(A=,B=,C=,T=,batch_size=,n_enc=,n_z=,n_dec=,read_n=,write_n=):
    x = tf.placeholder(tf.float32, shape=[], name=)
    noise = tf.placeholder(tf.float32, shape=[], name=)
    rnn_enc = tf.contrib.rnn.GRUCell()
    rnn_dec = tf.contrib.rnn.GRUCell()
    enc_state, dec_state =, None
    canvas = [tf.zeros([], name=)]
    h_enc_t = tf.zeros([])
    h_dec_t = tf.zeros([])
    reuse =
    z_mus, z_log_sigmas = [], []
    for t_i in range():
        x_hat_t = x - tf.nn.sigmoid(canvas[])
        r_t = read(x_t=,x_hat_t=,h_dec_t=,read_n=,A=,B=,C=,use_attention=,reuse=)
        h_enc_t, enc_state = encoder(x=tf.concat([], axis=),rnn=,batch_size=,state=,n_enc=,reuse=)
        z_t, z_mu, z_log_sigma = variational_layer(h_enc=, noise=, n_z=, reuse=)
        z_mus.append()
        z_log_sigmas.append()
        h_dec_t, dec_state = decoder(z=,rnn=,batch_size=,state=,n_dec=,reuse=)
        w_t = write(h_dec_t=,write_n=,A=,B=,C=,use_attention=,reuse=)
        c_t = canvas[] + w_t
        canvas.append()
        reuse =
    x_recon = tf.nn.sigmoid(canvas[])
    with tf.variable_scope():
        loss_x = tf.reduce_mean(tf.reduce_sum(binary_cross_entropy(), 1))
        loss_zs = []
        for z_mu, z_log_sigma in zip():
            loss_zs.append(tf.reduce_sum(tf.square() + tf.square(tf.exp()) -2 * z_log_sigma, 1))
        loss_z = tf.reduce_mean(0.5 * tf.reduce_sum() - T * 0.5)
        cost =
    return {'x':,'loss_x':,'loss_z':,'canvas':,'cost':,'recon':,'noise':}
def test_mnist():
    A =
    B =
    C =
    T =
    n_enc =
    n_z =
    n_dec =
    read_n =
    write_n =
    batch_size =
    mnist = MNIST(split=[])
    n_examples =
    zs = np.random.uniform(-1.0, 1.0, []).astype()
    zs = utils.make_latent_manifold()
    g = tf.Graph()
    with tf.Session(graph=) as sess:
        draw = create_model(A=,B=,C=,T=,batch_size=,n_enc=,n_z=,n_dec=,read_n=,write_n=)
        opt = tf.train.AdamOptimizer(learning_rate=)
        grads = opt.compute_gradients(draw[])
        for i, () in enumerate():
            if g is not None:
                grads[] = (tf.clip_by_norm(), v)
        train_op = opt.apply_gradients()
        init_op = tf.group(tf.global_variables_initializer(),tf.local_variables_initializer())
        sess.run()
        saver = tf.train.Saver()
        batch_i =
        n_epochs =
        test_xs = mnist.test.images[:]
        utils.montage(test_xs.reshape(()), "")
        for epoch_i in range():
            for batch_xs, _ in mnist.train.next_batch():
                noise = np.random.randn()
                lx, lz = sess.run([draw[], draw[], train_op],feed_dict={draw[]:,draw[]:})[0:]
                if batch_i % 1000 == 0:
                    recon = sess.run(draw[],feed_dict={draw[]:,draw[]:})
                    recon = [utils.montage(r.reshape()) for r in recon]
                    gif.build_gif(recon,cmap=,saveto=)
                    saver.save(sess, "", global_step=)
                batch_i +=
def train_dataset(ds,A,B,C,T=,n_enc=,n_z=,n_dec=,read_n=,write_n=,batch_size=,n_epochs=):
    if ds is None:
        ds = CIFAR10(split=[])
        A, B, C = ()
    n_examples =
    zs = np.random.uniform(-1.0, 1.0, []).astype()
    zs = utils.make_latent_manifold()
    g = tf.Graph()
    with tf.Session(graph=) as sess:
        draw = create_model(A=,B=,C=,T=,batch_size=,n_enc=,n_z=,n_dec=,read_n=,write_n=)
        opt = tf.train.AdamOptimizer(learning_rate=)
        grads = opt.compute_gradients(draw[])
        for i, () in enumerate():
            if g is not None:
                grads[] = (tf.clip_by_norm(), v)
        train_op = opt.apply_gradients()
        tf.summary.scalar(name=, tensor=draw[])
        tf.summary.scalar(name=, tensor=draw[])
        tf.summary.scalar(name=, tensor=draw[])
        tf.summary.histogram(name=, values=draw[][])
        tf.summary.histogram(name=, values=draw[][])
        tf.summary.image(name=,tensor=tf.reshape(draw[][], ()),max_outputs=)
        tf.summary.image(name=,tensor=tf.reshape(draw[][], ()),max_outputs=)
        sums = tf.summary.merge_all()
        train_writer = tf.summary.FileWriter(logdir=)
        valid_writer = tf.summary.FileWriter(logdir=)
        init_op = tf.group(tf.global_variables_initializer(),tf.local_variables_initializer())
        sess.run()
        saver = tf.train.Saver()
        batch_i =
        test_xs = ds.test.images[:] / 255.0
        utils.montage(test_xs.reshape(()), "")
        for epoch_i in range():
            for batch_xs, _ in ds.train.next_batch():
                noise = np.random.randn()
                cost, summary = sess.run([draw[], sums, train_op],feed_dict={draw[]:,draw[]:})[0:]
                train_writer.add_summary()
                if batch_i % 1000 == 0:
                    recon = sess.run(draw[],feed_dict={draw[]:,draw[]:})
                    recon = [utils.montage(r.reshape()) for r in recon]
                    gif.build_gif(recon,cmap=,saveto=)
                    saver.save(sess, "", global_step=)
                batch_i +=
            if batch_i % 1000 == 0:
                for batch_xs, _ in ds.valid.next_batch():
                    noise = np.random.randn()
                    cost, summary = sess.run([draw[], sums],feed_dict={draw[]:,draw[]:})[0:]
                    valid_writer.add_summary()
                    batch_i +=
def train_input_pipeline(files,A,B,C,T=,n_enc=,n_z=,n_dec=,read_n=,write_n=,batch_size=,n_epochs=,input_shape=()):
    g = tf.Graph()
    with tf.Session(graph=) as sess:
        batch = create_input_pipeline(files=,batch_size=,n_epochs=,crop_shape=(),shape=)
        draw = create_model(A=,B=,C=,T=,batch_size=,n_enc=,n_z=,n_dec=,read_n=,write_n=)
        opt = tf.train.AdamOptimizer(learning_rate=)
        grads = opt.compute_gradients(draw[])
        for i, () in enumerate():
            if g is not None:
                grads[] = (tf.clip_by_norm(), v)
        train_op = opt.apply_gradients()
        init_op = tf.group(tf.global_variables_initializer(),tf.local_variables_initializer())
        sess.run()
        coord = tf.train.Coordinator()
        tf.get_default_graph().finalize()
        threads = tf.train.start_queue_runners(sess=, coord=)
        batch_i =
        epoch_i =
        n_files = len()
        test_xs = sess.run().reshape(()) / 255.0
        utils.montage(test_xs.reshape(()), "")
        try:
            while not coord.should_stop() and epoch_i < n_epochs:
                batch_xs = sess.run()
                noise = np.random.randn()
                lx, lz = sess.run([draw[], draw[], train_op],feed_dict={draw[]:,draw[]:})[0:]
                if batch_i % n_files == 0:
                    batch_i =
                    epoch_i +=
                if batch_i % 1000 == 0:
                    recon = sess.run(draw[],feed_dict={draw[]:,draw[]:})
                    recon = [utils.montage(r.reshape()) for r in recon]
                    gif.build_gif(recon, saveto=)
                    plt.close()
                batch_i +=
        except tf.errors.OutOfRangeError:
        finally:
            coord.request_stop()
        coord.join()
        sess.close()
import os
import numpy as np
import tensorflow as tf
from cadl import librispeech
from cadl import wavenet_utils as wnu
from cadl.utils import sample_categorical
from scipy.io import wavfile
def get_sequence_length():
    sequence_length =
    return sequence_length
def create_generation_model(n_stages=, n_layers_per_stage=,n_hidden=, batch_size=, n_skip=,n_quantization=, filter_length=,onehot=):
    offset =
    X = tf.placeholder(name=, shape=[], dtype=)
    X_quantized = wnu.mu_law()
    if onehot:
        X_onehot = tf.one_hot(tf.cast(),n_quantization)
    else:
        X_onehot = tf.expand_dims()
    push_ops, init_ops = [], []
    h, init, push = wnu.causal_linear(X=,n_inputs=,n_outputs=,name=,rate=,batch_size=,filter_length=)
    init_ops.extend()
    push_ops.extend()
    s = wnu.linear(h, n_hidden, n_skip, name=)
    for i in range():
        dilation = 2**()
        d, init, push = wnu.causal_linear(X=,n_inputs=,n_outputs=,name="",rate=,batch_size=,filter_length=)
        init_ops.extend()
        push_ops.extend()
        m = d.get_shape().as_list()[] // 2
        d = tf.sigmoid(d[:, :, :]) * tf.tanh(d[:, :, m:])
        h += wnu.linear(d, n_hidden, n_hidden, name="")
        s += wnu.linear(d, n_hidden, n_skip, name="")
    s = tf.nn.relu()
    s = wnu.linear(s, n_skip, n_skip, name=)
    s = tf.nn.relu()
    logits = tf.clip_by_value(wnu.linear(s, n_skip, n_quantization, name=) + offset,0.0, n_quantization - 1.0,name=)
    logits = tf.reshape(logits, [])
    probs = tf.nn.softmax(logits, name=)
    synthesis = tf.reshape(wnu.inv_mu_law(tf.cast(tf.argmax(), tf.float32) - offset,n_quantization),[])
    return {'X':,'init_ops':,'push_ops':,'probs':,'synthesis':}
def train_librispeech():
    dataset = librispeech.get_dataset(convert_to_wav=)
    it_i =
    n_epochs =
    batch_size =
    n_stages =
    n_layers_per_stage =
    n_hidden =
    filter_length =
    n_skip =
    sequence_length = get_sequence_length()
    ckpt_path = ""
    with tf.Graph().as_default() as g, tf.Session(graph=) as sess:
        net = create_generation_model(n_stages=,n_layers_per_stage=,n_hidden=,batch_size=,n_skip=,filter_length=)
        batch =
        opt = tf.train.AdamOptimizer(learning_rate=).minimize(net[])
        sess.run(tf.global_variables_initializer())
        saver = tf.train.Saver()
        writer = tf.summary.FileWriter()
        if tf.train.latest_checkpoint() is not None:
            saver.restore(sess, tf.train.latest_checkpoint())
        for epoch_i in range():
            for batch_xs, batch_hs in batch():
                loss, _ = sess.run([net[], opt], feed_dict={net[]:})
                if it_i % 100 == 0:
                    summary = sess.run(net[], feed_dict={net[]:})
                    writer.add_summary()
                    saver.save(sess,os.path.join(),global_step=)
                it_i += 1
def test_librispeech():
    prime_length =
    total_length =
    batch_size =
    n_stages =
    n_layers_per_stage =
    n_hidden =
    filter_length =
    n_skip =
    onehot =
    sequence_length = get_sequence_length()
    ckpt_path = ""
    dataset = librispeech.get_dataset()
    batch = next(librispeech.batch_generator())[]
    with tf.Graph().as_default(), tf.Session() as sess:
        net = create_generation_model(batch_size=,filter_length=,n_hidden=,n_skip=,n_layers_per_stage=,n_stages=,onehot=)
        saver = tf.train.Saver()
        if tf.train.latest_checkpoint() is not None:
            saver.restore(sess, tf.train.latest_checkpoint())
        else:
        sess.run(net[])
        synth = np.zeros([], dtype=)
        synth[:, :] =
        for sample_i in range():
            probs = sess.run([net[], net[]],feed_dict={net[]: synth[:,})[]
            idxs = sample_categorical()
            audio = wnu.inv_mu_law_numpy()
            if sample_i >= prime_length:
                synth[:, sample_i + 1] =
        for i in range():
            wavfile.write()
import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt
import os
from cadl import utils
from cadl.dataset_utils import create_input_pipeline
from cadl.datasets import CELEB
def encoder(x,dimensions=[],filter_sizes=[],convolutional=,activation=,output_activation=,reuse=):
    if convolutional:
        x_tensor = utils.to_tensor()
    else:
        x_tensor = tf.reshape(tensor=, shape=[-1, dimensions[]])
        dimensions = dimensions[1:]
    current_input =
    for layer_i, n_output in enumerate():
        with tf.variable_scope(str(), reuse=):
            if convolutional:
                h, W = utils.conv2d(x=,n_output=,k_h=filter_sizes[],k_w=filter_sizes[],padding=,reuse=)
            else:
                h, W = utils.linear(x=, n_output=, reuse=)
            output = activation()
        current_input =
    flattened = utils.flatten(current_input, name=, reuse=)
    if output_activation is None:
        return flattened
    else:
        return output_activation()
def decoder(z,dimensions=[],channels=[],filter_sizes=[],convolutional=,activation=,output_activation=,reuse=):
    if convolutional:
        with tf.variable_scope("", reuse=):
            z1, W = utils.linear(x=,n_output=channels[] * dimensions[][] * dimensions[][],reuse=)
            rsz = tf.reshape(z1, [-1, dimensions[][], dimensions[][], channels[]])
            current_input = activation()
        dimensions = dimensions[1:]
        channels = channels[1:]
        filter_sizes = filter_sizes[1:]
    else:
        current_input =
    for layer_i, n_output in enumerate():
        with tf.variable_scope(str(), reuse=):
            if convolutional:
                h, W = utils.deconv2d(x=,n_output_h=n_output[],n_output_w=n_output[],n_output_ch=channels[],k_h=filter_sizes[],k_w=filter_sizes[],padding=,reuse=)
            else:
                h, W = utils.linear(x=, n_output=, reuse=)
            if layer_i < len() - 1:
                output = activation()
            else:
                output =
        current_input =
    if output_activation is None:
        return current_input
    else:
        return output_activation()
def generator(z,output_h,output_w,convolutional=,n_features=,rgb=,reuse=):
    n_channels =
    with tf.variable_scope("", reuse=):
        return decoder(z=,convolutional=,filter_sizes=[],channels=[],dimensions=[[], [],[],[], []]if convolutional else [],activation=,output_activation=,reuse=)
def discriminator(x, convolutional=, n_features=, rgb=, reuse=):
    with tf.variable_scope("", reuse=):
        return encoder(x=,convolutional=,filter_sizes=[],dimensions=[] if convolutional else [],activation=,output_activation=,reuse=)
def GAN(input_shape, n_latent, n_features, rgb, debug=):
    x = tf.placeholder()
    x = () - 1.0
    sum_x = tf.summary.image()
    D_real_logits = discriminator(x, n_features=, rgb=)
    D_real = tf.nn.sigmoid()
    sum_D_real = tf.summary.histogram()
    z = tf.placeholder(tf.float32, [], "")
    sum_z = tf.summary.histogram()
    G = generator(z,output_h=input_shape[],output_w=input_shape[],n_features=,rgb=)
    sum_G = tf.summary.image()
    D_fake_logits = discriminator(G, n_features=, rgb=, reuse=)
    D_fake = tf.nn.sigmoid()
    sum_D_fake = tf.summary.histogram()
    with tf.variable_scope():
        loss_D_real = utils.binary_cross_entropy(D_real, tf.ones_like(), name=)
        loss_D_fake = utils.binary_cross_entropy(D_fake, tf.zeros_like(), name=)
        loss_D = tf.reduce_mean(() / 2)
        loss_G = tf.reduce_mean(utils.binary_cross_entropy(D_fake, tf.ones_like(), name=))
        sum_loss_D_real = tf.summary.histogram()
        sum_loss_D_fake = tf.summary.histogram()
        sum_loss_D = tf.summary.scalar()
        sum_loss_G = tf.summary.scalar()
        sum_D_real = tf.summary.histogram()
        sum_D_fake = tf.summary.histogram()
    return {'loss_D':,'loss_G':,'x':,'G':,'z':,'sums': {'G':,'D_real':,'D_fake':,'loss_G':,'loss_D':,'loss_D_real':,'loss_D_fake':,'z':,'x':}}
def train_input_pipeline(files,init_lr_g=,init_lr_d=,n_features=,n_latent=,n_epochs=,batch_size=,n_samples=,input_shape=[],crop_shape=[],crop_factor=):
    with tf.Graph().as_default(), tf.Session() as sess:
        batch = create_input_pipeline(files=,batch_size=,n_epochs=,crop_shape=,crop_factor=,shape=)
        gan = GAN(input_shape=[] + crop_shape,n_features=,n_latent=,rgb=,debug=)
        vars_d = [v for v in tf.trainable_variables()if v.name.startswith()]
        [print() for v in tf.trainable_variables()if v.name.startswith()]
        vars_g = [v for v in tf.trainable_variables()if v.name.startswith()]
        [print() for v in tf.trainable_variables()if v.name.startswith()]
        zs = np.random.uniform(-1.0, 1.0, []).astype()
        zs = utils.make_latent_manifold()
        lr_g = tf.placeholder(tf.float32, shape=[], name=)
        lr_d = tf.placeholder(tf.float32, shape=[], name=)
        try:
            from tf.contrib.layers import apply_regularization
            d_reg = apply_regularization(tf.contrib.layers.l2_regularizer(), vars_d)
            g_reg = apply_regularization(tf.contrib.layers.l2_regularizer(), vars_g)
        except:
            d_reg, g_reg =, 0
        opt_g = tf.train.AdamOptimizer(lr_g, name=).minimize(gan[] + g_reg, var_list=)
        opt_d = tf.train.AdamOptimizer(lr_d, name=).minimize(gan[] + d_reg, var_list=)
        saver = tf.train.Saver()
        sums = gan[]
        G_sum_op = tf.summary.merge([sums[], sums[], sums[], sums[],sums[]])
        D_sum_op = tf.summary.merge([sums[], sums[], sums[], sums[],sums[], sums[], sums[]])
        writer = tf.summary.FileWriter()
        init_op = tf.group(tf.global_variables_initializer(),tf.local_variables_initializer())
        sess.run()
        coord = tf.train.Coordinator()
        tf.get_default_graph().finalize()
        threads = tf.train.start_queue_runners(sess=, coord=)
        if os.path.exists():
            saver.restore()
        fig, ax = plt.subplots(1, 1, figsize=())
        step_i, t_i =, 0
        loss_d =
        loss_g =
        n_loss_d, total_loss_d =, 1
        n_loss_g, total_loss_g =, 1
        try:
            while not coord.should_stop():
                batch_xs = sess.run()
                step_i +=
                batch_zs = np.random.uniform(-1.0, 1.0, []).astype()
                this_lr_g = min(1e-2,max(1e-6, init_lr_g * ()**2))
                this_lr_d = min(1e-2,max(1e-6, init_lr_d * ()**2))
                if step_i % 3 == 1:
                    loss_d, _, sum_d = sess.run([gan[], opt_d, D_sum_op],feed_dict={gan[]:,gan[]:,lr_d:})
                    total_loss_d +=
                    n_loss_d +=
                    writer.add_summary()
                else:
                    loss_g, _, sum_g = sess.run([gan[], opt_g, G_sum_op],feed_dict={gan[]:,lr_g:})
                    total_loss_g +=
                    n_loss_g +=
                    writer.add_summary()
                if step_i % 100 == 0:
                    samples = sess.run(gan[], feed_dict={gan[]:})
                    utils.montage(np.clip(() * 127.5, 0, 255).astype(),"")
                    t_i +=
                    save_path = saver.save(sess,"",global_step=,write_meta_graph=)
        except tf.errors.OutOfRangeError:
        finally:
            coord.request_stop()
        coord.join()
if __name__ == "__main__":
    files = CELEB()
    train_input_pipeline(files=)
import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
import tensorflow.contrib.layers as tfl
from skimage.data import astronaut, coffee
from scipy.misc import imresize
def gausspdf_np():
    return np.exp(-()**2 /()) / (np.sqrt() * sigma)
def gausspdf():
    return tf.exp(-()**2 /()) / (tf.sqrt() * sigma)
def build_single_gaussian_model(n_input_features=,n_output_features=,n_neurons=[]):
    X = tf.placeholder(tf.float32, shape=[], name=)
    Y = tf.placeholder(tf.float32, shape=[], name=)
    current_input =
    for layer_i in range(len()):
        current_input = tfl.linear(inputs=,num_outputs=n_neurons[],activation_fn=,scope="" + str())
    means = tfl.linear(inputs=,num_outputs=,activation_fn=,scope=)
    sigmas = tf.maximum(tfl.linear(inputs=,num_outputs=,activation_fn=,scope=), 1e-10)
    p = gausspdf()
    negloglike = -tf.log(tf.maximum())
    cost = tf.reduce_mean(tf.reduce_mean())
    return X, Y, cost, means
def get_data():
    xs = []
    ys = []
    for row_i in range(img.shape[]):
        for col_i in range(img.shape[]):
            xs.append([])
            ys.append(img[])
    xs = np.array()
    ys = np.array()
    xs = (xs - np.mean()) / np.std()
    ys = ()
    return xs, ys
def train_single_gaussian_model():
    img = imresize(astronaut(), ())
    xs, ys = get_data()
    n_iterations =
    batch_size =
    fig, ax = plt.subplots()
    with tf.Graph().as_default() as g, tf.Session(graph=) as sess:
        X, Y, cost, means = build_single_gaussian_model()
        optimizer = tf.train.AdamOptimizer().minimize()
        init_op = tf.global_variables_initializer()
        sess.run()
        for it_i in range():
            idxs = np.random.permutation(range(len()))
            n_batches = len() // batch_size
            for batch_i in range():
                idxs_i = idxs[batch_i * batch_size:() * batch_size]
                sess.run(optimizer, feed_dict={X:, Y:})
            this_cost = sess.run([], feed_dict={X:, Y:})
            if () % 20 == 0:
                ys_pred = means.eval(feed_dict={X:}, session=)
                img = np.clip(ys_pred.reshape(), 0, 1)
                plt.imshow()
                plt.show()
                fig.canvas.show()
def build_multiple_gaussians_model(n_input_features=,n_output_features=,n_gaussians=,n_neurons=[]):
    X = tf.placeholder(tf.float32, shape=[], name=)
    Y = tf.placeholder(tf.float32, shape=[], name=)
    current_input =
    for layer_i in range(len()):
        current_input = tfl.linear(inputs=,num_outputs=n_neurons[],activation_fn=,scope="" + str())
    means = tf.reshape(tfl.linear(inputs=,num_outputs=,activation_fn=,scope=), [])
    sigmas = tf.maximum(tf.reshape(tfl.linear(inputs=,num_outputs=,activation_fn=,scope=), []), 1e-10)
    weights = tf.reshape(tfl.linear(inputs=,num_outputs=,activation_fn=,scope=), [])
    Y_3d = tf.reshape(Y, [])
    p = gausspdf()
    weighted =
    sump = tf.reduce_sum(weighted, axis=)
    negloglike = -tf.log(tf.maximum())
    cost = tf.reduce_mean(tf.reduce_mean())
    return X, Y, cost, means, sigmas, weights
def train_multiple_gaussians_model():
    img1 = imresize(astronaut(), ())
    img2 = imresize(coffee(), ())
    xs1, ys1 = get_data()
    xs2, ys2 = get_data()
    xs = np.r_[]
    ys = np.r_[]
    n_iterations =
    batch_size =
    fig, ax = plt.subplots()
    with tf.Graph().as_default() as g, tf.Session(graph=) as sess:
        X, Y, cost, means, sigmas, weights = build_multiple_gaussians_model()
        optimizer = tf.train.AdamOptimizer().minimize()
        init_op = tf.global_variables_initializer()
        sess.run()
        for it_i in range():
            idxs = np.random.permutation(range(len()))
            n_batches = len() // batch_size
            for batch_i in range():
                idxs_i = idxs[batch_i * batch_size:() * batch_size]
                sess.run(optimizer, feed_dict={X:, Y:})
            this_cost = sess.run([], feed_dict={X:, Y:})
            if () % 20 == 0:
                y_mu, y_dev, y_pi = sess.run([],feed_dict={X: xs[:np.prod(img1.shape[:})
                if False:
                    ys_pred = np.sum(y_mu * y_pi, axis=)
                    img = np.clip()
                    ax.imshow(img.reshape())
                else:
                    ys_pred = np.array([y_mu[obv, :, idx]for obv, idx in enumerate(np.argmax(y_pi.sum(), 1))])
                    img = np.clip(ys_pred.reshape(), 0, 1)
                    ax.imshow(img.reshape())
                plt.show()
                fig.canvas.draw()
import tensorflow as tf
from scipy.io import wavfile
import numpy as np
from cadl.utils import download_and_extract_tar
from magenta.models.nsynth import utils
from magenta.models.nsynth import reader
from magenta.models.nsynth.wavenet import masked
import os
def get_model():
    download_and_extract_tar('http:)
def causal_linear():
    q_1 = tf.FIFOQueue(rate, dtypes=, shapes=())
    q_2 = tf.FIFOQueue(rate, dtypes=, shapes=())
    init_1 = q_1.enqueue_many(tf.zeros(()))
    init_2 = q_2.enqueue_many(tf.zeros(()))
    state_1 = q_1.dequeue()
    push_1 = q_1.enqueue()
    state_2 = q_2.dequeue()
    push_2 = q_2.enqueue()
    W = tf.get_variable(name=,shape=[],dtype=)
    b = tf.get_variable(name=, shape=[], dtype=)
    W_q_2 = tf.slice(W, [], [])
    W_q_1 = tf.slice(W, [], [])
    W_x = tf.slice(W, [], [])
    y = tf.expand_dims(tf.nn.bias_add(tf.matmul(state_2, W_q_2[][]) + tf.matmul(state_1, W_q_1[][]) +tf.matmul(x, W_x[][]), b), 0)
    return y, (), ()
def linear():
    W = tf.get_variable(name=, shape=[], dtype=)
    b = tf.get_variable(name=, shape=[], dtype=)
    return tf.expand_dims(tf.nn.bias_add(tf.matmul(x[], W[][]), b), 0)
class FastGenerationConfig():
    def __init__(self, batch_size=):
        self.batch_size =
    def build():
        num_stages =
        num_layers =
        filter_length =
        width =
        skip_width =
        num_z =
        x = inputs[]
        batch_size =
        x_quantized = utils.mu_law()
        x_scaled = tf.cast() / 128.0
        x_scaled = tf.expand_dims()
        encoding = tf.placeholder(name=, shape=[], dtype=)
        en = tf.expand_dims()
        init_ops, push_ops = [], []
        l =
        l, inits, pushs = utils.causal_linear(x=,n_inputs=,n_outputs=,name=,rate=,batch_size=,filter_length=)
        for init in inits:
            init_ops.append()
        for push in pushs:
            push_ops.append()
        s = utils.linear(l, width, skip_width, name=)
        for i in range():
            dilation = 2**(i % num_stages)
            d, inits, pushs = utils.causal_linear(x=,n_inputs=,n_outputs=,name="",rate=,batch_size=,filter_length=)
            for init in inits:
                init_ops.append()
            for push in pushs:
                push_ops.append()
            d += utils.linear(en, num_z, width * 2, name="")
            m = d.get_shape().as_list()[2] // 2
            d = tf.sigmoid(d[:, :, :]) * tf.tanh(d[:, :, m:])
            l += utils.linear(d, width, width, name="")
            s += utils.linear(d, width, skip_width, name="")
        s = tf.nn.relu()
        s = (utils.linear(s, skip_width, skip_width, name=) + utils.linear(en, num_z, skip_width, name=))
        s = tf.nn.relu()
        logits = utils.linear(s, skip_width, 256, name=)
        logits = tf.reshape(logits, [])
        probs = tf.nn.softmax(logits, name=)
        return {'init_ops':,'push_ops':,'predictions':,'encoding':,'quantized_input':,}
class Config():
    def __init__(self, train_path=):
        self.num_iters =
        self.learning_rate_schedule = {0:,90000:,120000:,150000:,180000:,210000:,240000:,}
        self.ae_hop_length =
        self.ae_bottleneck_width =
        self.train_path =
    def get_batch():
        data_train = reader.NSynthDataset(self.train_path, is_training=)
        return data_train.get_wavenet_batch(batch_size, length=)
    def _condition():
        mb, length, channels = x.get_shape().as_list()
        enc_mb, enc_length, enc_channels = encoding.get_shape().as_list()
        encoding = tf.reshape(encoding, [])
        x = tf.reshape(x, [])
        x +=
        x = tf.reshape(x, [])
        x.set_shape([])
        return x
    def build():
        del is_training
        num_stages =
        num_layers =
        filter_length =
        width =
        skip_width =
        ae_num_stages =
        ae_num_layers =
        ae_filter_length =
        ae_width =
        x = inputs[]
        x_quantized = utils.mu_law()
        x_scaled = tf.cast() / 128.0
        x_scaled = tf.expand_dims()
        en = masked.conv1d(x_scaled,causal=,num_filters=,filter_length=,name=)
        for num_layer in range():
            dilation = 2**(num_layer % ae_num_stages)
            d = tf.nn.relu()
            d = masked.conv1d(d,causal=,num_filters=,filter_length=,dilation=,name="")
            d = tf.nn.relu()
            en += masked.conv1d(d,num_filters=,filter_length=,name="")
        en = masked.conv1d(en,num_filters=,filter_length=,name=)
        en = masked.pool1d(en, self.ae_hop_length, name=, mode=)
        encoding =
        l = masked.shift_right()
        l = masked.conv1d(l, num_filters=, filter_length=, name=)
        s = masked.conv1d(l, num_filters=, filter_length=, name=)
        for i in range():
            dilation = 2**(i % num_stages)
            d = masked.conv1d(l,num_filters=,filter_length=,dilation=,name="")
            d = self._condition(d,masked.conv1d(en,num_filters=,filter_length=,name=""))
            m = d.get_shape().as_list()[2] // 2
            d_sigmoid = tf.sigmoid(d[:, :, :])
            d_tanh = tf.tanh(d[:, :, m:])
            d =
            l += masked.conv1d(d, num_filters=, filter_length=, name="")
            s += masked.conv1d(d, num_filters=, filter_length=, name="")
        s = tf.nn.relu()
        s = masked.conv1d(s, num_filters=, filter_length=, name=)
        s = self._condition(s,masked.conv1d(en,num_filters=,filter_length=,name=))
        s = tf.nn.relu()
        logits = masked.conv1d(s, num_filters=, filter_length=, name=)
        logits = tf.reshape(logits, [])
        probs = tf.nn.softmax(logits, name=)
        x_indices = tf.cast(tf.reshape(x_quantized, []), tf.int32) + 128
        loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=, labels=, name=),0,name=)
        return {'predictions':,'loss':,'eval': {'nll':},'quantized_input':,'encoding':,}
def inv_mu_law(x, mu=):
    x = np.array().astype()
    out = () * 2. / ()
    out = np.sign() / mu * (()**np.abs() - 1)
    out = np.where(np.equal(), x, out)
    return out
def load_audio(wav_file, sample_length=):
    wav_data = np.array([utils.load_audio()[:]])
    wav_data_padded = np.zeros(())
    wav_data_padded[0, :wav_data.shape[]] =
    wav_data =
    return wav_data
def load_nsynth(batch_size=, sample_length=):
    config = Config()
    with tf.device('/gpu:):
        X = tf.placeholder(tf.float32, shape=[])
        graph = config.build({"wav":}, is_training=)
        graph.update({'X':})
    return graph
def load_fastgen_nsynth(batch_size=, sample_length=):
    config = FastGenerationConfig()
    X = tf.placeholder(tf.float32, shape=[])
    graph = config.build({"wav":})
    graph.update({'X':})
    return graph
def sample_categorical():
    if pmf.ndim == 1:
        pmf = np.expand_dims()
    batch_size = pmf.shape[]
    cdf = np.cumsum(pmf, axis=)
    rand_vals = np.random.rand()
    idxs = np.zeros([])
    for i in range():
        idxs[] = cdf[].searchsorted(rand_vals[])
    return idxs
def load_batch(files, sample_length=):
    batch_data = []
    max_length =
    is_npy = (os.path.splitext(files[])[] ==)
    for f in files:
        if is_npy:
            data = np.load()
            batch_data.append()
        else:
            data = utils.load_audio(f, sample_length, sr=)
            batch_data.append()
        if data.shape[] > max_length:
            max_length = data.shape[]
    for i, data in enumerate():
        if data.shape[] < max_length:
            if is_npy:
                padded = np.zeros([max_length, +data.shape[]])
                padded[:data.shape[], :] =
            else:
                padded = np.zeros([])
                padded[:data.shape[]] =
            batch_data[] =
    batch_data = np.array()
    return batch_data
def save_batch():
    for audio, name in zip():
        wavfile.write()
def encode(wav_data, checkpoint_path, sample_length=):
    if wav_data.ndim == 1:
        wav_data = np.expand_dims()
        batch_size =
    elif wav_data.ndim == 2:
        batch_size = wav_data.shape[]
    session_config = tf.ConfigProto(allow_soft_placement=)
    with tf.Graph().as_default(), tf.Session(config=) as sess:
        hop_length = Config().ae_hop_length
        wav_data, sample_length = utils.trim_for_encoding()
        net = load_nsynth(batch_size=, sample_length=)
        saver = tf.train.Saver()
        saver.restore()
        encodings = sess.run(net[], feed_dict={net[]:})
    return encodings
def synthesize(encodings,save_paths,hop_length=,checkpoint_path=,samples_per_save=):
    if hop_length is None:
        hop_length = Config().ae_hop_length
    batch_size = encodings.shape[]
    encoding_length = encodings.shape[]
    total_length =
    session_config = tf.ConfigProto(allow_soft_placement=)
    with tf.Graph().as_default(), tf.Session(config=) as sess:
        net = load_fastgen_nsynth(batch_size=)
        saver = tf.train.Saver()
        saver.restore()
        sess.run(net[])
        audio_batch = np.zeros((), dtype=)
        audio = np.zeros([])
        for sample_i in range():
            enc_i =
            pmf = sess.run([net[], net[]],feed_dict={net[]:,net[]: encodings[:,, :})[]
            sample_bin = sample_categorical()
            audio = utils.inv_mu_law_numpy()
            audio_batch[:, sample_i] = audio[:, 0]
            if sample_i % 100 == 0:
            if sample_i % samples_per_save == 0:
                save_batch()
    save_batch()
import tensorflow as tf
import numpy as np
import os
from cadl import dataset_utils as dsu
def gated_conv2d(X,K_h,K_w,K_c,strides=[],padding=,mask=,cond_h=,vertical_h=):
    with tf.variable_scope():
        W = tf.get_variable(name=,shape=[K_h, K_w, X.shape[].value, K_c * 2],initializer=tf.contrib.layers.xavier_initializer_conv2d())
        b = tf.get_variable(name=, shape=[], initializer=tf.zeros_initializer())
        if mask is not None:
            W = tf.multiply()
        h = tf.nn.bias_add(tf.nn.conv2d(X, W, strides=, padding=), b)
    if vertical_h is not None:
        with tf.variable_scope():
            W_vtoh = tf.get_variable(name=,shape=[],initializer=tf.contrib.layers.xavier_initializer_conv2d())
            b_vtob = tf.get_variable(name=, shape=[], initializer=tf.zeros_initializer())
            h = tf.add(h,tf.nn.bias_add(tf.nn.conv2d(vertical_h,W_vtoh,strides=,padding=), b_vtob))
    if cond_h is not None:
        with tf.variable_scope():
            V = tf.get_variable(name=,shape=[cond_h.shape[].value, K_c],initializer=tf.contrib.layers.xavier_initializer_conv2d())
            b = tf.get_variable(name=, shape=[], initializer=tf.zeros_initializer())
            h = tf.add(h,tf.reshape(tf.nn.bias_add(tf.matmul(), b),tf.shape()[0:] + []),name=)
    with tf.variable_scope():
        h_f = tf.slice(h, [], [])
        h_g = tf.slice(h, [], [])
        y = tf.multiply(tf.nn.tanh(), tf.sigmoid())
    return y, h
def build_conditional_pixel_cnn_model(B=,H=,W=,C=,n_conditionals=):
    n_conditionals =
    X = tf.placeholder(name=, dtype=, shape=[])
    X_ = (tf.cast() - 127.5) / 2.0
    n_layers =
    D =
    fmaps =
    K_hs = [] + [] * ()
    K_ws = [] + [] * ()
    K_cs = [] * n_layers
    if n_conditionals is not None:
        cond_h = tf.placeholder(name=, dtype=, shape=[])
    else:
        cond_h =
    vertical_X =
    horizontal_X =
    for K_h, K_w, K_c, layer_i in zip(K_hs, K_ws, K_cs, range()):
        if layer_i == 0:
            mask = np.ones((), dtype=)
            mask[():, :, :, :] =
            mask[K_h // 2, K_w // 2:, :, :] =
        else:
            mask = np.ones((), dtype=)
            mask[():, :, :, :] =
            mask[K_h // 2, ():, :, :] =
        with tf.variable_scope(""):
            with tf.variable_scope():
                vertical_Y, vertical_h = gated_conv2d(vertical_X, K_h, K_w, K_c, mask=, cond_h=)
            with tf.variable_scope():
                horizontal_Y, horizontal_h = gated_conv2d(horizontal_X,1,K_w,K_c,mask=mask[K_h // 2, :, :, :],vertical_h=,cond_h=)
                with tf.variable_scope():
                    W_1x1 = tf.get_variable(name=,shape=[],initializer=tf.contrib.layers.xavier_initializer_conv2d())
                    b_1x1 = tf.get_variable(name=, shape=[], initializer=tf.ones_initializer())
                    horizontal_Y = tf.nn.bias_add(tf.nn.conv2d(horizontal_Y,W_1x1,strides=[],padding=), b_1x1)
                if layer_i > 0:
                    with tf.variable_scope():
                        horizontal_Y = tf.add()
            vertical_X =
            horizontal_X =
    Y =
    with tf.variable_scope():
        W_1x1 = tf.get_variable(name=,shape=[],initializer=tf.contrib.layers.xavier_initializer_conv2d())
        b_1x1 = tf.get_variable(name=, shape=[], initializer=tf.ones_initializer())
        Y = tf.nn.relu(tf.nn.bias_add(tf.nn.conv2d(Y, W_1x1, strides=[], padding=),b_1x1))
    with tf.variable_scope():
        W_1x1 = tf.get_variable(name=,shape=[],initializer=tf.contrib.layers.xavier_initializer_conv2d())
        b_1x1 = tf.get_variable(name=, shape=[], initializer=tf.ones_initializer())
        Y = tf.nn.bias_add(tf.nn.conv2d(Y, W_1x1, strides=[], padding=), b_1x1)
        Y = tf.reshape(Y, [])
    loss = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=, labels=tf.cast(tf.reshape(X, []), tf.int32))
    cost = tf.reduce_mean()
    preds = tf.nn.softmax()
    sampled_preds = tf.multinomial(Y, num_samples=)
    tf.summary.image()
    tf.summary.image("",tf.reshape(tf.cast(tf.argmax(Y, axis=), tf.uint8), ()))
    tf.summary.histogram()
    tf.summary.scalar()
    summaries = tf.summary.merge_all()
    return {'cost':,'X':,'preds':,'sampled_preds':,'summaries':}
def train_tiny_imagenet(ckpt_path=,n_epochs=,save_step=,write_step=,B=,H=,W=,C=):
    ckpt_name = os.path.join()
    with tf.Graph().as_default(), tf.Session() as sess:
        net = build_conditional_pixel_cnn_model(B=, H=, W=, C=)
        optimizer = tf.train.AdamOptimizer(learning_rate=).minimize(net[])
        imagenet_files = dsu.tiny_imagenet_load()
        batch = dsu.create_input_pipeline(imagenet_files[],batch_size=,n_epochs=,shape=[],crop_shape=[],crop_factor=,n_threads=)
        saver = tf.train.Saver()
        writer = tf.summary.FileWriter()
        init_op = tf.group(tf.global_variables_initializer(),tf.local_variables_initializer())
        sess.run()
        coord = tf.train.Coordinator()
        tf.get_default_graph().finalize()
        threads = tf.train.start_queue_runners(sess=, coord=)
        if os.path.exists() or os.path.exists():
            saver.restore()
            saver.restore(sess, tf.train.latest_checkpoint())
        epoch_i =
        batch_i =
        try:
            while not coord.should_stop() and epoch_i < n_epochs:
                batch_i +=
                batch_xs = sess.run()
                train_cost = sess.run([net[], optimizer], feed_dict={net[]:})[]
                if batch_i % write_step == 0:
                    summary = sess.run(net[], feed_dict={net[]:})
                    writer.add_summary()
                if batch_i % save_step == 0:
                    saver.save(sess,ckpt_name,global_step=,write_meta_graph=)
        except tf.errors.OutOfRangeError:
        finally:
            coord.request_stop()
        coord.join()
def generate():
    ckpt_path =
    B =
    H =
    W =
    C =
    with tf.Graph().as_default(), tf.Session() as sess:
        net = build_conditional_pixel_cnn_model(B=, H=, W=, C=)
        imagenet_files = dsu.tiny_imagenet_load()
        saver = tf.train.Saver()
        init_op = tf.group(tf.global_variables_initializer(),tf.local_variables_initializer())
        sess.run()
        saver.restore(sess, tf.train.latest_checkpoint())
        import matplotlib.pyplot as plt
        img = plt.imread(imagenet_files[][])
        from scipy.misc import imresize
        og_img = imresize(img, ())
        img = og_img.copy()
        img[H // 2:, :, :] =
        for h_i in range():
            for w_i in range():
                for c_i in range():
                    X = img.copy()
                    preds = sess.run(net[],feed_dict={net[]:})
                    X = preds.reshape(()).astype()
                    img[] = X[]
        fig, axs = plt.subplots()
        axs[].imshow()
        axs[].imshow()
if __name__ == "__main__":
    train_tiny_imagenet()
import os
import numpy as np
import tensorflow as tf
import tensorflow.contrib.slim as slim
from cadl import dataset_utils as dsu
ckpt_name =
n_epochs =
n_units =
B =
H =
W =
C =
def build_pixel_rnn_basic_model(B=, H=, W=, C=, n_units=,n_layers=):
    X = tf.placeholder(tf.float32, shape=[], name=)
    keep_prob = tf.placeholder(tf.float32, shape=, name=)
    X_2d = tf.reshape(X, [])
    X_onehot = tf.one_hot(tf.cast(), depth=, axis=)
    pixels = [tf.squeeze(p, axis=) for p in tf.split(X_onehot, H * W * C, axis=)]
    cells = tf.contrib.rnn.GRUCell()
    initial_state = cells.zero_state(batch_size=tf.shape()[], dtype=)
    if n_layers > 1:
        cells = tf.contrib.rnn.MultiRNNCell([] * n_layers, state_is_tuple=)
        initial_state = cells.zero_state(tf.shape()[], tf.float32)
    cells = tf.contrib.rnn.DropoutWrapper(cells, output_keep_prob=)
    hs, final_state = tf.contrib.rnn.static_rnn(cells, pixels, initial_state=)
    stacked = tf.concat([tf.expand_dims(h_i, axis=) for h_i in hs], axis=)
    stacked = tf.reshape(stacked, [])
    prediction = slim.linear(stacked, 256, scope=)
    if B * H * W * C > 1:
        prediction = tf.slice(prediction, [],[int(prediction.shape[] - 1), -1])
        X_onehot_flat = tf.slice(tf.reshape(X_onehot, []), [], [])
        loss = tf.nn.softmax_cross_entropy_with_logits(labels=, logits=)
        cost = tf.reduce_mean()
    else:
        cost =
    return {'X':,'recon':,'cost':,'initial_state':,'final_state':}
def infer(sess, net, H, W, C, pixel_value=, state=):
    X = np.reshape(pixel_value, [])
    synthesis = []
    if state is None:
        state = sess.run(net[])
    for pixel_i in range():
        next, state = sess.run([net[], net[]],feed_dict={net[]:,net[]:})
        synthesis.append(np.argmax())
    return synthesis
def train_tiny_imagenet():
    net = build_pixel_rnn_basic_model()
    optimizer = tf.train.AdamOptimizer(learning_rate=).minimize(net[])
    imagenet_files = dsu.tiny_imagenet_load()
    batch = dsu.create_input_pipeline(imagenet_files,batch_size=,n_epochs=,shape=[],crop_shape=[],crop_factor=,n_threads=)
    sess = tf.Session()
    saver = tf.train.Saver()
    init_op = tf.group(tf.global_variables_initializer(),tf.local_variables_initializer())
    sess.run()
    coord = tf.train.Coordinator()
    tf.get_default_graph().finalize()
    threads = tf.train.start_queue_runners(sess=, coord=)
    if os.path.exists() or os.path.exists():
        saver.restore()
        saver.restore(sess, tf.train.latest_checkpoint())
    epoch_i =
    batch_i =
    save_step =
    try:
        while not coord.should_stop() and epoch_i < n_epochs:
            batch_i +=
            batch_xs = sess.run()
            train_cost = sess.run([net[], optimizer], feed_dict={net[]:})[]
            if batch_i % save_step == 0:
                saver.save(sess,ckpt_name,global_step=,write_meta_graph=)
    except tf.errors.OutOfRangeError:
    finally:
        coord.request_stop()
    coord.join()
    sess.close()
if __name__ == "__main__":
    train_tiny_imagenet()
from __future__ import print_function
import numpy as np
import tensorflow as tf
import speech_data
from speech_data import Source,Target
from tensorflow.python.ops import ctc_ops as ctc
import time
start=int(time.time())
display_step =
test_step =
save_step =
learning_rate =
training_iters =
batch_size =
width=features=
height=max_input_length=
classes = num_characters =
max_word_length =
keep_prob=dropout=
batch = speech_data.mfcc_batch_generator(batch_size, source=, target=)
X,Y=next()
x= inputX=inputs=tf.placeholder(tf.float32, shape=())
inputs = tf.transpose(inputs, [])
inputs = tf.split(axis=, num_or_size_splits=, value=)
num_hidden =
cell = tf.nn.rnn_cell.LSTMCell(num_hidden, state_is_tuple=)
state = cell.zero_state(batch_size, dtype=)
if "" == 0:
	outputs = []
	for input_ in inputs:
		input_= tf.reshape(input_, [])
		output, state = cell()
		outputs.append()
	y_=
else:
	inputs=[tf.reshape(input_, []) for input_ in inputs]
	outputs, states = tf.nn.rnn(cell, inputs, initial_state=)
y = target = tf.placeholder(tf.float32, shape=())
logits=[]
costs=[]
i=
accuracy=
for i in range():
	output=outputs[]
	weights = tf.Variable(tf.random_uniform([], minval=, maxval=), name=)
	bias = tf.Variable(tf.random_uniform([], minval=, maxval=), name=)
	y_ = outputY = tf.matmul(output, weights, name=) + bias
	cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=, labels=y[:,i,:]), name=)
	costs.append()
	logits.append()
	correct_pred = tf.equal(tf.argmax(), tf.argmax(y[:,i], 1))
	accuraci = tf.reduce_mean(tf.cast())
	accuracy+=
targetY = tf.SparseTensor()
logits=
logits3d = tf.stack()
seqLengths=[]*batch_size
cost = tf.reduce_mean(ctc.ctc_loss())
tf.summary.scalar()
tf.summary.scalar()
optimizer = tf.train.AdamOptimizer().minimize()
steps =
session=tf.Session()
try:saver = tf.train.Saver(tf.global_variables())
except:saver = tf.train.Saver(tf.global_variables())
snapshot =
checkpoint = tf.train.latest_checkpoint(checkpoint_dir=)
if checkpoint:
	try:saver.restore()
	except: print()
try: session.run([tf.global_variables_initializer()])
except: session.run([tf.global_variables_initializer()])
step =
try:summaries = tf.summary.merge_all()
except:summaries = tf.summary.merge_all()
try:summary_writer = tf.summary.FileWriter()
except:summary_writer = tf.summary.FileWriter()
while step < steps:
	batch_xs, batch_ys = next()
	feed_dict = {x:, y:}
	loss, _ = session.run([], feed_dict=)
	if step % display_step == 0:
		seconds = int(time.time()) - start
		feed = {x:, y:}
		acc, summary = session.run([], feed_dict=)
		if str() == "":
			quit()
	if step % save_step == 0 and step > 0:
		saver.save()
	step =
import tensorflow as tf
import numpy as np
import nltk
import pickle
from cadl import cornell
_PAD, _GO, _EOS, _UNK =, "", "", ""
_START_VOCAB = []
PAD_ID, GO_ID, EOS_ID, UNK_ID = range()
def _create_embedding(x, vocab_size, embed_size, embed_matrix=):
    if embed_matrix is None:
        embed_matrix = tf.get_variable(name=,shape=[],dtype=,initializer=tf.random_uniform_initializer())
    embed = tf.nn.embedding_lookup()
    return embed, embed_matrix
def _create_rnn_cell():
    import tensorflow.contrib.rnn as rnn
    cell_fw = rnn.LayerNormBasicLSTMCell(num_units=, dropout_keep_prob=)
    if n_layers > 1:
        cells = []
        for layer_i in range():
            with tf.variable_scope(""):
                cell_fw = rnn.LayerNormBasicLSTMCell(num_units=, dropout_keep_prob=)
                cells.append()
        cell_fw = rnn.MultiRNNCell()
    return cell_fw
def _create_encoder():
    with tf.variable_scope():
        cell_fw = _create_rnn_cell()
    with tf.variable_scope():
        cell_bw = _create_rnn_cell()
    () = tf.nn.bidirectional_dynamic_rnn(cell_fw=,cell_bw=,inputs=,sequence_length=,time_major=,dtype=)
    return outputs, final_state
def _create_decoder(cells,batch_size,encoder_outputs,encoder_state,encoder_lengths,decoding_inputs,decoding_lengths,embed_matrix,target_vocab_size,scope,max_sequence_size,use_attention=):
    from tensorflow.python.layers.core import Dense
    output_layer = Dense(target_vocab_size, name=)
    if use_attention:
        attn_mech = tf.contrib.seq2seq.LuongAttention(cells.output_size, encoder_outputs, encoder_lengths, scale=)
        cells = tf.contrib.seq2seq.AttentionWrapper(cell=,attention_mechanism=,attention_layer_size=,alignment_history=)
        initial_state = cells.zero_state(dtype=, batch_size=)
        initial_state = initial_state.clone(cell_state=)
    helper = tf.contrib.seq2seq.TrainingHelper(inputs=,sequence_length=,time_major=)
    train_decoder = tf.contrib.seq2seq.BasicDecoder(cell=,helper=,initial_state=,output_layer=)
    train_outputs, _, _ = tf.contrib.seq2seq.dynamic_decode(train_decoder,output_time_major=,impute_finished=,maximum_iterations=)
    train_logits = tf.identity(train_outputs.rnn_output, name=)
    scope.reuse_variables()
    start_tokens = tf.tile(tf.constant([], dtype=), [])
    helper = tf.contrib.seq2seq.GreedyEmbeddingHelper(embedding=, start_tokens=, end_token=)
    infer_decoder = tf.contrib.seq2seq.BasicDecoder(cell=,helper=,initial_state=,output_layer=)
    infer_outputs, _, _ = tf.contrib.seq2seq.dynamic_decode(infer_decoder,output_time_major=,impute_finished=,maximum_iterations=)
    infer_logits = tf.identity(infer_outputs.sample_id, name=)
    return train_logits, infer_logits
def create_model(source_vocab_size=,target_vocab_size=,input_embed_size=,target_embed_size=,share_input_and_target_embedding=,n_neurons=,n_layers=,use_attention=,max_sequence_size=):
    n_enc_neurons =
    n_dec_neurons =
    source = tf.placeholder(tf.int32, shape=(), name=)
    source_lengths = tf.placeholder(tf.int32, shape=(), name=)
    target = tf.placeholder(tf.int32, shape=(), name=)
    target_lengths = tf.placeholder(tf.int32, shape=(), name=)
    keep_prob = tf.placeholder(tf.float32, name=)
    batch_size, sequence_length = tf.unstack(tf.shape())
    with tf.variable_scope():
        slice = tf.slice(target, [], [])
        decoder_input = tf.concat([tf.fill([], GO_ID), slice], 1)
    with tf.variable_scope():
        source_embed, source_embed_matrix = _create_embedding(x=, vocab_size=, embed_size=)
    with tf.variable_scope():
        if (share_input_and_target_embedding andsource_vocab_size ==):
            target_input_embed, target_embed_matrix = _create_embedding(x=,vocab_size=,embed_size=,embed_matrix=)
        elif source_vocab_size != target_vocab_size:
            raise ValueError()
        else:
            target_input_embed, target_embed_matrix = _create_embedding(x=,vocab_size=,embed_size=)
    with tf.variable_scope():
        encoder_outputs, encoder_state = _create_encoder(embed=,lengths=,batch_size=,n_enc_neurons=,n_layers=,keep_prob=)
    with tf.variable_scope() as scope:
        cell_fw = _create_rnn_cell()
        decoding_train_logits, decoding_infer_logits = _create_decoder(cells=,batch_size=,encoder_outputs=encoder_outputs[],encoder_state=encoder_state[],encoder_lengths=,decoding_inputs=,decoding_lengths=,embed_matrix=,target_vocab_size=,scope=,max_sequence_size=)
    with tf.variable_scope():
        weights = tf.cast(tf.sequence_mask(), tf.float32)
        loss = tf.contrib.seq2seq.sequence_loss(logits=tf.reshape(decoding_train_logits, [batch_size, tf.reduce_max(), target_vocab_size]),targets=,weights=)
    return {'loss':,'source':,'source_lengths':,'target':,'target_lengths':,'keep_prob':,'thought_vector':,'decoder':}
def batch_generator(sources,targets,source_lengths,target_lengths,batch_size=):
    idxs = np.random.permutation(np.arange(len()))
    n_batches = len() // batch_size
    for batch_i in range():
        this_idxs = idxs[batch_i * batch_size:() * batch_size]
        this_sources, this_targets = sources[this_idxs, :], targets[this_idxs, :]
        this_source_lengths, this_target_lengths = source_lengths[], target_lengths[]
        yield (this_sources[:, :np.max()],this_targets[:, :np.max()],this_source_lengths, this_target_lengths)
def preprocess(text, min_count=, min_length=, max_length=):
    sentences = [el for s in text for el in nltk.sent_tokenize()]
    words = [[word.lower() for word in nltk.word_tokenize()]for s in sentences]
    lengths = np.array([len() for s in words])
    good_idxs = np.where((lengths >=) & ())[]
    dataset = [words[] for idx in good_idxs]
    fdist = nltk.FreqDist([])
    vocab_counts = [el for el in fdist.most_common() if el[] > min_count]
    vocab = [v[] for v in vocab_counts]
    vocab.sort()
    vocab =
    vocab = {k:,}
    with open() as fp:
        pickle.dump()
    unked = word2id()
    return unked, vocab
def word2id():
    unked = []
    for s in words:
        this_sentence = [vocab.get() for w in s]
        unked.append()
    return unked
def id2word():
    words = []
    id2words = {v:,}
    for s in ids:
        this_sentence = [id2words.get() for w in s]
        words.append()
    return words
def train(text,max_sequence_size=,use_attention=,min_count=,min_length=,n_epochs=,batch_size=):
    unked, vocab = preprocess(text,min_count=,min_length=,max_length=)
    vocab_size = len()
    sources_list, targets_list = unked[:], unked[1:]
    source_lengths = np.zeros((len()), dtype=)
    target_lengths = np.zeros((len()), dtype=)
    sources = np.ones((len(), max_sequence_size), dtype=) * PAD_ID
    targets = np.ones((len(), max_sequence_size), dtype=) * PAD_ID
    for i, () in enumerate(zip()):
        el =
        source_lengths[] = len()
        sources[i, :len()] =
        el = target_i + []
        target_lengths[] = len()
        targets[i, :len()] =
    sess = tf.Session()
    net = create_model(max_sequence_size=,use_attention=,source_vocab_size=,target_vocab_size=)
    learning_rate = tf.placeholder(tf.float32, name=)
    opt = tf.train.AdamOptimizer(learning_rate=).minimize(net[])
    init_op = tf.group(tf.global_variables_initializer(),tf.local_variables_initializer())
    sess.run()
    saver = tf.train.Saver()
    def decode():
        decoding = sess.run(net[],feed_dict={net[]:,net[]:,net[]:})
    current_learning_rate =
    for epoch_i in range():
        total =
        for it_i, () in enumerate(batch_generator(sources, targets, source_lengths, target_lengths, batch_size=)):
            if it_i % 1000 == 0:
                current_learning_rate = max()
                decode(this_sources[0:], this_source_lengths[0:])
            l = sess.run([net[], opt],feed_dict={learning_rate:,net[]:,net[]:,net[]:,net[]:,net[]:})[]
            total =
        saver.save(sess, "", global_step=)
    sess.close()
def train_cornell():
    text = cornell.get_scripts()
    return train()
import os
import numpy as np
from scipy.io import wavfile
from collections import OrderedDict
import tensorflow as tf
def parse_timit_entry():
    path = os.path.join()
    phnfile = os.path.join(dirpath, file.strip() + "")
    with open() as fp:
        phones = []
        for line_i in fp.readlines():
            els = line_i.split()
            phones.append({'start_time':,'end_time':,'phone':})
    wrdfile = os.path.join(dirpath, file.strip() + "")
    with open() as fp:
        words = []
        for line_i in fp.readlines():
            els = line_i.split()
            words.append({'start_time':,'end_time':,'word':})
    txtfile = os.path.join(dirpath, file.strip() + "")
    starttime =
    endtime =
    with open() as fp:
        lines = fp.readlines()
        els = lines[].split()
        starttime = els[]
        endtime = els[]
        text = "".join(els[2:]).strip()
    entry = {'path':,'name':,'phones':,'words':,'start':,'end':,'text':}
    return entry
def parse_timit(timit_dir=):
    timit = []
    for dirpath, dirnames, filenames in os.walk():
        for file in filenames:
            if file.endswith():
                timit.append(parse_timit_entry())
    phones = list(set([ph[]for t in timit for ph in t[]]))
    phones.sort()
    phones = phones + []
    words = list(set([ph[]for t in timit for ph in t[]]))
    words.sort()
    encoder = OrderedDict(zip(phones, range(len())))
    decoder = OrderedDict(zip(range(len()), phones))
    return {'data':,'phones':,'words':,'encoder':,'decoder':}
def preprocess():
    fft_size =
    sr, s = wavfile.read()
    s = s / np.abs().max()
    mag, phs = dft.forward(s, hop_size=, fft_size=)
    cqft = dft.mel()
    mel = np.dot(mag, cqft[:, :])
    mfcc = dft.mfcc().astype()
    return mfcc
def create_observation(el, max_sequence_length, hop_size=):
    all_Xs = preprocess(el[])
    X, Y = [], []
    for i, ph in enumerate(el[]):
        s1, s2 = ph[], ph[]
        f1, f2 = [min(int(np.round(float() / hop_size)), len())for s in ()]
        n_frames =
        if len() + n_frames > max_sequence_length:
            if len() and len():
                yield (np.array(),np.array())
                X, Y = [], []
        if n_frames < max_sequence_length:
            for f in range():
                X.append(all_Xs[])
            Y.append(ph[])
            Y.append()
def batch_generator(timit, batch_size=, max_sequence_length=):
    data = timit[]
    rand_idxs = np.random.permutation(range(len()))
    n_batches = len() // batch_size
    seq_lens_Xs, seq_lens_Ys = [], []
    Xs, Ys = [], []
    batch_i =
    while batch_i < n_batches:
        el = rand_idxs[]
        batch_i +=
        for X, Y in create_observation(data[], max_sequence_length):
            seq_lens_Xs.append(len())
            seq_lens_Ys.append(len())
            Y_enc = np.array([timit[][] for y_i in Y],dtype=)[]
            if len() < max_sequence_length:
                X_pad = np.zeros((1, max_sequence_length, X.shape[]))
                X_pad[:, :len(), :] =
            else:
                X_pad = X[]
            if len():
                Xs = np.r_[]
                Ys = np.r_[]
            else:
                Xs =
                Ys =
            if len() == batch_size:
                yield Xs, Ys, seq_lens_Xs, seq_lens_Ys
                Xs, Ys = [], []
                seq_lens_Xs, seq_lens_Ys = [], []
def sparse_tuple_from(sequences, dtype=):
    indices = []
    values = []
    for n, seq in enumerate():
        indices.extend(zip([] * len(), range(len())))
        values.extend()
    indices = np.asarray(indices, dtype=)
    values = np.asarray(values, dtype=)
    shape = np.asarray([len(),np.asarray().max()[] + 1], dtype=)
    return indices, np.squeeze(), shape
def build_model(batch_size=, sequence_length=, n_features=,n_cells=, n_layers=, n_classes=, bi=):
    with tf.name_scope():
        X = tf.placeholder(tf.float32, shape=[], name=)
        seqlens_X = tf.placeholder(tf.int32, shape=[], name=)
    with tf.name_scope():
        forward_cells = tf.nn.rnn_cell.LSTMCell(n_cells, use_peepholes=, state_is_tuple=)
        if bi:
            backward_cells = tf.nn.rnn_cell.LSTMCell(n_cells, use_peepholes=, state_is_tuple=)
        if n_layers > 1:
            forward_cells = tf.nn.rnn_cell.MultiRNNCell([] * n_layers, state_is_tuple=)
            if bi:
                backward_cells = tf.nn.rnn_cell.MultiRNNCell([] * n_layers, state_is_tuple=)
        initial_state_fw = forward_cells.zero_state(tf.shape()[], tf.float32)
        if bi:
            initial_state_bw = backward_cells.zero_state(tf.shape()[], tf.float32)
        if bi:
            outputs, output_states = tf.nn.bidirectional_dynamic_rnn(forward_cells, backward_cells,X, tf.cast(),initial_state_fw, initial_state_bw)
        else:
            outputs, output_states = tf.nn.dynamic_rnn()
        outputs = tf.pack()
        outputs = tf.reshape(outputs, [])
    with tf.variable_scope():
        W = tf.get_variable("",shape=[],initializer=tf.random_normal_initializer(stddev=))
        b = tf.get_variable("",shape=[],initializer=tf.random_normal_initializer(stddev=))
        logits = tf.matmul() + b
        logits = tf.reshape(logits, [])
    with tf.name_scope():
        Y = tf.sparse_placeholder(tf.int32, name=)
        seqlens_Y = tf.placeholder(tf.int32, shape=[], name=)
    with tf.name_scope():
        losses = tf.nn.ctc_loss(logits, Y, seqlens_X,preprocess_collapse_repeated=,ctc_merge_repeated=)
        cost = tf.reduce_mean()
    with tf.name_scope():
        decoder, log_prob = tf.nn.ctc_beam_search_decoder()
        acc = tf.reduce_mean(tf.edit_distance(tf.cast(decoder[], tf.int32), Y))
    return {'X':, 'Y':, 'cost':, 'decoder':, 'acc':,'seqlens_X':, 'seqlens_Y':}
def train():
    n_epochs =
    batch_size =
    sequence_length =
    ckpt_name =
    timit = parse_timit()
    g = tf.Graph()
    with tf.Session(graph=) as sess, g.as_default():
        model = build_model(batch_size=,sequence_length=,n_classes=len(timit[]) + 1)
        opt = tf.train.AdamOptimizer().minimize(model[])
        sess.run(tf.initialize_all_variables())
        saver = tf.train.Saver()
        if os.path.exists():
            saver.restore()
        for epoch_i in range():
            avg_acc =
            avg_cost =
            it_i =
            for X, Y, seqlens_X, seqlens_Y in batch_generator():
                feed_dict = {model[]:,model[]:,model[]:,model[]:}
                this_acc, this_cost, _ = sess.run([model[], model[], opt], feed_dict=)
                it_i +=
                avg_acc +=
                avg_cost +=
            save_path = saver.save(sess, "" + ckpt_name,global_step=,write_meta_graph=)
if __name__ == "__main__":
    train()
import tensorflow as tf
import numpy as np
import os
from cadl.dataset_utils import create_input_pipeline
from cadl.datasets import CELEB, MNIST
from cadl.batch_norm import batch_norm
from cadl import utils
def VAE(input_shape=[],n_filters=[],filter_sizes=[],n_hidden=,n_code=,activation=,dropout=,denoising=,convolutional=,variational=):
    x = tf.placeholder()
    phase_train = tf.placeholder(tf.bool, name=)
    keep_prob = tf.placeholder(tf.float32, name=)
    corrupt_prob = tf.placeholder(tf.float32, [])
    if denoising:
        current_input = utils.corrupt() * corrupt_prob + x * ()
    x_tensor = utils.to_tensor() if convolutional else x
    current_input =
    Ws = []
    shapes = []
    for layer_i, n_output in enumerate():
        with tf.variable_scope(""):
            shapes.append(current_input.get_shape().as_list())
            if convolutional:
                h, W = utils.conv2d(x=,n_output=,k_h=filter_sizes[],k_w=filter_sizes[])
            else:
                h, W = utils.linear(x=, n_output=)
            h = activation(batch_norm(h, phase_train, "" + str()))
            if dropout:
                h = tf.nn.dropout()
            Ws.append()
            current_input =
    shapes.append(current_input.get_shape().as_list())
    with tf.variable_scope():
        if variational:
            dims = current_input.get_shape().as_list()
            flattened = utils.flatten()
            if n_hidden:
                h = utils.linear(flattened, n_hidden, name=)[]
                h = activation(batch_norm())
                if dropout:
                    h = tf.nn.dropout()
            else:
                h =
            z_mu = utils.linear(h, n_code, name=)[]
            z_log_sigma = 0.5 * utils.linear(h, n_code, name=)[]
            epsilon = tf.random_normal(tf.stack([tf.shape()[], n_code]))
            z = z_mu + tf.multiply(epsilon, tf.exp())
            if n_hidden:
                h = utils.linear(z, n_hidden, name=)[]
                h = activation(batch_norm())
                if dropout:
                    h = tf.nn.dropout()
            else:
                h =
            size = dims[] * dims[] * dims[] if convolutional else dims[]
            h = utils.linear(h, size, name=)[]
            current_input = activation(batch_norm())
            if dropout:
                current_input = tf.nn.dropout()
            if convolutional:
                current_input = tf.reshape(current_input,tf.stack([tf.shape()[],dims[], dims[], dims[]]))
        else:
            z =
    shapes.reverse()
    n_filters.reverse()
    Ws.reverse()
    n_filters += [input_shape[]]
    for layer_i, n_output in enumerate(n_filters[1:]):
        with tf.variable_scope(""):
            shape = shapes[]
            if convolutional:
                h, W = utils.deconv2d(x=,n_output_h=shape[],n_output_w=shape[],n_output_ch=shape[],n_input_ch=shapes[][],k_h=filter_sizes[],k_w=filter_sizes[])
            else:
                h, W = utils.linear(x=, n_output=)
            h = activation(batch_norm(h, phase_train, "" + str()))
            if dropout:
                h = tf.nn.dropout()
            current_input =
    y =
    x_flat = utils.flatten()
    y_flat = utils.flatten()
    loss_x = tf.reduce_sum(tf.squared_difference(), 1)
    if variational:
        loss_z = -0.5 * tf.reduce_sum(1.0 + 2.0 * z_log_sigma - tf.square()- tf.exp(), 1)
        cost = tf.reduce_mean()
    else:
        cost = tf.reduce_mean()
    return {'cost':,'Ws':,'x':,'z':,'y':,'keep_prob':,'corrupt_prob':,'train':}
def train_vae(files,input_shape,learning_rate=,batch_size=,n_epochs=,n_examples=,crop_shape=[],crop_factor=,n_filters=[],n_hidden=,n_code=,convolutional=,variational=,filter_sizes=[],dropout=,keep_prob=,activation=,img_step=,save_step=,ckpt_name=):
    batch = create_input_pipeline(files=,batch_size=,n_epochs=,crop_shape=,crop_factor=,shape=)
    ae = VAE(input_shape=[] + crop_shape,convolutional=,variational=,n_filters=,n_hidden=,n_code=,dropout=,filter_sizes=,activation=)
    zs = np.random.uniform(-1.0, 1.0, []).astype()
    zs = utils.make_latent_manifold()
    optimizer = tf.train.AdamOptimizer(learning_rate=).minimize(ae[])
    sess = tf.Session()
    saver = tf.train.Saver()
    init_op = tf.group(tf.global_variables_initializer(),tf.local_variables_initializer())
    sess.run()
    coord = tf.train.Coordinator()
    tf.get_default_graph().finalize()
    threads = tf.train.start_queue_runners(sess=, coord=)
    if os.path.exists() or os.path.exists():
        saver.restore()
    t_i =
    batch_i =
    epoch_i =
    cost =
    n_files = len()
    test_xs = sess.run() / 255.0
    utils.montage()
    try:
        while not coord.should_stop() and epoch_i < n_epochs:
            batch_i +=
            batch_xs = sess.run() / 255.0
            train_cost = sess.run([ae[], optimizer],feed_dict={ae[]:,ae[]:,ae[]:})[]
            cost +=
            if batch_i % n_files == 0:
                cost =
                batch_i =
                epoch_i +=
            if batch_i % img_step == 0:
                recon = sess.run(ae[],feed_dict={ae[]:,ae[]:,ae[]:})
                utils.montage(recon.reshape([] + crop_shape), "")
                recon = sess.run(ae[],feed_dict={ae[]:,ae[]:,ae[]:})
                utils.montage(recon.reshape([] + crop_shape),"")
                t_i +=
            if batch_i % save_step == 0:
                saver.save(sess,ckpt_name,global_step=,write_meta_graph=)
    except tf.errors.OutOfRangeError:
    finally:
        coord.request_stop()
    coord.join()
    sess.close()
def test_mnist():
    n_code =
    mnist = MNIST(split=[])
    ae = VAE(input_shape=[],n_filters=[],n_hidden=,n_code=,activation=,convolutional=,variational=)
    n_examples =
    zs = np.random.uniform(-1.0, 1.0, []).astype()
    zs = utils.make_latent_manifold()
    learning_rate =
    optimizer = tf.train.AdamOptimizer(learning_rate=).minimize(ae[])
    sess = tf.Session()
    init_op = tf.group(tf.global_variables_initializer(),tf.local_variables_initializer())
    sess.run()
    t_i =
    batch_i =
    batch_size =
    n_epochs =
    test_xs = mnist.test.images[:]
    utils.montage(test_xs.reshape(()), "")
    for epoch_i in range():
        train_i =
        train_cost =
        for batch_xs, _ in mnist.train.next_batch():
            train_cost += sess.run([ae[], optimizer],feed_dict={ae[]:,ae[]:,ae[]:})[]
            train_i +=
            if batch_i % 10 == 0:
                recon = sess.run(ae[],feed_dict={ae[]:,ae[]:,ae[]:})
                utils.montage(recon.reshape(()), "")
                recon = sess.run(ae[],feed_dict={ae[]:,ae[]:,ae[]:})
                utils.montage(recon.reshape(()),"")
                t_i +=
            batch_i +=
        valid_i =
        valid_cost =
        for batch_xs, _ in mnist.valid.next_batch():
            valid_cost += sess.run([ae[]],feed_dict={ae[]:,ae[]:,ae[]:})[]
            valid_i +=
def test_celeb():
    files = CELEB()
    train_vae(files=,input_shape=[],batch_size=,n_epochs=,crop_shape=[],crop_factor=,convolutional=,variational=,n_filters=[],n_hidden=,n_code=,dropout=,filter_sizes=[],activation=,ckpt_name=)
def test_sita():
    if not os.path.exists():
        os.system('wget http:)
        os.mkdir()
        os.system()
    files = [os.path.join() for f in os.listdir()]
    train_vae(files=,input_shape=[],batch_size=,n_epochs=,crop_shape=[],crop_factor=,convolutional=,variational=,n_filters=[],n_hidden=,n_code=,dropout=,filter_sizes=[],activation=,ckpt_name=)
if __name__ == "__main__":
    test_celeb()
import tensorflow as tf
import numpy as np
import os
from cadl.dataset_utils import create_input_pipeline
from cadl.datasets import CELEB
from cadl import utils
def encoder(x,n_hidden=,dimensions=[],filter_sizes=[],convolutional=,activation=,output_activation=):
    if convolutional:
        x_tensor = utils.to_tensor()
    else:
        x_tensor = tf.reshape(tensor=, shape=[-1, dimensions[]])
        dimensions = dimensions[1:]
    current_input =
    Ws = []
    hs = []
    shapes = []
    for layer_i, n_output in enumerate():
        with tf.variable_scope(str()):
            shapes.append(current_input.get_shape().as_list())
            if convolutional:
                h, W = utils.conv2d(x=,n_output=,k_h=filter_sizes[],k_w=filter_sizes[],padding=)
            else:
                h, W = utils.linear(x=, n_output=)
            h = activation()
            Ws.append()
            hs.append()
        current_input =
    shapes.append(h.get_shape().as_list())
    with tf.variable_scope():
        flattened = utils.flatten()
    with tf.variable_scope():
        if n_hidden:
            h, W = utils.linear(flattened, n_hidden, name=)
            h = activation()
        else:
            h =
    return {'z':, 'Ws':, 'hs':, 'shapes':}
def decoder(z,shapes,n_hidden=,dimensions=[],filter_sizes=[],convolutional=,activation=,output_activation=):
    with tf.variable_scope():
        if n_hidden:
            h = utils.linear(z, n_hidden, name=)[]
            h = activation()
        else:
            h =
    with tf.variable_scope():
        dims = shapes[]
        size = dims[] * dims[] * dims[] if convolutional else dims[]
        h = utils.linear(h, size, name=)[]
        current_input = activation()
        if convolutional:
            current_input = tf.reshape(current_input,tf.stack([tf.shape()[], dims[], dims[], dims[]]))
    Ws = []
    hs = []
    for layer_i, n_output in enumerate(dimensions[1:]):
        with tf.variable_scope(""):
            if convolutional:
                shape = shapes[]
                h, W = utils.deconv2d(x=,n_output_h=shape[],n_output_w=shape[],n_output_ch=shape[],n_input_ch=shapes[][],k_h=filter_sizes[],k_w=filter_sizes[])
            else:
                h, W = utils.linear(x=, n_output=)
            if () < len():
                h = activation()
            else:
                h = output_activation()
            Ws.append()
            hs.append()
            current_input =
    z = tf.identity(current_input, name=)
    return {'x_tilde':, 'Ws':, 'hs':}
def variational_bayes():
    z_mu = utils.linear(h, n_code, name=)[]
    z_log_sigma = 0.5 * utils.linear(h, n_code, name=)[]
    epsilon = tf.random_normal(tf.stack([tf.shape()[], n_code]))
    z = tf.add(z_mu, tf.multiply(epsilon, tf.exp()), name=)
    loss_z = -0.5 * tf.reduce_sum(1.0 + 2.0 * z_log_sigma - tf.square() -tf.exp(), 1)
    return z, z_mu, z_log_sigma, loss_z
def discriminator(x,convolutional=,filter_sizes=[],activation=,n_filters=[]):
    encoding = encoder(x=,convolutional=,dimensions=,filter_sizes=,activation=)
    res = utils.flatten(encoding[], name=)
    if res.get_shape().as_list()[] > 1:
        res = utils.linear()[]
    return {'logits':,'probs':,'Ws':,'hs':}
def VAE(input_shape=[],n_filters=[],filter_sizes=[],n_hidden=,n_code=,activation=,convolutional=,variational=):
    x = tf.placeholder()
    with tf.variable_scope():
        encoding = encoder(x=,n_hidden=,convolutional=,dimensions=,filter_sizes=,activation=)
    if variational:
        with tf.variable_scope():
            z, z_mu, z_log_sigma, loss_z = variational_bayes(h=encoding[], n_code=)
    else:
        z = encoding[]
        loss_z =
    shapes = encoding[].copy()
    shapes.reverse()
    n_filters = n_filters.copy()
    n_filters.reverse()
    n_filters += [input_shape[]]
    with tf.variable_scope():
        decoding = decoder(z=,shapes=,n_hidden=,dimensions=,filter_sizes=,convolutional=,activation=)
    x_tilde = decoding[]
    x_flat = utils.flatten()
    x_tilde_flat = utils.flatten()
    loss_x = tf.reduce_sum(tf.squared_difference(), 1)
    return {'loss_x':,'loss_z':,'x':,'z':,'Ws':,'hs':,'x_tilde':}
def VAEGAN(input_shape=[],n_filters=[],filter_sizes=[],n_hidden=,n_code=,activation=,convolutional=,variational=):
    x = tf.placeholder()
    z_samp = tf.placeholder(tf.float32, [], "")
    with tf.variable_scope():
        encoding = encoder(x=,n_hidden=,convolutional=,dimensions=,filter_sizes=,activation=)
        with tf.variable_scope():
            z, z_mu, z_log_sigma, loss_z = variational_bayes(h=encoding[], n_code=)
    shapes = encoding[].copy()
    shapes.reverse()
    n_filters_decoder = n_filters.copy()
    n_filters_decoder.reverse()
    n_filters_decoder += [input_shape[]]
    with tf.variable_scope():
        decoding_actual = decoder(z=,shapes=,n_hidden=,convolutional=,dimensions=,filter_sizes=,activation=)
    with tf.variable_scope("", reuse=):
        decoding_sampled = decoder(z=,shapes=,n_hidden=,convolutional=,dimensions=,filter_sizes=,activation=)
    with tf.variable_scope():
        D_real = discriminator(x,filter_sizes=,n_filters=,activation=)
    with tf.variable_scope("", reuse=):
        D_fake = discriminator(decoding_actual[],filter_sizes=,n_filters=,activation=)
    with tf.variable_scope("", reuse=):
        D_samp = discriminator(decoding_sampled[],filter_sizes=,n_filters=,activation=)
    with tf.variable_scope():
        gamma = tf.placeholder(tf.float32, name=)
        loss_D_llike =
        for h_fake, h_real in zip(D_fake[][3:], D_real[][3:]):
            loss_D_llike += tf.reduce_sum(0.5 * tf.squared_difference(utils.flatten(), utils.flatten()), 1)
        eps =
        loss_real = tf.reduce_sum(tf.log(D_real[] + eps), 1)
        loss_fake = tf.reduce_sum(tf.log(1 - D_fake[] + eps), 1)
        loss_samp = tf.reduce_sum(tf.log(1 - D_samp[] + eps), 1)
        loss_GAN = () / 3.0
        loss_enc = tf.reduce_mean()
        loss_gen = tf.reduce_mean()
        loss_dis = -tf.reduce_mean()
    return {'x':,'z':,'x_tilde':,'z_samp':,'x_tilde_samp':,'loss_real':,'loss_fake':,'loss_samp':,'loss_GAN':,'loss_D_llike':,'loss_enc':,'loss_gen':,'loss_dis':,'gamma':}
def train_vaegan(files,learning_rate=,batch_size=,n_epochs=,n_examples=,input_shape=[],crop_shape=[],crop_factor=,n_filters=[],n_hidden=,n_code=,convolutional=,variational=,filter_sizes=[],activation=,ckpt_name=):
    ae = VAEGAN(input_shape=[] + crop_shape,convolutional=,variational=,n_filters=,n_hidden=,n_code=,filter_sizes=,activation=)
    batch = create_input_pipeline(files=,batch_size=,n_epochs=,crop_shape=,crop_factor=,shape=)
    zs = np.random.randn().astype()
    zs = utils.make_latent_manifold()
    opt_enc = tf.train.AdamOptimizer(learning_rate=).minimize(ae[],var_list=[var_i for var_i in tf.trainable_variables()if var_i.name.startswith()])
    opt_gen = tf.train.AdamOptimizer(learning_rate=).minimize(ae[],var_list=[var_i for var_i in tf.trainable_variables()if var_i.name.startswith()])
    opt_dis = tf.train.AdamOptimizer(learning_rate=).minimize(ae[],var_list=[var_i for var_i in tf.trainable_variables()if var_i.name.startswith()])
    sess = tf.Session()
    saver = tf.train.Saver()
    init_op = tf.group(tf.global_variables_initializer(),tf.local_variables_initializer())
    sess.run()
    coord = tf.train.Coordinator()
    tf.get_default_graph().finalize()
    threads = tf.train.start_queue_runners(sess=, coord=)
    if os.path.exists() or os.path.exists():
        saver.restore()
    t_i =
    batch_i =
    epoch_i =
    equilibrium =
    margin =
    n_files = len()
    test_xs = sess.run() / 255.0
    utils.montage()
    try:
        while not coord.should_stop() and epoch_i < n_epochs:
            if batch_i % () == 0:
                batch_i =
                epoch_i +=
            batch_i +=
            batch_xs = sess.run() / 255.0
            batch_zs = np.random.randn().astype()
            real_cost, fake_cost, _ = sess.run([ae[], ae[], opt_enc],feed_dict={ae[]:,ae[]:})
            real_cost = -np.mean()
            fake_cost = -np.mean()
            gen_update =
            dis_update =
            if real_cost > () or fake_cost > ():
                gen_update =
            if real_cost < () or fake_cost < ():
                dis_update =
            if not ():
                gen_update =
                dis_update =
            if gen_update:
                sess.run(opt_gen,feed_dict={ae[]:,ae[]:,ae[]:})
            if dis_update:
                sess.run(opt_dis,feed_dict={ae[]:,ae[]:,ae[]:})
            if batch_i % 50 == 0:
                recon = sess.run(ae[], feed_dict={ae[]:})
                recon = np.clip(recon / recon.max(), 0, 1)
                utils.montage(recon.reshape([] + crop_shape),"")
                recon = sess.run(ae[], feed_dict={ae[]:})
                recon = np.clip(recon / recon.max(), 0, 1)
                utils.montage(recon.reshape([] + crop_shape),"")
                t_i +=
            if batch_i % 100 == 0:
                save_path = saver.save(sess,ckpt_name,global_step=,write_meta_graph=)
    except tf.errors.OutOfRangeError:
    finally:
        coord.request_stop()
    coord.join()
    sess.close()
def test_celeb(n_epochs=,filter_sizes=[],n_filters=[],crop_shape=[]):
    files = CELEB()
    train_vaegan(files=,batch_size=,n_epochs=,crop_shape=,crop_factor=,input_shape=[],convolutional=,variational=,n_filters=,n_hidden=,n_code=,filter_sizes=,activation=,ckpt_name=)
def test_sita(n_epochs=):
    if not os.path.exists():
        os.system('wget http:)
        os.mkdir()
        os.system()
    files = [os.path.join() for f in os.listdir()]
    train_vaegan(files=,batch_size=,n_epochs=,crop_shape=[],crop_factor=,input_shape=[],convolutional=,variational=,n_filters=[],n_hidden=,n_code=,filter_sizes=[],activation=,ckpt_name=)
if __name__ == "__main__":
    test_celeb()
import os
import numpy as np
import tensorflow as tf
from cadl import librispeech, vctk
from cadl import wavenet_utils as wnu
from cadl.utils import sample_categorical
from scipy.io import wavfile
def get_sequence_length():
    sequence_length =
    return sequence_length
def condition():
    batch_size, length, channels = x.get_shape().as_list()
    enc_batch_size, enc_length, enc_channels = encoding.get_shape().as_list()
    encoding = tf.reshape(encoding, [])
    x = tf.reshape(x, [])
    x +=
    x = tf.reshape(x, [])
    x.set_shape([])
    return x
def create_wavenet_autoencoder():
    offset =
    sequence_length =
    X = tf.placeholder(name=, shape=[], dtype=)
    X_quantized = wnu.mu_law()
    X_scaled = tf.cast()
    X_scaled = tf.expand_dims()
    en = wnu.conv1d(X=,causal=,num_filters=,filter_length=,name=)
    for i in range():
        dilation = 2**()
        d = tf.nn.relu()
        d = wnu.conv1d(d,causal=,num_filters=,filter_length=,dilation=,name="")
        d = tf.nn.relu()
        en += wnu.conv1d(d,num_filters=,filter_length=,name="")
    en = wnu.conv1d(en, num_filters=, filter_length=, name=)
    en = wnu.pool1d(en, hop_length, name=, mode=)
    encoding =
    l = wnu.shift_right()
    l = wnu.conv1d(l, num_filters=, filter_length=, name=)
    s = wnu.conv1d(l, num_filters=, filter_length=, name=)
    for i in range():
        dilation = 2**()
        d = wnu.conv1d(l,num_filters=,filter_length=,dilation=,name="")
        d = condition(d,wnu.conv1d(en,num_filters=,filter_length=,name=""))
        m = d.get_shape().as_list()[] // 2
        d_sigmoid = tf.sigmoid(d[:, :, :])
        d_tanh = tf.tanh(d[:, :, m:])
        d =
        l += wnu.conv1d(d, num_filters=, filter_length=, name="")
        s += wnu.conv1d(d, num_filters=, filter_length=, name="")
    s = tf.nn.relu()
    s = wnu.conv1d(s, num_filters=, filter_length=, name=)
    s = condition(s,wnu.conv1d(en,num_filters=,filter_length=,name=))
    s = tf.nn.relu()
    logits = wnu.conv1d(s, num_filters=, filter_length=, name=)
    logits = tf.reshape(logits, [])
    probs = tf.nn.softmax(logits, name=)
    synthesis = tf.reshape(wnu.inv_mu_law(tf.cast(tf.argmax(), tf.float32) - offset, n_quantization),[])
    labels = tf.cast(tf.reshape(X_quantized, []), tf.int32) + int()
    loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=, labels=, name=),0,name=)
    tf.summary.audio("", synthesis, sample_rate=)
    tf.summary.histogram()
    tf.summary.histogram()
    tf.summary.histogram()
    tf.summary.histogram()
    tf.summary.histogram()
    tf.summary.scalar()
    summaries = tf.summary.merge_all()
    return {'X':,'quantized':,'encoding':,'probs':,'synthesis':,'summaries':,'loss':}
def create_wavenet(n_stages=,n_layers_per_stage=,n_hidden=,batch_size=,n_skip=,filter_length=,shift=,n_quantization=,sample_rate=):
    offset =
    sequence_length =
    X = tf.placeholder(name=, shape=[], dtype=)
    X_quantized = wnu.mu_law()
    X_onehot = tf.expand_dims()
    if shift:
        X_onehot = wnu.shift_right()
    h = wnu.conv1d(X=,num_filters=,filter_length=,name=)
    s = wnu.conv1d(X=, num_filters=, filter_length=, name=)
    for i in range():
        dilation = 2**()
        d = wnu.conv1d(X=,num_filters=,filter_length=,dilation=,name="")
        m = d.get_shape().as_list()[] // 2
        d = tf.sigmoid(d[:, :, :]) * tf.tanh(d[:, :, m:])
        h += wnu.conv1d(X=, num_filters=, filter_length=, name="")
        s += wnu.conv1d(X=, num_filters=, filter_length=, name="")
    s = tf.nn.relu()
    s = wnu.conv1d(X=, num_filters=, filter_length=, name=)
    s = tf.nn.relu()
    logits = tf.clip_by_value(wnu.conv1d(X=,num_filters=,filter_length=,name=) + offset,0.0,n_quantization - 1.0,name=)
    logits = tf.reshape(logits, [])
    labels = tf.cast(tf.reshape(X_quantized + offset, []), tf.int32)
    loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=, labels=, name=),0,name=)
    probs = tf.nn.softmax(logits, name=)
    synthesis = tf.reshape(wnu.inv_mu_law(tf.cast(tf.argmax(), tf.float32) - offset, n_quantization),[])
    tf.summary.audio("", synthesis, sample_rate=)
    tf.summary.histogram()
    tf.summary.histogram()
    tf.summary.histogram()
    tf.summary.histogram()
    tf.summary.histogram()
    tf.summary.scalar()
    summaries = tf.summary.merge_all()
    return {'X':,'quantized':,'probs':,'synthesis':,'summaries':,'loss':}
def train_vctk():
    batch_size =
    filter_length =
    n_stages =
    n_layers_per_stage =
    n_hidden =
    n_skip =
    dataset = vctk.get_dataset()
    it_i =
    n_epochs =
    sequence_length = get_sequence_length()
    ckpt_path = ""
    with tf.Graph().as_default(), tf.Session() as sess:
        net = create_wavenet(batch_size=,filter_length=,n_hidden=,n_skip=,n_stages=,n_layers_per_stage=)
        saver = tf.train.Saver()
        init_op = tf.group(tf.global_variables_initializer(),tf.local_variables_initializer())
        sess.run()
        if tf.train.latest_checkpoint() is not None:
            saver.restore(sess, tf.train.latest_checkpoint())
        batch =
        with tf.variable_scope():
            opt = tf.train.AdamOptimizer(learning_rate=).minimize(net[])
        var_list = [v for v in tf.global_variables() if v.name.startswith()]
        sess.run(tf.variables_initializer())
        writer = tf.summary.FileWriter()
        for epoch_i in range():
            for batch_xs in batch():
                loss, quantized, _ = sess.run([net[], net[], opt],feed_dict={net[]:})
                if it_i % 100 == 0:
                    summary = sess.run(net[], feed_dict={net[]:})
                    writer.add_summary()
                    saver.save(sess,os.path.join(),global_step=)
                it_i +=
    return loss
def test_librispeech():
    batch_size =
    filter_length =
    n_stages =
    n_layers_per_stage =
    n_hidden =
    n_skip =
    total_length =
    sequence_length = get_sequence_length()
    prime_length =
    ckpt_path = ""
    dataset = librispeech.get_dataset()
    batch = next(librispeech.batch_generator())[]
    sess = tf.Session()
    net = create_wavenet(batch_size=,filter_length=,n_hidden=,n_skip=,n_layers_per_stage=,n_stages=,shift=)
    init_op = tf.group(tf.global_variables_initializer(),tf.local_variables_initializer())
    sess.run()
    saver = tf.train.Saver()
    if tf.train.latest_checkpoint() is not None:
        saver.restore(sess, tf.train.latest_checkpoint())
    else:
    synth = np.zeros([], dtype=)
    synth[:, :] =
    for sample_i in range():
        probs = sess.run(net[],feed_dict={net[]: synth[:, sample_i:})
        idxs = sample_categorical()
        idxs = idxs.reshape(())
        if sample_i == 0:
            audio = wnu.inv_mu_law_numpy()
            synth[:, :] =
        else:
            audio = wnu.inv_mu_law_numpy(idxs[:, -1] - 128)
            synth[:, prime_length + sample_i] =
    for i in range():
        wavfile.write("", 16000, synth[])
import numpy as np
import tensorflow as tf
import gym, time, random, threading
from keras.models import *
from keras.layers import *
from keras import backend as K
ENV =
RUN_TIME =
THREADS =
OPTIMIZERS =
THREAD_DELAY =
GAMMA =
N_STEP_RETURN =
GAMMA_N =
EPS_START =
EPS_STOP  =
EPS_STEPS =
MIN_BATCH =
LEARNING_RATE =
LOSS_V =
LOSS_ENTROPY =
class Brain:
	train_queue = [ [], [], [], [], [] ]
	lock_queue = threading.Lock()
	def __init__():
		self.session = tf.Session()
		K.set_session()
		K.manual_variable_initialization()
		self.model = self._build_model()
		self.graph = self._build_graph()
		self.session.run(tf.global_variables_initializer())
		self.default_graph = tf.get_default_graph()
		self.default_graph.finalize()
	def _build_model():
		l_input = Input( batch_shape=() )
		l_dense = Dense(16, activation=)()
		out_actions = Dense(NUM_ACTIONS, activation=)()
		out_value   = Dense(1, activation=)()
		model = Model(inputs=[], outputs=[])
		model._make_predict_function()
		return model
	def _build_graph():
		s_t = tf.placeholder(tf.float32, shape=())
		a_t = tf.placeholder(tf.float32, shape=())
		r_t = tf.placeholder(tf.float32, shape=())
		p, v = model()
		log_prob = tf.log( tf.reduce_sum(p * a_t, axis=, keep_dims=) + 1e-10)
		advantage =
		loss_policy = - log_prob * tf.stop_gradient()
		loss_value  = LOSS_V * tf.square()
		entropy = LOSS_ENTROPY * tf.reduce_sum(p * tf.log(), axis=, keep_dims=)
		loss_total = tf.reduce_mean()
		optimizer = tf.train.RMSPropOptimizer(LEARNING_RATE, decay=)
		minimize = optimizer.minimize()
		return s_t, a_t, r_t, minimize
	def optimize():
		if len(self.train_queue[]) < MIN_BATCH:
			time.sleep()
			return
		with self.lock_queue:
			if len(self.train_queue[]) < MIN_BATCH:
				return
			s, a, r, s_, s_mask =
			self.train_queue = [ [], [], [], [], [] ]
		s = np.vstack()
		a = np.vstack()
		r = np.vstack()
		s_ = np.vstack()
		s_mask = np.vstack()
		if len() > 5*MIN_BATCH: print(""))
		v = self.predict_v()
		r =
		s_t, a_t, r_t, minimize =
		self.session.run(minimize, feed_dict={s_t:, a_t:, r_t:})
	def train_push():
		with self.lock_queue:
			self.train_queue[].append()
			self.train_queue[].append()
			self.train_queue[].append()
			if s_ is None:
				self.train_queue[].append()
				self.train_queue[].append()
			else:
				self.train_queue[].append()
				self.train_queue[].append()
	def predict():
		with self.default_graph.as_default():
			p, v = self.model.predict()
			return p, v
	def predict_p():
		with self.default_graph.as_default():
			p, v = self.model.predict()
			return p
	def predict_v():
		with self.default_graph.as_default():
			p, v = self.model.predict()
			return v
frames =
class Agent:
	def __init__():
		self.eps_start =
		self.eps_end   =
		self.eps_steps =
		self.memory = []
		self.R =
	def getEpsilon():
		if(frames >=):
			return self.eps_end
		else:
			return self.eps_start + frames * () / self.eps_steps
	def act():
		eps = self.getEpsilon()
		global frames; frames =
		if random.random() < eps:
			return random.randint()
		else:
			s = np.array([])
			p = brain.predict_p()[]
			a = np.random.choice(NUM_ACTIONS, p=)
			return a
	def train():
		def get_sample():
			s, a, _, _  = memory[]
			_, _, _, s_ = memory[]
			return s, a, self.R, s_
		a_cats = np.zeros()
		a_cats[] =
		self.memory.append( () )
		self.R = () / GAMMA
		if s_ is None:
			while len() > 0:
				n = len()
				s, a, r, s_ = get_sample()
				brain.train_push()
				self.R = ( self.R - self.memory[][] ) / GAMMA
				self.memory.pop()
			self.R =
		if len() >= N_STEP_RETURN:
			s, a, r, s_ = get_sample()
			brain.train_push()
			self.R = self.R - self.memory[][]
			self.memory.pop()
class Environment():
	stop_signal =
	def __init__(self, render=, eps_start=, eps_end=, eps_steps=):
		threading.Thread.__init__()
		self.render =
		self.env = gym.make()
		self.agent = Agent()
	def runEpisode():
		s = self.env.reset()
		R =
		while True:
			time.sleep()
			if self.render: self.env.render()
			a = self.agent.act()
			s_, r, done, info = self.env.step()
			if done:
				s_ =
			self.agent.train()
			s =
			R +=
			if done or self.stop_signal:
				break
	def run():
		while not self.stop_signal:
			self.runEpisode()
	def stop():
		self.stop_signal =
class Optimizer():
	stop_signal =
	def __init__():
		threading.Thread.__init__()
	def run():
		while not self.stop_signal:
			brain.optimize()
	def stop():
		self.stop_signal =
env_test = Environment(render=, eps_start=, eps_end=)
NUM_STATE = env_test.env.observation_space.shape[]
NUM_ACTIONS =
NONE_STATE = np.zeros()
brain = Brain()
envs = [Environment() for i in range()]
opts = [Optimizer() for i in range()]
for o in opts:
	o.start()
for e in envs:
	e.start()
time.sleep()
for e in envs:
	e.stop()
for e in envs:
	e.join()
for o in opts:
	o.stop()
for o in opts:
	o.join()
env_test.run()import argparse
import tensorflow as tf
import tensorflow.contrib.slim as slim
def _batch_norm_fn(x, scope=):
    if scope is None:
        scope = tf.get_variable_scope().name + ""
    return slim.batch_norm(x, scope=)
def create_link(incoming, network_builder, scope, nonlinearity=,weights_initializer=tf.truncated_normal_initializer(stddev=),regularizer=, is_first=, summarize_activations=):
    if is_first:
        network =
    else:
        network = _batch_norm_fn(incoming, scope=)
        network = nonlinearity()
        if summarize_activations:
            tf.summary.histogram()
    pre_block_network =
    post_block_network = network_builder()
    incoming_dim = pre_block_network.get_shape().as_list()[]
    outgoing_dim = post_block_network.get_shape().as_list()[]
    if incoming_dim != outgoing_dim:
        projection = slim.conv2d(incoming, outgoing_dim, 1, 2, padding=, activation_fn=,scope=, weights_initializer=,biases_initializer=, weights_regularizer=)
        network =
    else:
        network =
    return network
def create_inner_block(incoming, scope, nonlinearity=,weights_initializer=tf.truncated_normal_initializer(),bias_initializer=tf.zeros_initializer(), regularizer=,increase_dim=, summarize_activations=):
    n = incoming.get_shape().as_list()[]
    stride =
    if increase_dim:
        n *=
        stride =
    incoming = slim.conv2d(incoming, n, [], stride, activation_fn=, padding=,normalizer_fn=, weights_initializer=,biases_initializer=, weights_regularizer=,scope=)
    if summarize_activations:
        tf.summary.histogram()
    incoming = slim.dropout(incoming, keep_prob=)
    incoming = slim.conv2d(incoming, n, [], 1, activation_fn=, padding=,normalizer_fn=, weights_initializer=,biases_initializer=, weights_regularizer=,scope=)
    return incoming
def residual_block(incoming, scope, nonlinearity=,weights_initializer=tf.truncated_normal_initializer(),bias_initializer=tf.zeros_initializer(), regularizer=,increase_dim=, is_first=,summarize_activations=):
    def network_builder():
        return create_inner_block()
    return create_link()
def _create_network(incoming, reuse=, weight_decay=):
    nonlinearity =
    conv_weight_init = tf.truncated_normal_initializer(stddev=)
    conv_bias_init = tf.zeros_initializer()
    conv_regularizer = slim.l2_regularizer()
    fc_weight_init = tf.truncated_normal_initializer(stddev=)
    fc_bias_init = tf.zeros_initializer()
    fc_regularizer = slim.l2_regularizer()
    def batch_norm_fn():
        return slim.batch_norm(x, scope=tf.get_variable_scope().name + "")
    network =
    network = slim.conv2d(network, 32, [], stride=, activation_fn=,padding=, normalizer_fn=, scope=,weights_initializer=, biases_initializer=,weights_regularizer=)
    network = slim.conv2d(network, 32, [], stride=, activation_fn=,padding=, normalizer_fn=, scope=,weights_initializer=, biases_initializer=,weights_regularizer=)
    network = slim.max_pool2d(network, [], [], scope=)
    network = residual_block(network, "", nonlinearity, conv_weight_init, conv_bias_init,conv_regularizer, increase_dim=, is_first=)
    network = residual_block(network, "", nonlinearity, conv_weight_init, conv_bias_init,conv_regularizer, increase_dim=)
    network = residual_block(network, "", nonlinearity, conv_weight_init, conv_bias_init,conv_regularizer, increase_dim=)
    network = residual_block(network, "", nonlinearity, conv_weight_init, conv_bias_init,conv_regularizer, increase_dim=)
    network = residual_block(network, "", nonlinearity, conv_weight_init, conv_bias_init,conv_regularizer, increase_dim=)
    network = residual_block(network, "", nonlinearity, conv_weight_init, conv_bias_init,conv_regularizer, increase_dim=)
    feature_dim = network.get_shape().as_list()[]
    network = slim.flatten()
    network = slim.dropout(network, keep_prob=)
    network = slim.fully_connected(network, feature_dim, activation_fn=,normalizer_fn=, weights_regularizer=,scope=, weights_initializer=,biases_initializer=)
    features =
    features = slim.batch_norm(features, scope=, reuse=)
    feature_norm = tf.sqrt(tf.constant() +tf.reduce_sum(tf.square(), [], keepdims=))
    features =
    return features, None
def _network_factory(weight_decay=):
    def factory_fn():
            with slim.arg_scope([],is_training=):
                with slim.arg_scope([],reuse=):
                    features, logits = _create_network(image, reuse=, weight_decay=)
                    return features, logits
    return factory_fn
def _preprocess():
    image = image[:, :, ::]
    return image
def parse_args():
    parser = argparse.ArgumentParser(description=)
    parser.add_argument("",default=,help=)
    parser.add_argument("",default=)
    return parser.parse_args()
def main():
    args = parse_args()
    with tf.Session(graph=tf.Graph()) as session:
        input_var = tf.placeholder(tf.uint8, (), name=)
        image_var = tf.map_fn(lambda x: _preprocess(), tf.cast(),back_prop=)
        factory_fn = _network_factory()
        features, _ = factory_fn(image_var, reuse=)
        features = tf.identity(features, name=)
        saver = tf.train.Saver(slim.get_variables_to_restore())
        saver.restore()
        output_graph_def = tf.graph_util.convert_variables_to_constants(session, tf.get_default_graph().as_graph_def(),[features.name.split(":)[]])
        with tf.gfile.GFile() as file_handle:
            file_handle.write(output_graph_def.SerializeToString())
if __name__ == "__main__":
    main()
import numpy as np
import time
import pprint
from collections import OrderedDict
from keras import backend as K
import tensorflow as tf
import os
if not os.path.exists():
    os.makedirs()
class StateSpace:
    def __init__():
        self.states = OrderedDict()
        self.state_count_ =
    def add_state():
        index_map = {}
        for i, val in enumerate():
            index_map[] =
        value_map = {}
        for i, val in enumerate():
            value_map[] =
        metadata = {'id':,'name':,'values':,'size':,'index_map_':,'value_map_':,}
        self.states[] =
        self.state_count_ +=
        return self.state_count_ - 1
    def embedding_encode():
        state = self[]
        size = state[]
        value_map = state[]
        value_idx = value_map[]
        one_hot = np.zeros((), dtype=)
        one_hot[np.arange(), value_idx] =
        return one_hot
    def get_state_value():
        state = self[]
        index_map = state[]
        if (type() == list or type() ==) and len() == 1:
            index = index[]
        value = index_map[]
        return value
    def get_random_state_space():
        states = []
        for id in range():
            state = self[]
            size = state[]
            sample = np.random.choice(size, size=)
            sample = state[][sample[]]
            state = self.embedding_encode()
            states.append()
        return states
    def parse_state_space_list():
        state_values = []
        for id, state_one_hot in enumerate():
            state_val_idx = np.argmax(state_one_hot, axis=)[]
            value = self.get_state_value()
            state_values.append()
        return state_values
    def print_state_space():
        pp = pprint.PrettyPrinter(indent=, width=)
        for id, state in self.states.items():
            pp.pprint()
    def print_actions():
        for id, action in enumerate():
            if id % self.size == 0:
            state = self[]
            name = state[]
            vals = [() for n, p in zip(state[], *action)]
    def __getitem__():
        return self.states[]
    def size():
        return self.state_count_
class Controller:
    def __init__(self, policy_session, num_layers, state_space,reg_param=,discount_factor=,exploration=,controller_cells=,embedding_dim=,clip_norm=,restore_controller=):
        self.policy_session =
        self.num_layers =
        self.state_space =
        self.state_size =
        self.controller_cells =
        self.embedding_dim =
        self.reg_strength =
        self.discount_factor =
        self.exploration =
        self.restore_controller =
        self.clip_norm =
        self.reward_buffer = []
        self.state_buffer = []
        self.cell_outputs = []
        self.policy_classifiers = []
        self.policy_actions = []
        self.policy_labels = []
        self.build_policy_network()
    def get_action():
        if np.random.random() < self.exploration:
            actions = []
            for i in range():
                state_ = self.state_space[]
                size = state_[]
                sample = np.random.choice(size, size=)
                sample = state_[][sample[]]
                action = self.state_space.embedding_encode()
                actions.append()
            return actions
        else:
            initial_state = self.state_space[]
            size = initial_state[]
            if state[].shape != ():
                state = state[].reshape(()).astype()
            else:
                state = state[]
            with self.policy_session.as_default():
                K.set_session()
                with tf.name_scope():
                    pred_actions = self.policy_session.run(self.policy_actions, feed_dict={self.state_input:})
                return pred_actions
    def build_policy_network():
        with self.policy_session.as_default():
            K.set_session()
            with tf.name_scope():
                with tf.variable_scope():
                    with tf.name_scope():
                        state_input = tf.placeholder(dtype=, shape=(), name=)
                    self.state_input =
                    nas_cell = tf.nn.rnn_cell.LSTMCell()
                    cell_state = nas_cell.zero_state(batch_size=, dtype=)
                    embedding_weights = []
                    with tf.variable_scope("", reuse=):
                        for i in range():
                            state_ = self.state_space[]
                            size = state_[]
                            weights = tf.get_variable("",shape=[],initializer=tf.initializers.random_uniform())
                            embedding_weights.append()
                        embeddings = tf.nn.embedding_lookup(embedding_weights[], state_input)
                    cell_input =
                    for i in range():
                        state_id =
                        state_space = self.state_space[]
                        size = state_space[]
                        with tf.name_scope():
                            outputs, final_state = tf.nn.dynamic_rnn(nas_cell,cell_input,initial_state=,dtype=)
                            classifier = tf.layers.dense(outputs[:, -1, :], units=, name="",reuse=)
                            preds = tf.nn.softmax()
                            cell_input = tf.argmax(preds, axis=)
                            cell_input = tf.expand_dims(cell_input, -1, name="")
                            cell_input = tf.cast()
                            cell_input = tf.add()
                            cell_input = tf.nn.embedding_lookup(embedding_weights[], cell_input,name="")
                            cell_state =
                        self.cell_outputs.append()
                        self.policy_classifiers.append()
                        self.policy_actions.append()
            policy_net_variables = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=)
            with tf.name_scope():
                self.global_step = tf.Variable(0, trainable=)
                starter_learning_rate =
                learning_rate = tf.train.exponential_decay(starter_learning_rate, self.global_step,500, 0.95, staircase=)
                tf.summary.scalar()
                self.optimizer = tf.train.RMSPropOptimizer(learning_rate=)
            with tf.name_scope():
                self.discounted_rewards = tf.placeholder(tf.float32, shape=(), name=)
                tf.summary.scalar("", tf.reduce_sum())
                cross_entropy_loss =
                for i in range():
                    classifier = self.policy_classifiers[]
                    state_space = self.state_space[]
                    size = state_space[]
                    with tf.name_scope(""):
                        labels = tf.placeholder(dtype=, shape=(), name=)
                        self.policy_labels.append()
                        ce_loss = tf.nn.softmax_cross_entropy_with_logits_v2(logits=, labels=)
                        tf.summary.scalar("", tf.reduce_mean())
                    cross_entropy_loss +=
                policy_gradient_loss = tf.reduce_mean()
                reg_loss = tf.reduce_sum([tf.reduce_sum(tf.square()) for x in policy_net_variables])
                self.total_loss =
                tf.summary.scalar()
                self.gradients = self.optimizer.compute_gradients()
                with tf.name_scope():
                    if self.clip_norm is not None and self.clip_norm != 0.0:
                        norm = tf.constant(self.clip_norm, dtype=)
                        gradients, vars = zip()
                        gradients, _ = tf.clip_by_global_norm()
                        self.gradients = list(zip())
                    for i, () in enumerate():
                        if grad is not None:
                            self.gradients[] = ()
                with tf.name_scope():
                    self.train_op = self.optimizer.apply_gradients(self.gradients, global_step=)
            self.summaries_op = tf.summary.merge_all()
            timestr = time.strftime()
            filename =
            self.summary_writer = tf.summary.FileWriter(filename, graph=)
            self.policy_session.run(tf.global_variables_initializer())
            self.saver = tf.train.Saver(max_to_keep=)
            if self.restore_controller:
                path = tf.train.latest_checkpoint()
                if path is not None and tf.train.checkpoint_exists():
                    self.saver.restore()
    def store_rollout():
        self.reward_buffer.append()
        self.state_buffer.append()
        if len() > 20:
            with open("", mode=) as f:
                for i in range():
                    state_ = self.state_buffer[]
                    state_list = self.state_space.parse_state_space_list()
                    state_list =,'.join(str() for v in state_list)
                    f.write("", state_list))
            self.reward_buffer = [self.reward_buffer[]]
            self.state_buffer = [self.state_buffer[]]
    def discount_rewards():
        rewards = np.asarray()
        discounted_rewards = np.zeros_like()
        running_add =
        for t in reversed(range()):
            if rewards[] != 0:
                running_add =
            running_add = running_add * self.discount_factor + rewards[]
            discounted_rewards[] =
        return discounted_rewards[]
    def train_step():
        states = self.state_buffer[]
        label_list = []
        state_list = self.state_space.parse_state_space_list()
        for id, state_value in enumerate():
            state_one_hot = self.state_space.embedding_encode()
            label_list.append()
        state_input_size = self.state_space[][]
        state_input = states[].reshape(()).astype()
        reward = self.discount_rewards()
        reward = np.asarray([]).astype()
        feed_dict = {self.state_input:,self.discounted_rewards:}
        for i, label in enumerate():
            feed_dict[self.policy_labels[]] =
        with self.policy_session.as_default():
            K.set_session()
            _, loss, summary, global_step = self.policy_session.run([],feed_dict=)
            self.summary_writer.add_summary()
            self.saver.save(self.policy_session, save_path=, global_step=)
            if global_step != 0 and global_step % 20 == 0 and self.exploration > 0.5:
                self.exploration *=
        return loss
    def remove_files():
        files = []
        for file in files:
            if os.path.exists():
                os.remove()
from __future__ import print_function
import tensorflow as tf
import numpy as np
def add_layer(inputs, in_size, out_size, activation_function=):
    Weights = tf.Variable(tf.random_normal([]))
    biases = tf.Variable(tf.zeros([]) + 0.1)
    Wx_plus_b = tf.matmul() + biases
    if activation_function is None:
        outputs =
    else:
        outputs = activation_function()
    return outputs
x_data = np.linspace()[:, np.newaxis]
noise = np.random.normal()
y_data = np.square() - 0.5 + noise
xs = tf.placeholder(tf.float32, [])
ys = tf.placeholder(tf.float32, [])
l1 = add_layer(xs, 1, 10, activation_function=)
prediction = add_layer(l1, 10, 1, activation_function=)
loss = tf.reduce_mean(tf.reduce_sum(tf.square(),reduction_indices=[]))
train_step = tf.train.GradientDescentOptimizer().minimize()
if int(().split()[]) < 12:
    init = tf.initialize_all_variables()
else:
    init = tf.global_variables_initializer()
sess = tf.Session()
sess.run()
for i in range():
    sess.run(train_step, feed_dict={xs:, ys:})
    if i % 50 == 0:
from __future__ import print_function
import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt
def add_layer(inputs, in_size, out_size, activation_function=):
    Weights = tf.Variable(tf.random_normal([]))
    biases = tf.Variable(tf.zeros([]) + 0.1)
    Wx_plus_b = tf.matmul() + biases
    if activation_function is None:
        outputs =
    else:
        outputs = activation_function()
    return outputs
x_data = np.linspace()[:, np.newaxis]
noise = np.random.normal()
y_data = np.square() - 0.5 + noise
xs = tf.placeholder(tf.float32, [])
ys = tf.placeholder(tf.float32, [])
l1 = add_layer(xs, 1, 10, activation_function=)
prediction = add_layer(l1, 10, 1, activation_function=)
loss = tf.reduce_mean(tf.reduce_sum(tf.square(),reduction_indices=[]))
train_step = tf.train.GradientDescentOptimizer().minimize()
if int(().split()[]) < 12 and int(().split()[]) < 1:
    init = tf.initialize_all_variables()
else:
    init = tf.global_variables_initializer()
sess = tf.Session()
sess.run()
fig = plt.figure()
ax = fig.add_subplot()
ax.scatter()
plt.ion()
plt.show()
for i in range():
    sess.run(train_step, feed_dict={xs:, ys:})
    if i % 50 == 0:
        try:
            ax.lines.remove(lines[])
        except Exception:
            pass
        prediction_value = sess.run(prediction, feed_dict={xs:})
        lines = ax.plot(x_data, prediction_value, "", lw=)
        plt.pause()
from __future__ import print_function
import numpy as np
import tensorflow as tf
import layer
import speech_data
from speech_data import Source,Target
from layer import net
import time
start=int(time.time())
display_step =
test_step =
save_step =
learning_rate =
training_iters =
batch_size =
width=features=
height=max_length=
classes=
keep_prob=dropout=
batch = speech_data.mfcc_batch_generator(batch_size,target=)
X,Y=next()
x=inputs=tf.placeholder(tf.float32, shape=())
inputs = tf.transpose(inputs, [])
inputs = tf.split(axis=, num_or_size_splits=, value=)
num_hidden =
cell = tf.nn.rnn_cell.LSTMCell(num_hidden, state_is_tuple=)
state = cell.zero_state(batch_size, dtype=)
if "" == 0:
	outputs = []
	for input_ in inputs:
		input_= tf.reshape(input_, [])
		output, state = cell()
		outputs.append()
	y_=
else:
	inputs=[tf.reshape(input_, []) for input_ in inputs]
	outputs, states = tf.nn.rnn(cell, inputs, initial_state=)
	y_=outputs[]
weights = tf.Variable(tf.random_uniform([], minval=, maxval=), name=)
bias = tf.Variable(tf.random_uniform([], minval=, maxval=), name=)
y_ = tf.matmul(y_, weights, name=) + bias
y=target=tf.placeholder(tf.float32, shape=())
cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=,labels=),name=)
tf.summary.scalar()
optimizer = tf.train.AdamOptimizer().minimize()
prediction =
correct_pred = tf.equal(tf.argmax(), tf.argmax())
accuracy = tf.reduce_mean(tf.cast())
tf.summary.scalar()
steps =
session=tf.Session()
saver = tf.train.Saver(tf.global_variables())
snapshot =
checkpoint = tf.train.latest_checkpoint(checkpoint_dir=)
if checkpoint:
	try:saver.restore()
	except: print()
try: session.run([tf.global_variables_initializer()])
except: session.run([tf.global_variables_initializer()])
step =
summaries = tf.summary.merge_all()
summary_writer = tf.summary.FileWriter()
while step < steps:
	batch_xs, batch_ys = next()
	feed_dict = {x:, y:}
	loss, _ = session.run([], feed_dict=)
	if step % display_step == 0:
		seconds = int(time.time()) - start
		feed = {x:, y:}
		acc, summary = session.run([], feed_dict=)
		if str() == "":
			quit()
	if step % save_step == 0 and step > 0:
		saver.save()
	step =
from __future__ import print_function
import tensorflow as tf
class TrainConfig:
    batch_size =
    time_steps =
    input_size =
    output_size =
    cell_size =
    learning_rate =
class TestConfig():
    time_steps =
class RNN():
    def __init__():
        self._batch_size =
        self._time_steps =
        self._input_size =
        self._output_size =
        self._cell_size =
        self._lr =
        self._built_RNN()
    def _built_RNN():
        with tf.variable_scope():
            self._xs = tf.placeholder(tf.float32, [], name=)
            self._ys = tf.placeholder(tf.float32, [], name=)
        with tf.name_scope():
            with tf.variable_scope():
                l_in_x = tf.reshape(self._xs, [], name=)
                Wi = self._weight_variable([])
                bi = self._bias_variable([])
                with tf.name_scope():
                    l_in_y = tf.matmul() + bi
                l_in_y = tf.reshape(l_in_y, [], name=)
            with tf.variable_scope():
                cell = tf.contrib.rnn.BasicLSTMCell()
                with tf.name_scope():
                    self._cell_initial_state = cell.zero_state(self._batch_size, dtype=)
                self.cell_outputs = []
                cell_state =
                for t in range():
                    if t > 0: tf.get_variable_scope().reuse_variables()
                    cell_output, cell_state = cell(l_in_y[:, t, :], cell_state)
                    self.cell_outputs.append()
                self._cell_final_state =
            with tf.variable_scope():
                cell_outputs_reshaped = tf.reshape(tf.concat(), [])
                Wo = self._weight_variable(())
                bo = self._bias_variable(())
                product = tf.matmul() + bo
                self._pred = tf.nn.relu()
        with tf.name_scope():
            _pred = tf.reshape(self._pred, [])
            mse = self.ms_error()
            mse_ave_across_batch = tf.reduce_mean()
            mse_sum_across_time = tf.reduce_sum()
            self._cost =
            self._cost_ave_time =
        with tf.variable_scope():
            self._lr = tf.convert_to_tensor()
            self.train_op = tf.train.AdamOptimizer().minimize()
    def ms_error():
        return tf.square(tf.subtract())
    def _weight_variable(shape, name=):
        initializer = tf.random_normal_initializer(mean=, stddev=, )
        return tf.get_variable(shape=, initializer=, name=)
    def _bias_variable(shape, name=):
        initializer = tf.constant_initializer()
        return tf.get_variable(name=, shape=, initializer=)
if __name__ == "__main__":
    train_config = TrainConfig()
    test_config = TestConfig()
    with tf.variable_scope():
        train_rnn1 = RNN()
    with tf.variable_scope():
        test_rnn1 = RNN()
    with tf.variable_scope() as scope:
        sess = tf.Session()
        train_rnn2 = RNN()
        scope.reuse_variables()
        test_rnn2 = RNN()
        if int(().split()[]) < 12 and int(().split()[]) < 1:
            init = tf.initialize_all_variables()
        else:
            init = tf.global_variables_initializer()
        sess.run()import numpy as np
import tensorflow as tf
import matplotlib.pyplot as plt
ACTIVATION =
N_LAYERS =
N_HIDDEN_UNITS =
def fix_seed(seed=):
    np.random.seed()
    tf.set_random_seed()
def plot_his():
    for j, all_inputs in enumerate([]):
        for i, input in enumerate():
            plt.subplot(2, len(), j*len()+())
            plt.cla()
            if i == 0:
                the_range = ()
            else:
                the_range = ()
            plt.hist(input.ravel(), bins=, range=, color=)
            plt.yticks(())
            if j == 1:
                plt.xticks()
            else:
                plt.xticks(())
            ax = plt.gca()
            ax.spines[].set_color()
            ax.spines[].set_color()
        plt.title(""))
    plt.draw()
    plt.pause()
def built_net():
    def add_layer(inputs, in_size, out_size, activation_function=, norm=):
        Weights = tf.Variable(tf.random_normal([], mean=, stddev=))
        biases = tf.Variable(tf.zeros([]) + 0.1)
        Wx_plus_b = tf.matmul() + biases
        if norm:
            fc_mean, fc_var = tf.nn.moments(Wx_plus_b,axes=[],)
            scale = tf.Variable(tf.ones([]))
            shift = tf.Variable(tf.zeros([]))
            epsilon =
            ema = tf.train.ExponentialMovingAverage(decay=)
            def mean_var_with_update():
                ema_apply_op = ema.apply([])
                with tf.control_dependencies([]):
                    return tf.identity(), tf.identity()
            mean, var = mean_var_with_update()
            Wx_plus_b = tf.nn.batch_normalization()
        if activation_function is None:
            outputs =
        else:
            outputs = activation_function()
        return outputs
    fix_seed()
    if norm:
        fc_mean, fc_var = tf.nn.moments(xs,axes=[],)
        scale = tf.Variable(tf.ones([]))
        shift = tf.Variable(tf.zeros([]))
        epsilon =
        ema = tf.train.ExponentialMovingAverage(decay=)
        def mean_var_with_update():
            ema_apply_op = ema.apply([])
            with tf.control_dependencies([]):
                return tf.identity(), tf.identity()
        mean, var = mean_var_with_update()
        xs = tf.nn.batch_normalization()
    layers_inputs = []
    for l_n in range():
        layer_input = layers_inputs[]
        in_size = layers_inputs[].get_shape()[].value
        output = add_layer()
        layers_inputs.append()
    prediction = add_layer(layers_inputs[], 30, 1, activation_function=)
    cost = tf.reduce_mean(tf.reduce_sum(tf.square(), reduction_indices=[]))
    train_op = tf.train.GradientDescentOptimizer().minimize()
    return []
fix_seed()
x_data = np.linspace()[:, np.newaxis]
np.random.shuffle()
noise = np.random.normal()
y_data = np.square() - 5 + noise
plt.scatter()
plt.show()
xs = tf.placeholder(tf.float32, [])
ys = tf.placeholder(tf.float32, [])
train_op, cost, layers_inputs = built_net(xs, ys, norm=)
train_op_norm, cost_norm, layers_inputs_norm = built_net(xs, ys, norm=)
sess = tf.Session()
if int(().split()[]) < 12 and int(().split()[]) < 1:
    init = tf.initialize_all_variables()
else:
    init = tf.global_variables_initializer()
sess.run()
cost_his = []
cost_his_norm = []
record_step =
plt.ion()
plt.figure(figsize=())
for i in range():
    if i % 50 == 0:
        all_inputs, all_inputs_norm = sess.run([], feed_dict={xs:, ys:})
        plot_his()
    sess.run([], feed_dict={xs: x_data[i*10:, ys: y_data[i*10:})
    if i % record_step == 0:
        cost_his.append(sess.run(cost, feed_dict={xs:, ys:}))
        cost_his_norm.append(sess.run(cost_norm, feed_dict={xs:, ys:}))
plt.ioff()
plt.figure()
plt.plot(np.arange(len())*record_step, np.array(), label=)
plt.plot(np.arange(len())*record_step, np.array(), label=)
plt.legend()
plt.show()
import tensorflow as tf
from tensorflow.examples.tutorials.mnist import input_data
import numpy as np
from scipy.misc import imsave
import os
import shutil
from PIL import Image
import time
import random
import sys
from layers import *
from model import *
img_height =
img_width =
img_layer =
img_size =
to_train =
to_test =
to_restore =
output_path =
check_dir =
temp_check =
max_epoch =
max_images =
h1_size =
h2_size =
z_size =
batch_size =
pool_size =
sample_size =
save_training_images =
ngf =
ndf =
class CycleGAN():
    def input_setup():
        filenames_A = tf.train.match_filenames_once()
        self.queue_length_A = tf.size()
        filenames_B = tf.train.match_filenames_once()
        self.queue_length_B = tf.size()
        filename_queue_A = tf.train.string_input_producer()
        filename_queue_B = tf.train.string_input_producer()
        image_reader = tf.WholeFileReader()
        _, image_file_A = image_reader.read()
        _, image_file_B = image_reader.read()
        self.image_A = tf.subtract(tf.div(tf.image.resize_images(tf.image.decode_jpeg(),[]),127.5),1)
        self.image_B = tf.subtract(tf.div(tf.image.resize_images(tf.image.decode_jpeg(),[]),127.5),1)
    def input_read():
        coord = tf.train.Coordinator()
        threads = tf.train.start_queue_runners(coord=)
        num_files_A = sess.run()
        num_files_B = sess.run()
        self.fake_images_A = np.zeros(())
        self.fake_images_B = np.zeros(())
        self.A_input = np.zeros(())
        self.B_input = np.zeros(())
        for i in range():
            image_tensor = sess.run()
            if(image_tensor.size() ==):
                self.A_input[] = image_tensor.reshape(())
        for i in range():
            image_tensor = sess.run()
            if(image_tensor.size() ==):
                self.B_input[] = image_tensor.reshape(())
        coord.request_stop()
        coord.join()
    def model_setup():
        self.input_A = tf.placeholder(tf.float32, [], name=)
        self.input_B = tf.placeholder(tf.float32, [], name=)
        self.fake_pool_A = tf.placeholder(tf.float32, [], name=)
        self.fake_pool_B = tf.placeholder(tf.float32, [], name=)
        self.global_step = tf.Variable(0, name=, trainable=)
        self.num_fake_inputs =
        self.lr = tf.placeholder(tf.float32, shape=[], name=)
        with tf.variable_scope() as scope:
            self.fake_B = build_generator_resnet_9blocks(self.input_A, name=)
            self.fake_A = build_generator_resnet_9blocks(self.input_B, name=)
            self.rec_A = build_gen_discriminator()
            self.rec_B = build_gen_discriminator()
            scope.reuse_variables()
            self.fake_rec_A = build_gen_discriminator()
            self.fake_rec_B = build_gen_discriminator()
            self.cyc_A = build_generator_resnet_9blocks()
            self.cyc_B = build_generator_resnet_9blocks()
            scope.reuse_variables()
            self.fake_pool_rec_A = build_gen_discriminator()
            self.fake_pool_rec_B = build_gen_discriminator()
    def loss_calc():
        cyc_loss = tf.reduce_mean(tf.abs()) + tf.reduce_mean(tf.abs())
        disc_loss_A = tf.reduce_mean(tf.squared_difference())
        disc_loss_B = tf.reduce_mean(tf.squared_difference())
        g_loss_A =
        g_loss_B =
        d_loss_A = (tf.reduce_mean(tf.square()) + tf.reduce_mean(tf.squared_difference()))/2.0
        d_loss_B = (tf.reduce_mean(tf.square()) + tf.reduce_mean(tf.squared_difference()))/2.0
        optimizer = tf.train.AdamOptimizer(self.lr, beta1=)
        self.model_vars = tf.trainable_variables()
        d_A_vars = []
        g_A_vars = []
        d_B_vars = []
        g_B_vars = []
        self.d_A_trainer = optimizer.minimize(d_loss_A, var_list=)
        self.d_B_trainer = optimizer.minimize(d_loss_B, var_list=)
        self.g_A_trainer = optimizer.minimize(g_loss_A, var_list=)
        self.g_B_trainer = optimizer.minimize(g_loss_B, var_list=)
        for var in self.model_vars: print()
        self.g_A_loss_summ = tf.summary.scalar()
        self.g_B_loss_summ = tf.summary.scalar()
        self.d_A_loss_summ = tf.summary.scalar()
        self.d_B_loss_summ = tf.summary.scalar()
    def save_training_images():
        if not os.path.exists():
            os.makedirs()
        for i in range():
            fake_A_temp, fake_B_temp, cyc_A_temp, cyc_B_temp = sess.run([],feed_dict={self.input_A:, self.input_B:})
            imsave(""+ str() + "" + str()+"",((fake_A_temp[]+1)*127.5).astype())
            imsave(""+ str() + "" + str()+"",((fake_B_temp[]+1)*127.5).astype())
            imsave(""+ str() + "" + str()+"",((cyc_A_temp[]+1)*127.5).astype())
            imsave(""+ str() + "" + str()+"",((cyc_B_temp[]+1)*127.5).astype())
            imsave(""+ str() + "" + str()+"",((self.A_input[][]+1)*127.5).astype())
            imsave(""+ str() + "" + str()+"",((self.B_input[][]+1)*127.5).astype())
    def fake_image_pool():
        if():
            fake_pool[] =
            return fake
        else:
            p = random.random()
            if p > 0.5:
                random_id = random.randint()
                temp = fake_pool[]
                fake_pool[] =
                return temp
            else :
                return fake
    def train():
        self.input_setup()
        self.model_setup()
        self.loss_calc()
        init = tf.global_variables_initializer()
        saver = tf.train.Saver()
        with tf.Session() as sess:
            sess.run()
            self.input_read()
            if to_restore:
                chkpt_fname = tf.train.latest_checkpoint()
                saver.restore()
            writer = tf.summary.FileWriter()
            if not os.path.exists():
                os.makedirs()
            for epoch in range(sess.run(),100):
                saver.save(sess,os.path.join(),global_step=)
                if() :
                    curr_lr =
                else:
                    curr_lr = 0.0002 - 0.0002*()/100
                if():
                    self.save_training_images()
                for ptr in range():
                    _, fake_B_temp, summary_str = sess.run([],feed_dict={self.input_A:, self.input_B:, self.lr:})
                    writer.add_summary()
                    fake_B_temp1 = self.fake_image_pool()
                    _, summary_str = sess.run([],feed_dict={self.input_A:, self.input_B:, self.lr:, self.fake_pool_B:})
                    writer.add_summary()
                    _, fake_A_temp, summary_str = sess.run([],feed_dict={self.input_A:, self.input_B:, self.lr:})
                    writer.add_summary()
                    fake_A_temp1 = self.fake_image_pool()
                    _, summary_str = sess.run([],feed_dict={self.input_A:, self.input_B:, self.lr:, self.fake_pool_A:})
                    writer.add_summary()
                    self.num_fake_inputs+=
                sess.run(tf.assign())
            writer.add_graph()
    def test():
        self.input_setup()
        self.model_setup()
        saver = tf.train.Saver()
        init = tf.global_variables_initializer()
        with tf.Session() as sess:
            sess.run()
            self.input_read()
            chkpt_fname = tf.train.latest_checkpoint()
            saver.restore()
            if not os.path.exists():
                os.makedirs()
            for i in range():
                fake_A_temp, fake_B_temp = sess.run([],feed_dict={self.input_A:, self.input_B:})
                imsave(""+str()+"",((fake_A_temp[]+1)*127.5).astype())
                imsave(""+str()+"",((fake_B_temp[]+1)*127.5).astype())
                imsave(""+str()+"",((self.A_input[][]+1)*127.5).astype())
                imsave(""+str()+"",((self.B_input[][]+1)*127.5).astype())
def main():
    model = CycleGAN()
    if to_train:
        model.train()
    elif to_test:
        model.test()
if __name__ == "__main__":
    main()from collections import OrderedDict
import multiprocessing
import queue
import threading
import time
import numpy as np
import tensorflow as tf
import logging
logger = logging.getLogger()
class BaseDataSource():
    def __init__(self,tensorflow_session:,data_format: str =,batch_size: int =,num_threads: int = max(4, multiprocessing.cpu_count()),min_after_dequeue: int =,fread_queue_capacity: int =,preprocess_queue_capacity: int =,staging=,shuffle=,testing=,):
        if shuffle is None:
            shuffle =
        self.testing =
        if testing:
        self.staging =
        self.shuffle =
        self.data_format = data_format.upper()
        self.batch_size =
        self.num_threads =
        self._tensorflow_session =
        self._coordinator = tf.train.Coordinator()
        self.all_threads = []
        self._fread_queue_capacity =
        if self._fread_queue_capacity == 0:
            self._fread_queue_capacity = () * batch_size
        self._fread_queue = queue.Queue(maxsize=)
        with tf.variable_scope("".join(c for c in self.short_name if c.isalnum())):
            labels, dtypes, shapes = self._determine_dtypes_and_shapes()
            self._preprocess_queue_capacity = (min_after_dequeue + () * batch_sizeif preprocess_queue_capacity ==)
            if shuffle:
                self._preprocess_queue = tf.RandomShuffleQueue(capacity=,min_after_dequeue=,dtypes=, shapes=,)
            else:
                self._preprocess_queue = tf.FIFOQueue(capacity=,dtypes=, shapes=,)
            self._tensors_to_enqueue = OrderedDict([(label, tf.placeholder(dtype, shape=, name=))for label, dtype, shape in zip()])
            self._enqueue_op = self._preprocess_queue.enqueue(tuple(self._tensors_to_enqueue.values()))
            self._preprocess_queue_close_op = self._preprocess_queue.close(cancel_pending_enqueues=)
            self._preprocess_queue_size_op = self._preprocess_queue.size()
            self._preprocess_queue_clear_op = self._preprocess_queue.dequeue_up_to(self._preprocess_queue.size())
            if not staging:
                output_tensors = self._preprocess_queue.dequeue_many()
                if not isinstance():
                    output_tensors = []
                self._output_tensors = dict([() for label, tensor in zip()])
            else:
                self._staging_area = tf.contrib.staging.StagingArea(dtypes=,shapes=[tuple([] + list()) for shape in shapes],capacity=,)
                self._staging_area_put_op = self._staging_area.put(self._preprocess_queue.dequeue_many())
                self._staging_area_clear_op = self._staging_area.clear()
                self._output_tensors = dict([() for label, tensor in zip(labels, self._staging_area.get())])
    def __del__():
        self.cleanup()
    def num_entries():
        raise NotImplementedError('BaseDataSource::)
    def short_name():
        raise NotImplementedError('BaseDataSource::)
    __cleaned_up =
    def cleanup():
        if self.__cleaned_up:
            return
        fread_threads = [t for t in self.all_threads if t.name.startswith()]
        preprocess_threads = [t for t in self.all_threads if t.name.startswith()]
        transfer_threads = [t for t in self.all_threads if t.name.startswith()]
        self._coordinator.request_stop()
        while True:
            try:
                self._fread_queue.get_nowait()
            except queue.Empty:
                break
            time.sleep()
        for _ in range():
            self._fread_queue.put()
        self._tensorflow_session.run()
        if self.staging:
            self._tensorflow_session.run()
        self._coordinator.join(self.all_threads, stop_grace_period_secs=)
        self.__cleaned_up =
    def reset():
        self._coordinator.request_stop()
        with self._fread_queue.mutex:
            self._fread_queue.queue.clear()
        for _ in range():
            self._fread_queue.put()
        while True:
            preprocess_queue_size = self._tensorflow_session.run()
            if preprocess_queue_size == 0:
                break
            self._tensorflow_session.run()
            time.sleep()
        while True:
            try:
                self._fread_queue.get_nowait()
            except queue.Empty:
                break
            time.sleep()
        self._coordinator.join(self.all_threads, stop_grace_period_secs=)
        self._coordinator.clear_stop()
        self.create_and_start_threads()
    def _determine_dtypes_and_shapes():
        while True:
            raw_entry = next(self.entry_generator(yield_just_one=))
            if raw_entry is None:
                continue
            preprocessed_entry_dict = self.preprocess_entry()
            if preprocessed_entry_dict is not None:
                break
        labels, values = zip(*list(preprocessed_entry_dict.items()))
        dtypes = []
        shapes = []
        return labels, dtypes, shapes
    def entry_generator(self, yield_just_one=):
        raise NotImplementedError('BaseDataSource::)
    def preprocess_entry():
        raise NotImplementedError('BaseDataSource::)
    def read_entry_job():
        read_entry = self.entry_generator()
        while not self._coordinator.should_stop():
            try:
                entry = next()
            except StopIteration:
                if not self.testing:
                    continue
                else:
                    break
            if entry is not None:
                self._fread_queue.put()
        read_entry.close()
    def preprocess_job():
        while not self._coordinator.should_stop():
            raw_entry = self._fread_queue.get()
            if raw_entry is None:
                return
            preprocessed_entry_dict = self.preprocess_entry()
            if preprocessed_entry_dict is not None:
                feed_dict = dict([(self._tensors_to_enqueue[], value)for label, value in preprocessed_entry_dict.items()])
                try:
                    self._tensorflow_session.run(self._enqueue_op, feed_dict=)
                except ():
                    break
    def transfer_to_gpu_job():
        while not self._coordinator.should_stop():
            try:
                self._tensorflow_session.run()
            except tf.errors.CancelledError or tf.errors.OutOfRangeError:
                break
    def create_threads():
        name =
        self.all_threads = []
        def _create_and_register_thread():
            thread = threading.Thread()
            thread.daemon =
            self.all_threads.append()
        for i in range():
            _create_and_register_thread(target=, name="")
            _create_and_register_thread(target=,name="")
        if self.staging:
            _create_and_register_thread(target=,name="")
    def start_threads():
        for thread in self.all_threads:
            thread.start()
    def create_and_start_threads():
        self.create_threads()
        self.start_threads()
    def output_tensors():
        return self._output_tensors
from .data_source import BaseDataSource
import os
import sys
import time
from typing import Any, Dict, List
import numpy as np
import tensorflow as tf
from .live_tester import LiveTester
from .time_manager import TimeManager
from .summary_manager import SummaryManager
from .checkpoint_manager import CheckpointManager
import logging
logger = logging.getLogger()
class BaseModel():
    def __init__(self,tensorflow_session:,learning_schedule: List[Dict[]] = [],train_data: Dict[] = },test_data:},test_losses_or_metrics: str =,use_batch_statistics_at_test: bool =,identifier: str =):
        self._tensorflow_session =
        self._train_data =
        self._test_data =
        self._test_losses_or_metrics =
        self._initialized =
        self.__identifier =
        self._learning_schedule =
        self._known_prefixes = []
        train_data_sources = list(train_data.values())
        test_data_sources = list(test_data.values())
        all_data_sources =
        first_data_source = all_data_sources.pop()
        self._batch_size =
        self._data_format =
        for data_source in all_data_sources:
            if data_source.batch_size != self._batch_size:
                raise ValueError()
            if data_source.data_format != self._data_format:
                raise ValueError()
        self._data_format_longer = ("" if self._data_format ==)
        if not os.path.isdir():
            os.makedirs()
        root_logger = logging.getLogger()
        file_handler = logging.FileHandler()
        file_handler.setFormatter(root_logger.handlers[].formatter)
        for handler in root_logger.handlers[1:]:
            root_logger.removeHandler()
        root_logger.addHandler()
        self.summary = SummaryManager()
        self.checkpoint = CheckpointManager()
        self.time = TimeManager()
        self._enable_live_testing = (len() > 0) and (len() > 0)
        self._tester = LiveTester()
        with tf.variable_scope():
            self.is_training = tf.placeholder()
            self.use_batch_statistics = tf.placeholder()
            self.learning_rate_multiplier = tf.Variable(1.0, trainable=, dtype=)
            self.learning_rate_multiplier_placeholder = tf.placeholder(dtype=)
            self.assign_learning_rate_multiplier = tf.assign()
        self._build_all_models()
    def __del__():
        train_data_sources = list(self._train_data.values())
        test_data_sources = list(self._test_data.values())
        all_data_sources =
        for data_source in all_data_sources:
            data_source.cleanup()
        self._tester.__del__()
    __identifier_stem =
    def identifier():
        if self.__identifier is not None:
            return self.__identifier
        if self.__identifier_stem is None:
            self.__identifier_stem = self.__class__.__name__ + "" + time.strftime()
        return self.__identifier_stem + self._identifier_suffix
    def _identifier_suffix():
        return ""
    def output_path():
        return "",self.identifier)
    def _build_all_models():
        self.output_tensors = {}
        self.loss_terms = {}
        self.metrics = {}
        def _build_datasource_summaries():
            with tf.variable_scope():
                for data_source_name, data_source in data_sources.items():
                    tensors =
                    for key, tensor in tensors.items():
                        summary_name = ""
                        shape = tensor.shape.as_list()
                        num_dims = len()
                        if num_dims == 4:
                            if shape[] == 1 or shape[] == 3:
                                self.summary.image(summary_name, tensor,data_format=)
                            elif shape[] == 1 or shape[] == 3:
                                self.summary.image(summary_name, tensor,data_format=)
                        elif num_dims == 2:
                            self.summary.histogram()
                        else:
        def _build_train_or_test():
            data_sources = self._train_data if mode ==
            output_tensors, loss_terms, metrics = self.build_model(data_sources, mode=)
            self.output_tensors[] =
            self.loss_terms[] =
            self.metrics[] =
            if mode == "":
                for name, loss_term in loss_terms.items():
                    self.summary.scalar("", loss_term)
                for name, metric in metrics.items():
                    self.summary.scalar("", metric)
        if len() > 0:
            _build_datasource_summaries(self._train_data, mode=)
            _build_train_or_test(mode=)
            flops = tf.profiler.profile(options=tf.profiler.ProfileOptionBuilder(tf.profiler.ProfileOptionBuilder.float_operation()).with_empty_output().build())
        if len() > 0:
            _build_datasource_summaries(self._test_data, mode=)
            with tf.variable_scope():
                _build_train_or_test(mode=)
        if self._enable_live_testing:
            self._tester._post_model_build()
    def build_model(self, data_sources: Dict[], mode:):
        raise NotImplementedError('BaseModel::)
    def initialize_if_not(self, training=):
        if self._initialized:
            return
        with tf.variable_scope():
            self.checkpoint.build_savers()
        if training:
            with tf.variable_scope():
                self._build_optimizers()
        for _, datasource in self._train_data.items():
            datasource.create_and_start_threads()
        self._tensorflow_session.run(tf.global_variables_initializer())
        self._initialized =
    def _build_optimizers():
        self._optimize_ops = []
        all_trainable_variables = tf.trainable_variables()
        all_update_ops = tf.get_collection()
        all_reg_losses = tf.losses.get_regularization_losses()
        for spec in self._learning_schedule:
            optimize_ops = []
            update_ops = []
            loss_terms = spec[]
            reg_losses = []
            for loss_term_key, prefixes in loss_terms.items():
                variables_to_train = []
                for prefix in prefixes:
                    variables_to_train += [v for v in all_trainable_variablesif v.name.startswith()]
                    update_ops += [o for o in all_update_opsif o.name.startswith()]
                    reg_losses += [l for l in all_reg_lossesif l.name.startswith()]
                optimizer_class =
                optimizer = optimizer_class(learning_rate=self.learning_rate_multiplier * spec[],)
                final_loss = self.loss_terms[][]
                if len() > 0:
                    final_loss += tf.reduce_sum()
                with tf.control_dependencies():
                    gradients, variables = zip(*optimizer.compute_gradients(loss=,var_list=,aggregation_method=,))
                    optimize_op = optimizer.apply_gradients(zip())
                optimize_ops.append()
            self._optimize_ops.append()
    def train_loop_pre():
        pass
    def train_loop_post():
        pass
    def train(self, num_epochs=, num_steps=):
        if num_steps is None:
            num_entries = np.min([s.num_entries for s in list(self._train_data.values())])
            num_steps = int()
        self.initialize_if_not(training=)
        try:
            initial_step = self.checkpoint.load_all()
            current_step =
            for current_step in range():
                self.train_loop_pre()
                fetches = {}
                schedule_id = current_step % len()
                schedule = self._learning_schedule[]
                fetches[] = self._optimize_ops[]
                loss_term_keys, _ = zip(*list(schedule[].items()))
                fetches[] = [self.loss_terms[][] for k in loss_term_keys]
                summary_op = self.summary.get_ops(mode=)
                if len() > 0:
                    fetches[] =
                self.time.start("", average_over_last_n_timings=)
                outcome = self._tensorflow_session.run(fetches=,feed_dict={self.is_training:,self.use_batch_statistics:,})
                self.time.end()
                to_print =
                to_print +=, '.join([""for k, v in zip(loss_term_keys, outcome[])])
                self.time.log_every("", to_print, seconds=)
                if self._enable_live_testing:
                    self._tester.trigger_test_if_not_testing()
                if "" in outcome:
                    self.summary.write_summaries(outcome[], current_step)
                if self.time.has_been_n_seconds_since_last() and current_step > initial_step:
                    self.checkpoint.save_all()
                self.train_loop_post()
        except KeyboardInterrupt:
            self.checkpoint.save_all()
            sys.exit()
        if self._enable_live_testing:
            self._tester.do_final_full_test()
        if current_step > initial_step:
            self.checkpoint.save_all()
    def inference_generator():
        self.initialize_if_not(training=)
        self.checkpoint.load_all()
        data_source = next(iter(self._train_data.values()))
        while True:
            fetches = dict(self.output_tensors[], **data_source.output_tensors)
            start_time = time.time()
            outputs = self._tensorflow_session.run(fetches=,feed_dict={self.is_training:,self.use_batch_statistics:,},)
            outputs[] = 1e3*(time.time() - start_time)
            yield outputs
import os
import sys
import time
import tensorflow as tf
from .utils.general import init_dir, get_logger
class BaseModel():
    def __init__():
        self._config =
        self._dir_output =
        init_dir()
        self.logger = get_logger()
        tf.reset_default_graph()
    def build_train(self, config=):
        raise NotImplementedError
    def build_pred(self, config=):
        raise NotImplementedError
    def _add_train_op(self, lr_method, lr, loss, clip=):
        _lr_m = lr_method.lower()
        with tf.variable_scope():
            if _lr_m == "":
                optimizer = tf.train.AdamOptimizer()
            elif _lr_m == "":
                optimizer = tf.train.AdagradOptimizer()
            elif _lr_m == "":
                optimizer = tf.train.GradientDescentOptimizer()
            elif _lr_m == "":
                optimizer = tf.train.RMSPropOptimizer()
            else:
                raise NotImplementedError("")
            update_ops = tf.get_collection()
            with tf.control_dependencies():
                if clip > 0:
                    grads, vs     = zip(*optimizer.compute_gradients())
                    grads, gnorm  = tf.clip_by_global_norm()
                    self.train_op = optimizer.apply_gradients(zip())
                else:
                    self.train_op = optimizer.minimize()
    def init_session():
        self.sess = tf.Session()
        self.sess.run(tf.global_variables_initializer())
        self.saver = tf.train.Saver()
    def restore_session():
        self.saver.restore()
    def save_session():
        dir_model =
        init_dir()
        sys.stdout.write()
        sys.stdout.flush()
        self.saver.save()
        sys.stdout.write()
        sys.stdout.flush()
    def close_session():
        self.sess.close()
    def _add_summary():
        self.merged      = tf.summary.merge_all()
        self.file_writer = tf.summary.FileWriter()
    def train():
        best_score =
        for epoch in range():
            tic = time.time()
            score = self._run_epoch()
            if best_score is None or score >= best_score:
                best_score =
                self.save_session()
            if lr_schedule.stop_training:
                break
            toc = time.time()
        return best_score
    def _run_epoch():
        raise NotImplementedError
    def evaluate():
        sys.stdout.write()
        sys.stdout.flush()
        scores = self._run_evaluate()
        sys.stdout.write()
        sys.stdout.flush()
        msg = ""for k, v in scores.items()])
        return scores
    def _run_evaluate():
        raise NotImplementedError
import tensorflow as tf
import numpy as np
import datetime
import os
import matplotlib.pyplot as plt
from matplotlib import gridspec
from tensorflow.examples.tutorials.mnist import input_data
mnist = input_data.read_data_sets("", one_hot=)
input_dim =
n_l1 =
n_l2 =
z_dim =
batch_size =
n_epochs =
learning_rate =
beta1 =
results_path =
x_input = tf.placeholder(dtype=, shape=[], name=)
x_target = tf.placeholder(dtype=, shape=[], name=)
real_distribution = tf.placeholder(dtype=, shape=[], name=)
decoder_input = tf.placeholder(dtype=, shape=[], name=)
def form_results():
    folder_name = 
    tensorboard_path =
    saved_model_path =
    log_path =
    if not os.path.exists():
        os.mkdir()
        os.mkdir()
        os.mkdir()
        os.mkdir()
    return tensorboard_path, saved_model_path, log_path
def generate_image_grid():
    x_points = np.arange().astype()
    y_points = np.arange().astype()
    nx, ny = len(), len()
    plt.subplot()
    gs = gridspec.GridSpec(nx, ny, hspace=, wspace=)
    for i, g in enumerate():
        z = np.concatenate(([x_points[int()]], [y_points[int()]]))
        z = np.reshape(z, ())
        x = sess.run(op, feed_dict={decoder_input:})
        ax = plt.subplot()
        img = np.array(x.tolist()).reshape()
        ax.imshow(img, cmap=)
        ax.set_xticks([])
        ax.set_yticks([])
        ax.set_aspect()
    plt.show()
def dense():
    with tf.variable_scope(name, reuse=):
        weights = tf.get_variable("", shape=[],initializer=tf.random_normal_initializer(mean=, stddev=))
        bias = tf.get_variable("", shape=[], initializer=tf.constant_initializer())
        out = tf.add(tf.matmul(), bias, name=)
        return out
def encoder(x, reuse=):
    if reuse:
        tf.get_variable_scope().reuse_variables()
    with tf.name_scope():
        e_dense_1 = tf.nn.relu(dense())
        e_dense_2 = tf.nn.relu(dense())
        latent_variable = dense()
        return latent_variable
def decoder(x, reuse=):
    if reuse:
        tf.get_variable_scope().reuse_variables()
    with tf.name_scope():
        d_dense_1 = tf.nn.relu(dense())
        d_dense_2 = tf.nn.relu(dense())
        output = tf.nn.sigmoid(dense())
        return output
def discriminator(x, reuse=):
    if reuse:
        tf.get_variable_scope().reuse_variables()
    with tf.name_scope():
        dc_den1 = tf.nn.relu(dense(x, z_dim, n_l1, name=))
        dc_den2 = tf.nn.relu(dense(dc_den1, n_l1, n_l2, name=))
        output = dense(dc_den2, n_l2, 1, name=)
        return output
def train(train_model=):
    with tf.variable_scope(tf.get_variable_scope()):
        encoder_output = encoder()
        decoder_output = decoder()
    with tf.variable_scope(tf.get_variable_scope()):
        d_real = discriminator()
        d_fake = discriminator(encoder_output, reuse=)
    with tf.variable_scope(tf.get_variable_scope()):
        decoder_image = decoder(decoder_input, reuse=)
    autoencoder_loss = tf.reduce_mean(tf.square())
    dc_loss_real = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=tf.ones_like(), logits=))
    dc_loss_fake = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=tf.zeros_like(), logits=))
    dc_loss =
    generator_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=tf.ones_like(), logits=))
    all_variables = tf.trainable_variables()
    dc_var = []
    en_var = []
    autoencoder_optimizer = tf.train.AdamOptimizer(learning_rate=,beta1=).minimize()
    discriminator_optimizer = tf.train.AdamOptimizer(learning_rate=,beta1=).minimize(dc_loss, var_list=)
    generator_optimizer = tf.train.AdamOptimizer(learning_rate=,beta1=).minimize(generator_loss, var_list=)
    init = tf.global_variables_initializer()
    input_images = tf.reshape(x_input, [])
    generated_images = tf.reshape(decoder_output, [])
    tf.summary.scalar(name=, tensor=)
    tf.summary.scalar(name=, tensor=)
    tf.summary.scalar(name=, tensor=)
    tf.summary.histogram(name=, values=)
    tf.summary.histogram(name=, values=)
    tf.summary.image(name=, tensor=, max_outputs=)
    tf.summary.image(name=, tensor=, max_outputs=)
    summary_op = tf.summary.merge_all()
    saver = tf.train.Saver()
    step =
    with tf.Session() as sess:
        if train_model:
            tensorboard_path, saved_model_path, log_path = form_results()
            sess.run()
            writer = tf.summary.FileWriter(logdir=, graph=)
            for i in range():
                n_batches = int()
                for b in range():
                    z_real_dist = np.random.randn() * 5.
                    batch_x, _ = mnist.train.next_batch()
                    sess.run(autoencoder_optimizer, feed_dict={x_input:, x_target:})
                    sess.run(discriminator_optimizer,feed_dict={x_input:, x_target:, real_distribution:})
                    sess.run(generator_optimizer, feed_dict={x_input:, x_target:})
                    if b % 50 == 0:
                        a_loss, d_loss, g_loss, summary = sess.run([],feed_dict={x_input:, x_target:,real_distribution:})
                        writer.add_summary(summary, global_step=)
                        with open() as log:
                    step +=
                saver.save(sess, save_path=, global_step=)
        else:
            all_results = os.listdir()
            all_results.sort()
            saver.restore(sess, save_path=tf.train.latest_checkpoint(results_path + "" + all_results[] + ""))
            generate_image_grid(sess, op=)
if __name__ == "__main__":
    train(train_model=)
import tensorflow as tf
import numpy as np
import datetime
import os
import matplotlib.pyplot as plt
from matplotlib import gridspec
from tensorflow.examples.tutorials.mnist import input_data
mnist = input_data.read_data_sets("", one_hot=)
input_dim =
n_l1 =
n_l2 =
z_dim =
batch_size =
n_epochs =
learning_rate =
beta1 =
results_path =
x_input = tf.placeholder(dtype=, shape=[], name=)
x_target = tf.placeholder(dtype=, shape=[], name=)
decoder_input = tf.placeholder(dtype=, shape=[], name=)
def generate_image_grid():
    x_points = np.arange().astype()
    y_points = np.arange().astype()
    nx, ny = len(), len()
    plt.subplot()
    gs = gridspec.GridSpec(nx, ny, hspace=, wspace=)
    for i, g in enumerate():
        z = np.concatenate(([x_points[int()]], [y_points[int()]]))
        z = np.reshape(z, ())
        x = sess.run(op, feed_dict={decoder_input:})
        ax = plt.subplot()
        img = np.array(x.tolist()).reshape()
        ax.imshow(img, cmap=)
        ax.set_xticks([])
        ax.set_yticks([])
        ax.set_aspect()
    plt.show()
def form_results():
    folder_name = 
    tensorboard_path =
    saved_model_path =
    log_path =
    if not os.path.exists():
        os.mkdir()
    return tensorboard_path, saved_model_path, log_path
def dense():
    with tf.variable_scope(name, reuse=):
        weights = tf.get_variable("", shape=[],initializer=tf.random_normal_initializer(mean=, stddev=))
        bias = tf.get_variable("", shape=[], initializer=tf.constant_initializer())
        out = tf.add(tf.matmul(), bias, name=)
        return out
def encoder(x, reuse=):
    if reuse:
        tf.get_variable_scope().reuse_variables()
    with tf.name_scope():
        e_dense_1 = tf.nn.relu(dense())
        e_dense_2 = tf.nn.relu(dense())
        latent_variable = dense()
        return latent_variable
def decoder(x, reuse=):
    if reuse:
        tf.get_variable_scope().reuse_variables()
    with tf.name_scope():
        d_dense_1 = tf.nn.relu(dense())
        d_dense_2 = tf.nn.relu(dense())
        output = tf.nn.sigmoid(dense())
        return output
def train():
    with tf.variable_scope(tf.get_variable_scope()):
        encoder_output = encoder()
        decoder_output = decoder()
    with tf.variable_scope(tf.get_variable_scope()):
        decoder_image = decoder(decoder_input, reuse=)
    loss = tf.reduce_mean(tf.square())
    optimizer = tf.train.AdamOptimizer(learning_rate=, beta1=).minimize()
    init = tf.global_variables_initializer()
    tf.summary.scalar(name=, tensor=)
    tf.summary.histogram(name=, values=)
    input_images = tf.reshape(x_input, [])
    generated_images = tf.reshape(decoder_output, [])
    tf.summary.image(name=, tensor=, max_outputs=)
    tf.summary.image(name=, tensor=, max_outputs=)
    summary_op = tf.summary.merge_all()
    saver = tf.train.Saver()
    step =
    with tf.Session() as sess:
        sess.run()
        if train_model:
            tensorboard_path, saved_model_path, log_path = form_results()
            writer = tf.summary.FileWriter(logdir=, graph=)
            for i in range():
                n_batches = int()
                for b in range():
                    batch_x, _ = mnist.train.next_batch()
                    sess.run(optimizer, feed_dict={x_input:, x_target:})
                    if b % 50 == 0:
                        batch_loss, summary = sess.run([], feed_dict={x_input:, x_target:})
                        writer.add_summary(summary, global_step=)
                        with open() as log:
                    step +=
                saver.save(sess, save_path=, global_step=)
        else:
            all_results = os.listdir()
            all_results.sort()
            saver.restore(sess,save_path=tf.train.latest_checkpoint(results_path + "" + all_results[] + ""))
            generate_image_grid(sess, op=)
if __name__ == "__main__":
    train(train_model=)
import tensorflow as tf
import numpy as np
import os
import datetime
from tensorflow.examples.tutorials.mnist import input_data
input_dim =
n_l1 =
n_l2 =
batch_size =
n_epochs =
learning_rate =
beta1 =
z_dim =
results_path =
n_labels =
n_labeled =
mnist = input_data.read_data_sets("", one_hot=)
x_input = tf.placeholder(dtype=, shape=[])
y_target = tf.placeholder(dtype=, shape=[])
def form_results():
    folder_name = 
    tensorboard_path =
    saved_model_path =
    log_path =
    if not os.path.exists():
        os.mkdir()
    return tensorboard_path, saved_model_path, log_path
def next_batch():
    index = np.arange()
    random_index = np.random.permutation()[:]
    return x[], y[]
def dense():
    with tf.name_scope():
        weights = tf.Variable(tf.random_normal(shape=[], mean=, stddev=), name=)
        bias = tf.Variable(tf.zeros(shape=[]), name=)
        output = tf.add(tf.matmul(), bias, name=)
        return output
def dense_nn():
    dense_1 = tf.nn.dropout(tf.nn.relu(dense()), keep_prob=)
    dense_2 = tf.nn.dropout(tf.nn.relu(dense()), keep_prob=)
    dense_3 = dense()
    return dense_3
def train():
    dense_output = dense_nn()
    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=, labels=))
    optimizer = tf.train.AdamOptimizer(learning_rate=, beta1=).minimize()
    pred_op = tf.equal(tf.argmax(), tf.argmax())
    accuracy = tf.reduce_mean(tf.cast(pred_op, dtype=))
    tf.summary.scalar(name=, tensor=)
    tf.summary.scalar(name=, tensor=)
    summary_op = tf.summary.merge_all()
    saver = tf.train.Saver()
    init = tf.global_variables_initializer()
    step =
    with tf.Session() as sess:
        tensorboard_path, saved_model_path, log_path = form_results()
        x_l, y_l = mnist.test.next_batch()
        writer = tf.summary.FileWriter(logdir=, graph=)
        sess.run()
        for e in range():
            n_batches = int()
            for b in range():
                batch_x_l, batch_y_l = next_batch(x_l, y_l, batch_size=)
                sess.run(optimizer, feed_dict={x_input:, y_target:})
                if b % 5 == 0:
                    loss_, summary = sess.run([], feed_dict={x_input:, y_target:})
                    writer.add_summary()
                    with open() as log:
                step +=
            acc =
            num_batches = int()
            for j in range():
                batch_x_l, batch_y_l = mnist.validation.next_batch(batch_size=)
                val_acc = sess.run(accuracy, feed_dict={x_input:, y_target:})
                acc +=
            acc /=
            with open() as log:
            saver.save(sess, save_path=, global_step=)
if __name__ == "__main__":
    train()
import tensorflow as tf
import numpy as np
import datetime
import os
import argparse
import matplotlib.pyplot as plt
from matplotlib import gridspec
from tensorflow.examples.tutorials.mnist import input_data
mnist = input_data.read_data_sets("", one_hot=)
input_dim =
n_l1 =
n_l2 =
z_dim =
batch_size =
n_epochs =
learning_rate =
beta1 =
results_path =
n_labels =
n_labeled =
x_input = tf.placeholder(dtype=, shape=[], name=)
x_input_l = tf.placeholder(dtype=, shape=[], name=)
y_input = tf.placeholder(dtype=, shape=[], name=)
x_target = tf.placeholder(dtype=, shape=[], name=)
real_distribution = tf.placeholder(dtype=, shape=[], name=)
categorial_distribution = tf.placeholder(dtype=, shape=[],name=)
manual_decoder_input = tf.placeholder(dtype=, shape=[], name=)
def form_results():
    folder_name = 
    tensorboard_path =
    saved_model_path =
    log_path =
    if not os.path.exists():
        os.mkdir()
    return tensorboard_path, saved_model_path, log_path
def generate_image_grid():
    nx, ny =, 10
    random_inputs = np.random.randn() * 5.
    sample_y = np.identity()
    plt.subplot()
    gs = gridspec.GridSpec(nx, ny, hspace=, wspace=)
    i =
    for r in random_inputs:
        for t in sample_y:
            r, t = np.reshape(r, ()), np.reshape(t, ())
            dec_input = np.concatenate((), 1)
            x = sess.run(op, feed_dict={manual_decoder_input:})
            ax = plt.subplot(gs[])
            i +=
            img = np.array(x.tolist()).reshape()
            ax.imshow(img, cmap=)
            ax.set_xticks([])
            ax.set_yticks([])
            ax.set_aspect()
    plt.show()
def dense():
    with tf.variable_scope(name, reuse=):
        weights = tf.get_variable("", shape=[],initializer=tf.random_normal_initializer(mean=, stddev=))
        bias = tf.get_variable("", shape=[], initializer=tf.constant_initializer())
        out = tf.add(tf.matmul(), bias, name=)
        return out
def encoder(x, reuse=, supervised=):
    if reuse:
        tf.get_variable_scope().reuse_variables()
    with tf.name_scope():
        e_dense_1 = tf.nn.relu(dense())
        e_dense_2 = tf.nn.relu(dense())
        latent_variable = dense()
        cat_op = dense()
        if not supervised:
            softmax_label = tf.nn.softmax(logits=, name=)
        else:
            softmax_label =
        return softmax_label, latent_variable
def decoder(x, reuse=):
    if reuse:
        tf.get_variable_scope().reuse_variables()
    with tf.name_scope():
        d_dense_1 = tf.nn.relu(dense())
        d_dense_2 = tf.nn.relu(dense())
        output = tf.nn.sigmoid(dense())
        return output
def discriminator_gauss(x, reuse=):
    if reuse:
        tf.get_variable_scope().reuse_variables()
    with tf.name_scope():
        dc_den1 = tf.nn.relu(dense(x, z_dim, n_l1, name=))
        dc_den2 = tf.nn.relu(dense(dc_den1, n_l1, n_l2, name=))
        output = dense(dc_den2, n_l2, 1, name=)
        return output
def discriminator_categorical(x, reuse=):
    if reuse:
        tf.get_variable_scope().reuse_variables()
    with tf.name_scope():
        dc_den1 = tf.nn.relu(dense(x, n_labels, n_l1, name=))
        dc_den2 = tf.nn.relu(dense(dc_den1, n_l1, n_l2, name=))
        output = dense(dc_den2, n_l2, 1, name=)
        return output
def next_batch():
    index = np.arange()
    random_index = np.random.permutation()[:]
    return x[], y[]
def train(train_model=):
    with tf.variable_scope(tf.get_variable_scope()):
        encoder_output_label, encoder_output_latent = encoder()
        decoder_input = tf.concat([], 1)
        decoder_output = decoder()
    with tf.variable_scope(tf.get_variable_scope()):
        d_g_real = discriminator_gauss()
        d_g_fake = discriminator_gauss(encoder_output_latent, reuse=)
    with tf.variable_scope(tf.get_variable_scope()):
        d_c_real = discriminator_categorical()
        d_c_fake = discriminator_categorical(encoder_output_label, reuse=)
    with tf.variable_scope(tf.get_variable_scope()):
        encoder_output_label_, _ = encoder(x_input_l, reuse=, supervised=)
    with tf.variable_scope(tf.get_variable_scope()):
        decoder_image = decoder(manual_decoder_input, reuse=)
    correct_pred = tf.equal(tf.argmax(), tf.argmax())
    accuracy = tf.reduce_mean(tf.cast())
    autoencoder_loss = tf.reduce_mean(tf.square())
    dc_g_loss_real = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=tf.ones_like(), logits=))
    dc_g_loss_fake = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=tf.zeros_like(), logits=))
    dc_g_loss =
    dc_c_loss_real = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=tf.ones_like(), logits=))
    dc_c_loss_fake = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=tf.zeros_like(), logits=))
    dc_c_loss =
    generator_g_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=tf.ones_like(), logits=))
    generator_c_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=tf.ones_like(), logits=))
    generator_loss =
    supervised_encoder_loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=, logits=))
    all_variables = tf.trainable_variables()
    dc_g_var = []
    dc_c_var = []
    en_var = []
    autoencoder_optimizer = tf.train.AdamOptimizer(learning_rate=,beta1=).minimize()
    discriminator_g_optimizer = tf.train.AdamOptimizer(learning_rate=,beta1=).minimize(dc_g_loss, var_list=)
    discriminator_c_optimizer = tf.train.AdamOptimizer(learning_rate=,beta1=).minimize(dc_c_loss, var_list=)
    generator_optimizer = tf.train.AdamOptimizer(learning_rate=,beta1=).minimize(generator_loss, var_list=)
    supervised_encoder_optimizer = tf.train.AdamOptimizer(learning_rate=,beta1=).minimize(supervised_encoder_loss,var_list=)
    init = tf.global_variables_initializer()
    input_images = tf.reshape(x_input, [])
    generated_images = tf.reshape(decoder_output, [])
    tf.summary.scalar(name=, tensor=)
    tf.summary.scalar(name=, tensor=)
    tf.summary.scalar(name=, tensor=)
    tf.summary.scalar(name=, tensor=)
    tf.summary.scalar(name=, tensor=)
    tf.summary.histogram(name=, values=)
    tf.summary.histogram(name=, values=)
    tf.summary.histogram(name=, values=)
    tf.summary.histogram(name=, values=)
    tf.summary.image(name=, tensor=, max_outputs=)
    tf.summary.image(name=, tensor=, max_outputs=)
    summary_op = tf.summary.merge_all()
    saver = tf.train.Saver()
    step =
    with tf.Session() as sess:
        if train_model:
            tensorboard_path, saved_model_path, log_path = form_results()
            sess.run()
            writer = tf.summary.FileWriter(logdir=, graph=)
            x_l, y_l = mnist.test.next_batch()
            for i in range():
                n_batches = int()
                for b in range():
                    z_real_dist = np.random.randn() * 5.
                    real_cat_dist = np.random.randint(low=, high=, size=)
                    real_cat_dist = np.eye()[]
                    batch_x_ul, _ = mnist.train.next_batch()
                    batch_x_l, batch_y_l = next_batch(x_l, y_l, batch_size=)
                    sess.run(autoencoder_optimizer, feed_dict={x_input:, x_target:})
                    sess.run(discriminator_g_optimizer,feed_dict={x_input:, x_target:, real_distribution:})
                    sess.run(discriminator_c_optimizer,feed_dict={x_input:, x_target:,categorial_distribution:})
                    sess.run(generator_optimizer, feed_dict={x_input:, x_target:})
                    sess.run(supervised_encoder_optimizer, feed_dict={x_input_l:, y_input:})
                    if b % 5 == 0:
                        a_loss, d_g_loss, d_c_loss, g_loss, s_loss, summary = sess.run([],feed_dict={x_input:, x_target:,real_distribution:, y_input:, x_input_l:,categorial_distribution:})
                        writer.add_summary(summary, global_step=)
                        with open() as log:
                    step +=
                acc =
                num_batches = int()
                for j in range():
                    batch_x_l, batch_y_l = mnist.validation.next_batch(batch_size=)
                    encoder_acc = sess.run(accuracy, feed_dict={x_input_l:, y_input:})
                    acc +=
                acc /=
                with open() as log:
                saver.save(sess, save_path=, global_step=)
        else:
            all_results = os.listdir()
            all_results.sort()
            saver.restore(sess, save_path=tf.train.latest_checkpoint(results_path + "" +all_results[] + ""))
            generate_image_grid(sess, op=)
if __name__ == "__main__":
    parser = argparse.ArgumentParser(description=)
    parser.add_argument("", "", type=, default=,help=)
    args = parser.parse_args()
    train(train_model=)
from __future__ import absolute_import
from __future__ import division
from __future__ import print_function
import tensorflow as tf
from tensorflow.python.ops import ctc_ops as ctc
from tensorflow.python.ops import rnn_cell
from tensorflow.python.ops.rnn import bidirectional_rnn
import numpy as np
import re
from bdlstm_utils import load_batched_data
INPUT_PATH =
TARGET_PATH =
our_data =
if our_data:
	INPUT_PATH =
	TARGET_PATH =
learningRate =
momentum =
nEpochs =
Size =
nFeatures =
nClasses =
if our_data:
	nFeatures =
	nClasses =
nHidden =
edData, maxTimeSteps, totalN, _ = load_batched_data(INPUT_PATH, TARGET_PATH, Size,match=)
graph = tf.Graph()
with graph.as_default():
	inputX = tf.placeholder(tf.float32, shape=())
	inputXrs = tf.reshape(inputX, [])
	inputList = tf.split(axis=, num_or_size_splits=, value=)
	targetIxs = tf.placeholder()
	targetVals = tf.placeholder()
	targetShape = tf.placeholder()
	targetY = tf.SparseTensor()
	seqLengths = tf.placeholder(tf.int32, shape=)
	stddev = np.sqrt(2.0 / ())
	truncated_normal = tf.truncated_normal([], stddev=)
	weightsOutH1 = tf.Variable()
	biasesOutH1 = tf.Variable(tf.zeros([]))
	weightsOutH2 = tf.Variable()
	biasesOutH2 = tf.Variable(tf.zeros([]))
	half_normal = tf.truncated_normal([], stddev=np.sqrt())
	weightsClasses = tf.Variable()
	biasesClasses = tf.Variable(tf.zeros([]))
	forwardH1 = rnn_cell.LSTMCell(nHidden, use_peepholes=, state_is_tuple=)
	backwardH1 = rnn_cell.LSTMCell(nHidden, use_peepholes=, state_is_tuple=)
	fbH1, _, _ = bidirectional_rnn(forwardH1, backwardH1, inputList, dtype=, scope=)
	fbH1rs = [tf.reshape(t, []) for t in fbH1]
	outH1 = [tf.reduce_sum(tf.multiply(), axis=) + biasesOutH1 for t in fbH1rs]
	logits = [tf.matmul() + biasesClasses for t in outH1]
	logits3d = tf.stack()
	loss = tf.reduce_mean(ctc.ctc_loss())
	out = tf.identity()
	optimizer = tf.train.MomentumOptimizer().minimize()
	logitsMaxTest = tf.slice(tf.argmax(), [], [seqLengths[], 1])
	predictions = tf.to_int32(ctc.ctc_beam_search_decoder()[][])
	reduced_sum = tf.reduce_sum(tf.edit_distance(predictions, targetY, normalize=))
	errorRate = reduced_sum / tf.to_float(tf.size())
	check_op = tf.add_check_numerics_ops()
with tf.Session(graph=) as session:
	try: merged = tf.summary.merge_all()
	except: merged = tf.summary.merge_all()
	try:writer = tf.summary.FileWriter()
	except: writer = tf.summary.FileWriter()
	try:saver = tf.train.Saver()
	except:
		saver = tf.train.Saver(tf.global_variables())
	ckpt = tf.train.get_checkpoint_state()
	start =
	if ckpt and ckpt.model_checkpoint_path:
		p = re.compile()
		m = p.match()
		try:start = int(m.group())
		except:
	if saver and start > 0:
		saver.restore()
	else:
		try: session.run(tf.global_variables_initializer())
		except:session.run(tf.global_variables_initializer())
	for epoch in range():
		errors = np.zeros(len())
		RandIxs = np.random.permutation(len())
		for Nr, OrigI in enumerate():
			Inputs, TargetSparse, SeqLengths = edData[]
			indices, values, shape =
			feedDict = {inputX:, targetIxs:, targetVals:, targetShape:, seqLengths:}
			_, l, er, lmt, ok = session.run([], feed_dict=)
			if () == 0:
			errors[] = er * len()
		epochErrorRate = errors.sum() / totalN
		if saver:saver.save(session, "", global_step=)
import tensorflow as tf
import numpy as np
import datetime
import os
import argparse
import matplotlib.pyplot as plt
from matplotlib import gridspec
from tensorflow.examples.tutorials.mnist import input_data
mnist = input_data.read_data_sets("", one_hot=)
input_dim =
n_l1 =
n_l2 =
z_dim =
batch_size =
n_epochs =
learning_rate =
beta1 =
results_path =
n_labels =
x_input = tf.placeholder(dtype=, shape=[], name=)
y_input = tf.placeholder(dtype=, shape=[], name=)
x_target = tf.placeholder(dtype=, shape=[], name=)
real_distribution = tf.placeholder(dtype=, shape=[], name=)
manual_decoder_input = tf.placeholder(dtype=, shape=[], name=)
def form_results():
    folder_name = 
    tensorboard_path =
    saved_model_path =
    log_path =
    if not os.path.exists():
        os.mkdir()
    return tensorboard_path, saved_model_path, log_path
def generate_image_grid():
    nx, ny =, 10
    random_inputs = np.random.randn() * 5.
    sample_y = np.identity()
    plt.subplot()
    gs = gridspec.GridSpec(nx, ny, hspace=, wspace=)
    i =
    for r in random_inputs:
        for t in sample_y:
            r, t = np.reshape(r, ()), np.reshape(t, ())
            dec_input = np.concatenate((), 1)
            x = sess.run(op, feed_dict={manual_decoder_input:})
            ax = plt.subplot(gs[])
            i +=
            img = np.array(x.tolist()).reshape()
            ax.imshow(img, cmap=)
            ax.set_xticks([])
            ax.set_yticks([])
            ax.set_aspect()
    plt.show()
def dense():
    with tf.variable_scope(name, reuse=):
        weights = tf.get_variable("", shape=[],initializer=tf.random_normal_initializer(mean=, stddev=))
        bias = tf.get_variable("", shape=[], initializer=tf.constant_initializer())
        out = tf.add(tf.matmul(), bias, name=)
        return out
def encoder(x, reuse=):
    if reuse:
        tf.get_variable_scope().reuse_variables()
    with tf.name_scope():
        e_dense_1 = tf.nn.relu(dense())
        e_dense_2 = tf.nn.relu(dense())
        latent_variable = dense()
        return latent_variable
def decoder(x, reuse=):
    if reuse:
        tf.get_variable_scope().reuse_variables()
    with tf.name_scope():
        d_dense_1 = tf.nn.relu(dense())
        d_dense_2 = tf.nn.relu(dense())
        output = tf.nn.sigmoid(dense())
        return output
def discriminator(x, reuse=):
    if reuse:
        tf.get_variable_scope().reuse_variables()
    with tf.name_scope():
        dc_den1 = tf.nn.relu(dense(x, z_dim, n_l1, name=))
        dc_den2 = tf.nn.relu(dense(dc_den1, n_l1, n_l2, name=))
        output = dense(dc_den2, n_l2, 1, name=)
        return output
def train(train_model=):
    with tf.variable_scope(tf.get_variable_scope()):
        encoder_output = encoder()
        decoder_input = tf.concat([], 1)
        decoder_output = decoder()
    with tf.variable_scope(tf.get_variable_scope()):
        d_real = discriminator()
        d_fake = discriminator(encoder_output, reuse=)
    with tf.variable_scope(tf.get_variable_scope()):
        decoder_image = decoder(manual_decoder_input, reuse=)
    autoencoder_loss = tf.reduce_mean(tf.square())
    dc_loss_real = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=tf.ones_like(), logits=))
    dc_loss_fake = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=tf.zeros_like(), logits=))
    dc_loss =
    generator_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=tf.ones_like(), logits=))
    all_variables = tf.trainable_variables()
    dc_var = []
    en_var = []
    autoencoder_optimizer = tf.train.AdamOptimizer(learning_rate=,beta1=).minimize()
    discriminator_optimizer = tf.train.AdamOptimizer(learning_rate=,beta1=).minimize(dc_loss, var_list=)
    generator_optimizer = tf.train.AdamOptimizer(learning_rate=,beta1=).minimize(generator_loss, var_list=)
    init = tf.global_variables_initializer()
    input_images = tf.reshape(x_input, [])
    generated_images = tf.reshape(decoder_output, [])
    tf.summary.scalar(name=, tensor=)
    tf.summary.scalar(name=, tensor=)
    tf.summary.scalar(name=, tensor=)
    tf.summary.histogram(name=, values=)
    tf.summary.histogram(name=, values=)
    tf.summary.image(name=, tensor=, max_outputs=)
    tf.summary.image(name=, tensor=, max_outputs=)
    summary_op = tf.summary.merge_all()
    saver = tf.train.Saver()
    step =
    with tf.Session() as sess:
        if train_model:
            tensorboard_path, saved_model_path, log_path = form_results()
            sess.run()
            writer = tf.summary.FileWriter(logdir=, graph=)
            for i in range():
                n_batches = int()
                for b in range():
                    z_real_dist = np.random.randn() * 5.
                    batch_x, batch_y = mnist.train.next_batch()
                    sess.run(autoencoder_optimizer, feed_dict={x_input:, x_target:, y_input:})
                    sess.run(discriminator_optimizer,feed_dict={x_input:, x_target:, real_distribution:})
                    sess.run(generator_optimizer, feed_dict={x_input:, x_target:})
                    if b % 50 == 0:
                        a_loss, d_loss, g_loss, summary = sess.run([],feed_dict={x_input:, x_target:,real_distribution:, y_input:})
                        writer.add_summary(summary, global_step=)
                        with open() as log:
                    step +=
                saver.save(sess, save_path=, global_step=)
        else:
            all_results = os.listdir()
            all_results.sort()
            saver.restore(sess, save_path=tf.train.latest_checkpoint(results_path + "" +all_results[] + ""))
            generate_image_grid(sess, op=)
if __name__ == "__main__":
    parser = argparse.ArgumentParser(description=)
    parser.add_argument("", "", type=, default=,help=, False to load weights and display image grid')
    args = parser.parse_args()
    train(train_model=)
__author__ =
import math
import numpy as np
from tqdm import tqdm
import tensorflow as tf
from tensorflow.contrib import rnn
from utils import uniform_tensor, get_sequence_actual_length, zero_nil_slot, shuffle_matrix
def get_activation(activation=):
    if activation is None:
        return None
    elif activation == "":
        return tf.nn.tanh
    elif activation == "":
        return tf.nn.relu
    elif activation == "":
        return tf.nn.softmax
    elif activation == "":
        return tf.sigmoid
    else:
        raise Exception('Unknow activation function:)
class MultiConvolutional3D():
    def __init__(self, input_data, filter_length_list, nb_filter_list, padding=,activation=, pooling=, name=):
        char_dim = int(input_data.get_shape()[])
        self._input_data = tf.expand_dims()
        self._filter_length_list =
        self._nb_filter_list =
        self._padding =
        self._activation = get_activation()
        self._name =
        pooling_outpouts = []
        for i in range(len()):
            filter_length = self._filter_length_list[]
            nb_filter = self._nb_filter_list[]
            with tf.variable_scope("") as scope:
                conv_output = tf.contrib.layers.conv3d(inputs=,num_outputs=,kernel_size=[],padding=)
                act_output = (conv_output if activation is Noneelse self._activation())
                if pooling == "":
                    pooling_output = tf.reduce_max(tf.squeeze(act_output, []), 2)
                elif pooling == "":
                    pooling_output = tf.reduce_mean(tf.squeeze(act_output, []), 2)
                else:
                    raise Exception()
                pooling_outpouts.append()
                scope.reuse_variables()
        self._output = tf.concat(pooling_outpouts, axis=)
    def output():
        return self._output
    def output_dim():
        return sum()
class SequenceLabelingModel():
    def __init__(self, sequence_length, nb_classes, nb_hidden=, num_layers=,rnn_dropout=, feature_names=, feature_init_weight_dict=,feature_weight_shape_dict=, feature_weight_dropout_dict=,dropout_rate=, use_crf=, path_model=, nb_epoch=,batch_size=, train_max_patience=, l2_rate=, rnn_unit=,learning_rate=, clip=, use_char_feature=, word_length=,conv_filter_size_list=, conv_filter_len_list=, cnn_dropout_rate=):
        self._sequence_length =
        self._nb_classes =
        self._nb_hidden =
        self._num_layers =
        self._rnn_dropout =
        self._feature_names =
        self._feature_init_weight_dict = feature_init_weight_dict if feature_init_weight_dict else dict()
        self._feature_weight_shape_dict =
        self._feature_weight_dropout_dict =
        self._dropout_rate =
        self._use_crf =
        self._path_model =
        self._nb_epoch =
        self._batch_size =
        self._train_max_patience =
        self._l2_rate =
        self._rnn_unit =
        self._learning_rate =
        self._clip =
        self._use_char_feature =
        self._word_length =
        self._conv_filter_len_list =
        self._conv_filter_size_list =
        self._cnn_dropout_rate =
        self.input_feature_ph_dict = dict()
        self.weight_dropout_ph_dict = dict()
        self.feature_weight_dict = dict()
        self.nil_vars = set()
        self.dropout_rate_ph = tf.placeholder(tf.float32, name=)
        self.rnn_dropout_rate_ph = tf.placeholder(tf.float32, name=)
        self.input_label_ph = tf.placeholder(dtype=, shape=[], name=)
        if self._use_char_feature:
            self.cnn_dropout_rate_ph = tf.placeholder(tf.float32, name=)
        self.build_model()
    def build_model():
        for feature_name in self._feature_names:
            self.input_feature_ph_dict[] = tf.placeholder(dtype=, shape=[],name=)
            self.weight_dropout_ph_dict[] = tf.placeholder(tf.float32, name=)
            if feature_name not in self._feature_init_weight_dict:
                feature_weight = uniform_tensor(shape=self._feature_weight_shape_dict[],name=)
                self.feature_weight_dict[] = tf.Variable(initial_value=, name=)
            else:
                self.feature_weight_dict[] = tf.Variable(initial_value=self._feature_init_weight_dict[],name=)
                self.nil_vars.add(self.feature_weight_dict[].name)
            if feature_name not in self._feature_weight_dropout_dict:
                self._feature_weight_dropout_dict[] =
        if self._use_char_feature:
            feature_weight = uniform_tensor(shape=self._feature_weight_shape_dict[], name=)
            self.feature_weight_dict[] = tf.Variable(initial_value=, name=)
            self.nil_vars.add(self.feature_weight_dict[].name)
            self.nil_vars.add(self.feature_weight_dict[].name)
            self.input_feature_ph_dict[] = tf.placeholder(dtype=, shape=[],name=)
        self.embedding_features = []
        for feature_name in self._feature_names:
            embedding_feature = tf.nn.dropout(tf.nn.embedding_lookup(self.feature_weight_dict[],ids=self.input_feature_ph_dict[],name=),keep_prob=1.-self.weight_dropout_ph_dict[],name=)
            self.embedding_features.append()
        if self._use_char_feature:
            char_embedding_feature = tf.nn.embedding_lookup(self.feature_weight_dict[],ids=self.input_feature_ph_dict[],name=)
            couv_feature_char = MultiConvolutional3D(char_embedding_feature, filter_length_list=,nb_filter_list=).output
            couv_feature_char = tf.nn.dropout(couv_feature_char, keep_prob=)
        input_features = self.embedding_features[] if len() == 1 else tf.concat(values=, axis=, name=)
        if self._use_char_feature:
            input_features = tf.concat([], axis=)
        _fw_cells = []
        _bw_cells = []
        for _ in range():
            fw, bw = self._get_rnn_unit()
            _fw_cells.append(tf.nn.rnn_cell.DropoutWrapper(fw, output_keep_prob=))
            _bw_cells.append(tf.nn.rnn_cell.DropoutWrapper(bw, output_keep_prob=))
        fw_cell = tf.nn.rnn_cell.MultiRNNCell()
        bw_cell = tf.nn.rnn_cell.MultiRNNCell()
        self.sequence_actual_length = get_sequence_actual_length(self.input_feature_ph_dict[self._feature_names[]])
        rnn_outputs, _ = tf.nn.bidirectional_dynamic_rnn(fw_cell, bw_cell, input_features, scope=,dtype=, sequence_length=)
        lstm_output = tf.nn.dropout(tf.concat(rnn_outputs, axis=, name=),keep_prob=, name=)
        hidden_size = int(lstm_output.shape[])
        self.outputs = tf.reshape(lstm_output, [], name=)
        self.softmax_w = tf.get_variable("", [])
        self.softmax_b = tf.get_variable("", [])
        self.logits = tf.reshape(tf.matmul() + self.softmax_b,shape=[], name=)
        self.loss = self.compute_loss()
        self.l2_loss = self._l2_rate * (tf.nn.l2_loss() + tf.nn.l2_loss())
        self.total_loss =
        optimizer = tf.train.AdamOptimizer(learning_rate=)
        grads_and_vars = optimizer.compute_gradients()
        nil_grads_and_vars = []
        for g, v in grads_and_vars:
            if v.name in self.nil_vars:
                nil_grads_and_vars.append((zero_nil_slot(), v))
            else:
                nil_grads_and_vars.append(())
        global_step = tf.Variable(0, name=, trainable=)
        if self._clip:
            gradients, variables = zip()
            gradients, _ = tf.clip_by_global_norm()
            self.train_op = optimizer.apply_gradients(zip(), name=, global_step=)
        else:
            self.train_op = optimizer.apply_gradients(nil_grads_and_vars, name=, global_step=)
        gpu_options = tf.GPUOptions(visible_device_list=, allow_growth=)
        self.sess = tf.Session(config=tf.ConfigProto(gpu_options=))
        init = tf.global_variables_initializer()
        self.sess.run()
    def _get_rnn_unit():
        if rnn_unit == "":
            fw_cell = rnn.BasicLSTMCell(self._nb_hidden, forget_bias=, state_is_tuple=)
            bw_cell = rnn.BasicLSTMCell(self._nb_hidden, forget_bias=, state_is_tuple=)
        elif rnn_unit == "":
            fw_cell = rnn.GRUCell()
            bw_cell = rnn.GRUCell()
        else:
            raise ValueError()
        return fw_cell, bw_cell
    def fit(self, data_dict, dev_size=, seed=):
        data_train_dict, data_dev_dict = self.split_train_dev(data_dict, dev_size=)
        self.saver = tf.train.Saver()
        train_data_count = data_train_dict[].shape[]
        nb_train = int(math.ceil(train_data_count / float()))
        min_dev_loss =
        current_patience =
        for step in range():
            data_list = [data_train_dict[]]
            [data_list.append(data_train_dict[]) for name in self._feature_names]
            shuffle_matrix(*data_list, seed=)
            train_loss, l2_loss =, 0.
            for i in tqdm(range()):
                feed_dict = dict()
                batch_indices = np.arange(i * self._batch_size, () * self._batch_size) if ()*self._batch_size <= train_data_count else np.arange()
                for feature_name in self._feature_names:
                    batch_data = data_train_dict[][]
                    item = {self.input_feature_ph_dict[]:}
                    feed_dict.update()
                    dropout_rate = self._feature_weight_dropout_dict[]
                    item = {self.weight_dropout_ph_dict[]:}
                    feed_dict.update()
                if self._use_char_feature:
                    batch_data = data_train_dict[][]
                    item = {self.input_feature_ph_dict[]:}
                    feed_dict.update()
                    item = {self.cnn_dropout_rate_ph:}
                    feed_dict.update()
                feed_dict.update({self.dropout_rate_ph:,self.rnn_dropout_rate_ph:,})
                batch_label = data_train_dict[][]
                feed_dict.update({self.input_label_ph:})
                _, loss, l2_loss = self.sess.run([], feed_dict=)
                train_loss +=
            train_loss /= float()
            dev_loss = self.evaluate()
            if not self._path_model:
                continue
            if dev_loss < min_dev_loss:
                min_dev_loss =
                current_patience =
                self.saver.save()
            else:
                current_patience +=
                if self._train_max_patience and current_patience >= self._train_max_patience:
                    return
        return
    def split_train_dev(self, data_dict, dev_size=):
        data_train_dict, data_dev_dict = dict(), dict()
        for name in data_dict.keys():
            boundary = int(() * data_dict[].shape[])
            data_train_dict[] = data_dict[][:]
            data_dev_dict[] = data_dict[][boundary:]
        return data_train_dict, data_dev_dict
    def evaluate():
        data_count = data_dict[].shape[]
        nb_eval = int(math.ceil(data_count / float()))
        eval_loss =
        for i in range():
            feed_dict = dict()
            batch_indices = np.arange(i * self._batch_size, () * self._batch_size) if ()*self._batch_size <= data_count else np.arange()
            for feature_name in self._feature_names:
                batch_data = data_dict[][]
                item = {self.input_feature_ph_dict[]:}
                feed_dict.update()
                item = {self.weight_dropout_ph_dict[]:}
                feed_dict.update()
            if self._use_char_feature:
                batch_data = data_dict[][]
                item = {self.input_feature_ph_dict[]:}
                feed_dict.update()
                item = {self.cnn_dropout_rate_ph:}
                feed_dict.update()
            feed_dict.update({self.dropout_rate_ph:, self.rnn_dropout_rate_ph:})
            batch_label = data_dict[][]
            feed_dict.update({self.input_label_ph:})
            loss = self.sess.run(self.loss, feed_dict=)
            eval_loss +=
        eval_loss /= float()
        return eval_loss
    def predict():
        data_count = data_test_dict[self._feature_names[]].shape[]
        nb_test = int(math.ceil(data_count / float()))
        result_sequences = []
        for i in tqdm(range()):
            feed_dict = dict()
            batch_indices = np.arange(i * self._batch_size, () * self._batch_size) if ()*self._batch_size <= data_count else np.arange()
            for feature_name in self._feature_names:
                batch_data = data_test_dict[][]
                item = {self.input_feature_ph_dict[]:}
                feed_dict.update()
                item = {self.weight_dropout_ph_dict[]:}
                feed_dict.update()
            if self._use_char_feature:
                batch_data = data_test_dict[][]
                item = {self.input_feature_ph_dict[]:}
                feed_dict.update()
                item = {self.cnn_dropout_rate_ph:}
                feed_dict.update()
            feed_dict.update({self.dropout_rate_ph:, self.rnn_dropout_rate_ph:})
            if self._use_crf:
                logits, sequence_actual_length, transition_params = self.sess.run([], feed_dict=)
                for logit, seq_len in zip():
                    logit_actual = logit[:]
                    viterbi_sequence, _ = tf.contrib.crf.viterbi_decode()
                    result_sequences.append()
            else:
                logits, sequence_actual_length = self.sess.run([], feed_dict=)
                for logit, seq_len in zip():
                    logit_actual = logit[:]
                    sequence = np.argmax(logit_actual, axis=)
                    result_sequences.append()
        return result_sequences
    def compute_loss():
        if not self._use_crf:
            labels = tf.reshape(tf.contrib.layers.one_hot_encoding(tf.reshape(self.input_label_ph, []), num_classes=),shape=[])
            logits = tf.nn.softmax(self.logits, dim=)
            cross_entropy = -tf.reduce_sum(labels * tf.log(), axis=)
            mask = tf.sign(tf.reduce_max(tf.abs(), axis=))
            cross_entropy_masked = tf.reduce_sum(cross_entropy*mask, axis=) / tf.cast()
            return tf.reduce_mean()
        else:
            log_likelihood, self.transition_params = tf.contrib.crf.crf_log_likelihood()
            return tf.reduce_mean()
import json
import struct
import tensorflow as tf
from tensorflow.python.tools.freeze_graph import freeze_graph
import cv2
import numpy as np
import os
import tempfile
from posenet.converter.config import load_config
BASE_DIR = os.path.join(tempfile.gettempdir(), "")
def to_output_strided_layers():
    current_stride =
    rate =
    block_id =
    buff = []
    for _a in convolution_def:
        conv_type = _a[]
        stride = _a[]
        if current_stride == output_stride:
            layer_stride =
            layer_rate =
            rate *=
        else:
            layer_stride =
            layer_rate =
            current_stride *=
        buff.append({'blockId':,'convType':,'stride':,'rate':,'outputStride':})
        block_id +=
    return buff
def load_variables(chkpoint, base_dir=):
    manifest_path = os.path.join()
    if not os.path.exists():
        from posenet.converter.wget import download
        download()
    with open() as f:
        variables = json.load()
    for x in variables:
        filename = variables[][]
        byte = open(os.path.join(), "").read()
        fmt = str(int(len() / struct.calcsize())) + ""
        d = struct.unpack()
        d = tf.cast()
        d = tf.reshape(d, variables[][])
        variables[][] = tf.Variable(d, name=)
    return variables
def _read_imgfile():
    img = cv2.imread()
    img = cv2.resize(img, ())
    img = cv2.cvtColor()
    img = img.astype()
    img = img * () - 1.0
    return img
def build_network():
    def _weights():
        return variables[][]
    def _biases():
        return variables[][]
    def _depthwise_weights():
        return variables[][]
    def _conv_to_output():
        w = tf.nn.conv2d(mobile_net_output, _weights(), [], padding=)
        w = tf.nn.bias_add(w, _biases(), name=)
        return w
    def _conv():
        return tf.nn.relu6(tf.nn.conv2d(inputs, _weights("" + str()), stride, padding=)+ _biases("" + str()))
    def _separable_conv():
        if dilations is None:
            dilations = []
        dw_layer = "" + str() + ""
        pw_layer = "" + str() + ""
        w = tf.nn.depthwise_conv2d(inputs, _depthwise_weights(), stride, "", rate=, data_format=)
        w = tf.nn.bias_add(w, _biases())
        w = tf.nn.relu6()
        w = tf.nn.conv2d(w, _weights(), [], padding=)
        w = tf.nn.bias_add(w, _biases())
        w = tf.nn.relu6()
        return w
    x =
    buff = []
    with tf.variable_scope():
        for m in layers:
            stride = [1, m[], m[], 1]
            rate = [m[], m[]]
            if m[] == "":
                x = _conv(x, stride, m[])
                buff.append()
            elif m[] == "":
                x = _separable_conv(x, stride, m[], rate)
                buff.append()
    heatmaps = _conv_to_output()
    offsets = _conv_to_output()
    displacement_fwd = _conv_to_output()
    displacement_bwd = _conv_to_output()
    heatmaps = tf.sigmoid()
    return heatmaps, offsets, displacement_fwd, displacement_bwd
def convert(model_id, model_dir, check=):
    cfg = load_config()
    checkpoints = cfg[]
    image_size = cfg[]
    output_stride = cfg[]
    chkpoint = checkpoints[]
    if chkpoint == "":
        mobile_net_arch = cfg[]
    elif chkpoint == "":
        mobile_net_arch = cfg[]
    else:
        mobile_net_arch = cfg[]
    width =
    height =
    if not os.path.exists():
        os.makedirs()
    cg = tf.Graph()
    with cg.as_default():
        layers = to_output_strided_layers()
        variables = load_variables()
        init = tf.global_variables_initializer()
        with tf.Session() as sess:
            sess.run()
            saver = tf.train.Saver()
            image_ph = tf.placeholder(tf.float32, shape=[], name=)
            outputs = build_network()
            sess.run([],feed_dict={image_ph:,})
            save_path = os.path.join()
            if not os.path.exists(os.path.dirname()):
                os.makedirs(os.path.dirname())
            checkpoint_path = saver.save(sess, save_path, write_state=)
            tf.train.write_graph()
            freeze_graph(input_graph=os.path.join(),input_saver=,input_binary=,input_checkpoint=,output_node_names=,offset_2,displacement_fwd_2,displacement_bwd_2""save/Const:,output_graph=os.path.join(),clear_devices=,initializer_nodes=)
            if check and os.path.exists():
                input_image = _read_imgfile()
                input_image = np.array(input_image, dtype=)
                input_image = input_image.reshape()
                heatmaps_result, offsets_result, displacement_fwd_result, displacement_bwd_result = sess.run(outputs,feed_dict={image_ph:})
                heatmaps_result = heatmaps_result[]
import os
import unittest
import tensorflow as tf
import tensorlayer as tl
from tests.utils import CustomTestCase
os.environ[] =
class Simple_MNIST_Test():
    def setUpClass():
        cls.x = tf.placeholder(tf.float32, shape=[], name=)
        cls.y_ = tf.placeholder(tf.int64, shape=[], name=)
        network = tl.layers.InputLayer(cls.x, name=)
        network = tl.layers.DropoutLayer(network, keep=, name=)
        network = tl.layers.DenseLayer(network, n_units=, act=, name=)
        network = tl.layers.DropoutLayer(network, keep=, name=)
        network = tl.layers.DenseLayer(network, n_units=, act=, name=)
        network = tl.layers.DropoutLayer(network, keep=, name=)
        cls.network = tl.layers.DenseLayer(network, n_units=, name=)
        y =
        cls.cost = tl.cost.cross_entropy(y, cls.y_, name=)
        correct_prediction = tf.equal(tf.argmax(), cls.y_)
        cls.acc = tf.reduce_mean(tf.cast())
        train_params =
        cls.train_op = tf.train.AdamOptimizer(learning_rate=).minimize(cls.cost, var_list=)
    def tearDownClass():
        tf.reset_default_graph()
    def test_reuse_vgg():
        X_train, y_train, X_val, y_val, X_test, y_test = tl.files.load_mnist_dataset(shape=())
        with self.assertNotRaises():
            with tf.Session() as sess:
                tl.layers.initialize_global_variables()
                self.network.print_params()
                self.network.print_layers()
                tl.utils.fit(sess, self.network, self.train_op, self.cost, X_train, y_train, self.x, self.y_, acc=,batch_size=, n_epoch=, print_freq=, X_val=, y_val=, eval_train=)
                tl.utils.test(sess, self.network, self.acc, X_test, y_test, self.x, self.y_, batch_size=, cost=)
                tl.files.save_npz(self.network.all_params, name=)
                sess.close()
if __name__ == "__main__":
    tf.logging.set_verbosity()
    tl.logging.set_verbosity()
    unittest.main()
import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.gridspec as gridspec
import os
from tensorflow.examples.tutorials.mnist import input_data
mnist = input_data.read_data_sets("", one_hot=)
mb_size =
z_dim =
X_dim = mnist.train.images.shape[]
y_dim = mnist.train.labels.shape[]
h_dim =
c =
lr =
def plot():
    fig = plt.figure(figsize=())
    gs = gridspec.GridSpec()
    gs.update(wspace=, hspace=)
    for i, sample in enumerate():
        ax = plt.subplot(gs[])
        plt.axis()
        ax.set_xticklabels([])
        ax.set_yticklabels([])
        ax.set_aspect()
        plt.imshow(sample.reshape(), cmap=)
    return fig
def xavier_init():
    in_dim = size[]
    xavier_stddev = 1. / tf.sqrt()
    return tf.random_normal(shape=, stddev=)
X = tf.placeholder(tf.float32, shape=[])
z = tf.placeholder(tf.float32, shape=[])
Q_W1 = tf.Variable(xavier_init([]))
Q_b1 = tf.Variable(tf.zeros(shape=[]))
Q_W2 = tf.Variable(xavier_init([]))
Q_b2 = tf.Variable(tf.zeros(shape=[]))
theta_Q = []
def Q():
    h = tf.nn.relu(tf.matmul() + Q_b1)
    z = tf.matmul() + Q_b2
    return z
P_W1 = tf.Variable(xavier_init([]))
P_b1 = tf.Variable(tf.zeros(shape=[]))
P_W2 = tf.Variable(xavier_init([]))
P_b2 = tf.Variable(tf.zeros(shape=[]))
theta_P = []
def P():
    h = tf.nn.relu(tf.matmul() + P_b1)
    logits = tf.matmul() + P_b2
    prob = tf.nn.sigmoid()
    return prob, logits
D_W1 = tf.Variable(xavier_init([]))
D_b1 = tf.Variable(tf.zeros(shape=[]))
D_W2 = tf.Variable(xavier_init([]))
D_b2 = tf.Variable(tf.zeros(shape=[]))
theta_D = []
def D():
    h = tf.nn.relu(tf.matmul() + D_b1)
    logits = tf.matmul() + D_b2
    prob = tf.nn.sigmoid()
    return prob
z_sample = Q()
_, logits = P()
X_samples, _ = P()
recon_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=, labels=))
D_real = D()
D_fake = D()
D_loss = -tf.reduce_mean(tf.log() + tf.log())
G_loss = -tf.reduce_mean(tf.log())
AE_solver = tf.train.AdamOptimizer().minimize(recon_loss, var_list=)
D_solver = tf.train.AdamOptimizer().minimize(D_loss, var_list=)
G_solver = tf.train.AdamOptimizer().minimize(G_loss, var_list=)
sess = tf.Session()
sess.run(tf.global_variables_initializer())
if not os.path.exists():
    os.makedirs()
i =
for it in range():
    X_mb, _ = mnist.train.next_batch()
    z_mb = np.random.randn()
    _, recon_loss_curr = sess.run([], feed_dict={X:})
    _, D_loss_curr = sess.run([], feed_dict={X:, z:})
    _, G_loss_curr = sess.run([], feed_dict={X:})
    if it % 1000 == 0:
        samples = sess.run(X_samples, feed_dict={z:})
        fig = plot()
        plt.savefig("".zfill()), bbox_inches=)
        i +=
        plt.close()
import tensorflow as tf
from tensorflow.examples.tutorials.mnist import input_data
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.gridspec as gridspec
import os
mnist = input_data.read_data_sets("", one_hot=)
mb_size =
X_dim = mnist.train.images.shape[]
y_dim = mnist.train.labels.shape[]
z_dim =
h_dim =
eps =
lr =
d_steps =
def plot():
    fig = plt.figure(figsize=())
    gs = gridspec.GridSpec()
    gs.update(wspace=, hspace=)
    for i, sample in enumerate():
        ax = plt.subplot(gs[])
        plt.axis()
        ax.set_xticklabels([])
        ax.set_yticklabels([])
        ax.set_aspect()
        plt.imshow(sample.reshape(), cmap=)
    return fig
def xavier_init():
    in_dim = size[]
    xavier_stddev = 1. / tf.sqrt()
    return tf.random_normal(shape=, stddev=)
X = tf.placeholder(tf.float32, shape=[])
y = tf.placeholder(tf.float32, shape=[])
z = tf.placeholder(tf.float32, shape=[])
G_W1 = tf.Variable(xavier_init([]))
G_b1 = tf.Variable(tf.zeros(shape=[]))
G_W2 = tf.Variable(xavier_init([]))
G_b2 = tf.Variable(tf.zeros(shape=[]))
def generator():
    inputs = tf.concat(axis=, values=[])
    G_h1 = tf.nn.relu(tf.matmul() + G_b1)
    G_log_prob = tf.matmul() + G_b2
    G_prob = tf.nn.sigmoid()
    return G_prob
D_W1 = tf.Variable(xavier_init([]))
D_b1 = tf.Variable(tf.zeros(shape=[]))
D_W2_gan = tf.Variable(xavier_init([]))
D_b2_gan = tf.Variable(tf.zeros(shape=[]))
D_W2_aux = tf.Variable(xavier_init([]))
D_b2_aux = tf.Variable(tf.zeros(shape=[]))
def discriminator():
    D_h1 = tf.nn.relu(tf.matmul() + D_b1)
    out_gan = tf.nn.sigmoid(tf.matmul() + D_b2_gan)
    out_aux = tf.matmul() + D_b2_aux
    return out_gan, out_aux
theta_G = []
theta_D = []
def sample_z():
    return np.random.uniform(-1., 1., size=[])
def cross_entropy():
    return -tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=, labels=))
G_sample = generator()
D_real, C_real = discriminator()
D_fake, C_fake = discriminator()
C_loss = cross_entropy() + cross_entropy()
D_loss = tf.reduce_mean(tf.log() + tf.log())
DC_loss = -()
G_loss = tf.reduce_mean(tf.log())
GC_loss = -()
D_solver = (tf.train.AdamOptimizer(learning_rate=).minimize(DC_loss, var_list=))
G_solver = (tf.train.AdamOptimizer(learning_rate=).minimize(GC_loss, var_list=))
sess = tf.Session()
sess.run(tf.global_variables_initializer())
if not os.path.exists():
    os.makedirs()
i =
for it in range():
    X_mb, y_mb = mnist.train.next_batch()
    z_mb = sample_z()
    _, DC_loss_curr = sess.run([],feed_dict={X:, y:, z:})
    _, GC_loss_curr = sess.run([],feed_dict={X:, y:, z:})
    if it % 1000 == 0:
        idx = np.random.randint()
        c = np.zeros([])
        c[range(), idx] =
        samples = sess.run(G_sample, feed_dict={z:, y:})
        fig = plot()
        plt.savefig("".zfill()), bbox_inches=)
        i +=
        plt.close()
import tensorflow as tf
from tensorflow.examples.tutorials.mnist import input_data
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.gridspec as gridspec
import os
mb_size =
X_dim =
z_dim =
h_dim =
lr =
d_steps =
mnist = input_data.read_data_sets("", one_hot=)
def plot():
    fig = plt.figure(figsize=())
    gs = gridspec.GridSpec()
    gs.update(wspace=, hspace=)
    for i, sample in enumerate():
        ax = plt.subplot(gs[])
        plt.axis()
        ax.set_xticklabels([])
        ax.set_yticklabels([])
        ax.set_aspect()
        plt.imshow(sample.reshape(), cmap=)
    return fig
def xavier_init():
    in_dim = size[]
    xavier_stddev = 1. / tf.sqrt()
    return tf.random_normal(shape=, stddev=)
def log():
    return tf.log()
X = tf.placeholder(tf.float32, shape=[])
z = tf.placeholder(tf.float32, shape=[])
D_W1 = tf.Variable(xavier_init([]))
D_b1 = tf.Variable(tf.zeros(shape=[]))
D_W2 = tf.Variable(xavier_init([]))
D_b2 = tf.Variable(tf.zeros(shape=[]))
Q_W1 = tf.Variable(xavier_init([]))
Q_b1 = tf.Variable(tf.zeros(shape=[]))
Q_W2 = tf.Variable(xavier_init([]))
Q_b2 = tf.Variable(tf.zeros(shape=[]))
P_W1 = tf.Variable(xavier_init([]))
P_b1 = tf.Variable(tf.zeros(shape=[]))
P_W2 = tf.Variable(xavier_init([]))
P_b2 = tf.Variable(tf.zeros(shape=[]))
theta_G = []
theta_D = []
def sample_z():
    return np.random.uniform(-1., 1., size=[])
def Q():
    h = tf.nn.relu(tf.matmul() + Q_b1)
    h = tf.matmul() + Q_b2
    return h
def P():
    h = tf.nn.relu(tf.matmul() + P_b1)
    h = tf.matmul() + P_b2
    return tf.nn.sigmoid()
def D():
    inputs = tf.concat([], axis=)
    h = tf.nn.relu(tf.matmul() + D_b1)
    return tf.nn.sigmoid(tf.matmul() + D_b2)
z_hat = Q()
X_hat = P()
D_enc = D()
D_gen = D()
D_loss = -tf.reduce_mean(log() + log())
G_loss = -tf.reduce_mean(log() + log())
D_solver = (tf.train.AdamOptimizer(learning_rate=).minimize(D_loss, var_list=))
G_solver = (tf.train.AdamOptimizer(learning_rate=).minimize(G_loss, var_list=))
sess = tf.Session()
sess.run(tf.global_variables_initializer())
if not os.path.exists():
    os.makedirs()
i =
for it in range():
    X_mb, _ = mnist.train.next_batch()
    z_mb = sample_z()
    _, D_loss_curr = sess.run([], feed_dict={X:, z:})
    _, G_loss_curr = sess.run([], feed_dict={X:, z:})
    if it % 1000 == 0:
        samples = sess.run(X_hat, feed_dict={z:})
        fig = plot()
        plt.savefig("".zfill()), bbox_inches=)
        i +=
        plt.close()
import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.gridspec as gridspec
import os
from torch.autograd import Variable
from tensorflow.examples.tutorials.mnist import input_data
mnist = input_data.read_data_sets("", one_hot=)
mb_size =
z_dim =
eps_dim =
X_dim = mnist.train.images.shape[]
y_dim = mnist.train.labels.shape[]
h_dim =
c =
lr =
def log():
    return tf.log()
def plot():
    fig = plt.figure(figsize=())
    gs = gridspec.GridSpec()
    gs.update(wspace=, hspace=)
    for i, sample in enumerate():
        ax = plt.subplot(gs[])
        plt.axis()
        ax.set_xticklabels([])
        ax.set_yticklabels([])
        ax.set_aspect()
        plt.imshow(sample.reshape(), cmap=)
    return fig
def xavier_init():
    in_dim = size[]
    xavier_stddev = 1. / tf.sqrt()
    return tf.random_normal(shape=, stddev=)
X = tf.placeholder(tf.float32, shape=[])
z = tf.placeholder(tf.float32, shape=[])
eps = tf.placeholder(tf.float32, shape=[])
Q_W1 = tf.Variable(xavier_init([]))
Q_b1 = tf.Variable(tf.zeros(shape=[]))
Q_W2 = tf.Variable(xavier_init([]))
Q_b2 = tf.Variable(tf.zeros(shape=[]))
theta_Q = []
def Q():
    inputs = tf.concat(axis=, values=[])
    h = tf.nn.relu(tf.matmul() + Q_b1)
    z = tf.matmul() + Q_b2
    return z
P_W1 = tf.Variable(xavier_init([]))
P_b1 = tf.Variable(tf.zeros(shape=[]))
P_W2 = tf.Variable(xavier_init([]))
P_b2 = tf.Variable(tf.zeros(shape=[]))
theta_P = []
def P():
    h = tf.nn.relu(tf.matmul() + P_b1)
    logits = tf.matmul() + P_b2
    prob = tf.nn.sigmoid()
    return prob, logits
D_W1 = tf.Variable(xavier_init([]))
D_b1 = tf.Variable(tf.zeros(shape=[]))
D_W2 = tf.Variable(xavier_init([]))
D_b2 = tf.Variable(tf.zeros(shape=[]))
theta_D = []
def D():
    inputs = tf.concat([], axis=)
    h = tf.nn.relu(tf.matmul() + D_b1)
    return tf.matmul() + D_b2
z_sample = Q()
_, X_logits = P()
D_sample = D()
D_q = tf.nn.sigmoid(D())
D_prior = tf.nn.sigmoid(D())
X_samples, _ = P()
disc = tf.reduce_mean()
nll = tf.reduce_sum(tf.nn.sigmoid_cross_entropy_with_logits(logits=, labels=),axis=)
loglike = -tf.reduce_mean()
elbo =
D_loss = tf.reduce_mean(log() + log())
VAE_solver = tf.train.AdamOptimizer().minimize(-elbo, var_list=)
D_solver = tf.train.AdamOptimizer().minimize(-D_loss, var_list=)
sess = tf.Session()
sess.run(tf.global_variables_initializer())
if not os.path.exists():
    os.makedirs()
i =
for it in range():
    X_mb, _ = mnist.train.next_batch()
    eps_mb = np.random.randn()
    z_mb = np.random.randn()
    _, elbo_curr = sess.run([],feed_dict={X:, eps:, z:})
    _, D_loss_curr = sess.run([],feed_dict={X:, eps:, z:})
    if it % 1000 == 0:
        samples = sess.run(X_samples, feed_dict={z:})
        fig = plot()
        plt.savefig("".zfill()), bbox_inches=)
        i +=
        plt.close()
import tensorflow as tf
from tensorflow.examples.tutorials.mnist import input_data
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.gridspec as gridspec
import os
mb_size =
X_dim =
z_dim =
h_dim =
lr =
m =
lam =
gamma =
k_curr =
mnist = input_data.read_data_sets("", one_hot=)
def plot():
    fig = plt.figure(figsize=())
    gs = gridspec.GridSpec()
    gs.update(wspace=, hspace=)
    for i, sample in enumerate():
        ax = plt.subplot(gs[])
        plt.axis()
        ax.set_xticklabels([])
        ax.set_yticklabels([])
        ax.set_aspect()
        plt.imshow(sample.reshape(), cmap=)
    return fig
def xavier_init():
    in_dim = size[]
    xavier_stddev = 1. / tf.sqrt()
    return tf.random_normal(shape=, stddev=)
X = tf.placeholder(tf.float32, shape=[])
z = tf.placeholder(tf.float32, shape=[])
k = tf.placeholder()
D_W1 = tf.Variable(xavier_init([]))
D_b1 = tf.Variable(tf.zeros(shape=[]))
D_W2 = tf.Variable(xavier_init([]))
D_b2 = tf.Variable(tf.zeros(shape=[]))
G_W1 = tf.Variable(xavier_init([]))
G_b1 = tf.Variable(tf.zeros(shape=[]))
G_W2 = tf.Variable(xavier_init([]))
G_b2 = tf.Variable(tf.zeros(shape=[]))
theta_G = []
theta_D = []
def sample_z():
    return np.random.uniform(-1., 1., size=[])
def G():
    G_h1 = tf.nn.relu(tf.matmul() + G_b1)
    G_log_prob = tf.matmul() + G_b2
    G_prob = tf.nn.sigmoid()
    return G_prob
def D():
    D_h1 = tf.nn.relu(tf.matmul() + D_b1)
    X_recon = tf.matmul() + D_b2
    return tf.reduce_mean(tf.reduce_sum(()**2, 1))
G_sample = G()
D_real = D()
D_fake = D()
D_loss =
G_loss =
D_solver = (tf.train.AdamOptimizer(learning_rate=).minimize(D_loss, var_list=))
G_solver = (tf.train.AdamOptimizer(learning_rate=).minimize(G_loss, var_list=))
sess = tf.Session()
sess.run(tf.global_variables_initializer())
if not os.path.exists():
    os.makedirs()
i =
for it in range():
    X_mb, _ = mnist.train.next_batch()
    _, D_real_curr = sess.run([],feed_dict={X:, z:, k:})
    _, D_fake_curr = sess.run([],feed_dict={X:, z:})
    k_curr = k_curr + lam * ()
    if it % 1000 == 0:
        measure = D_real_curr + np.abs()
        samples = sess.run(G_sample, feed_dict={z:})
        fig = plot()
        plt.savefig("".zfill()), bbox_inches=)
        i +=
        plt.close()
import tensorflow as tf
from tensorflow.examples.tutorials.mnist import input_data
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.gridspec as gridspec
import os
mb_size =
X_dim =
z_dim =
h_dim =
lr =
d_steps =
mnist = input_data.read_data_sets("", one_hot=)
def plot():
    fig = plt.figure(figsize=())
    gs = gridspec.GridSpec()
    gs.update(wspace=, hspace=)
    for i, sample in enumerate():
        ax = plt.subplot(gs[])
        plt.axis()
        ax.set_xticklabels([])
        ax.set_yticklabels([])
        ax.set_aspect()
        plt.imshow(sample.reshape(), cmap=)
    return fig
def xavier_init():
    in_dim = size[]
    xavier_stddev = 1. / tf.sqrt()
    return tf.random_normal(shape=, stddev=)
def log():
    return tf.log()
X = tf.placeholder(tf.float32, shape=[])
z = tf.placeholder(tf.float32, shape=[])
D_W1 = tf.Variable(xavier_init([]))
D_b1 = tf.Variable(tf.zeros(shape=[]))
D_W2 = tf.Variable(xavier_init([]))
D_b2 = tf.Variable(tf.zeros(shape=[]))
G_W1 = tf.Variable(xavier_init([]))
G_b1 = tf.Variable(tf.zeros(shape=[]))
G_W2 = tf.Variable(xavier_init([]))
G_b2 = tf.Variable(tf.zeros(shape=[]))
theta_G = []
theta_D = []
def sample_z():
    return np.random.uniform(-1., 1., size=[])
def generator():
    G_h1 = tf.nn.relu(tf.matmul() + G_b1)
    G_log_prob = tf.matmul() + G_b2
    G_prob = tf.nn.sigmoid()
    return G_prob
def discriminator():
    D_h1 = tf.nn.relu(tf.matmul() + D_b1)
    out = tf.nn.sigmoid(tf.matmul() + D_b2)
    return out
G_sample = generator()
D_real = discriminator()
D_fake = discriminator()
D_loss = -tf.reduce_mean(log() + log())
G_loss = 0.5 * tf.reduce_mean((log() - log())**2)
D_solver = (tf.train.AdamOptimizer(learning_rate=).minimize(D_loss, var_list=))
G_solver = (tf.train.AdamOptimizer(learning_rate=).minimize(G_loss, var_list=))
sess = tf.Session()
sess.run(tf.global_variables_initializer())
if not os.path.exists():
    os.makedirs()
i =
for it in range():
    X_mb, _ = mnist.train.next_batch()
    z_mb = sample_z()
    _, D_loss_curr = sess.run([],feed_dict={X:, z:})
    _, G_loss_curr = sess.run([],feed_dict={X:, z:})
    if it % 1000 == 0:
        samples = sess.run(G_sample, feed_dict={z:})
        fig = plot()
        plt.savefig("".zfill()), bbox_inches=)
        i +=
        plt.close()
from __future__ import print_function
import time
import numpy as np
import tensorflow as tf
from tensorflow.contrib.tensorboard.plugins import projector
from .tensorboard_util import *
start = int(time.time())
set_tensorboard_run(auto_increment=)
run_tensorboard(restart=)
gpu =
debug =
debug =
visualize_cluster =
slim =
weight_divider =
default_learning_rate =
decay_steps =
decay_size =
save_step =
checkpoint_dir =
if not os.path.exists():
	os.makedirs()
def nop():
def closest_unitary():
	import scipy
	V, __, Wh = scipy.linalg.svd()
	return np.matrix(V.dot())
_cpu = '/cpu:0'
class net():
	def __init__(self, model, data=, input_width=, output_width=, input_shape=, name=,learning_rate=):
		device = '/GPU:0' if gpu else '/cpu:0'
		with tf.device():
			self.session = sess = session = tf.Session()
			self.model =
			self.input_shape = input_shape or []
			self.data =
			if not input_width:
				input_width = self.get_data_shape()
			self.input_width =
			self.last_width =
			self.output_width =
			self.num_classes =
			self.layers = []
			self.learning_rate =
			if not name: name =
			self.name = str()
			if name and os.path.exists():
				return self.load_model()
			self.generate_model()
	def get_data_shape():
		if self.input_shape:
			return self.input_shape[], self.input_shape[]
		try:
			return self.data.shape[], self.data.shape[]
		except:
			raise Exception()
	def generate_model(self, model, name=):
		if not model:
		with tf.name_scope():
			self.keep_prob = tf.placeholder()
			self.train_phase = tf.placeholder(tf.bool, name=)
			with tf.device(): self.global_step = tf.Variable()
		with tf.name_scope():
			if len() == 1:
				self.input_width = self.input_shape[]
			elif self.input_shape:
				self.x = x = self.input = tf.placeholder(tf.float32, [None, self.input_shape[], self.input_shape[]])
				self.last_layer =
				self.last_shape =
			elif self.input_width:
				self.x = x = self.target = tf.placeholder(tf.float32, [])
				self.last_layer =
			else:
				raise Exception()
			self.y = y = self.target = tf.placeholder(tf.float32, [])
		with tf.name_scope():
			model()
		if (self.last_width !=):
			self.classifier()
	def dropout(self, keep_rate=):
		self.add(tf.nn.dropout())
	def fully_connected(self, hidden=, depth=, activation=, dropout=, parent=, norm=):
		return self.dense()
	def denseNet(self, hidden=, depth=, act=, dropout=, norm=):
		if (): print("" + str())
		if (): print(""dense"" + str())
		inputs =
		inputs_width =
		width =
		while depth > 0:
			with tf.name_scope("") as scope:
				nr = len()
				weights = tf.Variable(tf.random_uniform([], minval=, maxval=),name=)
				bias = tf.Variable(tf.random_uniform([], minval=, maxval=),name=)
				dense1 = tf.matmul(inputs, weights, name="" + str()) + bias
				tf.summary.histogram("" + str(), dense1)
				tf.summary.histogram("" + str() + "", tf.nn.zero_fraction())
				tf.summary.histogram("" + str(), weights)
				tf.summary.histogram("" + str() + "", tf.nn.zero_fraction())
				tf.summary.histogram("" + str(), bias)
				if act: dense1 = act()
				if norm: dense1 = self.norm(dense1, lsize=)
				if dropout: dense1 = tf.nn.dropout()
				self.add()
				self.last_width =
				inputs = tf.concat(1, [])
				inputs_width +=
				depth =
		self.last_width =
	def add():
		self.layers.append()
		self.last_layer =
		self.last_shape = layer.get_shape()
	def reshape():
		self.last_layer = tf.reshape()
		self.last_shape =
		self.last_width = shape[]
	def batchnorm():
		from tensorflow.contrib.layers.python.layers import batch_norm as batch_norm
		with tf.name_scope() as scope:
			input =
			train_op = batch_norm(input, is_training=, center=, updates_collections=, scope=)
			test_op = batch_norm(input, is_training=, updates_collections=, center=, scope=,reuse=)
			self.add(tf.cond(self.train_phase, lambda:, lambda:))
	def addLayer():
		ident =
		self.batchnorm()
		self.conv([], pool=, dropout=, norm=)
		concat = tf.concat(3, [])
		self.add()
	def addTransition():
		self.batchnorm()
		self.add(tf.nn.relu())
		self.conv([], pool=, dropout=, norm=)
	def buildDenseConv(self, N_blocks=, magic_factor=):
		depth =
		if () % 3:  raise Exception()
		N = () / 3
		do_dropout =
		nChannels =
		growthRate =
		self.conv([])
		for i in range():
			self.addLayer()
			nChannels =
		self.addTransition()
		for i in range():
			self.addLayer()
			nChannels =
		self.addTransition()
		for i in range():
			self.addLayer()
			nChannels =
		self.batchnorm()
		self.add(tf.nn.relu())
		self.add(tf.nn.max_pool(self.last_layer, ksize=[], strides=[], padding=))
		if magic_factor == 16:
			self.reshape([])
		else:
			self.reshape([])
	def dense(self, hidden=, depth=, activation=, dropout=, parent=, norm=):
		if parent == -1: parent =
		shape = self.last_layer.get_shape()
		if shape and len() > 2:
			if len() == 3:
				self.last_width = int(shape[] * shape[])
			else:
				self.last_width = int(shape[] * shape[] * shape[])
			parent = tf.reshape(parent, [])
		width =
		while depth > 0:
			with tf.name_scope("") as scope:
				nr = len()
				if self.last_width == width:
					U = closest_unitary(np.random.rand() / ()) / weight_divider
					weights = tf.Variable(U, name="" + str(), dtype=)
				else:
					weights = tf.Variable(tf.random_uniform([], minval=, maxval=),name=)
				bias = tf.Variable(tf.random_uniform([], minval=, maxval=), name=)
				dense1 = tf.matmul(parent, weights, name="" + str()) + bias
				tf.summary.histogram("" + str(), dense1)
				tf.summary.histogram("" + str(), weights)
				tf.summary.histogram("" + str(), bias)
				tf.summary.histogram("" + str() + "", tf.nn.zero_fraction())
				tf.summary.histogram("" + str() + "", tf.nn.zero_fraction())
				if activation: dense1 = activation()
				if norm: dense1 = self.norm(dense1, lsize=)
				if dropout: dense1 = tf.nn.dropout()
				self.layers.append()
				self.last_layer = parent =
				self.last_width =
				depth =
				self.last_shape = []
	def conv2(self, shape, act=, pool=, dropout=, norm=, name=):
		with tf.name_scope():
			conv = slim.conv2d(self.last_layer, shape[], [shape[], shape[]], 3, padding=, scope=)
			self.add()
	def conv(self, shape, act=, pool=, dropout=, norm=,name=):
		with tf.name_scope():
			width = shape[]
			filters = tf.Variable(tf.random_normal(), name=)
			_bias = tf.Variable(tf.random_normal([shape[]]), name=)
			conv1 = tf.nn.bias_add(tf.nn.conv2d(self.last_layer, filter=, strides=[], padding=),_bias)
			if debug: tf.summary.histogram("" + str(len()), conv1)
			if act: conv1 = act()
			if pool: conv1 = tf.nn.max_pool(conv1, ksize=[], strides=[], padding=)
			if norm: conv1 = tf.nn.lrn(conv1, depth_radius=, bias=, alpha=, beta=)
			if debug: tf.summary.histogram("" + str(len()), conv1)
			if dropout: conv1 = tf.nn.dropout()
			self.add()
	def rnn():
		num_hidden =
		cell = tf.nn.rnn_cell.LSTMCell()
		val, _ = tf.nn.dynamic_rnn(cell, self.last_layer, dtype=)
		val = tf.nn.dropout()
		val = tf.transpose(val, [])
		self.last = tf.gather(val, int(val.get_shape()[]) - 1)
	def classifier(self, classes=):
		if not classes: classes =
		with tf.name_scope():
			if self.last_width != classes:
				self.dense(hidden=, activation=, dropout=)
		with tf.name_scope():
			y_ =
			manual =
			if classes > 100:
				y = prediction =
				self.cost = tf.reduce_mean(tf.nn.sampled_softmax_loss())
			elif manual:
				prediction = y = tf.nn.log_softmax()
				self.cost = cross_entropy = -tf.reduce_sum()
			else:
				y = prediction =
				self.cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits())
			with tf.device():
				tf.summary.scalar()
			learning_scheme = tf.train.exponential_decay(self.learning_rate, self.global_step, decay_steps, decay_size,staircase=)
			with tf.device():
				tf.summary.scalar()
			self.optimizer = tf.train.AdamOptimizer().minimize()
			correct_pred = tf.equal(tf.argmax(), tf.argmax())
			self.accuracy = tf.reduce_mean(tf.cast())
			if not gpu: tf.summary.scalar()
	def next_batch(self, batch_size, session, test=):
		try:
			if test:
				test_images = self.data.test.images[:]
				test_labels = self.data.test.labels[:]
				return test_images, test_labels
			return self.data.train.next_batch()
		except:
			try:
				return next()
			except:
				return next()
	def train(self, data=, steps=, dropout=, display_step=, test_step=, batch_size=,do_resume=):
		if data: self.data =
		steps = 9999999 if steps ==
		session =
		tf.add_check_numerics_ops()
		try:
			self.summaries = tf.summary.merge_all()
		except:
			self.summaries = tf.merge_all_summaries()
		try:
			self.summary_writer = tf.summary.FileWriter(current_logdir(), session.graph)
		except:
			self.summary_writer = tf.train.SummaryWriter(current_logdir(), session.graph)
		if not dropout: dropout =
		x =
		y =
		keep_prob =
		try:
			saver = tf.train.Saver(tf.global_variables())
		except:
			saver = tf.train.Saver(tf.all_variables())
		snapshot = self.name + str(get_last_tensorboard_run_nr())
		checkpoint = tf.train.latest_checkpoint()
		if do_resume and checkpoint:
			saver.restore()
		try:
			session.run([tf.global_variables_initializer()])
		except:
			session.run([tf.initialize_all_variables()])
		step =
		while step < steps:
			batch_xs, batch_ys = self.next_batch()
			feed_dict = {x:, y:, keep_prob:, self.train_phase:}
			loss, _ = session.run([], feed_dict=)
			if step % display_step == 0:
				seconds = int(time.time()) - start
				feed = {x:, y:, keep_prob:, self.train_phase:}
				acc, summary = session.run([], feed_dict=)
				if str() == "": return print()
			if step % test_step == 0: self.test()
			if step % save_step == 0 and step > 0:
				saver.save()
			step +=
		self.test(step, number=)
	def test(self, step, number=):
		session = sess =
		config = projector.ProjectorConfig()
		if visualize_cluster:
			embedding = config.embeddings.add()
			embedding.tensor_name =
			embedding.sprite.image_path =
			embedding.sprite.single_image_dim.extend([])
			embedding.metadata_path = os.path.join()
			projector.visualize_embeddings()
		run_metadata = tf.RunMetadata()
		run_options = tf.RunOptions(trace_level=)
		test_images, test_labels = self.next_batch(number, session, test=)
		feed_dict = {self.x:, self.y:, self.keep_prob:, self.train_phase:}
		accuracy, summary = session.run([], feed_dict, run_options, run_metadata)
import tensorflow as tf
from tensorflow.examples.tutorials.mnist import input_data
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.gridspec as gridspec
import os
mnist = input_data.read_data_sets("", one_hot=)
mb_size =
Z_dim =
X_dim = mnist.train.images.shape[]
y_dim = mnist.train.labels.shape[]
h_dim =
def xavier_init():
    in_dim = size[]
    xavier_stddev = 1. / tf.sqrt()
    return tf.random_normal(shape=, stddev=)
X = tf.placeholder(tf.float32, shape=[])
y = tf.placeholder(tf.float32, shape=[])
D_W1 = tf.Variable(xavier_init([]))
D_b1 = tf.Variable(tf.zeros(shape=[]))
D_W2 = tf.Variable(xavier_init([]))
D_b2 = tf.Variable(tf.zeros(shape=[]))
theta_D = []
def discriminator():
    inputs = tf.concat(axis=, values=[])
    D_h1 = tf.nn.relu(tf.matmul() + D_b1)
    D_logit = tf.matmul() + D_b2
    D_prob = tf.nn.sigmoid()
    return D_prob, D_logit
Z = tf.placeholder(tf.float32, shape=[])
G_W1 = tf.Variable(xavier_init([]))
G_b1 = tf.Variable(tf.zeros(shape=[]))
G_W2 = tf.Variable(xavier_init([]))
G_b2 = tf.Variable(tf.zeros(shape=[]))
theta_G = []
def generator():
    inputs = tf.concat(axis=, values=[])
    G_h1 = tf.nn.relu(tf.matmul() + G_b1)
    G_log_prob = tf.matmul() + G_b2
    G_prob = tf.nn.sigmoid()
    return G_prob
def sample_Z():
    return np.random.uniform(-1., 1., size=[])
def plot():
    fig = plt.figure(figsize=())
    gs = gridspec.GridSpec()
    gs.update(wspace=, hspace=)
    for i, sample in enumerate():
        ax = plt.subplot(gs[])
        plt.axis()
        ax.set_xticklabels([])
        ax.set_yticklabels([])
        ax.set_aspect()
        plt.imshow(sample.reshape(), cmap=)
    return fig
G_sample = generator()
D_real, D_logit_real = discriminator()
D_fake, D_logit_fake = discriminator()
D_loss_real = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=, labels=tf.ones_like()))
D_loss_fake = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=, labels=tf.zeros_like()))
D_loss =
G_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=, labels=tf.ones_like()))
D_solver = tf.train.AdamOptimizer().minimize(D_loss, var_list=)
G_solver = tf.train.AdamOptimizer().minimize(G_loss, var_list=)
sess = tf.Session()
sess.run(tf.global_variables_initializer())
if not os.path.exists():
    os.makedirs()
i =
for it in range():
    if it % 1000 == 0:
        n_sample =
        Z_sample = sample_Z()
        y_sample = np.zeros(shape=[])
        y_sample[:, 7] =
        samples = sess.run(G_sample, feed_dict={Z:, y:})
        fig = plot()
        plt.savefig("".zfill()), bbox_inches=)
        i +=
        plt.close()
    X_mb, y_mb = mnist.train.next_batch()
    Z_sample = sample_Z()
    _, D_loss_curr = sess.run([], feed_dict={X:, Z:, y:})
    _, G_loss_curr = sess.run([], feed_dict={Z:, y:})
    if it % 1000 == 0:
import tensorflow as tf
from tensorflow.examples.tutorials.mnist import input_data
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.gridspec as gridspec
import os
import scipy.ndimage.interpolation
mnist = input_data.read_data_sets("", one_hot=)
mb_size =
X_dim = mnist.train.images.shape[]
y_dim = mnist.train.labels.shape[]
z_dim =
h_dim =
eps =
lr =
d_steps =
def plot():
    fig = plt.figure(figsize=())
    gs = gridspec.GridSpec()
    gs.update(wspace=, hspace=)
    for i, sample in enumerate():
        ax = plt.subplot(gs[])
        plt.axis()
        ax.set_xticklabels([])
        ax.set_yticklabels([])
        ax.set_aspect()
        plt.imshow(sample.reshape(), cmap=)
    return fig
def xavier_init():
    in_dim = size[]
    xavier_stddev = 1. / tf.sqrt()
    return tf.random_normal(shape=, stddev=)
X1 = tf.placeholder(tf.float32, shape=[])
X2 = tf.placeholder(tf.float32, shape=[])
z = tf.placeholder(tf.float32, shape=[])
G_W1 = tf.Variable(xavier_init([]))
G_b1 = tf.Variable(tf.zeros(shape=[]))
G1_W2 = tf.Variable(xavier_init([]))
G1_b2 = tf.Variable(tf.zeros(shape=[]))
G2_W2 = tf.Variable(xavier_init([]))
G2_b2 = tf.Variable(tf.zeros(shape=[]))
def G():
    h = tf.nn.relu(tf.matmul() + G_b1)
    G1 = tf.nn.sigmoid(tf.matmul() + G1_b2)
    G2 = tf.nn.sigmoid(tf.matmul() + G2_b2)
    return G1, G2
D1_W1 = tf.Variable(xavier_init([]))
D1_b1 = tf.Variable(tf.zeros(shape=[]))
D2_W1 = tf.Variable(xavier_init([]))
D2_b1 = tf.Variable(tf.zeros(shape=[]))
D_W2 = tf.Variable(xavier_init([]))
D_b2 = tf.Variable(tf.zeros(shape=[]))
def D():
    h1 = tf.nn.relu(tf.matmul() + D1_b1)
    h2 = tf.nn.relu(tf.matmul() + D2_b1)
    D1_out = tf.nn.sigmoid(tf.matmul() + D_b2)
    D2_out = tf.nn.sigmoid(tf.matmul() + D_b2)
    return D1_out, D2_out
theta_G = []
theta_G_shared = []
theta_D = []
theta_D_shared = []
G1_sample, G2_sample = G()
D1_real, D2_real = D()
D1_fake, D2_fake = D()
D1_loss = -tf.reduce_mean(tf.log() + tf.log())
D2_loss = -tf.reduce_mean(tf.log() + tf.log())
D_loss =
G1_loss = -tf.reduce_mean(tf.log())
G2_loss = -tf.reduce_mean(tf.log())
G_loss =
D_opt = tf.train.AdamOptimizer(learning_rate=)
D_gv = D_opt.compute_gradients()
D_shared_gv = D_opt.compute_gradients()
D_shared_gv = [(0.5 * x[], x[]) for x in D_shared_gv]
D_solver = tf.group(D_opt.apply_gradients(), D_opt.apply_gradients())
G_opt = tf.train.AdamOptimizer(learning_rate=)
G_gv = G_opt.compute_gradients()
G_shared_gv = G_opt.compute_gradients()
G_shared_gv = [(0.5 * x[], x[]) for x in G_shared_gv]
G_solver = tf.group(G_opt.apply_gradients(), G_opt.apply_gradients())
sess = tf.Session()
sess.run(tf.global_variables_initializer())
X_train =
half = int(X_train.shape[] / 2)
X_train1 = X_train[:]
X_train2 = X_train[half:].reshape()
X_train2 = scipy.ndimage.interpolation.rotate(X_train2, 90, axes=())
X_train2 = X_train2.reshape()
del X_train
def sample_X():
    start_idx = np.random.randint(0, X.shape[]-size)
    return X[start_idx:]
def sample_z():
    return np.random.uniform(-1., 1., size=[])
if not os.path.exists():
    os.makedirs()
i =
for it in range():
    X1_mb, X2_mb = sample_X(), sample_X()
    z_mb = sample_z()
    _, D_loss_curr = sess.run([],feed_dict={X1:, X2:, z:})
    _, G_loss_curr = sess.run([], feed_dict={z:})
    if it % 1000 == 0:
        sample1, sample2 = sess.run([], feed_dict={z:})
        samples = np.vstack([])
        fig = plot()
        plt.savefig("".zfill()), bbox_inches=)
        i +=
        plt.close()
import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.gridspec as gridspec
import os
from torch.autograd import Variable
from tensorflow.examples.tutorials.mnist import input_data
mnist = input_data.read_data_sets("", one_hot=)
mb_size =
z_dim =
X_dim = mnist.train.images.shape[]
y_dim = mnist.train.labels.shape[]
h_dim =
c =
lr =
def plot():
    fig = plt.figure(figsize=())
    gs = gridspec.GridSpec()
    gs.update(wspace=, hspace=)
    for i, sample in enumerate():
        ax = plt.subplot(gs[])
        plt.axis()
        ax.set_xticklabels([])
        ax.set_yticklabels([])
        ax.set_aspect()
        plt.imshow(sample.reshape(), cmap=)
    return fig
def xavier_init():
    in_dim = size[]
    xavier_stddev = 1. / tf.sqrt()
    return tf.random_normal(shape=, stddev=)
X = tf.placeholder(tf.float32, shape=[])
c = tf.placeholder(tf.float32, shape=[])
z = tf.placeholder(tf.float32, shape=[])
Q_W1 = tf.Variable(xavier_init([]))
Q_b1 = tf.Variable(tf.zeros(shape=[]))
Q_W2_mu = tf.Variable(xavier_init([]))
Q_b2_mu = tf.Variable(tf.zeros(shape=[]))
Q_W2_sigma = tf.Variable(xavier_init([]))
Q_b2_sigma = tf.Variable(tf.zeros(shape=[]))
def Q():
    inputs = tf.concat(axis=, values=[])
    h = tf.nn.relu(tf.matmul() + Q_b1)
    z_mu = tf.matmul() + Q_b2_mu
    z_logvar = tf.matmul() + Q_b2_sigma
    return z_mu, z_logvar
def sample_z():
    eps = tf.random_normal(shape=tf.shape())
    return mu + tf.exp() * eps
P_W1 = tf.Variable(xavier_init([]))
P_b1 = tf.Variable(tf.zeros(shape=[]))
P_W2 = tf.Variable(xavier_init([]))
P_b2 = tf.Variable(tf.zeros(shape=[]))
def P():
    inputs = tf.concat(axis=, values=[])
    h = tf.nn.relu(tf.matmul() + P_b1)
    logits = tf.matmul() + P_b2
    prob = tf.nn.sigmoid()
    return prob, logits
z_mu, z_logvar = Q()
z_sample = sample_z()
_, logits = P()
X_samples, _ = P()
recon_loss = tf.reduce_sum(tf.nn.sigmoid_cross_entropy_with_logits(logits=, labels=), 1)
kl_loss = 0.5 * tf.reduce_sum(tf.exp() + z_mu**2 - 1. - z_logvar, 1)
vae_loss = tf.reduce_mean()
solver = tf.train.AdamOptimizer().minimize()
sess = tf.Session()
sess.run(tf.global_variables_initializer())
if not os.path.exists():
    os.makedirs()
i =
for it in range():
    X_mb, y_mb = mnist.train.next_batch()
    _, loss = sess.run([], feed_dict={X:, c:})
    if it % 1000 == 0:
        y = np.zeros(shape=[])
        y[:, np.random.randint()] =
        samples = sess.run(X_samples,feed_dict={z:, c:})
        fig = plot()
        plt.savefig("".zfill()), bbox_inches=)
        i +=
        plt.close()
import tensorflow as tf
from tensorflow.examples.tutorials.mnist import input_data
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.gridspec as gridspec
import os
import scipy.ndimage.interpolation
mb_size =
X_dim =
z_dim =
h_dim =
lr =
d_steps =
mnist = input_data.read_data_sets("", one_hot=)
def plot():
    fig = plt.figure(figsize=())
    gs = gridspec.GridSpec()
    gs.update(wspace=, hspace=)
    for i, sample in enumerate():
        ax = plt.subplot(gs[])
        plt.axis()
        ax.set_xticklabels([])
        ax.set_yticklabels([])
        ax.set_aspect()
        plt.imshow(sample.reshape(), cmap=)
    return fig
def xavier_init():
    in_dim = size[]
    xavier_stddev = 1. / tf.sqrt()
    return tf.random_normal(shape=, stddev=)
def log():
    return tf.log()
X_A = tf.placeholder(tf.float32, shape=[])
X_B = tf.placeholder(tf.float32, shape=[])
D_A_W1 = tf.Variable(xavier_init([]))
D_A_b1 = tf.Variable(tf.zeros(shape=[]))
D_A_W2 = tf.Variable(xavier_init([]))
D_A_b2 = tf.Variable(tf.zeros(shape=[]))
D_B_W1 = tf.Variable(xavier_init([]))
D_B_b1 = tf.Variable(tf.zeros(shape=[]))
D_B_W2 = tf.Variable(xavier_init([]))
D_B_b2 = tf.Variable(tf.zeros(shape=[]))
G_AB_W1 = tf.Variable(xavier_init([]))
G_AB_b1 = tf.Variable(tf.zeros(shape=[]))
G_AB_W2 = tf.Variable(xavier_init([]))
G_AB_b2 = tf.Variable(tf.zeros(shape=[]))
G_BA_W1 = tf.Variable(xavier_init([]))
G_BA_b1 = tf.Variable(tf.zeros(shape=[]))
G_BA_W2 = tf.Variable(xavier_init([]))
G_BA_b2 = tf.Variable(tf.zeros(shape=[]))
theta_D = []
theta_G = []
def D_A():
    h = tf.nn.relu(tf.matmul() + D_A_b1)
    return tf.nn.sigmoid(tf.matmul() + D_A_b2)
def D_B():
    h = tf.nn.relu(tf.matmul() + D_B_b1)
    return tf.nn.sigmoid(tf.matmul() + D_B_b2)
def G_AB():
    h = tf.nn.relu(tf.matmul() + G_AB_b1)
    return tf.nn.sigmoid(tf.matmul() + G_AB_b2)
def G_BA():
    h = tf.nn.relu(tf.matmul() + G_BA_b1)
    return tf.nn.sigmoid(tf.matmul() + G_BA_b2)
X_BA = G_BA()
D_A_real = D_A()
D_A_fake = D_A()
X_AB = G_AB()
D_B_real = D_B()
D_B_fake = D_B()
X_ABA = G_BA()
X_BAB = G_AB()
L_D_A = -tf.reduce_mean(log() + log())
L_D_B = -tf.reduce_mean(log() + log())
D_loss =
L_adv_B = -tf.reduce_mean(log())
L_recon_A = tf.reduce_mean(tf.reduce_sum(()**2, 1))
L_G_AB =
L_adv_A = -tf.reduce_mean(log())
L_recon_B = tf.reduce_mean(tf.reduce_sum(()**2, 1))
L_G_BA =
G_loss =
solver = tf.train.AdamOptimizer(learning_rate=)
D_solver = solver.minimize(D_loss, var_list=)
G_solver = solver.minimize(G_loss, var_list=)
sess = tf.Session()
sess.run(tf.global_variables_initializer())
X_train =
half = int(X_train.shape[] / 2)
X_train1 = X_train[:]
X_train2 = X_train[half:].reshape()
X_train2 = scipy.ndimage.interpolation.rotate(X_train2, 90, axes=())
X_train2 = X_train2.reshape()
del X_train
def sample_X():
    start_idx = np.random.randint(0, X.shape[]-size)
    return X[start_idx:]
if not os.path.exists():
    os.makedirs()
i =
for it in range():
    X_A_mb = sample_X()
    X_B_mb = sample_X()
    _, D_loss_curr = sess.run([], feed_dict={X_A:, X_B:})
    _, G_loss_curr = sess.run([], feed_dict={X_A:, X_B:})
    if it % 1000 == 0:
        input_A = sample_X(X_train1, size=)
        input_B = sample_X(X_train2, size=)
        samples_A = sess.run(X_BA, feed_dict={X_B:})
        samples_B = sess.run(X_AB, feed_dict={X_A:})
        samples = np.vstack([])
        fig = plot()
        plt.savefig("".zfill()), bbox_inches=)
        i +=
        plt.close()
import tensorflow as tf
from tensorflow.examples.tutorials.mnist import input_data
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.gridspec as gridspec
import os
import scipy.ndimage.interpolation
mnist = input_data.read_data_sets("", one_hot=)
mb_size =
X_dim = mnist.train.images.shape[]
y_dim = mnist.train.labels.shape[]
z_dim =
h_dim =
eps =
lr =
d_steps =
lam1, lam2 =, 1000
def plot():
    fig = plt.figure(figsize=())
    gs = gridspec.GridSpec()
    gs.update(wspace=, hspace=)
    for i, sample in enumerate():
        ax = plt.subplot(gs[])
        plt.axis()
        ax.set_xticklabels([])
        ax.set_yticklabels([])
        ax.set_aspect()
        plt.imshow(sample.reshape(), cmap=)
    return fig
def xavier_init():
    in_dim = size[]
    xavier_stddev = 1. / tf.sqrt()
    return tf.random_normal(shape=, stddev=)
X1 = tf.placeholder(tf.float32, shape=[])
X2 = tf.placeholder(tf.float32, shape=[])
z = tf.placeholder(tf.float32, shape=[])
G1_W1 = tf.Variable(xavier_init([]))
G1_b1 = tf.Variable(tf.zeros(shape=[]))
G1_W2 = tf.Variable(xavier_init([]))
G1_b2 = tf.Variable(tf.zeros(shape=[]))
G2_W1 = tf.Variable(xavier_init([]))
G2_b1 = tf.Variable(tf.zeros(shape=[]))
G2_W2 = tf.Variable(xavier_init([]))
G2_b2 = tf.Variable(tf.zeros(shape=[]))
def G1():
    inputs = tf.concat([], 1)
    h = tf.nn.relu(tf.matmul() + G1_b1)
    return tf.nn.sigmoid(tf.matmul() + G1_b2)
def G2():
    inputs = tf.concat([], 1)
    h = tf.nn.relu(tf.matmul() + G2_b1)
    return tf.nn.sigmoid(tf.matmul() + G2_b2)
D1_W1 = tf.Variable(xavier_init([]))
D1_b1 = tf.Variable(tf.zeros(shape=[]))
D1_W2 = tf.Variable(xavier_init([]))
D1_b2 = tf.Variable(tf.zeros(shape=[]))
D2_W1 = tf.Variable(xavier_init([]))
D2_b1 = tf.Variable(tf.zeros(shape=[]))
D2_W2 = tf.Variable(xavier_init([]))
D2_b2 = tf.Variable(tf.zeros(shape=[]))
def D1():
    h = tf.nn.relu(tf.matmul() + D1_b1)
    return tf.matmul() + D1_b2
def D2():
    h = tf.nn.relu(tf.matmul() + D1_b1)
    return tf.matmul() + D2_b2
theta_G1 = []
theta_G2 = []
theta_G =
theta_D1 = []
theta_D2 = []
X1_sample = G2()
X2_sample = G1()
D1_real = D1()
D1_fake = D1()
D2_real = D2()
D2_fake = D2()
D1_G = D1()
D2_G = D2()
X1_recon = G2()
X2_recon = G1()
recon1 = tf.reduce_mean(tf.reduce_sum(tf.abs(), 1))
recon2 = tf.reduce_mean(tf.reduce_sum(tf.abs(), 1))
D1_loss = tf.reduce_mean() - tf.reduce_mean()
D2_loss = tf.reduce_mean() - tf.reduce_mean()
G_loss = -tf.reduce_mean() + lam1*recon1 + lam2*recon2
D1_solver = (tf.train.RMSPropOptimizer(learning_rate=).minimize(D1_loss, var_list=))
D2_solver = (tf.train.RMSPropOptimizer(learning_rate=).minimize(D2_loss, var_list=))
G_solver = (tf.train.RMSPropOptimizer(learning_rate=).minimize(G_loss, var_list=))
clip_D = [p.assign(tf.clip_by_value()) for p in theta_D1 + theta_D2]
sess = tf.Session()
sess.run(tf.global_variables_initializer())
X_train =
half = int(X_train.shape[] / 2)
X_train1 = X_train[:]
X_train2 = X_train[half:].reshape()
X_train2 = scipy.ndimage.interpolation.rotate(X_train2, 90, axes=())
X_train2 = X_train2.reshape()
del X_train
def sample_X():
    start_idx = np.random.randint(0, X.shape[]-size)
    return X[start_idx:]
def sample_z():
    return np.random.uniform(-1., 1., size=[])
if not os.path.exists():
    os.makedirs()
i =
for it in range():
    for _ in range():
        X1_mb, X2_mb = sample_X(), sample_X()
        z_mb = sample_z()
        _, _, D1_loss_curr, D2_loss_curr, _ = sess.run([],feed_dict={X1:, X2:, z:})
    _, G_loss_curr = sess.run([], feed_dict={X1:, X2:, z:})
    if it % 1000 == 0:
        sample1, sample2 = sess.run([],feed_dict={X1: X1_mb[:, X2: X2_mb[:, z:})
        samples = np.vstack([X1_mb[:], sample1, X2_mb[:], sample2])
        fig = plot()
        plt.savefig("".zfill()), bbox_inches=)
        i +=
        plt.close()
import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.gridspec as gridspec
import os
from torch.autograd import Variable
from tensorflow.examples.tutorials.mnist import input_data
mnist = input_data.read_data_sets("", one_hot=)
mb_size =
z_dim =
X_dim = mnist.train.images.shape[]
y_dim = mnist.train.labels.shape[]
h_dim =
c =
lr =
noise_factor =
def plot():
    fig = plt.figure(figsize=())
    gs = gridspec.GridSpec()
    gs.update(wspace=, hspace=)
    for i, sample in enumerate():
        ax = plt.subplot(gs[])
        plt.axis()
        ax.set_xticklabels([])
        ax.set_yticklabels([])
        ax.set_aspect()
        plt.imshow(sample.reshape(), cmap=)
    return fig
def xavier_init():
    in_dim = size[]
    xavier_stddev = 1. / tf.sqrt()
    return tf.random_normal(shape=, stddev=)
X = tf.placeholder(tf.float32, shape=[])
z = tf.placeholder(tf.float32, shape=[])
Q_W1 = tf.Variable(xavier_init([]))
Q_b1 = tf.Variable(tf.zeros(shape=[]))
Q_W2_mu = tf.Variable(xavier_init([]))
Q_b2_mu = tf.Variable(tf.zeros(shape=[]))
Q_W2_sigma = tf.Variable(xavier_init([]))
Q_b2_sigma = tf.Variable(tf.zeros(shape=[]))
def Q():
    h = tf.nn.relu(tf.matmul() + Q_b1)
    z_mu = tf.matmul() + Q_b2_mu
    z_logvar = tf.matmul() + Q_b2_sigma
    return z_mu, z_logvar
def sample_z():
    eps = tf.random_normal(shape=tf.shape())
    return mu + tf.exp() * eps
P_W1 = tf.Variable(xavier_init([]))
P_b1 = tf.Variable(tf.zeros(shape=[]))
P_W2 = tf.Variable(xavier_init([]))
P_b2 = tf.Variable(tf.zeros(shape=[]))
def P():
    h = tf.nn.relu(tf.matmul() + P_b1)
    logits = tf.matmul() + P_b2
    prob = tf.nn.sigmoid()
    return prob, logits
X_noise = X + noise_factor * tf.random_normal(tf.shape())
X_noise = tf.clip_by_value()
z_mu, z_logvar = Q()
z_sample = sample_z()
_, logits = P()
X_samples, _ = P()
recon_loss = tf.reduce_sum(tf.nn.sigmoid_cross_entropy_with_logits(logits=, labels=), 1)
kl_loss = 0.5 * tf.reduce_sum(tf.exp() + z_mu**2 - 1. - z_logvar, 1)
vae_loss = tf.reduce_mean()
solver = tf.train.AdamOptimizer().minimize()
sess = tf.Session()
sess.run(tf.global_variables_initializer())
if not os.path.exists():
    os.makedirs()
i =
for it in range():
    X_mb, _ = mnist.train.next_batch()
    _, loss = sess.run([], feed_dict={X:})
    if it % 1000 == 0:
        samples = sess.run(X_samples, feed_dict={z:})
        fig = plot()
        plt.savefig("".zfill()), bbox_inches=)
        i +=
        plt.close()
import tensorflow as tf
from tensorflow.examples.tutorials.mnist import input_data
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.gridspec as gridspec
import os
mb_size =
X_dim =
z_dim =
h_dim =
lr =
m =
mnist = input_data.read_data_sets("", one_hot=)
def plot():
    fig = plt.figure(figsize=())
    gs = gridspec.GridSpec()
    gs.update(wspace=, hspace=)
    for i, sample in enumerate():
        ax = plt.subplot(gs[])
        plt.axis()
        ax.set_xticklabels([])
        ax.set_yticklabels([])
        ax.set_aspect()
        plt.imshow(sample.reshape(), cmap=)
    return fig
def xavier_init():
    in_dim = size[]
    xavier_stddev = 1. / tf.sqrt()
    return tf.random_normal(shape=, stddev=)
X = tf.placeholder(tf.float32, shape=[])
z = tf.placeholder(tf.float32, shape=[])
D_W1 = tf.Variable(xavier_init([]))
D_b1 = tf.Variable(tf.zeros(shape=[]))
D_W2 = tf.Variable(xavier_init([]))
D_b2 = tf.Variable(tf.zeros(shape=[]))
G_W1 = tf.Variable(xavier_init([]))
G_b1 = tf.Variable(tf.zeros(shape=[]))
G_W2 = tf.Variable(xavier_init([]))
G_b2 = tf.Variable(tf.zeros(shape=[]))
theta_G = []
theta_D = []
def sample_z():
    return np.random.uniform(-1., 1., size=[])
def generator():
    G_h1 = tf.nn.relu(tf.matmul() + G_b1)
    G_log_prob = tf.matmul() + G_b2
    G_prob = tf.nn.sigmoid()
    return G_prob
def discriminator():
    D_h1 = tf.nn.relu(tf.matmul() + D_b1)
    X_recon = tf.matmul() + D_b2
    mse = tf.reduce_mean(tf.reduce_sum(()**2, 1))
    return mse
G_sample = generator()
D_real = discriminator()
D_fake = discriminator()
D_loss = D_real + tf.maximum()
G_loss =
D_solver = (tf.train.AdamOptimizer(learning_rate=).minimize(D_loss, var_list=))
G_solver = (tf.train.AdamOptimizer(learning_rate=).minimize(G_loss, var_list=))
sess = tf.Session()
sess.run(tf.global_variables_initializer())
if not os.path.exists():
    os.makedirs()
i =
for it in range():
    X_mb, _ = mnist.train.next_batch()
    z_mb = sample_z()
    _, D_loss_curr = sess.run([], feed_dict={X:, z:})
    _, G_loss_curr = sess.run([], feed_dict={X:, z:})
    if it % 1000 == 0:
        samples = sess.run(G_sample, feed_dict={z:})
        fig = plot()
        plt.savefig("".zfill()), bbox_inches=)
        i +=
        plt.close()
import tensorflow as tf
from tensorflow.examples.tutorials.mnist import input_data
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.gridspec as gridspec
import os
mb_size =
X_dim =
z_dim =
h_dim =
lr =
d_steps =
mnist = input_data.read_data_sets("", one_hot=)
def plot():
    fig = plt.figure(figsize=())
    gs = gridspec.GridSpec()
    gs.update(wspace=, hspace=)
    for i, sample in enumerate():
        ax = plt.subplot(gs[])
        plt.axis()
        ax.set_xticklabels([])
        ax.set_yticklabels([])
        ax.set_aspect()
        plt.imshow(sample.reshape(), cmap=)
    return fig
def xavier_init():
    in_dim = size[]
    xavier_stddev = 1. / tf.sqrt()
    return tf.random_normal(shape=, stddev=)
X = tf.placeholder(tf.float32, shape=[])
z = tf.placeholder(tf.float32, shape=[])
D_W1 = tf.Variable(xavier_init([]))
D_b1 = tf.Variable(tf.zeros(shape=[]))
D_W2 = tf.Variable(xavier_init([]))
D_b2 = tf.Variable(tf.zeros(shape=[]))
G_W1 = tf.Variable(xavier_init([]))
G_b1 = tf.Variable(tf.zeros(shape=[]))
G_W2 = tf.Variable(xavier_init([]))
G_b2 = tf.Variable(tf.zeros(shape=[]))
theta_G = []
theta_D = []
def sample_z():
    return np.random.uniform(-1., 1., size=[])
def generator():
    G_h1 = tf.nn.relu(tf.matmul() + G_b1)
    G_log_prob = tf.matmul() + G_b2
    G_prob = tf.nn.sigmoid()
    return G_prob
def discriminator():
    D_h1 = tf.nn.relu(tf.matmul() + D_b1)
    out = tf.matmul() + D_b2
    return out
G_sample = generator()
D_real = discriminator()
D_fake = discriminator()
D_loss = -(tf.reduce_mean() - tf.reduce_mean())
G_loss = -tf.reduce_mean()
D_solver = (tf.train.AdamOptimizer(learning_rate=).minimize(D_loss, var_list=))
G_solver = (tf.train.AdamOptimizer(learning_rate=).minimize(G_loss, var_list=))
sess = tf.Session()
sess.run(tf.global_variables_initializer())
if not os.path.exists():
    os.makedirs()
i =
for it in range():
    X_mb, _ = mnist.train.next_batch()
    z_mb = sample_z()
    _, D_loss_curr = sess.run([], feed_dict={X:, z:})
    _, G_loss_curr = sess.run([], feed_dict={z:})
    if it % 1000 == 0:
        samples = sess.run(G_sample, feed_dict={z:})
        fig = plot()
        plt.savefig("".zfill()), bbox_inches=)
        i +=
        plt.close()
import tensorflow as tf
from tensorflow.examples.tutorials.mnist import input_data
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.gridspec as gridspec
import os
def xavier_init():
    in_dim = size[]
    xavier_stddev = 1. / tf.sqrt()
    return tf.random_normal(shape=, stddev=)
X = tf.placeholder(tf.float32, shape=[])
D_W1 = tf.Variable(xavier_init([]))
D_b1 = tf.Variable(tf.zeros(shape=[]))
D_W2 = tf.Variable(xavier_init([]))
D_b2 = tf.Variable(tf.zeros(shape=[]))
theta_D = []
Z = tf.placeholder(tf.float32, shape=[])
G_W1 = tf.Variable(xavier_init([]))
G_b1 = tf.Variable(tf.zeros(shape=[]))
G_W2 = tf.Variable(xavier_init([]))
G_b2 = tf.Variable(tf.zeros(shape=[]))
theta_G = []
def sample_Z():
    return np.random.uniform(-1., 1., size=[])
def generator():
    G_h1 = tf.nn.relu(tf.matmul() + G_b1)
    G_log_prob = tf.matmul() + G_b2
    G_prob = tf.nn.sigmoid()
    return G_prob
def discriminator():
    D_h1 = tf.nn.relu(tf.matmul() + D_b1)
    D_logit = tf.matmul() + D_b2
    D_prob = tf.nn.sigmoid()
    return D_prob, D_logit
def plot():
    fig = plt.figure(figsize=())
    gs = gridspec.GridSpec()
    gs.update(wspace=, hspace=)
    for i, sample in enumerate():
        ax = plt.subplot(gs[])
        plt.axis()
        ax.set_xticklabels([])
        ax.set_yticklabels([])
        ax.set_aspect()
        plt.imshow(sample.reshape(), cmap=)
    return fig
G_sample = generator()
D_real, D_logit_real = discriminator()
D_fake, D_logit_fake = discriminator()
D_loss_real = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=, labels=tf.ones_like()))
D_loss_fake = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=, labels=tf.zeros_like()))
D_loss =
G_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=, labels=tf.ones_like()))
D_solver = tf.train.AdamOptimizer().minimize(D_loss, var_list=)
G_solver = tf.train.AdamOptimizer().minimize(G_loss, var_list=)
mb_size =
Z_dim =
mnist = input_data.read_data_sets("", one_hot=)
sess = tf.Session()
sess.run(tf.global_variables_initializer())
if not os.path.exists():
    os.makedirs()
i =
for it in range():
    if it % 1000 == 0:
        samples = sess.run(G_sample, feed_dict={Z:})
        fig = plot()
        plt.savefig("".zfill()), bbox_inches=)
        i +=
        plt.close()
    X_mb, _ = mnist.train.next_batch()
    _, D_loss_curr = sess.run([], feed_dict={X:, Z:})
    _, G_loss_curr = sess.run([], feed_dict={Z:})
    if it % 1000 == 0:
import tensorflow as tf
from tensorflow.examples.tutorials.mnist import input_data
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.gridspec as gridspec
import os
def xavier_init():
    in_dim = size[]
    xavier_stddev = 1. / tf.sqrt()
    return tf.random_normal(shape=, stddev=)
X = tf.placeholder(tf.float32, shape=[])
D_W1 = tf.Variable(xavier_init([]))
D_b1 = tf.Variable(tf.zeros(shape=[]))
D_W2 = tf.Variable(xavier_init([]))
D_b2 = tf.Variable(tf.zeros(shape=[]))
theta_D = []
Z = tf.placeholder(tf.float32, shape=[])
c = tf.placeholder(tf.float32, shape=[])
G_W1 = tf.Variable(xavier_init([]))
G_b1 = tf.Variable(tf.zeros(shape=[]))
G_W2 = tf.Variable(xavier_init([]))
G_b2 = tf.Variable(tf.zeros(shape=[]))
theta_G = []
Q_W1 = tf.Variable(xavier_init([]))
Q_b1 = tf.Variable(tf.zeros(shape=[]))
Q_W2 = tf.Variable(xavier_init([]))
Q_b2 = tf.Variable(tf.zeros(shape=[]))
theta_Q = []
def sample_Z():
    return np.random.uniform(-1., 1., size=[])
def sample_c():
    return np.random.multinomial(1, 10*[], size=)
def generator():
    inputs = tf.concat(axis=, values=[])
    G_h1 = tf.nn.relu(tf.matmul() + G_b1)
    G_log_prob = tf.matmul() + G_b2
    G_prob = tf.nn.sigmoid()
    return G_prob
def discriminator():
    D_h1 = tf.nn.relu(tf.matmul() + D_b1)
    D_logit = tf.matmul() + D_b2
    D_prob = tf.nn.sigmoid()
    return D_prob
def Q():
    Q_h1 = tf.nn.relu(tf.matmul() + Q_b1)
    Q_prob = tf.nn.softmax(tf.matmul() + Q_b2)
    return Q_prob
def plot():
    fig = plt.figure(figsize=())
    gs = gridspec.GridSpec()
    gs.update(wspace=, hspace=)
    for i, sample in enumerate():
        ax = plt.subplot(gs[])
        plt.axis()
        ax.set_xticklabels([])
        ax.set_yticklabels([])
        ax.set_aspect()
        plt.imshow(sample.reshape(), cmap=)
    return fig
G_sample = generator()
D_real = discriminator()
D_fake = discriminator()
Q_c_given_x = Q()
D_loss = -tf.reduce_mean(tf.log() + tf.log())
G_loss = -tf.reduce_mean(tf.log())
cross_ent = tf.reduce_mean(-tf.reduce_sum(tf.log() * c, 1))
Q_loss =
D_solver = tf.train.AdamOptimizer().minimize(D_loss, var_list=)
G_solver = tf.train.AdamOptimizer().minimize(G_loss, var_list=)
Q_solver = tf.train.AdamOptimizer().minimize(Q_loss, var_list=)
mb_size =
Z_dim =
mnist = input_data.read_data_sets("", one_hot=)
sess = tf.Session()
sess.run(tf.global_variables_initializer())
if not os.path.exists():
    os.makedirs()
i =
for it in range():
    if it % 1000 == 0:
        Z_noise = sample_Z()
        idx = np.random.randint()
        c_noise = np.zeros([])
        c_noise[range(), idx] =
        samples = sess.run(G_sample,feed_dict={Z:, c:})
        fig = plot()
        plt.savefig("".zfill()), bbox_inches=)
        i +=
        plt.close()
    X_mb, _ = mnist.train.next_batch()
    Z_noise = sample_Z()
    c_noise = sample_c()
    _, D_loss_curr = sess.run([],feed_dict={X:, Z:, c:})
    _, G_loss_curr = sess.run([],feed_dict={Z:, c:})
    sess.run([], feed_dict={Z:, c:})
    if it % 1000 == 0:
import tensorflow as tf
from tensorflow.examples.tutorials.mnist import input_data
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.gridspec as gridspec
import os
mb_size =
X_dim =
z_dim =
h_dim =
lr =
d_steps =
mnist = input_data.read_data_sets("", one_hot=)
def plot():
    fig = plt.figure(figsize=())
    gs = gridspec.GridSpec()
    gs.update(wspace=, hspace=)
    for i, sample in enumerate():
        ax = plt.subplot(gs[])
        plt.axis()
        ax.set_xticklabels([])
        ax.set_yticklabels([])
        ax.set_aspect()
        plt.imshow(sample.reshape(), cmap=)
    return fig
def xavier_init():
    in_dim = size[]
    xavier_stddev = 1. / tf.sqrt()
    return tf.random_normal(shape=, stddev=)
X = tf.placeholder(tf.float32, shape=[])
z = tf.placeholder(tf.float32, shape=[])
D_W1 = tf.Variable(xavier_init([]))
D_b1 = tf.Variable(tf.zeros(shape=[]))
D_W2 = tf.Variable(xavier_init([]))
D_b2 = tf.Variable(tf.zeros(shape=[]))
G_W1 = tf.Variable(xavier_init([]))
G_b1 = tf.Variable(tf.zeros(shape=[]))
G_W2 = tf.Variable(xavier_init([]))
G_b2 = tf.Variable(tf.zeros(shape=[]))
theta_G = []
theta_D = []
def sample_z():
    return np.random.uniform(-1., 1., size=[])
def generator():
    G_h1 = tf.nn.relu(tf.matmul() + G_b1)
    G_log_prob = tf.matmul() + G_b2
    G_prob = tf.nn.sigmoid()
    return G_prob
def discriminator():
    D_h1 = tf.nn.relu(tf.matmul() + D_b1)
    out = tf.matmul() + D_b2
    return out
G_sample = generator()
D_real = discriminator()
D_fake = discriminator()
D_loss = 0.5 * (tf.reduce_mean(()**2) + tf.reduce_mean())
G_loss = 0.5 * tf.reduce_mean(()**2)
D_solver = (tf.train.AdamOptimizer(learning_rate=).minimize(D_loss, var_list=))
G_solver = (tf.train.AdamOptimizer(learning_rate=).minimize(G_loss, var_list=))
sess = tf.Session()
sess.run(tf.global_variables_initializer())
if not os.path.exists():
    os.makedirs()
i =
for it in range():
    for _ in range():
        X_mb, _ = mnist.train.next_batch()
        z_mb = sample_z()
        _, D_loss_curr = sess.run([],feed_dict={X:, z:})
    X_mb, _ = mnist.train.next_batch()
    z_mb = sample_z()
    _, G_loss_curr = sess.run([],feed_dict={X:, z:})
    if it % 1000 == 0:
        samples = sess.run(G_sample, feed_dict={z:})
        fig = plot()
        plt.savefig("".zfill()), bbox_inches=)
        i +=
        plt.close()
import tensorflow as tf
from tensorflow.examples.tutorials.mnist import input_data
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.gridspec as gridspec
import os
mb_size =
X_dim =
z_dim =
h_dim =
lr =
n_iter =
n_epoch =
N =
mnist = input_data.read_data_sets("", one_hot=)
def plot():
    fig = plt.figure(figsize=())
    gs = gridspec.GridSpec()
    gs.update(wspace=, hspace=)
    for i, sample in enumerate():
        ax = plt.subplot(gs[])
        plt.axis()
        ax.set_xticklabels([])
        ax.set_yticklabels([])
        ax.set_aspect()
        plt.imshow(sample.reshape(), cmap=)
    return fig
def xavier_init():
    in_dim = size[]
    xavier_stddev = 1. / tf.sqrt()
    return tf.random_normal(shape=, stddev=)
X = tf.placeholder(tf.float32, shape=[])
z = tf.placeholder(tf.float32, shape=[])
m = tf.placeholder()
D_W1 = tf.Variable(xavier_init([]))
D_b1 = tf.Variable(tf.zeros(shape=[]))
D_W2 = tf.Variable(xavier_init([]))
D_b2 = tf.Variable(tf.zeros(shape=[]))
G_W1 = tf.Variable(xavier_init([]))
G_b1 = tf.Variable(tf.zeros(shape=[]))
G_W2 = tf.Variable(xavier_init([]))
G_b2 = tf.Variable(tf.zeros(shape=[]))
theta_G = []
theta_D = []
def sample_z():
    return np.random.uniform(-1., 1., size=[])
def G():
    G_h1 = tf.nn.relu(tf.matmul() + G_b1)
    G_log_prob = tf.matmul() + G_b2
    G_prob = tf.nn.sigmoid()
    return G_prob
def D():
    D_h1 = tf.nn.relu(tf.matmul() + D_b1)
    X_recon = tf.matmul() + D_b2
    return tf.reduce_sum(()**2, 1)
G_sample = G()
D_real = D()
D_fake = D()
D_recon_loss = tf.reduce_mean()
D_loss = tf.reduce_mean(D_real + tf.maximum())
G_loss = tf.reduce_mean()
D_recon_solver = (tf.train.AdamOptimizer(learning_rate=).minimize(D_recon_loss, var_list=))
D_solver = (tf.train.AdamOptimizer(learning_rate=).minimize(D_loss, var_list=))
G_solver = (tf.train.AdamOptimizer(learning_rate=).minimize(G_loss, var_list=))
sess = tf.Session()
sess.run(tf.global_variables_initializer())
if not os.path.exists():
    os.makedirs()
for it in range():
    X_mb, _ = mnist.train.next_batch()
    _, D_recon_loss_curr = sess.run([], feed_dict={X:})
    if it % 1000 == 0:
i =
margin = sess.run(D_recon_loss, feed_dict={X:})
s_z_before =
for t in range():
    s_x, s_z =, 0.
    for it in range():
        X_mb, _ = mnist.train.next_batch()
        z_mb = sample_z()
        _, D_loss_curr, D_real_curr = sess.run([], feed_dict={X:, z:, m:})
        s_x += np.sum()
        _, G_loss_curr, D_fake_curr = sess.run([],feed_dict={X:, z:, m:})
        s_z += np.sum()
    if () and () and ():
        margin =
    s_z_before =
    Ex =
    Ez =
    L = Ex + np.abs()
    samples = sess.run(G_sample, feed_dict={z:})
    fig = plot()
    plt.savefig("".zfill()), bbox_inches=)
    i +=
    plt.close()
import tensorflow as tf
from tensorflow.examples.tutorials.mnist import input_data
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.gridspec as gridspec
import os
mb_size =
X_dim =
z_dim =
h_dim =
lam1 =
lam2 =
mnist = input_data.read_data_sets("", one_hot=)
def plot():
    fig = plt.figure(figsize=())
    gs = gridspec.GridSpec()
    gs.update(wspace=, hspace=)
    for i, sample in enumerate():
        ax = plt.subplot(gs[])
        plt.axis()
        ax.set_xticklabels([])
        ax.set_yticklabels([])
        ax.set_aspect()
        plt.imshow(sample.reshape(), cmap=)
    return fig
def xavier_init():
    in_dim = size[]
    xavier_stddev = 1. / tf.sqrt()
    return tf.random_normal(shape=, stddev=)
def log():
    return tf.log()
X = tf.placeholder(tf.float32, shape=[])
z = tf.placeholder(tf.float32, shape=[])
E_W1 = tf.Variable(xavier_init([]))
E_b1 = tf.Variable(tf.zeros(shape=[]))
E_W2 = tf.Variable(xavier_init([]))
E_b2 = tf.Variable(tf.zeros(shape=[]))
D_W1 = tf.Variable(xavier_init([]))
D_b1 = tf.Variable(tf.zeros(shape=[]))
D_W2 = tf.Variable(xavier_init([]))
D_b2 = tf.Variable(tf.zeros(shape=[]))
G_W1 = tf.Variable(xavier_init([]))
G_b1 = tf.Variable(tf.zeros(shape=[]))
G_W2 = tf.Variable(xavier_init([]))
G_b2 = tf.Variable(tf.zeros(shape=[]))
theta_E = []
theta_G = []
theta_D = []
def sample_z():
    return np.random.uniform(-1., 1., size=[])
def encoder():
    E_h1 = tf.nn.relu(tf.matmul() + E_b1)
    out = tf.matmul() + E_b2
    return out
def generator():
    G_h1 = tf.nn.relu(tf.matmul() + G_b1)
    G_log_prob = tf.matmul() + G_b2
    G_prob = tf.nn.sigmoid()
    return G_prob
def discriminator():
    D_h1 = tf.nn.relu(tf.matmul() + D_b1)
    D_log_prob = tf.matmul() + D_b2
    D_prob = tf.nn.sigmoid()
    return D_prob
G_sample = generator()
G_sample_reg = generator(encoder())
D_real = discriminator()
D_fake = discriminator()
D_reg = discriminator()
mse = tf.reduce_sum(()**2, 1)
D_loss = -tf.reduce_mean(log() + log())
E_loss = tf.reduce_mean(lam1 * mse + lam2 * log())
G_loss = -tf.reduce_mean(log()) + E_loss
E_solver = (tf.train.AdamOptimizer(learning_rate=).minimize(E_loss, var_list=))
D_solver = (tf.train.AdamOptimizer(learning_rate=).minimize(D_loss, var_list=))
G_solver = (tf.train.AdamOptimizer(learning_rate=).minimize(G_loss, var_list=))
sess = tf.Session()
sess.run(tf.global_variables_initializer())
if not os.path.exists():
    os.makedirs()
i =
for it in range():
    X_mb, _ = mnist.train.next_batch()
    _, D_loss_curr = sess.run([],feed_dict={X:, z:})
    _, G_loss_curr = sess.run([],feed_dict={X:, z:})
    _, E_loss_curr = sess.run([],feed_dict={X:, z:})
    if it % 1000 == 0:
        samples = sess.run(G_sample, feed_dict={z:})
        fig = plot()
        plt.savefig("".zfill()), bbox_inches=)
        i +=
        plt.close()
import tensorflow as tf
from tensorflow.examples.tutorials.mnist import input_data
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.gridspec as gridspec
import os
mb_size =
X_dim =
z_dim =
h_dim =
lr =
d_steps =
mnist = input_data.read_data_sets("", one_hot=)
def plot():
    fig = plt.figure(figsize=())
    gs = gridspec.GridSpec()
    gs.update(wspace=, hspace=)
    for i, sample in enumerate():
        ax = plt.subplot(gs[])
        plt.axis()
        ax.set_xticklabels([])
        ax.set_yticklabels([])
        ax.set_aspect()
        plt.imshow(sample.reshape(), cmap=)
    return fig
def xavier_init():
    in_dim = size[]
    xavier_stddev = 1. / tf.sqrt()
    return tf.random_normal(shape=, stddev=)
def log():
    return tf.log()
X = tf.placeholder(tf.float32, shape=[])
z = tf.placeholder(tf.float32, shape=[])
D_W1 = tf.Variable(xavier_init([]))
D_b1 = tf.Variable(tf.zeros(shape=[]))
D_W2 = tf.Variable(xavier_init([]))
D_b2 = tf.Variable(tf.zeros(shape=[]))
G_W1 = tf.Variable(xavier_init([]))
G_b1 = tf.Variable(tf.zeros(shape=[]))
G_W2 = tf.Variable(xavier_init([]))
G_b2 = tf.Variable(tf.zeros(shape=[]))
theta_G = []
theta_D = []
def sample_z():
    return np.random.uniform(-1., 1., size=[])
def G():
    G_h1 = tf.nn.relu(tf.matmul() + G_b1)
    G_log_prob = tf.matmul() + G_b2
    G_prob = tf.nn.sigmoid()
    return G_prob
def D():
    D_h1 = tf.nn.relu(tf.matmul() + D_b1)
    out = tf.matmul() + D_b2
    return out
G_sample = G()
D_real = D()
D_fake = D()
D_target =
G_target = 1./()
Z = tf.reduce_sum(tf.exp()) + tf.reduce_sum(tf.exp())
D_loss = tf.reduce_sum() + log()
G_loss = tf.reduce_sum() + tf.reduce_sum() + log()
D_solver = (tf.train.AdamOptimizer(learning_rate=).minimize(D_loss, var_list=))
G_solver = (tf.train.AdamOptimizer(learning_rate=).minimize(G_loss, var_list=))
sess = tf.Session()
sess.run(tf.global_variables_initializer())
if not os.path.exists():
    os.makedirs()
i =
for it in range():
    X_mb, _ = mnist.train.next_batch()
    z_mb = sample_z()
    _, D_loss_curr = sess.run([], feed_dict={X:, z:})
    _, G_loss_curr = sess.run([], feed_dict={X:, z:})
    if it % 1000 == 0:
        samples = sess.run(G_sample, feed_dict={z:})
        fig = plot()
        plt.savefig("".zfill()), bbox_inches=)
        i +=
        plt.close()
import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.gridspec as gridspec
import os
from tensorflow.examples.tutorials.mnist import input_data
mnist = input_data.read_data_sets("", one_hot=)
mb_size =
z_dim =
X_dim = mnist.train.images.shape[]
y_dim = mnist.train.labels.shape[]
h_dim =
c =
lr =
def plot():
    fig = plt.figure(figsize=())
    gs = gridspec.GridSpec()
    gs.update(wspace=, hspace=)
    for i, sample in enumerate():
        ax = plt.subplot(gs[])
        plt.axis()
        ax.set_xticklabels([])
        ax.set_yticklabels([])
        ax.set_aspect()
        plt.imshow(sample.reshape(), cmap=)
    return fig
def xavier_init():
    in_dim = size[]
    xavier_stddev = 1. / tf.sqrt()
    return tf.random_normal(shape=, stddev=)
X = tf.placeholder(tf.float32, shape=[])
z = tf.placeholder(tf.float32, shape=[])
Q_W1 = tf.Variable(xavier_init([]))
Q_b1 = tf.Variable(tf.zeros(shape=[]))
Q_W2_mu = tf.Variable(xavier_init([]))
Q_b2_mu = tf.Variable(tf.zeros(shape=[]))
Q_W2_sigma = tf.Variable(xavier_init([]))
Q_b2_sigma = tf.Variable(tf.zeros(shape=[]))
def Q():
    h = tf.nn.relu(tf.matmul() + Q_b1)
    z_mu = tf.matmul() + Q_b2_mu
    z_logvar = tf.matmul() + Q_b2_sigma
    return z_mu, z_logvar
def sample_z():
    eps = tf.random_normal(shape=tf.shape())
    return mu + tf.exp() * eps
P_W1 = tf.Variable(xavier_init([]))
P_b1 = tf.Variable(tf.zeros(shape=[]))
P_W2 = tf.Variable(xavier_init([]))
P_b2 = tf.Variable(tf.zeros(shape=[]))
def P():
    h = tf.nn.relu(tf.matmul() + P_b1)
    logits = tf.matmul() + P_b2
    prob = tf.nn.sigmoid()
    return prob, logits
z_mu, z_logvar = Q()
z_sample = sample_z()
_, logits = P()
X_samples, _ = P()
recon_loss = tf.reduce_sum(tf.nn.sigmoid_cross_entropy_with_logits(logits=, labels=), 1)
kl_loss = 0.5 * tf.reduce_sum(tf.exp() + z_mu**2 - 1. - z_logvar, 1)
vae_loss = tf.reduce_mean()
solver = tf.train.AdamOptimizer().minimize()
sess = tf.Session()
sess.run(tf.global_variables_initializer())
if not os.path.exists():
    os.makedirs()
i =
for it in range():
    X_mb, _ = mnist.train.next_batch()
    _, loss = sess.run([], feed_dict={X:})
    if it % 1000 == 0:
        samples = sess.run(X_samples, feed_dict={z:})
        fig = plot()
        plt.savefig("".zfill()), bbox_inches=)
        i +=
        plt.close()
import tensorflow as tf
from tensorflow.examples.tutorials.mnist import input_data
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.gridspec as gridspec
import os
mb_size =
X_dim =
z_dim =
h_dim =
lam =
n_disc =
lr =
mnist = input_data.read_data_sets("", one_hot=)
def plot():
    fig = plt.figure(figsize=())
    gs = gridspec.GridSpec()
    gs.update(wspace=, hspace=)
    for i, sample in enumerate():
        ax = plt.subplot(gs[])
        plt.axis()
        ax.set_xticklabels([])
        ax.set_yticklabels([])
        ax.set_aspect()
        plt.imshow(sample.reshape(), cmap=)
    return fig
def xavier_init():
    in_dim = size[]
    xavier_stddev = 1. / tf.sqrt()
    return tf.random_normal(shape=, stddev=)
X = tf.placeholder(tf.float32, shape=[])
D_W1 = tf.Variable(xavier_init([]))
D_b1 = tf.Variable(tf.zeros(shape=[]))
D_W2 = tf.Variable(xavier_init([]))
D_b2 = tf.Variable(tf.zeros(shape=[]))
theta_D = []
z = tf.placeholder(tf.float32, shape=[])
G_W1 = tf.Variable(xavier_init([]))
G_b1 = tf.Variable(tf.zeros(shape=[]))
G_W2 = tf.Variable(xavier_init([]))
G_b2 = tf.Variable(tf.zeros(shape=[]))
theta_G = []
def sample_z():
    return np.random.uniform(-1., 1., size=[])
def G():
    G_h1 = tf.nn.relu(tf.matmul() + G_b1)
    G_log_prob = tf.matmul() + G_b2
    G_prob = tf.nn.sigmoid()
    return G_prob
def D():
    D_h1 = tf.nn.relu(tf.matmul() + D_b1)
    out = tf.matmul() + D_b2
    return out
G_sample = G()
D_real = D()
D_fake = D()
eps = tf.random_uniform([], minval=, maxval=)
X_inter = eps*X + ()*G_sample
grad = tf.gradients(D(), [])[]
grad_norm = tf.sqrt(tf.reduce_sum(()**2, axis=))
grad_pen = lam * tf.reduce_mean(()**2)
D_loss = tf.reduce_mean() - tf.reduce_mean() + grad_pen
G_loss = -tf.reduce_mean()
D_solver = (tf.train.AdamOptimizer(learning_rate=, beta1=).minimize(D_loss, var_list=))
G_solver = (tf.train.AdamOptimizer(learning_rate=, beta1=).minimize(G_loss, var_list=))
sess = tf.Session()
sess.run(tf.global_variables_initializer())
if not os.path.exists():
    os.makedirs()
i =
for it in range():
    for _ in range():
        X_mb, _ = mnist.train.next_batch()
        _, D_loss_curr = sess.run([],feed_dict={X:, z:})
    _, G_loss_curr = sess.run([],feed_dict={z:})
    if it % 1000 == 0:
        if it % 1000 == 0:
            samples = sess.run(G_sample, feed_dict={z:})
            fig = plot()
            plt.savefig("".zfill()), bbox_inches=)
            i +=
            plt.close()
import tensorflow as tf
from tensorflow.examples.tutorials.mnist import input_data
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.gridspec as gridspec
import os
mb_size =
X_dim =
z_dim =
h_dim =
mnist = input_data.read_data_sets("", one_hot=)
def plot():
    fig = plt.figure(figsize=())
    gs = gridspec.GridSpec()
    gs.update(wspace=, hspace=)
    for i, sample in enumerate():
        ax = plt.subplot(gs[])
        plt.axis()
        ax.set_xticklabels([])
        ax.set_yticklabels([])
        ax.set_aspect()
        plt.imshow(sample.reshape(), cmap=)
    return fig
def xavier_init():
    in_dim = size[]
    xavier_stddev = 1. / tf.sqrt()
    return tf.random_normal(shape=, stddev=)
X = tf.placeholder(tf.float32, shape=[])
D_W1 = tf.Variable(xavier_init([]))
D_b1 = tf.Variable(tf.zeros(shape=[]))
D_W2 = tf.Variable(xavier_init([]))
D_b2 = tf.Variable(tf.zeros(shape=[]))
theta_D = []
z = tf.placeholder(tf.float32, shape=[])
G_W1 = tf.Variable(xavier_init([]))
G_b1 = tf.Variable(tf.zeros(shape=[]))
G_W2 = tf.Variable(xavier_init([]))
G_b2 = tf.Variable(tf.zeros(shape=[]))
theta_G = []
def sample_z():
    return np.random.uniform(-1., 1., size=[])
def generator():
    G_h1 = tf.nn.relu(tf.matmul() + G_b1)
    G_log_prob = tf.matmul() + G_b2
    G_prob = tf.nn.sigmoid()
    return G_prob
def discriminator():
    D_h1 = tf.nn.relu(tf.matmul() + D_b1)
    out = tf.matmul() + D_b2
    return out
G_sample = generator()
D_real = discriminator()
D_fake = discriminator()
D_loss = tf.reduce_mean() - tf.reduce_mean()
G_loss = -tf.reduce_mean()
D_solver = (tf.train.RMSPropOptimizer(learning_rate=).minimize(-D_loss, var_list=))
G_solver = (tf.train.RMSPropOptimizer(learning_rate=).minimize(G_loss, var_list=))
clip_D = [p.assign(tf.clip_by_value()) for p in theta_D]
sess = tf.Session()
sess.run(tf.global_variables_initializer())
if not os.path.exists():
    os.makedirs()
i =
for it in range():
    for _ in range():
        X_mb, _ = mnist.train.next_batch()
        _, D_loss_curr, _ = sess.run([],feed_dict={X:, z:})
    _, G_loss_curr = sess.run([],feed_dict={z:})
    if it % 100 == 0:
        if it % 1000 == 0:
            samples = sess.run(G_sample, feed_dict={z:})
            fig = plot()
            plt.savefig("".zfill()), bbox_inches=)
            i +=
            plt.close()
import multiprocessing
import threading
import tensorflow as tf
import numpy as np
import gym
import os
import shutil
import matplotlib.pyplot as plt
GAME =
OUTPUT_GRAPH =
LOG_DIR =
N_WORKERS = multiprocessing.cpu_count()
MAX_GLOBAL_EP =
GLOBAL_NET_SCOPE =
UPDATE_GLOBAL_ITER =
GAMMA =
ENTROPY_BETA =
LR_A =
LR_C =
GLOBAL_RUNNING_R = []
GLOBAL_EP =
env = gym.make()
N_S = env.observation_space.shape[]
N_A =
del env
class ACNet():
    def __init__(self, scope, globalAC=):
        if scope == GLOBAL_NET_SCOPE:
            with tf.variable_scope():
                self.s = tf.placeholder(tf.float32, [], "")
                self._build_net()
                self.a_params = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=)
                self.c_params = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=)
        else:
            with tf.variable_scope():
                self.s = tf.placeholder(tf.float32, [], "")
                self.a_his = tf.placeholder(tf.int32, [], "")
                self.v_target = tf.placeholder(tf.float32, [], "")
                self.a_prob, self.v = self._build_net()
                td = tf.subtract(self.v_target, self.v, name=)
                with tf.name_scope():
                    self.c_loss = tf.reduce_mean(tf.square())
                with tf.name_scope():
                    log_prob = tf.reduce_sum(tf.log() * tf.one_hot(self.a_his, N_A, dtype=), axis=, keep_dims=)
                    exp_v =
                    entropy = -tf.reduce_sum(self.a_prob * tf.log(), axis=, keep_dims=)
                    self.exp_v =
                    self.a_loss = tf.reduce_mean()
                with tf.name_scope():
                    self.a_params = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=)
                    self.c_params = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=)
                    self.a_grads = tf.gradients()
                    self.c_grads = tf.gradients()
            with tf.name_scope():
                with tf.name_scope():
                    self.pull_a_params_op = [l_p.assign() for l_p, g_p in zip()]
                    self.pull_c_params_op = [l_p.assign() for l_p, g_p in zip()]
                with tf.name_scope():
                    self.update_a_op = OPT_A.apply_gradients(zip())
                    self.update_c_op = OPT_C.apply_gradients(zip())
    def _build_net():
        w_init = tf.random_normal_initializer()
        with tf.variable_scope():
            cell_size =
            s = tf.expand_dims(self.s, axis=,name=)
            rnn_cell = tf.contrib.rnn.BasicRNNCell()
            self.init_state = rnn_cell.zero_state(batch_size=, dtype=)
            outputs, self.final_state = tf.nn.dynamic_rnn(cell=, inputs=, initial_state=, time_major=)
            cell_out = tf.reshape(outputs, [], name=)
            l_c = tf.layers.dense(cell_out, 200, tf.nn.relu6, kernel_initializer=, name=)
            v = tf.layers.dense(l_c, 1, kernel_initializer=, name=)
        with tf.variable_scope():
            cell_out = tf.stop_gradient(cell_out, name=)
            l_a = tf.layers.dense(cell_out, 300, tf.nn.relu6, kernel_initializer=, name=)
            a_prob = tf.layers.dense(l_a, n_a, tf.nn.softmax, kernel_initializer=, name=)
        return a_prob, v
    def update_global():
        SESS.run([], feed_dict)
    def pull_global():
        SESS.run([])
    def choose_action():
        prob_weights, cell_state = SESS.run([], feed_dict={self.s:, :,self.init_state:})
        action = np.random.choice(range(prob_weights.shape[]),p=prob_weights.ravel())
        return action, cell_state
class Worker():
    def __init__():
        self.env = gym.make()
        self.name =
        self.AC = ACNet()
    def work():
        global GLOBAL_RUNNING_R, GLOBAL_EP
        total_step =
        r_scale =
        buffer_s, buffer_a, buffer_r = [], [], []
        while not COORD.should_stop() and GLOBAL_EP < MAX_GLOBAL_EP:
            s = self.env.reset()
            ep_r =
            ep_t =
            rnn_state = SESS.run()
            keep_state = rnn_state.copy()
            while True:
                a, rnn_state_ = self.AC.choose_action()
                s_, r, done, info = self.env.step()
                if r == -100: r =
                ep_r +=
                buffer_s.append()
                buffer_a.append()
                buffer_r.append()
                if total_step % UPDATE_GLOBAL_ITER == 0 or done:
                    if done:
                        v_s_ =
                    else:
                        v_s_ = SESS.run(self.AC.v, {self.AC.s:, :, self.AC.init_state:})[]
                    buffer_v_target = []
                    for r in buffer_r[::]:
                        v_s_ =
                        buffer_v_target.append()
                    buffer_v_target.reverse()
                    buffer_s, buffer_a, buffer_v_target = np.vstack(), np.array(), np.vstack()
                    feed_dict = {self.AC.s:,self.AC.a_his:,self.AC.v_target:,self.AC.init_state:,}
                    self.AC.update_global()
                    buffer_s, buffer_a, buffer_r = [], [], []
                    self.AC.pull_global()
                    keep_state = rnn_state_.copy()
                s =
                total_step +=
                rnn_state =
                ep_t +=
                if done:
                    if len() == 0:
                        GLOBAL_RUNNING_R.append()
                    else:
                        GLOBAL_RUNNING_R.append(0.99 * GLOBAL_RUNNING_R[] + 0.01 * ep_r)
                    if not self.env.unwrapped.lander.awake: solve =
                    else: solve =
                    GLOBAL_EP +=
                    break
if __name__ == "__main__":
    SESS = tf.Session()
    with tf.device("/cpu:):
        OPT_A = tf.train.RMSPropOptimizer(LR_A, name=)
        OPT_C = tf.train.RMSPropOptimizer(LR_C, name=)
        GLOBAL_AC = ACNet()
        workers = []
        for i in range():
            i_name =
            workers.append(Worker())
    COORD = tf.train.Coordinator()
    SESS.run(tf.global_variables_initializer())
    if OUTPUT_GRAPH:
        if os.path.exists():
            shutil.rmtree()
        tf.summary.FileWriter()
    worker_threads = []
    for worker in workers:
        job = lambda: worker.work()
        t = threading.Thread(target=)
        t.start()
        worker_threads.append()
    COORD.join()
    plt.plot(np.arange(len()), GLOBAL_RUNNING_R)
    plt.xlabel()
    plt.ylabel()
    plt.show()
import multiprocessing
import threading
import tensorflow as tf
import numpy as np
import gym
import os
import shutil
import matplotlib.pyplot as plt
GAME =
OUTPUT_GRAPH =
LOG_DIR =
N_WORKERS = multiprocessing.cpu_count()
MAX_EP_STEP =
MAX_GLOBAL_EP =
GLOBAL_NET_SCOPE =
UPDATE_GLOBAL_ITER =
GAMMA =
ENTROPY_BETA =
LR_A =
LR_C =
GLOBAL_RUNNING_R = []
GLOBAL_EP =
env = gym.make()
N_S = env.observation_space.shape[]
N_A = env.action_space.shape[]
A_BOUND = []
class ACNet():
    def __init__(self, scope, globalAC=):
        if scope == GLOBAL_NET_SCOPE:
            with tf.variable_scope():
                self.s = tf.placeholder(tf.float32, [], "")
                self.a_params, self.c_params = self._build_net()[-2:]
        else:
            with tf.variable_scope():
                self.s = tf.placeholder(tf.float32, [], "")
                self.a_his = tf.placeholder(tf.float32, [], "")
                self.v_target = tf.placeholder(tf.float32, [], "")
                mu, sigma, self.v, self.a_params, self.c_params = self._build_net()
                td = tf.subtract(self.v_target, self.v, name=)
                with tf.name_scope():
                    self.c_loss = tf.reduce_mean(tf.square())
                with tf.name_scope():
                    mu, sigma = mu * A_BOUND[], sigma + 1e-4
                normal_dist = tf.distributions.Normal()
                with tf.name_scope():
                    log_prob = normal_dist.log_prob()
                    exp_v = log_prob * tf.stop_gradient()
                    entropy = normal_dist.entropy()
                    self.exp_v =
                    self.a_loss = tf.reduce_mean()
                with tf.name_scope():
                    self.A = tf.clip_by_value(tf.squeeze(normal_dist.sample(), axis=[]), A_BOUND[], A_BOUND[])
                with tf.name_scope():
                    self.a_grads = tf.gradients()
                    self.c_grads = tf.gradients()
            with tf.name_scope():
                with tf.name_scope():
                    self.pull_a_params_op = [l_p.assign() for l_p, g_p in zip()]
                    self.pull_c_params_op = [l_p.assign() for l_p, g_p in zip()]
                with tf.name_scope():
                    self.update_a_op = OPT_A.apply_gradients(zip())
                    self.update_c_op = OPT_C.apply_gradients(zip())
    def _build_net():
        w_init = tf.random_normal_initializer()
        with tf.variable_scope():
            l_a = tf.layers.dense(self.s, 200, tf.nn.relu6, kernel_initializer=, name=)
            mu = tf.layers.dense(l_a, N_A, tf.nn.tanh, kernel_initializer=, name=)
            sigma = tf.layers.dense(l_a, N_A, tf.nn.softplus, kernel_initializer=, name=)
        with tf.variable_scope():
            l_c = tf.layers.dense(self.s, 100, tf.nn.relu6, kernel_initializer=, name=)
            v = tf.layers.dense(l_c, 1, kernel_initializer=, name=)
        a_params = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=)
        c_params = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=)
        return mu, sigma, v, a_params, c_params
    def update_global():
        SESS.run([], feed_dict)
    def pull_global():
        SESS.run([])
    def choose_action():
        s = s[np.newaxis, :]
        return SESS.run(self.A, {self.s:})
class Worker():
    def __init__():
        self.env = gym.make().unwrapped
        self.name =
        self.AC = ACNet()
    def work():
        global GLOBAL_RUNNING_R, GLOBAL_EP
        total_step =
        buffer_s, buffer_a, buffer_r = [], [], []
        while not COORD.should_stop() and GLOBAL_EP < MAX_GLOBAL_EP:
            s = self.env.reset()
            ep_r =
            for ep_t in range():
                a = self.AC.choose_action()
                s_, r, done, info = self.env.step()
                done = True if ep_t ==
                ep_r +=
                buffer_s.append()
                buffer_a.append()
                buffer_r.append(()/8)
                if total_step % UPDATE_GLOBAL_ITER == 0 or done:
                    if done:
                        v_s_ =
                    else:
                        v_s_ = SESS.run(self.AC.v, {self.AC.s:, :})[]
                    buffer_v_target = []
                    for r in buffer_r[::]:
                        v_s_ =
                        buffer_v_target.append()
                    buffer_v_target.reverse()
                    buffer_s, buffer_a, buffer_v_target = np.vstack(), np.vstack(), np.vstack()
                    feed_dict = {self.AC.s:,self.AC.a_his:,self.AC.v_target:,}
                    self.AC.update_global()
                    buffer_s, buffer_a, buffer_r = [], [], []
                    self.AC.pull_global()
                s =
                total_step +=
                if done:
                    if len() == 0:
                        GLOBAL_RUNNING_R.append()
                    else:
                        GLOBAL_RUNNING_R.append(0.9 * GLOBAL_RUNNING_R[] + 0.1 * ep_r)
                    GLOBAL_EP +=
                    break
if __name__ == "__main__":
    SESS = tf.Session()
    with tf.device("/cpu:):
        OPT_A = tf.train.RMSPropOptimizer(LR_A, name=)
        OPT_C = tf.train.RMSPropOptimizer(LR_C, name=)
        GLOBAL_AC = ACNet()
        workers = []
        for i in range():
            i_name =
            workers.append(Worker())
    COORD = tf.train.Coordinator()
    SESS.run(tf.global_variables_initializer())
    if OUTPUT_GRAPH:
        if os.path.exists():
            shutil.rmtree()
        tf.summary.FileWriter()
    worker_threads = []
    for worker in workers:
        job = lambda: worker.work()
        t = threading.Thread(target=)
        t.start()
        worker_threads.append()
    COORD.join()
    plt.plot(np.arange(len()), GLOBAL_RUNNING_R)
    plt.xlabel()
    plt.ylabel()
    plt.show()
import multiprocessing
import threading
import tensorflow as tf
import numpy as np
import gym
import os
import shutil
import matplotlib.pyplot as plt
GAME =
OUTPUT_GRAPH =
LOG_DIR =
N_WORKERS = multiprocessing.cpu_count()
MAX_GLOBAL_EP =
GLOBAL_NET_SCOPE =
UPDATE_GLOBAL_ITER =
GAMMA =
ENTROPY_BETA =
LR_A =
LR_C =
GLOBAL_RUNNING_R = []
GLOBAL_EP =
env = gym.make()
N_S = env.observation_space.shape[]
N_A =
class ACNet():
    def __init__(self, scope, globalAC=):
        if scope == GLOBAL_NET_SCOPE:
            with tf.variable_scope():
                self.s = tf.placeholder(tf.float32, [], "")
                self.a_params, self.c_params = self._build_net()[-2:]
        else:
            with tf.variable_scope():
                self.s = tf.placeholder(tf.float32, [], "")
                self.a_his = tf.placeholder(tf.int32, [], "")
                self.v_target = tf.placeholder(tf.float32, [], "")
                self.a_prob, self.v, self.a_params, self.c_params = self._build_net()
                td = tf.subtract(self.v_target, self.v, name=)
                with tf.name_scope():
                    self.c_loss = tf.reduce_mean(tf.square())
                with tf.name_scope():
                    log_prob = tf.reduce_sum(tf.log() * tf.one_hot(self.a_his, N_A, dtype=), axis=, keep_dims=)
                    exp_v = log_prob * tf.stop_gradient()
                    entropy = -tf.reduce_sum(self.a_prob * tf.log(),axis=, keep_dims=)
                    self.exp_v =
                    self.a_loss = tf.reduce_mean()
                with tf.name_scope():
                    self.a_grads = tf.gradients()
                    self.c_grads = tf.gradients()
            with tf.name_scope():
                with tf.name_scope():
                    self.pull_a_params_op = [l_p.assign() for l_p, g_p in zip()]
                    self.pull_c_params_op = [l_p.assign() for l_p, g_p in zip()]
                with tf.name_scope():
                    self.update_a_op = OPT_A.apply_gradients(zip())
                    self.update_c_op = OPT_C.apply_gradients(zip())
    def _build_net():
        w_init = tf.random_normal_initializer()
        with tf.variable_scope():
            l_a = tf.layers.dense(self.s, 200, tf.nn.relu6, kernel_initializer=, name=)
            a_prob = tf.layers.dense(l_a, N_A, tf.nn.softmax, kernel_initializer=, name=)
        with tf.variable_scope():
            l_c = tf.layers.dense(self.s, 100, tf.nn.relu6, kernel_initializer=, name=)
            v = tf.layers.dense(l_c, 1, kernel_initializer=, name=)
        a_params = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=)
        c_params = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=)
        return a_prob, v, a_params, c_params
    def update_global():
        SESS.run([], feed_dict)
    def pull_global():
        SESS.run([])
    def choose_action():
        prob_weights = SESS.run(self.a_prob, feed_dict={self.s:, :})
        action = np.random.choice(range(prob_weights.shape[]),p=prob_weights.ravel())
        return action
class Worker():
    def __init__():
        self.env = gym.make().unwrapped
        self.name =
        self.AC = ACNet()
    def work():
        global GLOBAL_RUNNING_R, GLOBAL_EP
        total_step =
        buffer_s, buffer_a, buffer_r = [], [], []
        while not COORD.should_stop() and GLOBAL_EP < MAX_GLOBAL_EP:
            s = self.env.reset()
            ep_r =
            while True:
                a = self.AC.choose_action()
                s_, r, done, info = self.env.step()
                if done: r =
                ep_r +=
                buffer_s.append()
                buffer_a.append()
                buffer_r.append()
                if total_step % UPDATE_GLOBAL_ITER == 0 or done:
                    if done:
                        v_s_ =
                    else:
                        v_s_ = SESS.run(self.AC.v, {self.AC.s:, :})[]
                    buffer_v_target = []
                    for r in buffer_r[::]:
                        v_s_ =
                        buffer_v_target.append()
                    buffer_v_target.reverse()
                    buffer_s, buffer_a, buffer_v_target = np.vstack(), np.array(), np.vstack()
                    feed_dict = {self.AC.s:,self.AC.a_his:,self.AC.v_target:,}
                    self.AC.update_global()
                    buffer_s, buffer_a, buffer_r = [], [], []
                    self.AC.pull_global()
                s =
                total_step +=
                if done:
                    if len() == 0:
                        GLOBAL_RUNNING_R.append()
                    else:
                        GLOBAL_RUNNING_R.append(0.99 * GLOBAL_RUNNING_R[] + 0.01 * ep_r)
                    GLOBAL_EP +=
                    break
if __name__ == "__main__":
    SESS = tf.Session()
    with tf.device("/cpu:):
        OPT_A = tf.train.RMSPropOptimizer(LR_A, name=)
        OPT_C = tf.train.RMSPropOptimizer(LR_C, name=)
        GLOBAL_AC = ACNet()
        workers = []
        for i in range():
            i_name =
            workers.append(Worker())
    COORD = tf.train.Coordinator()
    SESS.run(tf.global_variables_initializer())
    if OUTPUT_GRAPH:
        if os.path.exists():
            shutil.rmtree()
        tf.summary.FileWriter()
    worker_threads = []
    for worker in workers:
        job = lambda: worker.work()
        t = threading.Thread(target=)
        t.start()
        worker_threads.append()
    COORD.join()
    plt.plot(np.arange(len()), GLOBAL_RUNNING_R)
    plt.xlabel()
    plt.ylabel()
    plt.show()
import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt
from tensorflow.examples.tutorials.mnist import input_data
mnist = input_data.read_data_sets("", one_hot=)
learning_rate =
training_epoch =
batch_size =
n_hidden =
n_input =
X = tf.placeholder(tf.float32, [])
W_encode = tf.Variable(tf.random_normal([]))
b_encode = tf.Variable(tf.random_normal([]))
encoder = tf.nn.sigmoid(tf.add(tf.matmul(), b_encode))
W_decode = tf.Variable(tf.random_normal([]))
b_decode = tf.Variable(tf.random_normal([]))
decoder = tf.nn.sigmoid(tf.add(tf.matmul(), b_decode))
cost = tf.reduce_mean(tf.pow())
optimizer = tf.train.RMSPropOptimizer().minimize()
init = tf.global_variables_initializer()
sess = tf.Session()
sess.run()
total_batch = int()
for epoch in range():
    total_cost =
    for i in range():
        batch_xs, batch_ys = mnist.train.next_batch()
        _, cost_val = sess.run([],feed_dict={X:})
        total_cost +=
sample_size =
samples = sess.run(decoder,feed_dict={X: mnist.test.images[:})
fig, ax = plt.subplots(2, sample_size, figsize=())
for i in range():
    ax[][].set_axis_off()
    ax[][].set_axis_off()
    ax[][].imshow(np.reshape(mnist.test.images[], ()))
    ax[][].imshow(np.reshape(samples[], ()))
plt.show()
import multiprocessing
import threading
import tensorflow as tf
import numpy as np
import gym
import os
import shutil
GAME =
OUTPUT_GRAPH =
LOG_DIR =
N_WORKERS = multiprocessing.cpu_count()
MAX_GLOBAL_EP =
GLOBAL_NET_SCOPE =
UPDATE_GLOBAL_ITER =
GAMMA =
ENTROPY_BETA =
LR_A =
LR_C =
GLOBAL_RUNNING_R = []
GLOBAL_EP =
env = gym.make()
N_S = env.observation_space.shape[]
N_A = env.action_space.shape[]
A_BOUND = []
del env
class ACNet():
    def __init__(self, scope, globalAC=):
        if scope == GLOBAL_NET_SCOPE:
            with tf.variable_scope():
                self.s = tf.placeholder(tf.float32, [], "")
                self._build_net()
                self.a_params = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=)
                self.c_params = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=)
        else:
            with tf.variable_scope():
                self.s = tf.placeholder(tf.float32, [], "")
                self.a_his = tf.placeholder(tf.float32, [], "")
                self.v_target = tf.placeholder(tf.float32, [], "")
                mu, sigma, self.v = self._build_net()
                td = tf.subtract(self.v_target, self.v, name=)
                with tf.name_scope():
                    self.c_loss = tf.reduce_mean(tf.square())
                with tf.name_scope():
                    self.test = sigma[]
                    mu, sigma = mu * A_BOUND[], sigma + 1e-5
                normal_dist = tf.contrib.distributions.Normal()
                with tf.name_scope():
                    log_prob = normal_dist.log_prob()
                    exp_v =
                    entropy = normal_dist.entropy()
                    self.exp_v =
                    self.a_loss = tf.reduce_mean()
                with tf.name_scope():
                    self.A = tf.clip_by_value(tf.squeeze(normal_dist.sample()), A_BOUND[], A_BOUND[])
                with tf.name_scope():
                    self.a_params = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=)
                    self.c_params = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=)
                    self.a_grads = tf.gradients()
                    self.c_grads = tf.gradients()
            with tf.name_scope():
                with tf.name_scope():
                    self.pull_a_params_op = [l_p.assign() for l_p, g_p inzip()]
                    self.pull_c_params_op = [l_p.assign() for l_p, g_p inzip()]
                with tf.name_scope():
                    self.update_a_op = OPT_A.apply_gradients(zip())
                    self.update_c_op = OPT_C.apply_gradients(zip())
    def _build_net():
        w_init = tf.random_normal_initializer()
        with tf.variable_scope():
            cell_size =
            s = tf.expand_dims(self.s, axis=,name=)
            rnn_cell = tf.contrib.rnn.BasicRNNCell()
            self.init_state = rnn_cell.zero_state(batch_size=, dtype=)
            outputs, self.final_state = tf.nn.dynamic_rnn(cell=, inputs=, initial_state=, time_major=)
            cell_out = tf.reshape(outputs, [], name=)
            l_c = tf.layers.dense(cell_out, 512, tf.nn.relu6, kernel_initializer=, name=)
            v = tf.layers.dense(l_c, 1, kernel_initializer=, name=)
        with tf.variable_scope():
            cell_out = tf.stop_gradient(cell_out, name=)
            l_a = tf.layers.dense(cell_out, 512, tf.nn.relu6, kernel_initializer=, name=)
            mu = tf.layers.dense(l_a, N_A, tf.nn.tanh, kernel_initializer=, name=)
            sigma = tf.layers.dense(l_a, N_A, tf.nn.softplus, kernel_initializer=, name=)
        return mu, sigma, v
    def update_global():
        _, _, t = SESS.run([], feed_dict)
        return t
    def pull_global():
        SESS.run([])
    def choose_action():
        s = s[np.newaxis, :]
        a, cell_state = SESS.run([], {self.s:, self.init_state:})
        return a, cell_state
class Worker():
    def __init__():
        self.env = gym.make()
        self.name =
        self.AC = ACNet()
    def work():
        global GLOBAL_RUNNING_R, GLOBAL_EP
        total_step =
        buffer_s, buffer_a, buffer_r = [], [], []
        while not COORD.should_stop() and GLOBAL_EP < MAX_GLOBAL_EP:
            s = self.env.reset()
            ep_r =
            rnn_state = SESS.run()
            keep_state = rnn_state.copy()
            while True:
                if self.name == 'W_0' and total_step % 30 == 0:
                    self.env.render()
                a, rnn_state_ = self.AC.choose_action()
                s_, r, done, info = self.env.step()
                if r == -100: r =
                ep_r +=
                buffer_s.append()
                buffer_a.append()
                buffer_r.append()
                if total_step % UPDATE_GLOBAL_ITER == 0 or done:
                    if done:
                        v_s_ =
                    else:
                        v_s_ = SESS.run(self.AC.v, {self.AC.s:, :, self.AC.init_state:})[]
                    buffer_v_target = []
                    for r in buffer_r[::]:
                        v_s_ =
                        buffer_v_target.append()
                    buffer_v_target.reverse()
                    buffer_s, buffer_a, buffer_v_target = np.vstack(), np.vstack(), np.vstack()
                    feed_dict = {self.AC.s:,self.AC.a_his:,self.AC.v_target:,self.AC.init_state:,}
                    test = self.AC.update_global()
                    buffer_s, buffer_a, buffer_r = [], [], []
                    self.AC.pull_global()
                    keep_state = rnn_state_.copy()
                s =
                rnn_state =
                total_step +=
                if done:
                    achieve = "" if self.env.unwrapped.hull.position[] >=
                    if len() == 0:
                        GLOBAL_RUNNING_R.append()
                    else:
                        GLOBAL_RUNNING_R.append(0.95 * GLOBAL_RUNNING_R[] + 0.05 * ep_r)
                    GLOBAL_EP +=
                    break
if __name__ == "__main__":
    SESS = tf.Session()
    with tf.device("/cpu:):
        OPT_A = tf.train.RMSPropOptimizer(LR_A, name=, decay=)
        OPT_C = tf.train.RMSPropOptimizer(LR_C, name=, decay=)
        GLOBAL_AC = ACNet()
        workers = []
        for i in range():
            i_name =
            workers.append(Worker())
    COORD = tf.train.Coordinator()
    SESS.run(tf.global_variables_initializer())
    if OUTPUT_GRAPH:
        if os.path.exists():
            shutil.rmtree()
        tf.summary.FileWriter()
    worker_threads = []
    for worker in workers:
        t = threading.Thread(target=)
        t.start()
        worker_threads.append()
    COORD.join()
    import matplotlib.pyplot as plt
    plt.plot()
    plt.xlabel()
    plt.ylabel()
    plt.show()import numpy as np
import tensorflow as tf
import gym
np.random.seed()
tf.set_random_seed()
OUTPUT_GRAPH =
MAX_EPISODE =
DISPLAY_REWARD_THRESHOLD =
MAX_EP_STEPS =
RENDER =
GAMMA =
LR_A =
LR_C =
env = gym.make()
env.seed()
env =
N_F = env.observation_space.shape[]
N_A =
class Actor():
    def __init__(self, sess, n_features, n_actions, lr=):
        self.sess =
        self.s = tf.placeholder(tf.float32, [], "")
        self.a = tf.placeholder()
        self.td_error = tf.placeholder()
        with tf.variable_scope():
            l1 = tf.layers.dense(inputs=,units=,activation=,kernel_initializer=tf.random_normal_initializer(),bias_initializer=tf.constant_initializer(),name=)
            self.acts_prob = tf.layers.dense(inputs=,units=,activation=,kernel_initializer=tf.random_normal_initializer(),bias_initializer=tf.constant_initializer(),name=)
        with tf.variable_scope():
            log_prob = tf.log(self.acts_prob[])
            self.exp_v = tf.reduce_mean()
        with tf.variable_scope():
            self.train_op = tf.train.AdamOptimizer().minimize()
    def learn():
        s = s[np.newaxis, :]
        feed_dict = {self.s:, self.a:, self.td_error:}
        _, exp_v = self.sess.run([], feed_dict)
        return exp_v
    def choose_action():
        s = s[np.newaxis, :]
        probs = self.sess.run(self.acts_prob, {self.s:})
        return np.random.choice(np.arange(probs.shape[]), p=probs.ravel())
class Critic():
    def __init__(self, sess, n_features, lr=):
        self.sess =
        self.s = tf.placeholder(tf.float32, [], "")
        self.v_ = tf.placeholder(tf.float32, [], "")
        self.r = tf.placeholder()
        with tf.variable_scope():
            l1 = tf.layers.dense(inputs=,units=,activation=,kernel_initializer=tf.random_normal_initializer(),bias_initializer=tf.constant_initializer(),name=)
            self.v = tf.layers.dense(inputs=,units=,activation=,kernel_initializer=tf.random_normal_initializer(),bias_initializer=tf.constant_initializer(),name=)
        with tf.variable_scope():
            self.td_error =
            self.loss = tf.square()
        with tf.variable_scope():
            self.train_op = tf.train.AdamOptimizer().minimize()
    def learn():
        s, s_ = s[np.newaxis, :], s_[np.newaxis, :]
        v_ = self.sess.run(self.v, {self.s:})
        td_error, _ = self.sess.run([],{self.s:, self.v_:, self.r:})
        return td_error
sess = tf.Session()
actor = Actor(sess, n_features=, n_actions=, lr=)
critic = Critic(sess, n_features=, lr=)
sess.run(tf.global_variables_initializer())
if OUTPUT_GRAPH:
    tf.summary.FileWriter()
for i_episode in range():
    s = env.reset()
    t =
    track_r = []
    while True:
        if RENDER: env.render()
        a = actor.choose_action()
        s_, r, done, info = env.step()
        if done: r =
        track_r.append()
        td_error = critic.learn()
        actor.learn()
        s =
        t +=
        if done or t >= MAX_EP_STEPS:
            ep_rs_sum = sum()
            if "" not in globals():
                running_reward =
            else:
                running_reward =
            if running_reward > DISPLAY_REWARD_THRESHOLD: RENDER = True  
            break
import tensorflow as tf
import numpy as np
import gym
np.random.seed()
tf.set_random_seed()
class Actor():
    def __init__(self, sess, n_features, action_bound, lr=):
        self.sess =
        self.s = tf.placeholder(tf.float32, [], "")
        self.a = tf.placeholder(tf.float32, None, name=)
        self.td_error = tf.placeholder(tf.float32, None, name=)
        l1 = tf.layers.dense(inputs=,units=,activation=,kernel_initializer=tf.random_normal_initializer(),bias_initializer=tf.constant_initializer(),name=)
        mu = tf.layers.dense(inputs=,units=,activation=,kernel_initializer=tf.random_normal_initializer(),bias_initializer=tf.constant_initializer(),name=)
        sigma = tf.layers.dense(inputs=,units=,activation=,kernel_initializer=tf.random_normal_initializer(),bias_initializer=tf.constant_initializer(),name=)
        global_step = tf.Variable(0, trainable=)
        self.mu, self.sigma = tf.squeeze(), tf.squeeze()
        self.normal_dist = tf.distributions.Normal()
        self.action = tf.clip_by_value(self.normal_dist.sample(), action_bound[], action_bound[])
        with tf.name_scope():
            log_prob = self.normal_dist.log_prob()
            self.exp_v =
            self.exp_v += 0.01*self.normal_dist.entropy()
        with tf.name_scope():
            self.train_op = tf.train.AdamOptimizer().minimize()
    def learn():
        s = s[np.newaxis, :]
        feed_dict = {self.s:, self.a:, self.td_error:}
        _, exp_v = self.sess.run([], feed_dict)
        return exp_v
    def choose_action():
        s = s[np.newaxis, :]
        return self.sess.run(self.action, {self.s:})
class Critic():
    def __init__(self, sess, n_features, lr=):
        self.sess =
        with tf.name_scope():
            self.s = tf.placeholder(tf.float32, [], "")
            self.v_ = tf.placeholder(tf.float32, [], name=)
            self.r = tf.placeholder(tf.float32, name=)
        with tf.variable_scope():
            l1 = tf.layers.dense(inputs=,units=,activation=,kernel_initializer=tf.random_normal_initializer(),bias_initializer=tf.constant_initializer(),name=)
            self.v = tf.layers.dense(inputs=,units=,activation=,kernel_initializer=tf.random_normal_initializer(),bias_initializer=tf.constant_initializer(),name=)
        with tf.variable_scope():
            self.td_error = tf.reduce_mean()
            self.loss = tf.square()
        with tf.variable_scope():
            self.train_op = tf.train.AdamOptimizer().minimize()
    def learn():
        s, s_ = s[np.newaxis, :], s_[np.newaxis, :]
        v_ = self.sess.run(self.v, {self.s:})
        td_error, _ = self.sess.run([],{self.s:, self.v_:, self.r:})
        return td_error
OUTPUT_GRAPH =
MAX_EPISODE =
MAX_EP_STEPS =
DISPLAY_REWARD_THRESHOLD =
RENDER =
GAMMA =
LR_A =
LR_C =
env = gym.make()
env.seed()
env =
N_S = env.observation_space.shape[]
A_BOUND =
sess = tf.Session()
actor = Actor(sess, n_features=, lr=, action_bound=[])
critic = Critic(sess, n_features=, lr=)
sess.run(tf.global_variables_initializer())
if OUTPUT_GRAPH:
    tf.summary.FileWriter()
for i_episode in range():
    s = env.reset()
    t =
    ep_rs = []
    while True:
        env.render()
        a = actor.choose_action()
        s_, r, done, info = env.step()
        r /=
        td_error = critic.learn()
        actor.learn()
        s =
        t +=
        ep_rs.append()
        if t > MAX_EP_STEPS:
            ep_rs_sum = sum()
            if "" not in globals():
                running_reward =
            else:
                running_reward =
            if running_reward > DISPLAY_REWARD_THRESHOLD: RENDER = True  
            break
import numpy as np
import tensorflow as tf
import gym
import matplotlib.pyplot as plt
class CuriosityNet:
    def __init__(self,n_a,n_s,lr=,gamma=,epsilon=,replace_target_iter=,memory_size=,batch_size=,output_graph=,):
        self.n_a =
        self.n_s =
        self.lr =
        self.gamma =
        self.epsilon =
        self.replace_target_iter =
        self.memory_size =
        self.batch_size =
        self.learn_step_counter =
        self.memory_counter =
        self.memory = np.zeros(())
        self.tfs, self.tfa, self.tfr, self.tfs_, self.dyn_train, self.dqn_train, self.q, self.int_r = self._build_nets()
        t_params = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope=)
        e_params = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope=)
        with tf.variable_scope():
            self.target_replace_op = [tf.assign() for t, e in zip()]
        self.sess = tf.Session()
        if output_graph:
            tf.summary.FileWriter()
        self.sess.run(tf.global_variables_initializer())
    def _build_nets():
        tfs = tf.placeholder(tf.float32, [], name=)
        tfa = tf.placeholder(tf.int32, [], name=)
        tfr = tf.placeholder(tf.float32, [], name=)
        tfs_ = tf.placeholder(tf.float32, [], name=)
        dyn_s_, curiosity, dyn_train = self._build_dynamics_net()
        total_reward = tf.add(curiosity, tfr, name=)
        q, dqn_loss, dqn_train = self._build_dqn()
        return tfs, tfa, tfr, tfs_, dyn_train, dqn_train, q, curiosity
    def _build_dynamics_net():
        with tf.variable_scope():
            float_a = tf.expand_dims(tf.cast(a, dtype=, name=), axis=, name=)
            sa = tf.concat((), axis=, name=)
            encoded_s_ =
            dyn_l = tf.layers.dense(sa, 32, activation=)
            dyn_s_ = tf.layers.dense()
        with tf.name_scope():
            squared_diff = tf.reduce_sum(tf.square(), axis=)
        train_op = tf.train.RMSPropOptimizer(self.lr, name=).minimize(tf.reduce_mean())
        return dyn_s_, squared_diff, train_op
    def _build_dqn():
        with tf.variable_scope():
            e1 = tf.layers.dense()
            q = tf.layers.dense(e1, self.n_a, name=)
        with tf.variable_scope():
            t1 = tf.layers.dense()
            q_ = tf.layers.dense(t1, self.n_a, name=)
        with tf.variable_scope():
            q_target = r + self.gamma * tf.reduce_max(q_, axis=, name=)
        with tf.variable_scope():
            a_indices = tf.stack([tf.range(tf.shape()[], dtype=), a], axis=)
            q_wrt_a = tf.gather_nd(params=, indices=)
        loss = tf.losses.mean_squared_error(labels=, predictions=)
        train_op = tf.train.RMSPropOptimizer(self.lr, name=).minimize(loss, var_list=tf.get_collection())
        return q, loss, train_op
    def store_transition():
        transition = np.hstack((s, [], s_))
        index =
        self.memory[index, :] =
        self.memory_counter +=
    def choose_action():
        s = observation[np.newaxis, :]
        if np.random.uniform() < self.epsilon:
            actions_value = self.sess.run(self.q, feed_dict={self.tfs:})
            action = np.argmax()
        else:
            action = np.random.randint()
        return action
    def learn():
        if self.learn_step_counter % self.replace_target_iter == 0:
            self.sess.run()
        top =
        sample_index = np.random.choice(top, size=)
        batch_memory = self.memory[sample_index, :]
        bs, ba, br, bs_ = batch_memory[:, :], batch_memory[:, self.n_s], batch_memory[:, self.n_s + 1], batch_memory[:, -self.n_s:]
        self.sess.run(self.dqn_train, feed_dict={self.tfs:, self.tfa:, self.tfr:, self.tfs_:})
        if self.learn_step_counter % 1000 == 0:
            self.sess.run(self.dyn_train, feed_dict={self.tfs:, self.tfa:, self.tfs_:})
        self.learn_step_counter +=
env = gym.make()
env =
dqn = CuriosityNet(n_a=, n_s=, lr=, output_graph=)
ep_steps = []
for epi in range():
    s = env.reset()
    steps =
    while True:
        env.render()
        a = dqn.choose_action()
        s_, r, done, info = env.step()
        dqn.store_transition()
        dqn.learn()
        if done:
            ep_steps.append()
            break
        s =
        steps +=
plt.plot()
plt.ylabel()
plt.xlabel()
plt.show()import tensorflow as tf
import numpy as np
import gym
import os
import shutil
np.random.seed()
tf.set_random_seed()
MAX_EPISODES =
LR_A =
LR_C =
GAMMA =
REPLACE_ITER_A =
REPLACE_ITER_C =
MEMORY_CAPACITY =
BATCH_SIZE =
DISPLAY_THRESHOLD =
DATA_PATH =
LOAD_MODEL =
SAVE_MODEL_ITER =
RENDER =
OUTPUT_GRAPH =
ENV_NAME =
GLOBAL_STEP = tf.Variable(0, trainable=)
INCREASE_GS = GLOBAL_STEP.assign(tf.add())
LR_A = tf.train.exponential_decay(LR_A, GLOBAL_STEP, 10000, .97, staircase=)
LR_C = tf.train.exponential_decay(LR_C, GLOBAL_STEP, 10000, .97, staircase=)
END_POINT = () * ()
env = gym.make()
env.seed()
STATE_DIM = env.observation_space.shape[]
ACTION_DIM = env.action_space.shape[]
ACTION_BOUND =
with tf.name_scope():
    S = tf.placeholder(tf.float32, shape=[], name=)
with tf.name_scope():
    R = tf.placeholder(tf.float32, [], name=)
with tf.name_scope():
    S_ = tf.placeholder(tf.float32, shape=[], name=)
class Actor():
    def __init__():
        self.sess =
        self.a_dim =
        self.action_bound =
        self.lr =
        self.t_replace_iter =
        self.t_replace_counter =
        with tf.variable_scope():
            self.a = self._build_net(S, scope=, trainable=)
            self.a_ = self._build_net(S_, scope=, trainable=)
        self.e_params = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope=)
        self.t_params = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope=)
    def _build_net():
        with tf.variable_scope():
            init_w = tf.random_normal_initializer()
            init_b = tf.constant_initializer()
            net = tf.layers.dense(s, 500, activation=,kernel_initializer=, bias_initializer=, name=, trainable=)
            net = tf.layers.dense(net, 200, activation=,kernel_initializer=, bias_initializer=, name=, trainable=)
            with tf.variable_scope():
                actions = tf.layers.dense(net, self.a_dim, activation=, kernel_initializer=,bias_initializer=, name=, trainable=)
                scaled_a = tf.multiply(actions, self.action_bound, name=)
        return scaled_a
    def learn():
        self.sess.run(self.train_op, feed_dict={S:})
        if self.t_replace_counter % self.t_replace_iter == 0:
            self.sess.run([tf.assign() for t, e in zip()])
        self.t_replace_counter +=
    def choose_action():
        s = s[np.newaxis, :]
        return self.sess.run(self.a, feed_dict={S:})[]
    def add_grad_to_graph():
        with tf.variable_scope():
            self.policy_grads_and_vars = tf.gradients(ys=, xs=, grad_ys=)
        with tf.variable_scope():
            opt = tf.train.RMSPropOptimizer()
            self.train_op = opt.apply_gradients(zip(), global_step=)
class Critic():
    def __init__():
        self.sess =
        self.s_dim =
        self.a_dim =
        self.lr =
        self.gamma =
        self.t_replace_iter =
        self.t_replace_counter =
        with tf.variable_scope():
            self.a =
            self.q = self._build_net(S, self.a, "", trainable=)
            self.q_ = self._build_net(S_, a_, "", trainable=)
            self.e_params = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope=)
            self.t_params = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope=)
        with tf.variable_scope():
            self.target_q =
        with tf.variable_scope():
            self.abs_td = tf.abs()
        self.ISWeights = tf.placeholder(tf.float32, [], name=)
        with tf.variable_scope():
            self.loss = tf.reduce_mean(self.ISWeights * tf.squared_difference())
        with tf.variable_scope():
            self.train_op = tf.train.AdamOptimizer().minimize(self.loss, global_step=)
        with tf.variable_scope():
            self.a_grads = tf.gradients()[]
    def _build_net():
        with tf.variable_scope():
            init_w = tf.random_normal_initializer()
            init_b = tf.constant_initializer()
            with tf.variable_scope():
                n_l1 =
                w1_s = tf.get_variable("", [], initializer=, trainable=)
                w1_a = tf.get_variable("", [], initializer=, trainable=)
                b1 = tf.get_variable("", [], initializer=, trainable=)
                net = tf.nn.relu(tf.matmul() + tf.matmul() + b1)
            with tf.variable_scope():
                net = tf.layers.dense(net, 20, activation=, kernel_initializer=,bias_initializer=, name=, trainable=)
            with tf.variable_scope():
                q = tf.layers.dense(net, 1, kernel_initializer=, bias_initializer=, trainable=)
        return q
    def learn():
        _, abs_td = self.sess.run([], feed_dict={S:, self.a:, R:, S_:, self.ISWeights:})
        if self.t_replace_counter % self.t_replace_iter == 0:
            self.sess.run([tf.assign() for t, e in zip()])
        self.t_replace_counter +=
        return abs_td
class SumTree():
    data_pointer =
    def __init__():
        self.capacity =
        self.tree = np.zeros()+1e-5
        self.data = np.zeros(capacity, dtype=)
    def add_new_priority():
        leaf_idx =
        self.data[] =
        self.update()
        self.data_pointer +=
        if self.data_pointer >= self.capacity:
            self.data_pointer =
    def update():
        change = p - self.tree[]
        self.tree[] =
        self._propagate_change()
    def _propagate_change():
        parent_idx = () // 2
        self.tree[] +=
        if parent_idx != 0:
            self._propagate_change()
    def get_leaf():
        leaf_idx = self._retrieve()
        data_idx =
        return [leaf_idx, self.tree[], self.data[]]
    def _retrieve(self, lower_bound, parent_idx=):
        left_child_idx =
        right_child_idx =
        if left_child_idx >= len():
            return parent_idx
        if self.tree[] == self.tree[]:
            return self._retrieve(lower_bound, np.random.choice([]))
        if lower_bound <= self.tree[]:
            return self._retrieve()
        else:
            return self._retrieve(lower_bound - self.tree[], right_child_idx)
    def root_priority():
        return self.tree[]
class Memory():
    epsilon =
    alpha =
    beta =
    beta_increment_per_sampling =
    abs_err_upper =
    def __init__():
        self.tree = SumTree()
    def store():
        p = self._get_priority()
        self.tree.add_new_priority()
    def prio_sample():
        batch_idx, batch_memory, ISWeights = [], [], []
        segment =
        self.beta = np.min([])
        min_prob = np.min(self.tree.tree[-self.tree.capacity:]) / self.tree.root_priority
        maxiwi = np.power()
        for i in range():
            a =
            b = segment * ()
            lower_bound = np.random.uniform()
            while True:
                idx, p, data = self.tree.get_leaf()
                if type() is int:
                    i -=
                    lower_bound = np.random.uniform(segment * i, segment * ())
                else:
                    break
            prob =
            ISWeights.append()
            batch_idx.append()
            batch_memory.append()
        ISWeights = np.vstack()
        ISWeights = np.power() / maxiwi
        return batch_idx, np.vstack(), ISWeights
    def random_sample():
        idx = np.random.randint(0, self.tree.capacity, size=, dtype=)
        return np.vstack(self.tree.data[])
    def update():
        p = self._get_priority()
        self.tree.update()
    def _get_priority():
        error +=
        clipped_error = np.clip()
        return np.power()
sess = tf.Session()
actor = Actor()
critic = Critic()
actor.add_grad_to_graph()
M = Memory()
saver = tf.train.Saver(max_to_keep=)
if LOAD_MODEL:
    all_ckpt = tf.train.get_checkpoint_state().all_model_checkpoint_paths
    saver.restore(sess, all_ckpt[])
else:
    if os.path.isdir(): shutil.rmtree()
    os.mkdir()
    sess.run(tf.global_variables_initializer())
if OUTPUT_GRAPH:
    tf.summary.FileWriter("", graph=)
var =
var_min =
for i_episode in range():
    s = env.reset()
    ep_r =
    while True:
        if RENDER:
            env.render()
        a = actor.choose_action()
        a = np.clip(np.random.normal(), -1, 1)
        s_, r, done, _ = env.step()
        if r == -100: r =
        ep_r +=
        transition = np.hstack((s, a, [], s_))
        max_p = np.max(M.tree.tree[-M.tree.capacity:])
        M.store()
        if GLOBAL_STEP.eval() > MEMORY_CAPACITY/20:
            var = max([])
            tree_idx, b_M, ISWeights = M.prio_sample()
            b_s = b_M[:, :]
            b_a = b_M[:, STATE_DIM:]
            b_r = b_M[:, -STATE_DIM - 1:]
            b_s_ = b_M[:, -STATE_DIM:]
            abs_td = critic.learn()
            actor.learn()
            for i in range(len()):
                idx = tree_idx[]
                M.update(idx, abs_td[])
        if GLOBAL_STEP.eval() % SAVE_MODEL_ITER == 0:
            ckpt_path = os.path.join()
            save_path = saver.save(sess, ckpt_path, global_step=, write_meta_graph=)
        if done:
            if "" not in globals():
                running_r =
            else:
                running_r =
            if running_r > DISPLAY_THRESHOLD: RENDER =
            else: RENDER =
            done = "" if env.unwrapped.hull.position[] >= END_POINT else ""
            break
        s =
        sess.run()import tensorflow as tf
import numpy as np
import gym
import time
MAX_EPISODES =
MAX_EP_STEPS =
LR_A =
LR_C =
GAMMA =
TAU =
MEMORY_CAPACITY =
BATCH_SIZE =
RENDER =
ENV_NAME =
class DDPG():
    def __init__():
        self.memory = np.zeros((), dtype=)
        self.pointer =
        self.sess = tf.Session()
        self.a_dim, self.s_dim, self.a_bound =, s_dim, a_bound,
        self.S = tf.placeholder(tf.float32, [], "")
        self.S_ = tf.placeholder(tf.float32, [], "")
        self.R = tf.placeholder(tf.float32, [], "")
        with tf.variable_scope():
            self.a = self._build_a(self.S, scope=, trainable=)
            a_ = self._build_a(self.S_, scope=, trainable=)
        with tf.variable_scope():
            q = self._build_c(self.S, self.a, scope=, trainable=)
            q_ = self._build_c(self.S_, a_, scope=, trainable=)
        self.ae_params = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope=)
        self.at_params = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope=)
        self.ce_params = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope=)
        self.ct_params = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope=)
        self.soft_replace = [tf.assign(t, () * t + TAU * e)for t, e in zip()]
        q_target =
        td_error = tf.losses.mean_squared_error(labels=, predictions=)
        self.ctrain = tf.train.AdamOptimizer().minimize(td_error, var_list=)
        a_loss = - tf.reduce_mean()
        self.atrain = tf.train.AdamOptimizer().minimize(a_loss, var_list=)
        self.sess.run(tf.global_variables_initializer())
    def choose_action():
        return self.sess.run(self.a, {self.S:, :})[]
    def learn():
        self.sess.run()
        indices = np.random.choice(MEMORY_CAPACITY, size=)
        bt = self.memory[indices, :]
        bs = bt[:, :]
        ba = bt[:, self.s_dim:]
        br = bt[:, -self.s_dim - 1:]
        bs_ = bt[:, -self.s_dim:]
        self.sess.run(self.atrain, {self.S:})
        self.sess.run(self.ctrain, {self.S:, self.a:, self.R:, self.S_:})
    def store_transition():
        transition = np.hstack((s, a, [], s_))
        index =
        self.memory[index, :] =
        self.pointer +=
    def _build_a():
        with tf.variable_scope():
            net = tf.layers.dense(s, 30, activation=, name=, trainable=)
            a = tf.layers.dense(net, self.a_dim, activation=, name=, trainable=)
            return tf.multiply(a, self.a_bound, name=)
    def _build_c():
        with tf.variable_scope():
            n_l1 =
            w1_s = tf.get_variable("", [], trainable=)
            w1_a = tf.get_variable("", [], trainable=)
            b1 = tf.get_variable("", [], trainable=)
            net = tf.nn.relu(tf.matmul() + tf.matmul() + b1)
            return tf.layers.dense(net, 1, trainable=)
env = gym.make()
env =
env.seed()
s_dim = env.observation_space.shape[]
a_dim = env.action_space.shape[]
a_bound =
ddpg = DDPG()
var =
t1 = time.time()
for i in range():
    s = env.reset()
    ep_reward =
    for j in range():
        if RENDER:
            env.render()
        a = ddpg.choose_action()
        a = np.clip(np.random.normal(), -2, 2)
        s_, r, done, info = env.step()
        ddpg.store_transition()
        if ddpg.pointer > MEMORY_CAPACITY:
            var *=
            ddpg.learn()
        s =
        ep_reward +=
        if j == MAX_EP_STEPS-1:
            break
import numpy as np
import gym
import time
MAX_EPISODES =
MAX_EP_STEPS =
LR_A =
LR_C =
GAMMA =
TAU =
MEMORY_CAPACITY =
BATCH_SIZE =
RENDER =
ENV_NAME =
class DDPG():
    def __init__():
        self.memory = np.zeros((), dtype=)
        self.pointer =
        self.sess = tf.Session()
        self.a_dim, self.s_dim, self.a_bound =, s_dim, a_bound,
        self.S = tf.placeholder(tf.float32, [], "")
        self.S_ = tf.placeholder(tf.float32, [], "")
        self.R = tf.placeholder(tf.float32, [], "")
        self.a = self._build_a()
        q = self._build_c()
        a_params = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=)
        c_params = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=)
        ema = tf.train.ExponentialMovingAverage(decay=)
        def ema_getter():
            return ema.average(getter())
        target_update = [ema.apply(), ema.apply()]
        a_ = self._build_a(self.S_, reuse=, custom_getter=)
        q_ = self._build_c(self.S_, a_, reuse=, custom_getter=)
        a_loss = - tf.reduce_mean()
        self.atrain = tf.train.AdamOptimizer().minimize(a_loss, var_list=)
        with tf.control_dependencies():
            q_target =
            td_error = tf.losses.mean_squared_error(labels=, predictions=)
            self.ctrain = tf.train.AdamOptimizer().minimize(td_error, var_list=)
        self.sess.run(tf.global_variables_initializer())
    def choose_action():
        return self.sess.run(self.a, {self.S:, :})[]
    def learn():
        indices = np.random.choice(MEMORY_CAPACITY, size=)
        bt = self.memory[indices, :]
        bs = bt[:, :]
        ba = bt[:, self.s_dim:]
        br = bt[:, -self.s_dim - 1:]
        bs_ = bt[:, -self.s_dim:]
        self.sess.run(self.atrain, {self.S:})
        self.sess.run(self.ctrain, {self.S:, self.a:, self.R:, self.S_:})
    def store_transition():
        transition = np.hstack((s, a, [], s_))
        index =
        self.memory[index, :] =
        self.pointer +=
    def _build_a(self, s, reuse=, custom_getter=):
        trainable =
        with tf.variable_scope("", reuse=, custom_getter=):
            net = tf.layers.dense(s, 30, activation=, name=, trainable=)
            a = tf.layers.dense(net, self.a_dim, activation=, name=, trainable=)
            return tf.multiply(a, self.a_bound, name=)
    def _build_c(self, s, a, reuse=, custom_getter=):
        trainable =
        with tf.variable_scope("", reuse=, custom_getter=):
            n_l1 =
            w1_s = tf.get_variable("", [], trainable=)
            w1_a = tf.get_variable("", [], trainable=)
            b1 = tf.get_variable("", [], trainable=)
            net = tf.nn.relu(tf.matmul() + tf.matmul() + b1)
            return tf.layers.dense(net, 1, trainable=)
env = gym.make()
env =
env.seed()
s_dim = env.observation_space.shape[]
a_dim = env.action_space.shape[]
a_bound =
ddpg = DDPG()
var =
t1 = time.time()
for i in range():
    s = env.reset()
    ep_reward =
    for j in range():
        if RENDER:
            env.render()
        a = ddpg.choose_action()
        a = np.clip(np.random.normal(), -2, 2)
        s_, r, done, info = env.step()
        ddpg.store_transition()
        if ddpg.pointer > MEMORY_CAPACITY:
            var *=
            ddpg.learn()
        s =
        ep_reward +=
        if j == MAX_EP_STEPS-1:
            break
import numpy as np
import matplotlib.pyplot as plt
import gym, threading, queue
EP_MAX =
EP_LEN =
N_WORKER =
GAMMA =
A_LR =
C_LR =
MIN_BATCH_SIZE =
UPDATE_STEP =
EPSILON =
GAME =
env = gym.make()
S_DIM = env.observation_space.shape[]
A_DIM =
class PPONet():
    def __init__():
        self.sess = tf.Session()
        self.tfs = tf.placeholder(tf.float32, [], "")
        w_init = tf.random_normal_initializer()
        lc = tf.layers.dense(self.tfs, 200, tf.nn.relu, kernel_initializer=, name=)
        self.v = tf.layers.dense()
        self.tfdc_r = tf.placeholder(tf.float32, [], "")
        self.advantage =
        self.closs = tf.reduce_mean(tf.square())
        self.ctrain_op = tf.train.AdamOptimizer().minimize()
        self.pi, pi_params = self._build_anet("", trainable=)
        oldpi, oldpi_params = self._build_anet("", trainable=)
        self.update_oldpi_op = [oldp.assign() for p, oldp in zip()]
        self.tfa = tf.placeholder(tf.int32, [], "")
        self.tfadv = tf.placeholder(tf.float32, [], "")
        a_indices = tf.stack([tf.range(tf.shape()[], dtype=), self.tfa], axis=)
        pi_prob = tf.gather_nd(params=, indices=)
        oldpi_prob = tf.gather_nd(params=, indices=)
        ratio = pi_prob/()
        surr =
        self.aloss = -tf.reduce_mean(tf.minimum(surr,tf.clip_by_value() * self.tfadv))
        self.atrain_op = tf.train.AdamOptimizer().minimize()
        self.sess.run(tf.global_variables_initializer())
    def update():
        global GLOBAL_UPDATE_COUNTER
        while not COORD.should_stop():
            if GLOBAL_EP < EP_MAX:
                UPDATE_EVENT.wait()
                self.sess.run()
                data = [QUEUE.get() for _ in range(QUEUE.qsize())]
                data = np.vstack()
                s, a, r = data[:, :], data[:, S_DIM:].ravel(), data[:, -1:]
                adv = self.sess.run(self.advantage, {self.tfs:, self.tfdc_r:})
                [self.sess.run(self.atrain_op, {self.tfs:, self.tfa:, self.tfadv:}) for _ in range()]
                [self.sess.run(self.ctrain_op, {self.tfs:, self.tfdc_r:}) for _ in range()]
                UPDATE_EVENT.clear()
                GLOBAL_UPDATE_COUNTER =
                ROLLING_EVENT.set()
    def _build_anet():
        with tf.variable_scope():
            l_a = tf.layers.dense(self.tfs, 200, tf.nn.relu, trainable=)
            a_prob = tf.layers.dense(l_a, A_DIM, tf.nn.softmax, trainable=)
        params = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope=)
        return a_prob, params
    def choose_action():
        prob_weights = self.sess.run(self.pi, feed_dict={self.tfs:, :})
        action = np.random.choice(range(prob_weights.shape[]),p=prob_weights.ravel())
        return action
    def get_v():
        if s.ndim < 2: s = s[np.newaxis, :]
        return self.sess.run(self.v, {self.tfs:})[]
class Worker():
    def __init__():
        self.wid =
        self.env = gym.make().unwrapped
        self.ppo =
    def work():
        global GLOBAL_EP, GLOBAL_RUNNING_R, GLOBAL_UPDATE_COUNTER
        while not COORD.should_stop():
            s = self.env.reset()
            ep_r =
            buffer_s, buffer_a, buffer_r = [], [], []
            for t in range():
                if not ROLLING_EVENT.is_set():
                    ROLLING_EVENT.wait()
                    buffer_s, buffer_a, buffer_r = [], [], []
                a = self.ppo.choose_action()
                s_, r, done, _ = self.env.step()
                if done: r =
                buffer_s.append()
                buffer_a.append()
                buffer_r.append()
                s =
                ep_r +=
                GLOBAL_UPDATE_COUNTER +=
                if t == EP_LEN - 1 or GLOBAL_UPDATE_COUNTER >= MIN_BATCH_SIZE or done:
                    if done:
                        v_s_ =
                    else:
                        v_s_ = self.ppo.get_v()
                    discounted_r = []
                    for r in buffer_r[::]:
                        v_s_ =
                        discounted_r.append()
                    discounted_r.reverse()
                    bs, ba, br = np.vstack(), np.vstack(), np.array()[:, None]
                    buffer_s, buffer_a, buffer_r = [], [], []
                    QUEUE.put(np.hstack(()))
                    if GLOBAL_UPDATE_COUNTER >= MIN_BATCH_SIZE:
                        ROLLING_EVENT.clear()
                        UPDATE_EVENT.set()
                    if GLOBAL_EP >= EP_MAX:
                        COORD.request_stop()
                        break
                    if done:
            if len() == 0: GLOBAL_RUNNING_R.append()
            else: GLOBAL_RUNNING_R.append(GLOBAL_RUNNING_R[]*0.9+ep_r*0.1)
            GLOBAL_EP +=
if __name__ == "__main__":
    GLOBAL_PPO = PPONet()
    UPDATE_EVENT, ROLLING_EVENT = threading.Event(), threading.Event()
    UPDATE_EVENT.clear()
    ROLLING_EVENT.set()
    workers = [Worker(wid=) for i in range()]
    GLOBAL_UPDATE_COUNTER, GLOBAL_EP =, 0
    GLOBAL_RUNNING_R = []
    COORD = tf.train.Coordinator()
    QUEUE = queue.Queue()
    threads = []
    for worker in workers:
        t = threading.Thread(target=, args=())
        t.start()
        threads.append()
    threads.append(threading.Thread(target=,))
    threads[].start()
    COORD.join()
    plt.plot(np.arange(len()), GLOBAL_RUNNING_R)
    plt.xlabel(); plt.ylabel(); plt.ion(); plt.show()
    env = gym.make()
    while True:
        s = env.reset()
        for t in range():
            env.render()
            s, r, done, info = env.step(GLOBAL_PPO.choose_action())
            if done:
                break
import tensorflow as tf
from tensorflow.contrib.distributions import Normal
import numpy as np
import matplotlib.pyplot as plt
import threading, queue
from arm_env import ArmEnv
EP_MAX =
EP_LEN =
N_WORKER =
GAMMA =
A_LR =
C_LR =
MIN_BATCH_SIZE =
UPDATE_STEP =
EPSILON =
MODE = []
n_model =
env = ArmEnv(mode=MODE[])
S_DIM =
A_DIM =
A_BOUND = env.action_bound[]
class PPO():
    def __init__():
        self.sess = tf.Session()
        self.tfs = tf.placeholder(tf.float32, [], "")
        l1 = tf.layers.dense()
        self.v = tf.layers.dense()
        self.tfdc_r = tf.placeholder(tf.float32, [], "")
        self.advantage =
        self.closs = tf.reduce_mean(tf.square())
        self.ctrain_op = tf.train.AdamOptimizer().minimize()
        pi, pi_params = self._build_anet("", trainable=)
        oldpi, oldpi_params = self._build_anet("", trainable=)
        self.sample_op = tf.squeeze(pi.sample(), axis=)
        self.update_oldpi_op = [oldp.assign() for p, oldp in zip()]
        self.tfa = tf.placeholder(tf.float32, [], "")
        self.tfadv = tf.placeholder(tf.float32, [], "")
        ratio = pi.prob() / (oldpi.prob() + 1e-5)
        surr =
        self.aloss = -tf.reduce_mean(tf.minimum(surr,tf.clip_by_value() * self.tfadv))
        self.atrain_op = tf.train.AdamOptimizer().minimize()
        self.sess.run(tf.global_variables_initializer())
    def update():
        global GLOBAL_UPDATE_COUNTER
        while not COORD.should_stop():
            if GLOBAL_EP < EP_MAX:
                UPDATE_EVENT.wait()
                self.sess.run()
                data = [QUEUE.get() for _ in range(QUEUE.qsize())]
                data = np.vstack()
                s, a, r = data[:, :], data[:, S_DIM:], data[:, -1:]
                adv = self.sess.run(self.advantage, {self.tfs:, self.tfdc_r:})
                [self.sess.run(self.atrain_op, {self.tfs:, self.tfa:, self.tfadv:}) for _ in range()]
                [self.sess.run(self.ctrain_op, {self.tfs:, self.tfdc_r:}) for _ in range()]
                UPDATE_EVENT.clear()
                GLOBAL_UPDATE_COUNTER =
                ROLLING_EVENT.set()
    def _build_anet():
        with tf.variable_scope():
            l1 = tf.layers.dense(self.tfs, 200, tf.nn.relu, trainable=)
            mu = A_BOUND * tf.layers.dense(l1, A_DIM, tf.nn.tanh, trainable=)
            sigma = tf.layers.dense(l1, A_DIM, tf.nn.softplus, trainable=)
            norm_dist = Normal(loc=, scale=)
        params = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope=)
        return norm_dist, params
    def choose_action():
        s = s[np.newaxis, :]
        a = self.sess.run(self.sample_op, {self.tfs:})[]
        return np.clip()
    def get_v():
        if s.ndim < 2: s = s[np.newaxis, :]
        return self.sess.run(self.v, {self.tfs:})[]
class Worker():
    def __init__():
        self.wid =
        self.env = ArmEnv(mode=MODE[])
        self.ppo =
    def work():
        global GLOBAL_EP, GLOBAL_RUNNING_R, GLOBAL_UPDATE_COUNTER
        while not COORD.should_stop():
            s = self.env.reset()
            ep_r =
            buffer_s, buffer_a, buffer_r = [], [], []
            for t in range():
                if not ROLLING_EVENT.is_set():
                    ROLLING_EVENT.wait()
                    buffer_s, buffer_a, buffer_r = [], [], []
                a = self.ppo.choose_action()
                s_, r, done = self.env.step()
                buffer_s.append()
                buffer_a.append()
                buffer_r.append()
                s =
                ep_r +=
                GLOBAL_UPDATE_COUNTER +=
                if t == EP_LEN - 1 or GLOBAL_UPDATE_COUNTER >= MIN_BATCH_SIZE:
                    v_s_ = self.ppo.get_v()
                    discounted_r = []
                    for r in buffer_r[::]:
                        v_s_ =
                        discounted_r.append()
                    discounted_r.reverse()
                    bs, ba, br = np.vstack(), np.vstack(), np.array()[:, np.newaxis]
                    buffer_s, buffer_a, buffer_r = [], [], []
                    QUEUE.put(np.hstack(()))
                    if GLOBAL_UPDATE_COUNTER >= MIN_BATCH_SIZE:
                        ROLLING_EVENT.clear()
                        UPDATE_EVENT.set()
                    if GLOBAL_EP >= EP_MAX:
                        COORD.request_stop()
                        break
            if len() == 0: GLOBAL_RUNNING_R.append()
            else: GLOBAL_RUNNING_R.append(GLOBAL_RUNNING_R[]*0.9+ep_r*0.1)
            GLOBAL_EP +=
if __name__ == "__main__":
    GLOBAL_PPO = PPO()
    UPDATE_EVENT, ROLLING_EVENT = threading.Event(), threading.Event()
    UPDATE_EVENT.clear()
    ROLLING_EVENT.set()
    workers = [Worker(wid=) for i in range()]
    GLOBAL_UPDATE_COUNTER, GLOBAL_EP =, 0
    GLOBAL_RUNNING_R = []
    COORD = tf.train.Coordinator()
    QUEUE = queue.Queue()
    threads = []
    for worker in workers:
        t = threading.Thread(target=, args=())
        t.start()
        threads.append()
    threads.append(threading.Thread(target=,))
    threads[].start()
    COORD.join()
    plt.plot(np.arange(len()), GLOBAL_RUNNING_R)
    plt.xlabel(); plt.ylabel(); plt.ion(); plt.show()
    env.set_fps()
    while True:
        s = env.reset()
        for t in range():
            env.render()
            s = env.step(GLOBAL_PPO.choose_action())[]import numpy as np
import tensorflow as tf
np.random.seed()
tf.set_random_seed()
class DeepQNetwork:
    def __init__(self,n_actions,n_features,learning_rate=,reward_decay=,e_greedy=,replace_target_iter=,memory_size=,batch_size=,e_greedy_increment=,output_graph=,):
        self.n_actions =
        self.n_features =
        self.lr =
        self.gamma =
        self.epsilon_max =
        self.replace_target_iter =
        self.memory_size =
        self.batch_size =
        self.epsilon_increment =
        self.epsilon =
        self.learn_step_counter =
        self.memory = np.zeros(())
        self._build_net()
        t_params = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope=)
        e_params = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope=)
        with tf.variable_scope():
            self.target_replace_op = [tf.assign() for t, e in zip()]
        self.sess = tf.Session()
        if output_graph:
            tf.summary.FileWriter()
        self.sess.run(tf.global_variables_initializer())
        self.cost_his = []
    def _build_net():
        self.s = tf.placeholder(tf.float32, [], name=)
        self.s_ = tf.placeholder(tf.float32, [], name=)
        self.r = tf.placeholder(tf.float32, [], name=)
        self.a = tf.placeholder(tf.int32, [], name=)
        w_initializer, b_initializer = tf.random_normal_initializer(), tf.constant_initializer()
        with tf.variable_scope():
            e1 = tf.layers.dense(self.s, 20, tf.nn.relu, kernel_initializer=,bias_initializer=, name=)
            self.q_eval = tf.layers.dense(e1, self.n_actions, kernel_initializer=,bias_initializer=, name=)
        with tf.variable_scope():
            t1 = tf.layers.dense(self.s_, 20, tf.nn.relu, kernel_initializer=,bias_initializer=, name=)
            self.q_next = tf.layers.dense(t1, self.n_actions, kernel_initializer=,bias_initializer=, name=)
        with tf.variable_scope():
            q_target = self.r + self.gamma * tf.reduce_max(self.q_next, axis=, name=)
            self.q_target = tf.stop_gradient()
        with tf.variable_scope():
            a_indices = tf.stack([tf.range(tf.shape()[], dtype=), self.a], axis=)
            self.q_eval_wrt_a = tf.gather_nd(params=, indices=)
        with tf.variable_scope():
            self.loss = tf.reduce_mean(tf.squared_difference(self.q_target, self.q_eval_wrt_a, name=))
        with tf.variable_scope():
            self._train_op = tf.train.RMSPropOptimizer().minimize()
    def store_transition():
        if not hasattr():
            self.memory_counter =
        transition = np.hstack((s, [], s_))
        index =
        self.memory[index, :] =
        self.memory_counter +=
    def choose_action():
        observation = observation[np.newaxis, :]
        if np.random.uniform() < self.epsilon:
            actions_value = self.sess.run(self.q_eval, feed_dict={self.s:})
            action = np.argmax()
        else:
            action = np.random.randint()
        return action
    def learn():
        if self.learn_step_counter % self.replace_target_iter == 0:
            self.sess.run()
        if self.memory_counter > self.memory_size:
            sample_index = np.random.choice(self.memory_size, size=)
        else:
            sample_index = np.random.choice(self.memory_counter, size=)
        batch_memory = self.memory[sample_index, :]
        _, cost = self.sess.run([],feed_dict={self.s: batch_memory[:, :,self.a: batch_memory[:,,self.r: batch_memory[:,,self.s_: batch_memory[:, -self.n_features:,})
        self.cost_his.append()
        self.epsilon =
        self.learn_step_counter +=
    def plot_cost():
        import matplotlib.pyplot as plt
        plt.plot(np.arange(len()), self.cost_his)
        plt.ylabel()
        plt.xlabel()
        plt.show()
if __name__ == "__main__":
    DQN = DeepQNetwork(3,4, output_graph=)
import tensorflow as tf
import numpy as np
x_data = np.array([[], [], [], [], [], []])
y_data = np.array([[],[],[],[],[],[]])
X = tf.placeholder()
Y = tf.placeholder()
W = tf.Variable(tf.random_uniform([], -1., 1.))
b = tf.Variable(tf.zeros([]))
L = tf.add(tf.matmul(), b)
L = tf.nn.relu()
model = tf.nn.softmax()
cost = tf.reduce_mean(-tf.reduce_sum(Y * tf.log(), axis=))
optimizer = tf.train.GradientDescentOptimizer(learning_rate=)
train_op = optimizer.minimize()
init = tf.global_variables_initializer()
sess = tf.Session()
sess.run()
for step in range():
    sess.run(train_op, feed_dict={X:, Y:})
    if () % 10 == 0:
prediction = tf.argmax()
target = tf.argmax()
is_correct = tf.equal()
accuracy = tf.reduce_mean(tf.cast())
import numpy as np
import tensorflow as tf
np.random.seed()
tf.set_random_seed()
class SumTree():
    data_pointer =
    def __init__():
        self.capacity =
        self.tree = np.zeros()
        self.data = np.zeros(capacity, dtype=)
    def add_new_priority():
        leaf_idx =
        self.data[] =
        self.update()
        self.data_pointer +=
        if self.data_pointer >= self.capacity:
            self.data_pointer =
    def update():
        change = p - self.tree[]
        self.tree[] =
        self._propagate_change()
    def _propagate_change():
        parent_idx = () // 2
        self.tree[] +=
        if parent_idx != 0:
            self._propagate_change()
    def get_leaf():
        leaf_idx = self._retrieve()
        data_idx =
        return [leaf_idx, self.tree[], self.data[]]
    def _retrieve(self, lower_bound, parent_idx=):
        left_child_idx =
        right_child_idx =
        if left_child_idx >= len():
            return parent_idx
        if self.tree[] == self.tree[]:
            return self._retrieve(lower_bound, np.random.choice([]))
        if lower_bound <= self.tree[]:
            return self._retrieve()
        else:
            return self._retrieve(lower_bound - self.tree[], right_child_idx)
    def root_priority():
        return self.tree[]
class Memory():
    epsilon =
    alpha =
    beta =
    beta_increment_per_sampling =
    abs_err_upper =
    def __init__():
        self.tree = SumTree()
    def store():
        p = self._get_priority()
        self.tree.add_new_priority()
    def sample():
        batch_idx, batch_memory, ISWeights = [], [], []
        segment =
        self.beta = np.min([])
        min_prob = np.min(self.tree.tree[-self.tree.capacity:]) / self.tree.root_priority
        maxiwi = np.power()
        for i in range():
            a =
            b = segment * ()
            lower_bound = np.random.uniform()
            idx, p, data = self.tree.get_leaf()
            prob =
            ISWeights.append()
            batch_idx.append()
            batch_memory.append()
        ISWeights = np.vstack()
        ISWeights = np.power() / maxiwi
        return batch_idx, np.vstack(), ISWeights
    def update():
        p = self._get_priority()
        self.tree.update()
    def _get_priority():
        error +=
        clipped_error = np.clip()
        return np.power()
class DuelingDQNPrioritizedReplay:
    def __init__(self,n_actions,n_features,learning_rate=,reward_decay=,e_greedy=,replace_target_iter=,memory_size=,batch_size=,e_greedy_increment=,hidden=[],output_graph=,sess=,):
        self.n_actions =
        self.n_features =
        self.lr =
        self.gamma =
        self.epsilon_max =
        self.replace_target_iter =
        self.memory_size =
        self.batch_size =
        self.hidden =
        self.epsilon_increment =
        self.epsilon =
        self.learn_step_counter =
        self._build_net()
        self.memory = Memory(capacity=)
        if sess is None:
            self.sess = tf.Session()
            self.sess.run(tf.global_variables_initializer())
        else:
            self.sess =
        if output_graph:
            tf.summary.FileWriter()
        self.cost_his = []
    def _build_net():
        def build_layers():
            for i, h in enumerate():
                if i == 0:
                    in_units, out_units, inputs =, self.hidden[], s
                else:
                    in_units, out_units, inputs = self.hidden[], self.hidden[], l
                with tf.variable_scope():
                    w = tf.get_variable("", [], initializer=, collections=)
                    b = tf.get_variable("", [], initializer=, collections=)
                    l = tf.nn.relu(tf.matmul() + b)
            with tf.variable_scope():
                w = tf.get_variable("", [self.hidden[], 1], initializer=, collections=)
                b = tf.get_variable("", [], initializer=, collections=)
                self.V = tf.matmul() + b
            with tf.variable_scope():
                w = tf.get_variable("", [self.hidden[], self.n_actions], initializer=, collections=)
                b = tf.get_variable("", [], initializer=, collections=)
                self.A = tf.matmul() + b
            with tf.variable_scope():
                out = self.V + (self.A - tf.reduce_mean(self.A, axis=, keep_dims=))
            return out
        self.s = tf.placeholder(tf.float32, [], name=)
        self.q_target = tf.placeholder(tf.float32, [], name=)
        self.ISWeights = tf.placeholder(tf.float32, [], name=)
        with tf.variable_scope():
            c_names, w_initializer, b_initializer = [], tf.random_normal_initializer(), tf.constant_initializer()
            self.q_eval = build_layers()
        with tf.variable_scope():
            self.abs_errors = tf.abs(tf.reduce_sum(self.q_target - self.q_eval, axis=))
            self.loss = tf.reduce_mean(self.ISWeights * tf.squared_difference())
        with tf.variable_scope():
            self._train_op = tf.train.AdamOptimizer().minimize()
        self.s_ = tf.placeholder(tf.float32, [], name=)
        with tf.variable_scope():
            c_names = []
            self.q_next = build_layers()
    def store_transition():
        transition = np.hstack((s, [], s_))
        max_p = np.max(self.memory.tree.tree[-self.memory.tree.capacity:])
        self.memory.store()
    def choose_action():
        observation = observation[np.newaxis, :]
        if np.random.uniform() < self.epsilon:
            actions_value = self.sess.run(self.q_eval, feed_dict={self.s:})
            action = np.argmax()
        else:
            action = np.random.randint()
        return action
    def _replace_target_params():
        t_params = tf.get_collection()
        e_params = tf.get_collection()
        self.sess.run([tf.assign() for t, e in zip()])
    def learn():
        if self.learn_step_counter % self.replace_target_iter == 0:
            self._replace_target_params()
        tree_idx, batch_memory, ISWeights = self.memory.sample()
        q_next, q_eval4next = self.sess.run([],feed_dict={self.s_: batch_memory[:, -self.n_features:,self.s: batch_memory[:, -self.n_features:})
        q_eval = self.sess.run(self.q_eval, {self.s: batch_memory[:, :})
        q_target = q_eval.copy()
        batch_index = np.arange(self.batch_size, dtype=)
        eval_act_index = batch_memory[:, self.n_features].astype()
        reward = batch_memory[:, self.n_features + 1]
        max_act4next = np.argmax(q_eval4next,axis=)
        selected_q_next = q_next[]
        q_target[] =
        _, abs_errors, self.cost = self.sess.run([],feed_dict={self.s: batch_memory[:, :,self.q_target:,self.ISWeights:})
        for i in range(len()):
            idx = tree_idx[]
            self.memory.update(idx, abs_errors[])
        self.cost_his.append()
        self.epsilon =
        self.learn_step_counter +=
import numpy as np
import tensorflow as tf
import gym
import matplotlib.pyplot as plt
class CuriosityNet:
    def __init__(self,n_a,n_s,lr=,gamma=,epsilon=,replace_target_iter=,memory_size=,batch_size=,output_graph=,):
        self.n_a =
        self.n_s =
        self.lr =
        self.gamma =
        self.epsilon =
        self.replace_target_iter =
        self.memory_size =
        self.batch_size =
        self.s_encode_size =
        self.learn_step_counter =
        self.memory_counter =
        self.memory = np.zeros(())
        self.tfs, self.tfa, self.tfr, self.tfs_, self.pred_train, self.dqn_train, self.q = self._build_nets()
        t_params = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope=)
        e_params = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope=)
        with tf.variable_scope():
            self.target_replace_op = [tf.assign() for t, e in zip()]
        self.sess = tf.Session()
        if output_graph:
            tf.summary.FileWriter()
        self.sess.run(tf.global_variables_initializer())
    def _build_nets():
        tfs = tf.placeholder(tf.float32, [], name=)
        tfa = tf.placeholder(tf.int32, [], name=)
        tfr = tf.placeholder(tf.float32, [], name=)
        tfs_ = tf.placeholder(tf.float32, [], name=)
        with tf.variable_scope():
            rand_encode_s_ = tf.layers.dense()
        ri, pred_train = self._build_predictor()
        q, dqn_loss, dqn_train = self._build_dqn()
        return tfs, tfa, tfr, tfs_, pred_train, dqn_train, q
    def _build_predictor():
        with tf.variable_scope():
            net = tf.layers.dense()
            out = tf.layers.dense()
        with tf.name_scope():
            ri = tf.reduce_sum(tf.square(), axis=)
        train_op = tf.train.RMSPropOptimizer(self.lr, name=).minimize(tf.reduce_mean(), var_list=tf.get_collection())
        return ri, train_op
    def _build_dqn():
        with tf.variable_scope():
            e1 = tf.layers.dense()
            q = tf.layers.dense(e1, self.n_a, name=)
        with tf.variable_scope():
            t1 = tf.layers.dense()
            q_ = tf.layers.dense(t1, self.n_a, name=)
        with tf.variable_scope():
            q_target = re + ri + self.gamma * tf.reduce_max(q_, axis=, name=)
        with tf.variable_scope():
            a_indices = tf.stack([tf.range(tf.shape()[], dtype=), a], axis=)
            q_wrt_a = tf.gather_nd(params=, indices=)
        loss = tf.losses.mean_squared_error(labels=, predictions=)
        train_op = tf.train.RMSPropOptimizer(self.lr, name=).minimize(loss, var_list=tf.get_collection())
        return q, loss, train_op
    def store_transition():
        transition = np.hstack((s, [], s_))
        index =
        self.memory[index, :] =
        self.memory_counter +=
    def choose_action():
        s = observation[np.newaxis, :]
        if np.random.uniform() < self.epsilon:
            actions_value = self.sess.run(self.q, feed_dict={self.tfs:})
            action = np.argmax()
        else:
            action = np.random.randint()
        return action
    def learn():
        if self.learn_step_counter % self.replace_target_iter == 0:
            self.sess.run()
        top =
        sample_index = np.random.choice(top, size=)
        batch_memory = self.memory[sample_index, :]
        bs, ba, br, bs_ = batch_memory[:, :], batch_memory[:, self.n_s], batch_memory[:, self.n_s + 1], batch_memory[:, -self.n_s:]
        self.sess.run(self.dqn_train, feed_dict={self.tfs:, self.tfa:, self.tfr:, self.tfs_:})
        if self.learn_step_counter % 100 == 0:
            self.sess.run(self.pred_train, feed_dict={self.tfs_:})
        self.learn_step_counter +=
env = gym.make()
env =
dqn = CuriosityNet(n_a=, n_s=, lr=, output_graph=)
ep_steps = []
for epi in range():
    s = env.reset()
    steps =
    while True:
        a = dqn.choose_action()
        s_, r, done, info = env.step()
        dqn.store_transition()
        dqn.learn()
        if done:
            ep_steps.append()
            break
        s =
        steps +=
plt.plot()
plt.ylabel()
plt.xlabel()
plt.show()import numpy as np
import tensorflow as tf
np.random.seed()
tf.set_random_seed()
class PolicyGradient:
    def __init__(self,n_actions,n_features,learning_rate=,reward_decay=,output_graph=,):
        self.n_actions =
        self.n_features =
        self.lr =
        self.gamma =
        self.ep_obs, self.ep_as, self.ep_rs = [], [], []
        self._build_net()
        self.sess = tf.Session()
        if output_graph:
            tf.summary.FileWriter()
        self.sess.run(tf.global_variables_initializer())
    def _build_net():
        with tf.name_scope():
            self.tf_obs = tf.placeholder(tf.float32, [], name=)
            self.tf_acts = tf.placeholder(tf.int32, [], name=)
            self.tf_vt = tf.placeholder(tf.float32, [], name=)
        layer = tf.layers.dense(inputs=,units=,activation=,kernel_initializer=tf.random_normal_initializer(mean=, stddev=),bias_initializer=tf.constant_initializer(),name=)
        all_act = tf.layers.dense(inputs=,units=,activation=,kernel_initializer=tf.random_normal_initializer(mean=, stddev=),bias_initializer=tf.constant_initializer(),name=)
        self.all_act_prob = tf.nn.softmax(all_act, name=)
        with tf.name_scope():
            neg_log_prob = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=, labels=)
            loss = tf.reduce_mean()
        with tf.name_scope():
            self.train_op = tf.train.AdamOptimizer().minimize()
    def choose_action():
        prob_weights = self.sess.run(self.all_act_prob, feed_dict={self.tf_obs:, :})
        action = np.random.choice(range(prob_weights.shape[]), p=prob_weights.ravel())
        return action
    def store_transition():
        self.ep_obs.append()
        self.ep_as.append()
        self.ep_rs.append()
    def learn():
        discounted_ep_rs_norm = self._discount_and_norm_rewards()
        self.sess.run(self.train_op, feed_dict={self.tf_obs:,self.tf_acts:,self.tf_vt:,})
        self.ep_obs, self.ep_as, self.ep_rs = [], [], []
        return discounted_ep_rs_norm
    def _discount_and_norm_rewards():
        discounted_ep_rs = np.zeros_like()
        running_add =
        for t in reversed(range(0, len())):
            running_add = running_add * self.gamma + self.ep_rs[]
            discounted_ep_rs[] =
        discounted_ep_rs -= np.mean()
        discounted_ep_rs /= np.std()
        return discounted_ep_rs
import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt
import gym
EP_MAX =
EP_LEN =
GAMMA =
A_LR =
C_LR =
BATCH =
A_UPDATE_STEPS =
C_UPDATE_STEPS =
S_DIM, A_DIM =, 1
METHOD = [dict(name=, kl_target=, lam=),dict(name=, epsilon=),][]
class PPO():
    def __init__():
        self.sess = tf.Session()
        self.tfs = tf.placeholder(tf.float32, [], "")
        with tf.variable_scope():
            l1 = tf.layers.dense()
            self.v = tf.layers.dense()
            self.tfdc_r = tf.placeholder(tf.float32, [], "")
            self.advantage =
            self.closs = tf.reduce_mean(tf.square())
            self.ctrain_op = tf.train.AdamOptimizer().minimize()
        pi, pi_params = self._build_anet("", trainable=)
        oldpi, oldpi_params = self._build_anet("", trainable=)
        with tf.variable_scope():
            self.sample_op = tf.squeeze(pi.sample(), axis=)
        with tf.variable_scope():
            self.update_oldpi_op = [oldp.assign() for p, oldp in zip()]
        self.tfa = tf.placeholder(tf.float32, [], "")
        self.tfadv = tf.placeholder(tf.float32, [], "")
        with tf.variable_scope():
            with tf.variable_scope():
                ratio = pi.prob() / (oldpi.prob() + 1e-5)
                surr =
            if METHOD[] == "":
                self.tflam = tf.placeholder()
                kl = tf.distributions.kl_divergence()
                self.kl_mean = tf.reduce_mean()
                self.aloss = -(tf.reduce_mean())
            else:
                self.aloss = -tf.reduce_mean(tf.minimum(surr,tf.clip_by_value(ratio, 1.-METHOD[], 1.+METHOD[])*self.tfadv))
        with tf.variable_scope():
            self.atrain_op = tf.train.AdamOptimizer().minimize()
        tf.summary.FileWriter()
        self.sess.run(tf.global_variables_initializer())
    def update():
        self.sess.run()
        adv = self.sess.run(self.advantage, {self.tfs:, self.tfdc_r:})
        if METHOD[] == "":
            for _ in range():
                _, kl = self.sess.run([],{self.tfs:, self.tfa:, self.tfadv:, self.tflam:})
                if kl > 4*METHOD[]:
                    break
            if kl < METHOD[] / 1.5:
                METHOD[] /=
            elif kl > METHOD[] * 1.5:
                METHOD[] *=
            METHOD[] = np.clip(METHOD[], 1e-4, 10)
        else:
            [self.sess.run(self.atrain_op, {self.tfs:, self.tfa:, self.tfadv:}) for _ in range()]
        [self.sess.run(self.ctrain_op, {self.tfs:, self.tfdc_r:}) for _ in range()]
    def _build_anet():
        with tf.variable_scope():
            l1 = tf.layers.dense(self.tfs, 100, tf.nn.relu, trainable=)
            mu = 2 * tf.layers.dense(l1, A_DIM, tf.nn.tanh, trainable=)
            sigma = tf.layers.dense(l1, A_DIM, tf.nn.softplus, trainable=)
            norm_dist = tf.distributions.Normal(loc=, scale=)
        params = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope=)
        return norm_dist, params
    def choose_action():
        s = s[np.newaxis, :]
        a = self.sess.run(self.sample_op, {self.tfs:})[]
        return np.clip()
    def get_v():
        if s.ndim < 2: s = s[np.newaxis, :]
        return self.sess.run(self.v, {self.tfs:})[]
env = gym.make().unwrapped
ppo = PPO()
all_ep_r = []
for ep in range():
    s = env.reset()
    buffer_s, buffer_a, buffer_r = [], [], []
    ep_r =
    for t in range():
        env.render()
        a = ppo.choose_action()
        s_, r, done, _ = env.step()
        buffer_s.append()
        buffer_a.append()
        buffer_r.append(()/8)
        s =
        ep_r +=
        if () % BATCH == 0 or t == EP_LEN-1:
            v_s_ = ppo.get_v()
            discounted_r = []
            for r in buffer_r[::]:
                v_s_ =
                discounted_r.append()
            discounted_r.reverse()
            bs, ba, br = np.vstack(), np.vstack(), np.array()[:, np.newaxis]
            buffer_s, buffer_a, buffer_r = [], [], []
            ppo.update()
    if ep == 0: all_ep_r.append()
    else: all_ep_r.append(all_ep_r[]*0.9 + ep_r*0.1)
plt.plot(np.arange(len()), all_ep_r)
plt.xlabel();plt.ylabel();plt.show()import os
import numpy as np
import six
from ..compat import tfv1 as tf
from ..utils import logger
from .common import get_op_tensor_name
from .varmanip import SessionUpdate, get_checkpoint_path, get_savename_from_varname, is_training_name
__all__ = []
class SessionInit():
    def init():
        self._setup_graph()
        self._run_init()
    def _setup_graph():
        pass
    def _run_init():
        pass
class JustCurrentSession():
    pass
class CheckpointReaderAdapter():
    def __init__():
        self._reader =
        m = self._reader.get_variable_to_shape_map()
        self._map = {k if k.endswith(':) else k + ':0':,}
    def get_variable_to_shape_map():
        return self._map
    def get_tensor():
        if self._reader.has_tensor():
            return self._reader.get_tensor()
        if name in self._map:
            name = name[:]
        return self._reader.get_tensor()
    def has_tensor():
        return name in self._map
    def get_real_name():
        if self._reader.has_tensor():
            return name
        return name[:]
class MismatchLogger():
    def __init__():
        self._exists =
        self._nonexists =
        self._names = []
    def add():
        self._names.append(get_op_tensor_name()[])
    def log():
        if len():
class SaverRestore():
    def __init__(self, model_path, prefix=, ignore=()):
        if model_path.endswith() or model_path.endswith():
        model_path = get_checkpoint_path()
        self.path =
        self.prefix =
        self.ignore = [i if i.endswith(':0') else i + ':0' for i in ignore]
    def _setup_graph():
        dic = self._get_restore_dict()
        self.saver = tf.train.Saver(var_list=, name=str(id()))
    def _run_init():
        self.saver.restore()
    def _read_checkpoint_vars():
        reader = tf.train.NewCheckpointReader()
        reader = CheckpointReaderAdapter()
        ckpt_vars = reader.get_variable_to_shape_map().keys()
        return reader, set()
    def _match_vars():
        reader, chkpt_vars = SaverRestore._read_checkpoint_vars()
        graph_vars = tf.global_variables()
        chkpt_vars_used = set()
        mismatch = MismatchLogger()
        for v in graph_vars:
            name = get_savename_from_varname(v.name, varname_prefix=)
            if name in self.ignore and reader.has_tensor():
            else:
                if reader.has_tensor():
                    func()
                    chkpt_vars_used.add()
                else:
                    if not is_training_name():
                        mismatch.add()
        mismatch.log()
        mismatch = MismatchLogger()
        if len() < len():
            unused =
            for name in sorted():
                if not is_training_name():
                    mismatch.add()
        mismatch.log()
    def _get_restore_dict():
        var_dict = {}
        def f():
            name = reader.get_real_name()
            var_dict[] =
        self._match_vars()
        return var_dict
class SaverRestoreRelaxed():
    def _setup_graph():
        pass
    def _run_init():
        matched_pairs = []
        def f():
            val = reader.get_tensor()
            val = SessionUpdate.relaxed_value_for_var(val, v, ignore_mismatch=)
            if val is not None:
                matched_pairs.append(())
        with sess.as_default():
            self._match_vars()
            upd = SessionUpdate(sess, [x[] for x in matched_pairs])
            upd.update({x[].name:})
class DictRestore():
    def __init__(self, variable_dict, ignore_mismatch=):
        self._prms = {get_op_tensor_name()[]:,}
        self._ignore_mismatch =
    def _run_init():
        variables = tf.get_collection()
        variable_names_list = []
        variable_names = set()
        param_names = set(six.iterkeys())
        intersect = []
        mismatch = MismatchLogger()
        for k in sorted():
            if not is_training_name():
                mismatch.add()
        mismatch.log()
        mismatch = MismatchLogger()
        for k in sorted():
            mismatch.add()
        mismatch.log()
        upd = SessionUpdate(sess, [], ignore_mismatch=)
        upd.update({name:,})
class ChainInit():
    def __init__():
        self.inits =
    def _setup_graph():
        for i in self.inits:
            i._setup_graph()
    def _run_init():
        for i in self.inits:
            i._run_init()
def SmartInit(obj, *, ignore_mismatch=):
    if not obj:
        return JustCurrentSession()
    if isinstance():
        return ChainInit([SmartInit(x, ignore_mismatch=) for x in obj])
    if isinstance():
        obj = os.path.expanduser()
        if obj.endswith() or obj.endswith():
            filename =
            if filename.endswith():
                obj = np.load(filename, encoding=).item()
            elif filename.endswith():
                obj = dict(np.load())
        elif len(tf.gfile.Glob()):
            return ()()
        else:
            raise ValueError()
    if isinstance():
        return DictRestore(obj, ignore_mismatch=)
    raise ValueError()
get_model_loader =
import tensorflow as tf
import time
from . import help
from . import flow
from .ops import op_create, identity
from .ops import HEADER, LINE
from .framework import create_framework
from ..dark.darknet import Darknet
import json
import os
class TFNet():
	_TRAINER = dict({'rmsprop':,'adadelta':,'adagrad':,'adagradDA':,'momentum':,'adam':,'ftrl':,'sgd':})
	_get_fps =
	say =
	train =
	camera =
	predict =
	return_predict =
	to_darknet =
	build_train_op =
	load_from_ckpt =
	def __init__(self, FLAGS, darknet =):
		self.ntrain =
		if isinstance():
			from ..defaults import argHandler
			newFLAGS = argHandler()
			newFLAGS.setDefaults()
			newFLAGS.update()
			FLAGS =
		self.FLAGS =
		if self.FLAGS.pbLoad and self.FLAGS.metaLoad:
			self.say()
			self.graph = tf.Graph()
			device_name =
			with tf.device():
				with self.graph.as_default() as g:
					self.build_from_pb()
			return
		if darknet is None:
			darknet = Darknet()
			self.ntrain = len()
		self.darknet =
		args = []
		self.num_layer = len()
		self.framework = create_framework()
		self.meta =
		self.say()
		start = time.time()
		self.graph = tf.Graph()
		device_name =
		with tf.device():
			with self.graph.as_default() as g:
				self.build_forward()
				self.setup_meta_ops()
		self.say("" - start))
	def build_from_pb():
		with tf.gfile.FastGFile() as f:
			graph_def = tf.GraphDef()
			graph_def.ParseFromString(f.read())
		tf.import_graph_def(graph_def,name=)
		with open() as fp:
			self.meta = json.load()
		self.framework = create_framework()
		self.inp = tf.get_default_graph().get_tensor_by_name('input:)
		self.feed = dict()
		self.out = tf.get_default_graph().get_tensor_by_name('output:)
		self.setup_meta_ops()
	def build_forward():
		verbalise =
		inp_size = [] + self.meta[]
		self.inp = tf.placeholder()
		self.feed = dict()
		state = identity()
		roof =
		self.say()
		for i, layer in enumerate():
			scope = "",layer.type)
			args = []
			state = op_create()
			mess = state.verbalise()
			self.say()
		self.say()
		self.top =
		self.out = tf.identity(state.out, name=)
	def setup_meta_ops():
		cfg = dict({'allow_soft_placement':,'log_device_placement':})
		utility = min()
		if utility > 0.0:
			self.say("")
			cfg[] = tf.GPUOptions(per_process_gpu_memory_fraction =)
			cfg[] =
		else:
			self.say()
			cfg[] = {'GPU':}
		if self.FLAGS.train: self.build_train_op()
		if self.FLAGS.summary:
			self.summary_op = tf.summary.merge_all()
			self.writer = tf.summary.FileWriter()
		self.sess = tf.Session(config = tf.ConfigProto())
		self.sess.run(tf.global_variables_initializer())
		if not self.ntrain:
		self.saver = tf.train.Saver(tf.global_variables(),max_to_keep =)
		if self.FLAGS.load != 0: self.load_from_ckpt()
		if self.FLAGS.summary:
			self.writer.add_graph()
	def savepb():
		darknet_pb = self.to_darknet()
		flags_pb =
		flags_pb.verbalise =
		flags_pb.train =
		tfnet_pb = TFNet()
		tfnet_pb.sess = tf.Session(graph =)
		name = ""
		os.makedirs(os.path.dirname(), exist_ok=)
		with open("", "") as fp:
			json.dump()
		self.say("")
		graph_def =
		tf.train.write_graph()from __future__ import absolute_import
from __future__ import division
from __future__ import print_function
import collections
import os
import re
import numpy as np
import six
from os.path import join
from six.moves import zip
from absl import flags
import tensorflow as tf
def configure_tpu():
  if FLAGS.use_tpu:
    tpu_cluster = tf.contrib.cluster_resolver.TPUClusterResolver(FLAGS.tpu, zone=, project=)
    master = tpu_cluster.get_master()
  else:
    tpu_cluster =
    master =
  session_config = tf.ConfigProto(allow_soft_placement=)
  if FLAGS.use_tpu:
    strategy =
  elif FLAGS.num_core_per_host == 1:
    strategy =
  else:
    strategy = tf.contrib.distribute.MirroredStrategy(num_gpus=)
  per_host_input =
  run_config = tf.contrib.tpu.RunConfig(master=,model_dir=,session_config=,tpu_config=tf.contrib.tpu.TPUConfig(iterations_per_loop=,num_shards=,per_host_input_for_training=),keep_checkpoint_max=,save_checkpoints_secs=,save_checkpoints_steps=,train_distribute=)
  return run_config
def init_from_checkpoint(FLAGS, global_vars=):
  tvars = tf.global_variables() if global_vars else tf.trainable_variables()
  initialized_variable_names = {}
  scaffold_fn =
  if FLAGS.init_checkpoint is not None:
    if FLAGS.init_checkpoint.endswith():
      ckpt_dir = os.path.dirname()
      init_checkpoint = tf.train.latest_checkpoint()
    else:
      init_checkpoint =
    () = get_assignment_map_from_checkpoint()
    if FLAGS.use_tpu:
      def tpu_scaffold():
        tf.train.init_from_checkpoint()
        return tf.train.Scaffold()
      scaffold_fn =
    else:
      tf.train.init_from_checkpoint()
    for var in tvars:
      init_string =
      if var.name in initialized_variable_names:
        init_string =
  return scaffold_fn
def get_train_op(FLAGS, total_loss, grads_and_vars=):
  global_step = tf.train.get_or_create_global_step()
  if FLAGS.warmup_steps > 0:
    warmup_lr = (tf.cast()/ tf.cast()* FLAGS.learning_rate)
  else:
    warmup_lr =
  if FLAGS.decay_method == "":
    decay_lr = tf.train.polynomial_decay(FLAGS.learning_rate,global_step=,decay_steps=,end_learning_rate=)
  elif FLAGS.decay_method == "":
    decay_lr = tf.train.cosine_decay(FLAGS.learning_rate,global_step=,decay_steps=,alpha=)
  else:
    raise ValueError()
  learning_rate = tf.where()
  if ():
    raise ValueError()
  if FLAGS.weight_decay == 0:
    optimizer = tf.train.AdamOptimizer(learning_rate=,epsilon=)
  else:
    optimizer = AdamWeightDecayOptimizer(learning_rate=,epsilon=,exclude_from_weight_decay=[],weight_decay_rate=)
  if FLAGS.use_tpu:
    optimizer = tf.contrib.tpu.CrossShardOptimizer()
  if grads_and_vars is None:
    grads_and_vars = optimizer.compute_gradients()
  gradients, variables = zip()
  clipped, gnorm = tf.clip_by_global_norm()
  if getattr() != 1.0:
    n_layer =
    for i in range(len()):
      m = re.search(r"", variables[].name)
      if not m:
      n_layer = max(n_layer, int(m.group()) + 1)
    for i in range(len()):
      for l in range():
        if "" in variables[].name:
          abs_rate = FLAGS.lr_layer_decay_rate ** ()
          clipped[] *=
          break
  train_op = optimizer.apply_gradients(zip(), global_step=)
  if FLAGS.weight_decay > 0:
    new_global_step =
    train_op = tf.group(train_op, [global_step.assign()])
  return train_op, learning_rate, gnorm
def clean_ckpt():
  input_ckpt =
  output_model_dir =
  tf.reset_default_graph()
  var_list = tf.contrib.framework.list_variables()
  var_values, var_dtypes = {}, {}
  for () in var_list:
    if not name.startswith() and "" not in name.lower():
      var_values[] =
    else:
  reader = tf.contrib.framework.load_checkpoint()
  for name in var_values:
    tensor = reader.get_tensor()
    var_dtypes[] =
    var_values[] =
  with tf.variable_scope(tf.get_variable_scope(), reuse=):
    tf_vars = [tf.get_variable(v, shape=var_values[].shape, dtype=var_dtypes[])for v in var_values]
  placeholders = [tf.placeholder(v.dtype, shape=) for v in tf_vars]
  assign_ops = [tf.assign() for () in zip()]
  global_step = tf.Variable(0, name=, trainable=, dtype=)
  saver = tf.train.Saver(tf.all_variables())
  if not tf.gfile.Exists():
    tf.gfile.MakeDirs()
  with tf.Session() as sess:
    sess.run(tf.initialize_all_variables())
    for p, assign_op, () in zip(placeholders, assign_ops,six.iteritems()):
      sess.run(assign_op, {p:})
    saver.save(sess, join(),global_step=)
def avg_checkpoints():
  tf.reset_default_graph()
  checkpoint_state = tf.train.get_checkpoint_state()
  checkpoints = checkpoint_state.all_model_checkpoint_paths[- last_k:]
  var_list = tf.contrib.framework.list_variables(checkpoints[])
  var_values, var_dtypes = {}, {}
  for () in var_list:
    if not name.startswith():
      var_values[] = np.zeros()
  for checkpoint in checkpoints:
    reader = tf.contrib.framework.load_checkpoint()
    for name in var_values:
      tensor = reader.get_tensor()
      var_dtypes[] =
      var_values[] +=
  for name in var_values:
    var_values[] /= len()
  with tf.variable_scope(tf.get_variable_scope(), reuse=):
    tf_vars = [tf.get_variable(v, shape=var_values[].shape, dtype=var_dtypes[])for v in var_values]
  placeholders = [tf.placeholder(v.dtype, shape=) for v in tf_vars]
  assign_ops = [tf.assign() for () in zip()]
  global_step = tf.Variable(0, name=, trainable=, dtype=)
  saver = tf.train.Saver(tf.all_variables())
  with tf.Session() as sess:
    sess.run(tf.initialize_all_variables())
    for p, assign_op, () in zip(placeholders, assign_ops,six.iteritems()):
      sess.run(assign_op, {p:})
    saver.save(sess, join(),global_step=)
def get_assignment_map_from_checkpoint():
  assignment_map = {}
  initialized_variable_names = {}
  name_to_variable = collections.OrderedDict()
  for var in tvars:
    name =
    m = re.match(r"", name)
    if m is not None:
      name = m.group()
    name_to_variable[] =
  init_vars = tf.train.list_variables()
  assignment_map = collections.OrderedDict()
  for x in init_vars:
    () = (x[], x[])
    if name not in name_to_variable:
      continue
    assignment_map[] = name_to_variable[]
    initialized_variable_names[] =
    initialized_variable_names[name + ""] =
  return ()
class AdamWeightDecayOptimizer():
  def __init__(self,learning_rate,weight_decay_rate=,beta_1=,beta_2=,epsilon=,exclude_from_weight_decay=,include_in_weight_decay=[],name=):
    super().__init__()
    self.learning_rate =
    self.weight_decay_rate =
    self.beta_1 =
    self.beta_2 =
    self.epsilon =
    self.exclude_from_weight_decay =
    self.include_in_weight_decay =
  def apply_gradients(self, grads_and_vars, global_step=, name=):
    assignments = []
    for () in grads_and_vars:
      if grad is None or param is None:
        continue
      param_name = self._get_variable_name()
      m = tf.get_variable(name=,shape=param.shape.as_list(),dtype=,trainable=,initializer=tf.zeros_initializer())
      v = tf.get_variable(name=,shape=param.shape.as_list(),dtype=,trainable=,initializer=tf.zeros_initializer())
      next_m = (tf.multiply() + tf.multiply())
      next_v = (tf.multiply() + tf.multiply(1.0 - self.beta_2,tf.square()))
      update = next_m / (tf.sqrt() + self.epsilon)
      if self._do_use_weight_decay():
        update +=
      update_with_lr =
      next_param =
      assignments.extend([param.assign(),m.assign(),v.assign()])
    return tf.group(*assignments, name=)
  def _do_use_weight_decay():
    if not self.weight_decay_rate:
      return False
    for r in self.include_in_weight_decay:
      if re.search() is not None:
        return True
    if self.exclude_from_weight_decay:
      for r in self.exclude_from_weight_decay:
        if re.search() is not None:
          return False
    return True
  def _get_variable_name():
    m = re.match("^():, param_name)
    if m is not None:
      param_name = m.group()
    return param_name
if __name__ == "__main__":
  flags.DEFINE_string()
  flags.DEFINE_string()
  FLAGS =
  tf.app.run()
from __future__ import absolute_import
from __future__ import division
from __future__ import print_function
import os, sys
import math
import json
import time
import numpy as np
from absl import flags
import absl.logging as _logging
import tensorflow as tf
import data_utils
import model_utils
from gpu_utils import assign_to_gpu, average_grads_and_vars
import function_builder
flags.DEFINE_integer("", default=,help=)
flags.DEFINE_integer("", default=,help=)
flags.DEFINE_bool("", default=,help=)
flags.DEFINE_integer("", default=,help=)
flags.DEFINE_string("", default=,help=)
flags.DEFINE_string("", default=,help=)
flags.DEFINE_string("", default=,help=)
flags.DEFINE_float("", default=,help=)
flags.DEFINE_float("", default=,help=)
flags.DEFINE_float("", default=,help=)
flags.DEFINE_integer("", default=,help=)
flags.DEFINE_float("", default=,help=)
flags.DEFINE_string("", default=,help=)
flags.DEFINE_float("", default=,help=)
flags.DEFINE_integer("", default=,help=)
flags.DEFINE_integer("", default=,help=)
flags.DEFINE_integer("", default=,help=)
flags.DEFINE_integer("", default=,help=)
flags.DEFINE_integer("", default=,help=)
flags.DEFINE_integer("", default=,help=)
flags.DEFINE_bool("", default=,help=, i.e., forward & backward.")
flags.DEFINE_integer("", default=,help=)
flags.DEFINE_integer("", default=,help=)
flags.DEFINE_integer("", default=,help=)
flags.DEFINE_integer("", default=,help=)
flags.DEFINE_bool("", False,help=)
flags.DEFINE_integer("", 32000, help=)
flags.DEFINE_integer("", default=,help=)
flags.DEFINE_bool("", default=,help=)
flags.DEFINE_integer("", default=,help=)
flags.DEFINE_integer("", default=,help=)
flags.DEFINE_integer("", default=,help=)
flags.DEFINE_integer("", default=,help=)
flags.DEFINE_integer("", default=,help=)
flags.DEFINE_integer("", default=,help=)
flags.DEFINE_integer("", default=,help=)
flags.DEFINE_float("", default=,help=)
flags.DEFINE_float("", default=,help=)
flags.DEFINE_bool("", default=,help=)
flags.DEFINE_string("", default=,help=)
flags.DEFINE_string("", default=,help=)
flags.DEFINE_bool("", False,help=)
flags.DEFINE_enum("", default=,enum_values=[],help=)
flags.DEFINE_float("", default=,help=)
flags.DEFINE_float("", default=,help=)
FLAGS =
def get_model_fn():
  def model_fn():
    total_loss, new_mems, monitor_dict = function_builder.get_loss()
    num_params = sum([np.prod() for v in tf.trainable_variables()])
    all_vars = tf.trainable_variables()
    grads = tf.gradients()
    grads_and_vars = list(zip())
    return total_loss, new_mems, grads_and_vars
  return model_fn
def single_core_graph():
  model_fn = get_model_fn()
  model_ret = model_fn(features=,labels=,mems=,is_training=)
  return model_ret
def create_mems_tf():
  mems = [tf.placeholder(dtype=,shape=[])for layer in range()]
  return mems
def initialize_mems_np():
  mems_np = [np.zeros(shape=[],dtype=)for layer in range()]
  return mems_np
def train():
  train_input_fn, record_info_dict = data_utils.get_input_fn(tfrecord_dir=,split=,bsz_per_host=,seq_len=,reuse_len=,bi_data=,num_hosts=,num_core_per_host=,perm_size=,mask_alpha=,mask_beta=,uncased=,num_passes=,use_bfloat16=,num_predict=)
  bsz_per_core =
  params = {"batch_size":}
  train_set = train_input_fn()
  example = train_set.make_one_shot_iterator().get_next()
  if FLAGS.num_core_per_host > 1:
    examples = [{} for _ in range()]
    for key in example.keys():
      vals = tf.split(example[], FLAGS.num_core_per_host, 0)
      for device_id in range():
        examples[][] = vals[]
  else:
    examples = []
  tower_mems, tower_losses, tower_new_mems, tower_grads_and_vars = [], [], [], []
  for i in range():
    reuse =
    with tf.device(assign_to_gpu()), tf.variable_scope(tf.get_variable_scope(), reuse=):
      mems_i = {}
      if FLAGS.mem_len:
        mems_i[] = create_mems_tf()
      loss_i, new_mems_i, grads_and_vars_i = single_core_graph(is_training=,features=examples[],mems=)
      tower_mems.append()
      tower_losses.append()
      tower_new_mems.append()
      tower_grads_and_vars.append()
  if len() > 1:
    loss = tf.add_n() / len()
    grads_and_vars = average_grads_and_vars()
  else:
    loss = tower_losses[]
    grads_and_vars = tower_grads_and_vars[]
  train_op, learning_rate, gnorm = model_utils.get_train_op(FLAGS, None,grads_and_vars=)
  global_step = tf.train.get_global_step()
  tower_mems_np = []
  for i in range():
    mems_i_np = {}
    for key in tower_mems[].keys():
      mems_i_np[] = initialize_mems_np()
    tower_mems_np.append()
  saver = tf.train.Saver()
  gpu_options = tf.GPUOptions(allow_growth=)
  model_utils.init_from_checkpoint(FLAGS, global_vars=)
  with tf.Session(config=tf.ConfigProto(allow_soft_placement=,gpu_options=)) as sess:
    sess.run(tf.global_variables_initializer())
    fetches = []
    total_loss, prev_step =, -1
    while True:
      feed_dict = {}
      for i in range():
        for key in tower_mems_np[].keys():
          for m, m_np in zip(tower_mems[][], tower_mems_np[][]):
            feed_dict[] =
      fetched = sess.run(fetches, feed_dict=)
      loss_np, tower_mems_np, curr_step = fetched[:]
      total_loss +=
      if curr_step > 0 and curr_step % FLAGS.iterations == 0:
        curr_loss = total_loss / ()
        total_loss, prev_step =, curr_step
      if curr_step > 0 and curr_step % FLAGS.save_steps == 0:
        save_path = os.path.join()
        saver.save()
      if curr_step >= FLAGS.train_steps:
        break
def main():
  del unused_argv
  tf.logging.set_verbosity()
  FLAGS.n_token =
  if not tf.gfile.Exists():
    tf.gfile.MakeDirs()
  train("/gpu:)
if __name__ == "__main__":
  tf.app.run()
import tensorflow as tf
import numpy as np
import os
import time
import datetime
import data_helpers
from text_cnn import TextCNN
from tensorflow.contrib import learn
import csv
tf.flags.DEFINE_string()
tf.flags.DEFINE_string()
tf.flags.DEFINE_integer()
tf.flags.DEFINE_string()
tf.flags.DEFINE_boolean()
tf.flags.DEFINE_boolean()
tf.flags.DEFINE_boolean()
FLAGS =
FLAGS._parse_flags()
for attr, value in sorted(FLAGS.__flags.items()):
if FLAGS.eval_train:
    x_raw, y_test = data_helpers.load_data_and_labels()
    y_test = np.argmax(y_test, axis=)
else:
    x_raw = []
    y_test = []
vocab_path = os.path.join()
vocab_processor = learn.preprocessing.VocabularyProcessor.restore()
x_test = np.array(list(vocab_processor.transform()))
checkpoint_file = tf.train.latest_checkpoint()
graph = tf.Graph()
with graph.as_default():
    session_conf = tf.ConfigProto(allow_soft_placement=,log_device_placement=)
    sess = tf.Session(config=)
    with sess.as_default():
        saver = tf.train.import_meta_graph("")
        saver.restore()
        input_x = graph.get_operation_by_name().outputs[]
        dropout_keep_prob = graph.get_operation_by_name().outputs[]
        predictions = graph.get_operation_by_name().outputs[]
        batches = data_helpers.batch_iter(list(), FLAGS.batch_size, 1, shuffle=)
        all_predictions = []
        for x_test_batch in batches:
            batch_predictions = sess.run(predictions, {input_x:, dropout_keep_prob:})
            all_predictions = np.concatenate([])
if y_test is not None:
    correct_predictions = float(sum(all_predictions ==))
predictions_human_readable = np.column_stack((np.array(), all_predictions))
out_path = os.path.join()
with open() as f:
    csv.writer().writerows()
import os
import time
from collections import OrderedDict
from PIL import Image
import numpy as np
import tensorflow as tf
import vgg
CONTENT_LAYERS = ()
STYLE_LAYERS = ()
try:
    reduce
except NameError:
    from functools import reduce
def get_loss_vals():
    return OrderedDict((key, val.eval()) for key,val in loss_store.items())
def print_progress():
    for key,val in loss_vals.items():
def stylize(network, initial, initial_noiseblend, content, styles, preserve_colors, iterations,content_weight, content_weight_blend, style_weight, style_layer_weight_exp, style_blend_weights, tv_weight,learning_rate, beta1, beta2, epsilon, pooling,print_iterations=, checkpoint_iterations=):
    shape = () + content.shape
    style_shapes = [() + style.shape for style in styles]
    content_features = {}
    style_features = [{} for _ in styles]
    vgg_weights, vgg_mean_pixel = vgg.load_net()
    layer_weight =
    style_layers_weights = {}
    for style_layer in STYLE_LAYERS:
        style_layers_weights[] =
        layer_weight *=
    layer_weights_sum =
    for style_layer in STYLE_LAYERS:
        layer_weights_sum += style_layers_weights[]
    for style_layer in STYLE_LAYERS:
        style_layers_weights[] /=
    g = tf.Graph()
    with g.as_default(), g.device('/cpu:), tf.Session() as sess:
        image = tf.placeholder("", shape=)
        net = vgg.net_preloaded()
        content_pre = np.array([vgg.preprocess()])
        for layer in CONTENT_LAYERS:
            content_features[] = net[].eval(feed_dict={image:})
    for i in range(len()):
        g = tf.Graph()
        with g.as_default(), g.device('/cpu:), tf.Session() as sess:
            image = tf.placeholder("", shape=style_shapes[])
            net = vgg.net_preloaded()
            style_pre = np.array([vgg.preprocess(styles[], vgg_mean_pixel)])
            for layer in STYLE_LAYERS:
                features = net[].eval(feed_dict={image:})
                features = np.reshape(features, (-1, features.shape[]))
                gram = np.matmul() / features.size
                style_features[][] =
    initial_content_noise_coeff =
    with tf.Graph().as_default():
        if initial is None:
            noise = np.random.normal(size=, scale=np.std() * 0.1)
            initial = tf.random_normal() * 0.256
        else:
            initial = np.array([vgg.preprocess()])
            initial = initial.astype()
            noise = np.random.normal(size=, scale=np.std() * 0.1)
            initial = () * initial_content_noise_coeff + (tf.random_normal() * 0.256) * ()
        image = tf.Variable()
        net = vgg.net_preloaded()
        content_layers_weights = {}
        content_layers_weights[] =
        content_layers_weights[] =
        content_loss =
        content_losses = []
        for content_layer in CONTENT_LAYERS:
            content_losses.append(content_layers_weights[] * content_weight * (2 * tf.nn.l2_loss(net[] - content_features[]) /content_features[].size))
        content_loss += reduce()
        style_loss =
        for i in range(len()):
            style_losses = []
            for style_layer in STYLE_LAYERS:
                layer = net[]
                _, height, width, number = map(lambda i:, layer.get_shape())
                size =
                feats = tf.reshape(layer, ())
                gram = tf.matmul(tf.transpose(), feats) / size
                style_gram = style_features[][]
                style_losses.append(style_layers_weights[] * 2 * tf.nn.l2_loss() / style_gram.size)
            style_loss += style_weight * style_blend_weights[] * reduce()
        tv_y_size = _tensor_size(image[:,1:,:,:])
        tv_x_size = _tensor_size(image[:,:,1:,:])
        tv_loss = tv_weight * 2 * ((tf.nn.l2_loss(image[:,1:,:,:] - image[:,:shape[]-1,:,:]) /tv_y_size) +(tf.nn.l2_loss(image[:,:,1:,:] - image[:,:,:shape[]-1,:]) /tv_x_size))
        loss =
        loss_store = OrderedDict([(),(),(),()])
        train_step = tf.train.AdamOptimizer().minimize()
        best_loss = float()
        best =
        with tf.Session() as sess:
            sess.run(tf.global_variables_initializer())
            if (print_iterations and print_iterations !=):
            iteration_times = []
            start = time.time()
            for i in range():
                iteration_start = time.time()
                if i > 0:
                    elapsed = time.time() - start
                    remaining = np.mean(iteration_times[-10:]) * ()
                else:
                train_step.run()
                last_step = (i ==)
                if last_step or (print_iterations and i % print_iterations ==):
                    loss_vals = get_loss_vals()
                else:
                    loss_vals =
                if (checkpoint_iterations and i % checkpoint_iterations ==) or last_step:
                    this_loss = loss.eval()
                    if this_loss < best_loss:
                        best_loss =
                        best = image.eval()
                    img_out = vgg.unprocess(best.reshape(shape[1:]), vgg_mean_pixel)
                    if preserve_colors and preserve_colors == True:
                        original_image = np.clip()
                        styled_image = np.clip()
                        styled_grayscale = rgb2gray()
                        styled_grayscale_rgb = gray2rgb()
                        styled_grayscale_yuv = np.array(Image.fromarray(styled_grayscale_rgb.astype()).convert())
                        original_yuv = np.array(Image.fromarray(original_image.astype()).convert())
                        w, h, _ =
                        combined_yuv = np.empty((), dtype=)
                        combined_yuv[] = styled_grayscale_yuv[]
                        combined_yuv[] = original_yuv[]
                        combined_yuv[] = original_yuv[]
                        img_out = np.array(Image.fromarray().convert())
                else:
                    img_out =
                yield i+1 if last_step else i, img_out, loss_vals
                iteration_end = time.time()
                iteration_times.append()
def _tensor_size():
    from operator import mul
    return reduce(mul, (d.value for d in tensor.get_shape()), 1)
def rgb2gray():
    return np.dot(rgb[], [])
def gray2rgb():
    w, h =
    rgb = np.empty((), dtype=)
    rgb[:, :, 2] = rgb[:, :, 1] = rgb[:, :, 0] =
    return rgb
def hms():
    seconds = int()
    hours = (seconds // ())
    minutes = () % 60
    seconds =
    if hours > 0:
        return ""
    elif minutes > 0:
        return ""
    else:
        return '%d sec' % seconds
import tensorflow as tf
from tensorflow.examples.tutorials.mnist import input_data
mnist = input_data.read_data_sets("", one_hot=)
X = tf.placeholder(tf.float32, [])
Y = tf.placeholder(tf.float32, [])
keep_prob = tf.placeholder()
W1 = tf.Variable(tf.random_normal([], stddev=))
L1 = tf.nn.conv2d(X, W1, strides=[], padding=)
L1 = tf.nn.relu()
L1 = tf.nn.max_pool(L1, ksize=[], strides=[], padding=)
W2 = tf.Variable(tf.random_normal([], stddev=))
L2 = tf.nn.conv2d(L1, W2, strides=[], padding=)
L2 = tf.nn.relu()
L2 = tf.nn.max_pool(L2, ksize=[], strides=[], padding=)
W3 = tf.Variable(tf.random_normal([], stddev=))
L3 = tf.reshape(L2, [])
L3 = tf.matmul()
L3 = tf.nn.relu()
L3 = tf.nn.dropout()
W4 = tf.Variable(tf.random_normal([], stddev=))
model = tf.matmul()
cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=, labels=))
optimizer = tf.train.AdamOptimizer().minimize()
init = tf.global_variables_initializer()
sess = tf.Session()
sess.run()
batch_size =
total_batch = int()
for epoch in range():
    total_cost =
    for i in range():
        batch_xs, batch_ys = mnist.train.next_batch()
        batch_xs = batch_xs.reshape()
        _, cost_val = sess.run([],feed_dict={X:,Y:,keep_prob:})
        total_cost +=
is_correct = tf.equal(tf.argmax(), tf.argmax())
accuracy = tf.reduce_mean(tf.cast())
from __future__ import absolute_import
import os
import tensorflow as tf
from tensorflow.contrib.slim.nets import vgg
from tensorflow.contrib.slim.nets import inception
from tensorflow.contrib.slim.nets import resnet_v1
from tensorflow.contrib.slim.nets import resnet_v2
from mmdnn.conversion.examples.tensorflow.models import inception_resnet_v2
from mmdnn.conversion.examples.tensorflow.models import mobilenet_v1
from mmdnn.conversion.examples.tensorflow.models import nasnet
from mmdnn.conversion.examples.tensorflow.models.mobilenet import mobilenet_v2
from mmdnn.conversion.examples.tensorflow.models import inception_resnet_v1
from mmdnn.conversion.examples.tensorflow.models import test_rnn
slim =
from mmdnn.conversion.examples.imagenet_test import TestKit
from mmdnn.conversion.examples.extractor import base_extractor
from mmdnn.conversion.common.utils import download_file
class tensorflow_extractor():
    MMDNN_BASE_URL = ""
    architecture_map = 
    def handle_checkpoint():
        with slim.arg_scope(cls.architecture_map[][]()):
            data_input = cls.architecture_map[][]()
            logits, endpoints = cls.architecture_map[][]()(data_input,num_classes=cls.architecture_map[][],is_training=)
            if logits.op.type == "":
                labels = tf.identity(logits, name=)
            else:
                labels = tf.squeeze(logits, name=)
        init = tf.global_variables_initializer()
        with tf.Session() as sess:
            sess.run()
            saver = tf.train.Saver()
            saver.restore(sess, path + cls.architecture_map[][])
            save_path = saver.save(sess, path + "")
        import tensorflow.contrib.keras as keras
        keras.backend.clear_session()
    def handle_frozen_graph():
        return
    def get_frozen_para():
        frozenname =
        tensor_in =  list(map(lambda x:x.split(':)[], cls.architecture_map[][]))
        tensor_out = list(map(lambda x:x.split(':)[], cls.architecture_map[][]))
        return cls.architecture_map[][], cls.architecture_map[][], tensor_in, tensor_out
    def download(cls, architecture, path=):
        if cls.sanity_check():
            architecture_file = download_file(cls.architecture_map[][], directory=, auto_unzip=)
            if not architecture_file:
                return None
            tf.reset_default_graph()
            if "" in cls.architecture_map[][]:
                cls.handle_checkpoint()
            elif cls.architecture_map[][].endswith():
                cls.handle_frozen_graph()
            else:
                raise ValueError()
            return architecture_file
        else:
            return None
    def inference(cls, architecture, files, path, test_input_path, is_frozen=):
        if is_frozen:
            architecture_ =
        else:
            architecture_ =
        if cls.download():
            import numpy as np
            if "" not in architecture_:
                func = TestKit.preprocess_func[][]
                img = func()
                img = np.expand_dims(img, axis=)
                input_data =
            else:
                input_data = np.load()
            if is_frozen:
                tf_model_path = cls.architecture_map[][]
                with open() as f:
                    serialized = f.read()
                tf.reset_default_graph()
                original_gdef = tf.GraphDef()
                original_gdef.ParseFromString()
                tf_output_name =  cls.architecture_map[][]
                tf_input_name =  cls.architecture_map[][]
                feed_dict = cls.architecture_map[][]
                with tf.Graph().as_default() as g:
                    tf.import_graph_def(original_gdef, name=)
                with tf.Session(graph =) as sess:
                    tf_out = sess.run(tf_output_name[], feed_dict=feed_dict())
                predict = np.squeeze()
                return predict
            else:
                with slim.arg_scope(cls.architecture_map[][]()):
                    data_input = cls.architecture_map[][]()
                    logits, endpoints = cls.architecture_map[][]()(data_input,num_classes=cls.architecture_map[][],is_training=)
                    labels = tf.squeeze()
                init = tf.global_variables_initializer()
                with tf.Session() as sess:
                    sess.run()
                    saver = tf.train.Saver()
                    saver.restore(sess, path + cls.architecture_map[][])
                    predict = sess.run(logits, feed_dict = {data_input :})
                import tensorflow.contrib.keras as keras
                keras.backend.clear_session()
                predict = np.squeeze()
                return predict
        else:
            return None
import argparse
from six import text_type as _text_type
import tensorflow as tf
from tensorflow.contrib.slim.python.slim.nets import vgg
from tensorflow.contrib.slim.python.slim.nets import inception
from tensorflow.contrib.slim.python.slim.nets import resnet_v1
from tensorflow.contrib.slim.python.slim.nets import resnet_v2
from mmdnn.conversion.examples.imagenet_test import TestKit
slim =
input_layer_map = 
arg_scopes_map = 
networks_map = 
def _main():
    parser = argparse.ArgumentParser()
    parser.add_argument("", "", type=, help=, required=,choices = input_layer_map.keys())
    parser.add_argument("", "",type=, help=)
    parser.add_argument("", "",type=, help=, required=)
    args = parser.parse_args()
    num_classes = 1000 if args.network in () else 1001
    with slim.arg_scope(arg_scopes_map[]()):
        data_input = input_layer_map[]()
        logits, endpoints = networks_map[]()(data_input, num_classes=, is_training=)
        labels = tf.squeeze()
    init = tf.global_variables_initializer()
    with tf.Session() as sess:
        writer = tf.summary.FileWriter()
        writer.close()
        sess.run()
        saver = tf.train.Saver()
        saver.restore()
        save_path = saver.save(sess, "")
        if args.image:
            import numpy as np
            func = TestKit.preprocess_func[][]
            img = func()
            img = np.expand_dims(img, axis =)
            predict = sess.run(logits, feed_dict = {data_input :})
            predict = np.squeeze()
            top_indices = predict.argsort()[-5:][::]
            result = [(i, predict[]) for i in top_indices]
if __name__=="":
    _main()
from __future__ import division
from __future__ import print_function
import argparse
from datetime import datetime
import json
import os
import librosa
import numpy as np
import tensorflow as tf
from wavenet import WaveNetModel, mu_law_decode, mu_law_encode, audio_reader
SAMPLES =
TEMPERATURE =
LOGDIR =
WAVENET_PARAMS =
SAVE_EVERY =
SILENCE_THRESHOLD =
def get_arguments():
    def _str_to_bool():
        if s.lower() not in []:
            raise ValueError()
        return {'true':, 'false':}[s.lower()]
    def _ensure_positive_float():
        if float() < 0:
            raise argparse.ArgumentTypeError()
        return float()
    parser = argparse.ArgumentParser(description=)
    parser.add_argument("", type=, help=)
    parser.add_argument("",type=,default=,help=)
    parser.add_argument("",type=,default=,help=)
    parser.add_argument("",type=,default=,help=)
    parser.add_argument("",type=,default=,help=)
    parser.add_argument("",type=,default=,help=)
    parser.add_argument("",type=,default=,help=)
    parser.add_argument("",type=,default=,help=)
    parser.add_argument("",type=,default=,help=)
    parser.add_argument("",type=,default=,help=)
    parser.add_argument("",type=,default=,help=)
    parser.add_argument("",type=,default=,help=, if globally conditioned.')
    arguments = parser.parse_args()
    if arguments.gc_channels is not None:
        if arguments.gc_cardinality is None:
            raise ValueError()
        if arguments.gc_id is None:
            raise ValueError()
    return arguments
def write_wav():
    y = np.array()
    librosa.output.write_wav()
def create_seed(filename,sample_rate,quantization_channels,window_size,silence_threshold=):
    audio, _ = librosa.load(filename, sr=, mono=)
    audio = audio_reader.trim_silence()
    quantized = mu_law_encode()
    cut_index = tf.cond(tf.size() < tf.constant(),lambda: tf.size(),lambda: tf.constant())
    return quantized[:]
def main():
    args = get_arguments()
    started_datestring = "")
    logdir = os.path.join()
    with open() as config_file:
        wavenet_params = json.load()
    sess = tf.Session()
    net = WaveNetModel(batch_size=,dilations=wavenet_params[],filter_width=wavenet_params[],residual_channels=wavenet_params[],dilation_channels=wavenet_params[],quantization_channels=wavenet_params[],skip_channels=wavenet_params[],use_biases=wavenet_params[],scalar_input=wavenet_params[],initial_filter_width=wavenet_params[],global_condition_channels=,global_condition_cardinality=)
    samples = tf.placeholder()
    if args.fast_generation:
        next_sample = net.predict_proba_incremental()
    else:
        next_sample = net.predict_proba()
    if args.fast_generation:
        sess.run(tf.global_variables_initializer())
        sess.run()
    variables_to_restore = {var.name[:]:}
    saver = tf.train.Saver()
    saver.restore()
    decode = mu_law_decode(samples, wavenet_params[])
    quantization_channels = wavenet_params[]
    if args.wav_seed:
        seed = create_seed(args.wav_seed,wavenet_params[],quantization_channels,net.receptive_field)
        waveform = sess.run().tolist()
    else:
        waveform = [] * ()
        waveform.append(np.random.randint())
    if args.fast_generation and args.wav_seed:
        outputs = []
        outputs.extend()
        for i, x in enumerate(waveform[-net.receptive_field:]):
            if i % 100 == 0:
            sess.run(outputs, feed_dict={samples:})
    last_sample_timestamp = datetime.now()
    for step in range():
        if args.fast_generation:
            outputs = []
            outputs.extend()
            window = waveform[]
        else:
            if len() > net.receptive_field:
                window = waveform[-net.receptive_field:]
            else:
                window =
            outputs = []
        prediction = sess.run(outputs, feed_dict={samples:})[]
        np.seterr(divide=)
        scaled_prediction = np.log() / args.temperature
        scaled_prediction = (scaled_prediction -np.logaddexp.reduce())
        scaled_prediction = np.exp()
        np.seterr(divide=)
        if args.temperature == 1.0:
            np.testing.assert_allclose(prediction, scaled_prediction, atol=,err_msg='Prediction scaling at temperature=)
        sample = np.random.choice(np.arange(), p=)
        waveform.append()
        current_sample_timestamp = datetime.now()
        time_since_print =
        if time_since_print.total_seconds() > 1.:
            last_sample_timestamp =
        if (args.wav_out_path and args.save_every and() % args.save_every ==):
            out = sess.run(decode, feed_dict={samples:})
            write_wav(out, wavenet_params[], args.wav_out_path)
    datestring = str(datetime.now()).replace()
    writer = tf.summary.FileWriter()
    tf.summary.audio("", decode, wavenet_params[])
    summaries = tf.summary.merge_all()
    summary_out = sess.run(summaries,feed_dict={samples:,})
    writer.add_summary()
    if args.wav_out_path:
        out = sess.run(decode, feed_dict={samples:})
        write_wav(out, wavenet_params[], args.wav_out_path)
if __name__ == "__main__":
    main()
import re
from logging import getLogger
from typing import List, Optional
import numpy as np
import tensorflow.compat.v1 as tf
from bert_dp.modeling import BertConfig, BertModel, create_initializer, get_assignment_map_from_checkpoint
from deeppavlov.core.commands.utils import expand_path
from deeppavlov.core.common.registry import register
from deeppavlov.core.models.tf_model import TFModel
from deeppavlov.models.preprocessors.bert_preprocessor import BertPreprocessor
logger = getLogger()
class BertAsSummarizer():
    def __init__(self, bert_config_file:,pretrained_bert:,vocab_file:,max_summary_length:,max_summary_length_in_tokens: Optional[] =,max_seq_length: Optional[] =,do_lower_case: Optional[] =,lang: Optional[] =,**kwargs) -> None:
        self.max_summary_length =
        self.max_summary_length_in_tokens =
        self.bert_config = BertConfig.from_json_file(str(expand_path()))
        self.bert_preprocessor = BertPreprocessor(vocab_file=, do_lower_case=,max_seq_length=)
        self.tokenize_reg = re.compile(r"[]+|[]")
        if lang == "":
            from ru_sent_tokenize import ru_sent_tokenize
            self.sent_tokenizer =
        else:
            from nltk import sent_tokenize
            self.sent_tokenizer =
        self.sess_config = tf.ConfigProto(allow_soft_placement=)
        self.sess_config.gpu_options.allow_growth =
        self.sess = tf.Session(config=)
        self._init_graph()
        self.sess.run(tf.global_variables_initializer())
        if pretrained_bert is not None:
            pretrained_bert = str(expand_path())
            if tf.train.checkpoint_exists():
                tvars = tf.trainable_variables()
                assignment_map, _ = get_assignment_map_from_checkpoint()
                tf.train.init_from_checkpoint()
    def _init_graph():
        self._init_placeholders()
        self.bert = BertModel(config=,is_training=,input_ids=,input_mask=,token_type_ids=,use_one_hot_embeddings=,)
        with tf.variable_scope():
            output_weights = tf.get_variable("",shape=[],initializer=create_initializer())
            output_bias = tf.get_variable("", shape=[], initializer=tf.zeros_initializer())
        nsp_logits = tf.matmul(self.bert.get_pooled_output(), output_weights, transpose_b=)
        nsp_logits = tf.nn.bias_add()
        self.nsp_probs = tf.nn.softmax(nsp_logits, axis=)
    def _init_placeholders():
        self.input_ids_ph = tf.placeholder(shape=(), dtype=, name=)
        self.input_masks_ph = tf.placeholder(shape=(), dtype=, name=)
        self.token_types_ph = tf.placeholder(shape=(), dtype=, name=)
        self.is_train_ph = tf.placeholder_with_default(False, shape=[], name=)
    def _build_feed_dict():
        feed_dict = {self.input_ids_ph:,self.input_masks_ph:,self.token_types_ph:,}
        return feed_dict
    def _get_nsp_predictions(self, sentences: List[], candidates: List[]):
        features = self.bert_preprocessor(texts_a=, texts_b=)
        input_ids = []
        input_masks = []
        input_type_ids = []
        feed_dict = self._build_feed_dict()
        nsp_probs = self.sess.run(self.nsp_probs, feed_dict=)
        return nsp_probs[:, 0]
    def __call__(self, texts: List[], init_sentences: Optional[List[]] =) -> List[List[]]:
        summaries = []
        if init_sentences is None:
            init_sentences = [] * len()
        for text, init_sentence in zip():
            text_sentences = self.sent_tokenizer()
            if init_sentence is None:
                init_sentence = text_sentences[]
                text_sentences = text_sentences[1:]
            text_sentences = list(set())
            text_sentences = [sent for sent in text_sentences if sent !=]
            summary = []
            if self.max_summary_length_in_tokens:
                def get_length():
                    return len(self.tokenize_reg.findall("".join()))
            else:
                get_length =
            candidates = text_sentences[:]
            while len() > 0:
                candidates_scores = [self._get_nsp_predictions(["".join()], []) for cand in candidates]
                best_candidate_idx = np.argmax()
                best_candidate = candidates[]
                del candidates[]
                if get_length(summary + []) > self.max_summary_length:
                    break
                summary = summary + []
            summaries += []
        return summaries
    def train_on_batch():
        raise NotImplementedError
from logging import getLogger
from typing import List, Dict, Union
import tensorflow as tf
from bert_dp.modeling import BertConfig, BertModel
from bert_dp.optimization import AdamWeightDecayOptimizer
from bert_dp.preprocessing import InputFeatures
from deeppavlov.core.commands.utils import expand_path
from deeppavlov.core.common.registry import register
from deeppavlov.core.models.tf_model import LRScheduledTFModel
logger = getLogger()
class BertClassifierModel():
    def __init__(self, bert_config_file, n_classes, keep_prob,one_hot_labels=, multilabel=, return_probas=,attention_probs_keep_prob=, hidden_keep_prob=,optimizer=, num_warmup_steps=, weight_decay_rate=,pretrained_bert=, min_learning_rate=, **kwargs) -> None:
        super().__init__()
        self.return_probas =
        self.n_classes =
        self.min_learning_rate =
        self.keep_prob =
        self.one_hot_labels =
        self.multilabel =
        self.optimizer =
        self.num_warmup_steps =
        self.weight_decay_rate =
        if self.multilabel and not self.one_hot_labels:
            raise RuntimeError()
        if self.multilabel and not self.return_probas:
            raise RuntimeError()
        self.bert_config = BertConfig.from_json_file(str(expand_path()))
        if attention_probs_keep_prob is not None:
            self.bert_config.attention_probs_dropout_prob =
        if hidden_keep_prob is not None:
            self.bert_config.hidden_dropout_prob =
        self.sess_config = tf.ConfigProto(allow_soft_placement=)
        self.sess_config.gpu_options.allow_growth =
        self.sess = tf.Session(config=)
        self._init_graph()
        self._init_optimizer()
        self.sess.run(tf.global_variables_initializer())
        if pretrained_bert is not None:
            pretrained_bert = str(expand_path())
            if tf.train.checkpoint_exists() and not (self.load_path and tf.train.checkpoint_exists(str(self.load_path.resolve()))):
                var_list = self._get_saveable_variables(exclude_scopes=())
                saver = tf.train.Saver()
                saver.restore()
        if self.load_path is not None:
            self.load()
    def _init_graph():
        self._init_placeholders()
        self.bert = BertModel(config=,is_training=,input_ids=,input_mask=,token_type_ids=,use_one_hot_embeddings=,)
        output_layer = self.bert.get_pooled_output()
        hidden_size = output_layer.shape[].value
        output_weights = tf.get_variable("", [],initializer=tf.truncated_normal_initializer(stddev=))
        output_bias = tf.get_variable("", [], initializer=tf.zeros_initializer())
        with tf.variable_scope():
            output_layer = tf.nn.dropout(output_layer, keep_prob=)
            logits = tf.matmul(output_layer, output_weights, transpose_b=)
            logits = tf.nn.bias_add()
            if self.one_hot_labels:
                one_hot_labels =
            else:
                one_hot_labels = tf.one_hot(self.y_ph, depth=, dtype=)
            self.y_predictions = tf.argmax(logits, axis=)
            if not self.multilabel:
                log_probs = tf.nn.log_softmax(logits, axis=)
                self.y_probas = tf.nn.softmax(logits, axis=)
                per_example_loss = -tf.reduce_sum(one_hot_labels * log_probs, axis=)
                self.loss = tf.reduce_mean()
            else:
                self.y_probas = tf.nn.sigmoid()
                self.loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=, logits=))
    def _init_placeholders():
        self.input_ids_ph = tf.placeholder(shape=(), dtype=, name=)
        self.input_masks_ph = tf.placeholder(shape=(), dtype=, name=)
        self.token_types_ph = tf.placeholder(shape=(), dtype=, name=)
        if not self.one_hot_labels:
            self.y_ph = tf.placeholder(shape=(), dtype=, name=)
        else:
            self.y_ph = tf.placeholder(shape=(), dtype=, name=)
        self.learning_rate_ph = tf.placeholder_with_default(0.0, shape=[], name=)
        self.keep_prob_ph = tf.placeholder_with_default(1.0, shape=[], name=)
        self.is_train_ph = tf.placeholder_with_default(False, shape=[], name=)
    def _init_optimizer():
        with tf.variable_scope():
            self.global_step = tf.get_variable("", shape=[], dtype=,initializer=tf.constant_initializer(), trainable=)
            if self.optimizer is None:
                self.train_op = self.get_train_op(self.loss, learning_rate=,optimizer=,weight_decay_rate=,beta_1=,beta_2=,epsilon=,exclude_from_weight_decay=[])
            else:
                self.train_op = self.get_train_op(self.loss, learning_rate=)
            if self.optimizer is None:
                new_global_step =
                self.train_op = tf.group(self.train_op, [self.global_step.assign()])
    def _build_feed_dict(self, input_ids, input_masks, token_types, y=):
        feed_dict = {self.input_ids_ph:,self.input_masks_ph:,self.token_types_ph:,}
        if y is not None:
            feed_dict.update({self.y_ph:,self.learning_rate_ph:,,self.keep_prob_ph:,self.is_train_ph:,})
        return feed_dict
    def train_on_batch(self, features: List[], y: Union[List[], List[List[]]]) -> Dict:
        input_ids = []
        input_masks = []
        input_type_ids = []
        feed_dict = self._build_feed_dict()
        _, loss = self.sess.run([], feed_dict=)
        return {'loss':, 'learning_rate':}
    def __call__(self, features: List[]) -> Union[List[], List[List[]]]:
        input_ids = []
        input_masks = []
        input_type_ids = []
        feed_dict = self._build_feed_dict()
        if not self.return_probas:
            pred = self.sess.run(self.y_predictions, feed_dict=)
        else:
            pred = self.sess.run(self.y_probas, feed_dict=)
        return pred
import re
from collections import OrderedDict
from logging import getLogger
from operator import itemgetter
from typing import List, Dict, Union
import numpy as np
import tensorflow as tf
from bert_dp.modeling import BertConfig, BertModel
from bert_dp.optimization import AdamWeightDecayOptimizer
from bert_dp.preprocessing import InputFeatures
from deeppavlov.core.commands.utils import expand_path
from deeppavlov.core.common.registry import register
from deeppavlov.core.models.tf_model import LRScheduledTFModel
from deeppavlov.models.bert.bert_classifier import BertClassifierModel
logger = getLogger()
class BertRankerModel():
    def __init__(self, bert_config_file, n_classes=, keep_prob=, return_probas=, **kwargs) -> None:
        super().__init__(bert_config_file=, n_classes=,keep_prob=, return_probas=, **kwargs)
    def train_on_batch(self, features_li: List[List[]], y: Union[List[], List[List[]]]) -> Dict:
        features = features_li[]
        input_ids = []
        input_masks = []
        input_type_ids = []
        feed_dict = self._build_feed_dict()
        _, loss = self.sess.run([], feed_dict=)
        return {'loss':, 'learning_rate':}
    def __call__(self, features_li: List[List[]]) -> Union[List[], List[List[]]]:
        if len() == 1 and len(features_li[]) == 1:
            msg = ""
            return []
        predictions = []
        for features in features_li:
            input_ids = []
            input_masks = []
            input_type_ids = []
            feed_dict = self._build_feed_dict()
            if not self.return_probas:
                pred = self.sess.run(self.y_predictions, feed_dict=)
            else:
                pred = self.sess.run(self.y_probas, feed_dict=)
            predictions.append(pred[:, 1])
        if len() == 1:
            predictions = predictions[]
        else:
            predictions = np.hstack([np.expand_dims() for el in predictions])
        return predictions
class BertSepRankerModel():
    def __init__(self, bert_config_file, keep_prob=,attention_probs_keep_prob=, hidden_keep_prob=,optimizer=, weight_decay_rate=,pretrained_bert=, min_learning_rate=, **kwargs) -> None:
        super().__init__()
        self.min_learning_rate =
        self.keep_prob =
        self.optimizer =
        self.weight_decay_rate =
        self.bert_config = BertConfig.from_json_file(str(expand_path()))
        if attention_probs_keep_prob is not None:
            self.bert_config.attention_probs_dropout_prob =
        if hidden_keep_prob is not None:
            self.bert_config.hidden_dropout_prob =
        self.sess_config = tf.ConfigProto(allow_soft_placement=)
        self.sess_config.gpu_options.allow_growth =
        self.sess = tf.Session(config=)
        self._init_graph()
        self._init_optimizer()
        if pretrained_bert is not None:
            pretrained_bert = str(expand_path())
            if tf.train.checkpoint_exists() and not (self.load_path and tf.train.checkpoint_exists(str(self.load_path.resolve()))):
                var_list = self._get_saveable_variables(exclude_scopes=())
                assignment_map = self.get_variables_to_restore()
                tf.train.init_from_checkpoint()
        self.sess.run(tf.global_variables_initializer())
        if self.load_path is not None:
            self.load()
    def get_variables_to_restore():
        assignment_map = OrderedDict()
        graph_names = []
        for var in tvars:
            name =
            m = re.match("^():, name)
            if m is not None:
                name = m.group()
                graph_names.append()
        ckpt_names = [el[] for el in tf.train.list_variables()]
        for u in ckpt_names:
            for v in graph_names:
                if u in v:
                    assignment_map[] =
        return assignment_map
    def _init_graph():
        self._init_placeholders()
        with tf.variable_scope():
            model_a = BertModel(config=,is_training=,input_ids=,input_mask=,token_type_ids=,use_one_hot_embeddings=)
        with tf.variable_scope("", reuse=):
            model_b = BertModel(config=,is_training=,input_ids=,input_mask=,token_type_ids=,use_one_hot_embeddings=)
        output_layer_a = model_a.get_pooled_output()
        output_layer_b = model_b.get_pooled_output()
        with tf.variable_scope():
            output_layer_a = tf.nn.dropout(output_layer_a, keep_prob=)
            output_layer_b = tf.nn.dropout(output_layer_b, keep_prob=)
            output_layer_a = tf.nn.l2_normalize(output_layer_a, axis=)
            output_layer_b = tf.nn.l2_normalize(output_layer_b, axis=)
            embeddings = tf.concat([], axis=)
            labels = tf.concat([], axis=)
            self.loss = tf.contrib.losses.metric_learning.triplet_semihard_loss()
            logits = tf.multiply()
            self.y_probas = tf.reduce_sum()
            self.pooled_out =
    def _init_placeholders():
        self.input_ids_a_ph = tf.placeholder(shape=(), dtype=, name=)
        self.input_masks_a_ph = tf.placeholder(shape=(), dtype=, name=)
        self.token_types_a_ph = tf.placeholder(shape=(), dtype=, name=)
        self.input_ids_b_ph = tf.placeholder(shape=(), dtype=, name=)
        self.input_masks_b_ph = tf.placeholder(shape=(), dtype=, name=)
        self.token_types_b_ph = tf.placeholder(shape=(), dtype=, name=)
        self.y_ph = tf.placeholder(shape=(), dtype=, name=)
        self.learning_rate_ph = tf.placeholder_with_default(0.0, shape=[], name=)
        self.keep_prob_ph = tf.placeholder_with_default(1.0, shape=[], name=)
        self.is_train_ph = tf.placeholder_with_default(False, shape=[], name=)
    def _init_optimizer():
        with tf.variable_scope():
            self.global_step = tf.get_variable("", shape=[], dtype=,initializer=tf.constant_initializer(), trainable=)
            if self.optimizer is None:
                self.train_op = self.get_train_op(self.loss, learning_rate=,optimizer=,weight_decay_rate=,beta_1=,beta_2=,epsilon=,exclude_from_weight_decay=[])
            else:
                self.train_op = self.get_train_op(self.loss, learning_rate=)
            if self.optimizer is None:
                new_global_step =
                self.train_op = tf.group(self.train_op, [self.global_step.assign()])
    def _build_feed_dict(self, input_ids_a, input_masks_a, token_types_a,input_ids_b, input_masks_b, token_types_b, y=):
        feed_dict = {self.input_ids_a_ph:,self.input_masks_a_ph:,self.token_types_a_ph:,self.input_ids_b_ph:,self.input_masks_b_ph:,self.token_types_b_ph:,}
        if y is not None:
            feed_dict.update({self.y_ph:,self.learning_rate_ph:,,self.keep_prob_ph:,self.is_train_ph:,})
        return feed_dict
    def train_on_batch(self, features_li: List[List[]], y: Union[List[], List[List[]]]) -> Dict:
        input_ids_a = [f.input_ids for f in features_li[]]
        input_masks_a = [f.input_mask for f in features_li[]]
        input_type_ids_a = [f.input_type_ids for f in features_li[]]
        input_ids_b = [f.input_ids for f in features_li[]]
        input_masks_b = [f.input_mask for f in features_li[]]
        input_type_ids_b = [f.input_type_ids for f in features_li[]]
        feed_dict = self._build_feed_dict()
        _, loss = self.sess.run([], feed_dict=)
        return {'loss':, 'learning_rate':}
    def __call__(self, features_li: List[List[]]) -> Union[List[], List[List[]]]:
        if len() == 1 and len(features_li[]) == 1:
            msg = ""
            return []
        predictions = []
        input_ids_a = [f.input_ids for f in features_li[]]
        input_masks_a = [f.input_mask for f in features_li[]]
        input_type_ids_a = [f.input_type_ids for f in features_li[]]
        for features in features_li[1:]:
            input_ids_b = []
            input_masks_b = []
            input_type_ids_b = []
            feed_dict = self._build_feed_dict()
            pred = self.sess.run(self.y_probas, feed_dict=)
            predictions.append()
        if len() == 1:
            predictions = predictions[]
        else:
            predictions = np.hstack([np.expand_dims() for el in predictions])
        return predictions
class BertSepRankerPredictor():
    def __init__(self, bert_config_file, interact_mode=, batch_size=,resps=, resp_features=, resp_vecs=,conts=, cont_features=, cont_vecs=, **kwargs) -> None:
        super().__init__(bert_config_file=,**kwargs)
        self.interact_mode =
        self.batch_size =
        self.resps =
        self.resp_vecs =
        self.resp_features =
        self.conts =
        self.cont_vecs =
        self.cont_features =
        if self.resps is not None and self.resp_vecs is None:
            self.resp_features = [resp_features[][i * self.batch_size: () * self.batch_size]for i in range(len(resp_features[]) // batch_size + 1)]
            self.resp_vecs = self._get_predictions()
            self.resp_vecs /= np.linalg.norm(self.resp_vecs, axis=, keepdims=)
            np.save()
        if self.conts is not None and self.cont_vecs is None:
            self.cont_features = [cont_features[][i * self.batch_size: () * self.batch_size]for i in range(len(cont_features[]) // batch_size + 1)]
            self.cont_vecs = self._get_predictions()
            self.cont_vecs /= np.linalg.norm(self.cont_vecs, axis=, keepdims=)
            np.save()
    def train_on_batch():
        pass
    def __call__():
        pred = self._get_predictions()
        return self._retrieve_db_response()
    def _get_predictions():
        pred = []
        for features in features_li:
            input_ids = []
            input_masks = []
            input_type_ids = []
            feed_dict = self._build_feed_dict()
            p = self.sess.run(self.pooled_out, feed_dict=)
            if len() == 1:
                p = np.expand_dims()
            p /= np.linalg.norm(p, axis=, keepdims=)
            pred.append()
        return np.vstack()
    def _retrieve_db_response():
        bs = ctx_vec.shape[]
        if self.interact_mode == 0:
            s =
            ids = np.argmax()
            rsp = [[self.resps[ids[]] for i in range()], [s[][ids[]] for i in range()]]
        if self.interact_mode == 1:
            sr = () / 2
            sc = () / 2
            ids = np.argsort()[:, -10:]
            sc = [sc[i, ids[]] for i in range()]
            ids = [sorted(zip(ids[], sc[]), key=itemgetter(), reverse=) for i in range()]
            sc = [list(map(lambda x: x[], ids[])) for i in range()]
            ids = [list(map(lambda x: x[], ids[])) for i in range()]
            rsp = [[self.resps[ids[][]] for i in range()], [float(sc[][]) for i in range()]]
        if self.interact_mode == 2:
            sr = () / 2
            sc = () / 2
            ids = np.argsort()[:, -10:]
            sr = [sr[i, ids[]] for i in range()]
            ids = [sorted(zip(ids[], sr[]), key=itemgetter(), reverse=) for i in range()]
            sr = [list(map(lambda x: x[], ids[])) for i in range()]
            ids = [list(map(lambda x: x[], ids[])) for i in range()]
            rsp = [[self.resps[ids[][]] for i in range()], [float(sr[][]) for i in range()]]
        if self.interact_mode == 3:
            sr = () / 2
            sc = () / 2
            s = () / 2
            ids = np.argmax()
            rsp = [[self.resps[ids[]] for i in range()], [float(s[][ids[]]) for i in range()]]
        rsp = [[el.replace().replace().strip() for el in rsp[]], rsp[]]
        return rsp
from logging import getLogger
from typing import List, Union, Dict, Optional
import numpy as np
import tensorflow as tf
from bert_dp.modeling import BertConfig, BertModel
from bert_dp.optimization import AdamWeightDecayOptimizer
from deeppavlov.core.commands.utils import expand_path
from deeppavlov.core.common.registry import register
from deeppavlov.core.layers.tf_layers import bi_rnn
from deeppavlov.core.models.tf_model import LRScheduledTFModel
log = getLogger()
def token_from_subtoken(units:, mask:) -> tf.Tensor:
    shape = tf.cast(tf.shape(), tf.int64)
    batch_size = shape[]
    nf = shape[]
    nf_int = units.get_shape().as_list()[]
    token_seq_lengths = tf.cast(tf.reduce_sum(), tf.int64)
    n_words = tf.reduce_sum()
    max_token_seq_len = tf.cast(tf.reduce_max(), tf.int64)
    idxs = tf.where()
    sample_ids_in_batch = tf.pad(idxs[:, 0], [[]])
    a = tf.cast(tf.not_equal(sample_ids_in_batch[1:], sample_ids_in_batch[:]), tf.int64)
    q = a * tf.cast(tf.range(), tf.int64)
    count_to_substract = tf.pad(tf.boolean_mask(), [()])
    new_word_indices = tf.cast(tf.range(), tf.int64) - tf.gather(count_to_substract, tf.cumsum())
    n_total_word_elements = tf.cast()
    word_indices_flat = tf.cast(idxs[:, 0] * max_token_seq_len + new_word_indices, tf.int32)
    x_mask = tf.reduce_sum(tf.one_hot(), 0)
    x_mask = tf.cast()
    full_range = tf.cast(tf.range(), tf.int32)
    nonword_indices_flat = tf.boolean_mask(full_range, tf.math.logical_not())
    elements = tf.gather_nd()
    paddings = tf.zeros(tf.stack([tf.reduce_sum(),nf], 0), tf.float32)
    tensor_flat = tf.dynamic_stitch([],[])
    tensor = tf.reshape(tensor_flat, tf.stack([], 0))
    return tensor
class BertSequenceNetwork():
    def __init__(self,keep_prob:,bert_config_file:,pretrained_bert: str =,attention_probs_keep_prob: float =,hidden_keep_prob: float =,encoder_layer_ids: List[] = (),encoder_dropout: float =,optimizer: str =,weight_decay_rate: float =,ema_decay: float =,ema_variables_on_cpu: bool =,freeze_embeddings: bool =,learning_rate: float =,bert_learning_rate: float =,min_learning_rate: float =,learning_rate_drop_patience: int =,learning_rate_drop_div: float =,load_before_drop: bool =,clip_norm: float =,**kwargs) -> None:
        super().__init__(learning_rate=,learning_rate_drop_div=,learning_rate_drop_patience=,load_before_drop=,clip_norm=,**kwargs)
        self.keep_prob =
        self.encoder_layer_ids =
        self.encoder_dropout =
        self.optimizer =
        self.weight_decay_rate =
        self.ema_decay =
        self.ema_variables_on_cpu =
        self.freeze_embeddings =
        self.bert_learning_rate_multiplier =
        self.min_learning_rate =
        self.bert_config = BertConfig.from_json_file(str(expand_path()))
        if attention_probs_keep_prob is not None:
            self.bert_config.attention_probs_dropout_prob =
        if hidden_keep_prob is not None:
            self.bert_config.hidden_dropout_prob =
        self.sess_config = tf.ConfigProto(allow_soft_placement=)
        self.sess_config.gpu_options.allow_growth =
        self.sess = tf.Session(config=)
        self._init_graph()
        self._init_optimizer()
        self.sess.run(tf.global_variables_initializer())
        if pretrained_bert is not None:
            pretrained_bert = str(expand_path())
            if tf.train.checkpoint_exists() and not (self.load_path and tf.train.checkpoint_exists(str(self.load_path.resolve()))):
                var_list = self._get_saveable_variables(exclude_scopes=())
                saver = tf.train.Saver()
                saver.restore()
        if self.load_path is not None:
            self.load()
        if self.ema:
            self.sess.run()
    def _init_graph() -> None:
        self.seq_lengths = tf.reduce_sum(self.y_masks_ph, axis=)
        self.bert = BertModel(config=,is_training=,input_ids=,input_mask=,token_type_ids=,use_one_hot_embeddings=)
        with tf.variable_scope():
            layer_weights = tf.get_variable("",shape=len(),initializer=tf.ones_initializer(),trainable=)
            layer_mask = tf.ones_like()
            layer_mask = tf.nn.dropout()
            layer_weights *=
            mask_sum = tf.maximum(tf.reduce_sum(), 1.0)
            layer_weights = tf.unstack()
            units = sum(w * l for w, l in zip(layer_weights, self.encoder_layers()))
            units = tf.nn.dropout(units, keep_prob=)
        return units
    def _get_tag_mask() -> tf.Tensor:
        max_length = tf.reduce_max()
        one_hot_max_len = tf.one_hot()
        tag_mask = tf.cumsum(one_hot_max_len[:, ::], axis=)[:, ::]
        return tag_mask
    def encoder_layers():
        return [self.bert.all_encoder_layers[] for i in self.encoder_layer_ids]
    def _init_placeholders() -> None:
        self.input_ids_ph = tf.placeholder(shape=(),dtype=,name=)
        self.input_masks_ph = tf.placeholder(shape=(),dtype=,name=)
        self.token_types_ph = tf.placeholder_with_default(tf.zeros_like(self.input_ids_ph, dtype=),shape=,name=)
        self.learning_rate_ph = tf.placeholder_with_default(0.0, shape=[], name=)
        self.keep_prob_ph = tf.placeholder_with_default(1.0, shape=[], name=)
        self.encoder_keep_prob_ph = tf.placeholder_with_default(1.0, shape=[], name=)
        self.is_train_ph = tf.placeholder_with_default(False, shape=[], name=)
    def _init_optimizer() -> None:
        with tf.variable_scope():
            self.global_step = tf.get_variable("",shape=[],dtype=,initializer=tf.constant_initializer(),trainable=)
        if self.optimizer is None:
            self.train_op = self.get_train_op(self.loss,learning_rate=,optimizer=,weight_decay_rate=,beta_1=,beta_2=,epsilon=,optimizer_scope_name=,exclude_from_weight_decay=[])
        else:
            self.train_op = self.get_train_op(self.loss,learning_rate=,optimizer_scope_name=)
        if self.optimizer is None:
            with tf.variable_scope():
                new_global_step =
                self.train_op = tf.group(self.train_op, [self.global_step.assign()])
        if self.ema_decay is not None:
            _vars = self._get_trainable_variables(exclude_scopes=[])
            self.ema = ExponentialMovingAverage(self.ema_decay,variables_on_cpu=)
            self.train_op = self.ema.build(self.train_op, _vars, name=)
        else:
            self.ema =
    def get_train_op(self, loss:, learning_rate: Union[], **kwargs) -> tf.Operation:
        kwargs[] = ()
        if self.freeze_embeddings:
            kwargs[] = ()
        bert_learning_rate =
        bert_train_op = super().get_train_op()
        kwargs[] = ()
        head_train_op = super().get_train_op()
        return tf.group()
    def _build_basic_feed_dict(self, input_ids:, input_masks:,token_types: Optional[]=, train: bool=) -> dict:
        feed_dict = {self.input_ids_ph:,self.input_masks_ph:,}
        if token_types is not None:
            feed_dict[] =
        if train:
            feed_dict.update({self.learning_rate_ph:,,self.keep_prob_ph:,self.encoder_keep_prob_ph:,self.is_train_ph:,})
        return feed_dict
    def _build_feed_dict(self, input_ids, input_masks, token_types=, *args,  **kwargs):
        raise NotImplementedError()
    def train_on_batch(self,input_ids: Union[List[List[]], np.ndarray],input_masks: Union[List[List[]], np.ndarray],*args, **kwargs) -> Dict[]:
        feed_dict = self._build_feed_dict()
        if self.ema:
            self.sess.run()
        _, loss, lr = self.sess.run([],feed_dict=)
        return {'loss':,'head_learning_rate':,'bert_learning_rate':}
    def __call__(self,input_ids: Union[List[List[]], np.ndarray],input_masks: Union[List[List[]], np.ndarray],**kwargs) -> Union[List[List[]], List[]]:
        raise NotImplementedError()
    def save(self, exclude_scopes=()) -> None:
        if self.ema:
            self.sess.run()
        return super().save(exclude_scopes=)
    def load(self,exclude_scopes=(),**kwargs) -> None:
        return super().load(exclude_scopes=, **kwargs)
class BertSequenceTagger():
    def __init__(self,n_tags: List[],keep_prob:,bert_config_file:,pretrained_bert: str =,attention_probs_keep_prob: float =,hidden_keep_prob: float =,use_crf=,encoder_layer_ids: List[] = (),encoder_dropout: float =,optimizer: str =,weight_decay_rate: float =,use_birnn: bool =,birnn_cell_type: str =,birnn_hidden_size: int =,ema_decay: float =,ema_variables_on_cpu: bool =,return_probas: bool =,freeze_embeddings: bool =,learning_rate: float =,bert_learning_rate: float =,min_learning_rate: float =,learning_rate_drop_patience: int =,learning_rate_drop_div: float =,load_before_drop: bool =,clip_norm: float =,**kwargs) -> None:
        self.n_tags =
        self.use_crf =
        self.use_birnn =
        self.birnn_cell_type =
        self.birnn_hidden_size =
        self.return_probas =
        super().__init__(keep_prob=,bert_config_file=,pretrained_bert=,attention_probs_keep_prob=,hidden_keep_prob=,encoder_layer_ids=,encoder_dropout=,optimizer=,weight_decay_rate=,ema_decay=,ema_variables_on_cpu=,freeze_embeddings=,learning_rate=,bert_learning_rate=,min_learning_rate=,learning_rate_drop_div=,learning_rate_drop_patience=,load_before_drop=,clip_norm=,**kwargs)
    def _init_graph() -> None:
        self._init_placeholders()
        units = super()._init_graph()
        with tf.variable_scope():
            if self.use_birnn:
                units, _ = bi_rnn(units,self.birnn_hidden_size,cell_type=,seq_lengths=,name=)
                units = tf.concat()
            logits = tf.layers.dense(units, units=, name=)
            self.logits = token_from_subtoken()
            if self.use_crf:
                transition_params = tf.get_variable("",shape=[],initializer=tf.zeros_initializer())
                log_likelihood, transition_params = tf.contrib.crf.crf_log_likelihood()
                loss_tensor =
                self._transition_params =
            self.y_predictions = tf.argmax()
            self.y_probas = tf.nn.softmax(self.logits, axis=)
        with tf.variable_scope():
            tag_mask = self._get_tag_mask()
            y_mask = tf.cast()
            if self.use_crf:
                self.loss = tf.reduce_mean()
            else:
                self.loss = tf.losses.sparse_softmax_cross_entropy(labels=,logits=,weights=)
    def _init_placeholders() -> None:
        super()._init_placeholders()
        self.y_ph = tf.placeholder(shape=(), dtype=, name=)
        self.y_masks_ph = tf.placeholder(shape=(),dtype=,name=)
    def _decode_crf(self, feed_dict: Dict[]) -> List[]:
        logits, trans_params, mask, seq_lengths = self.sess.run([],feed_dict=)
        y_pred = []
        for logit, sequence_length in zip():
            logit = logit[:int()]
            viterbi_seq, viterbi_score = tf.contrib.crf.viterbi_decode()
            y_pred += []
        return y_pred
    def _build_feed_dict(self, input_ids, input_masks, y_masks, y=):
        feed_dict = self._build_basic_feed_dict(input_ids, input_masks, train=())
        feed_dict[] =
        if y is not None:
            feed_dict[] =
        return feed_dict
    def __call__(self,input_ids: Union[List[List[]], np.ndarray],input_masks: Union[List[List[]], np.ndarray],y_masks: Union[List[List[]], np.ndarray]) -> Union[List[List[]], List[]]:
        feed_dict = self._build_feed_dict()
        if self.ema:
            self.sess.run()
        if not self.return_probas:
            if self.use_crf:
                pred = self._decode_crf()
            else:
                pred, seq_lengths = self.sess.run([], feed_dict=)
                pred = [p[:] for l, p in zip()]
        else:
            pred = self.sess.run(self.y_probas, feed_dict=)
        return pred
class ExponentialMovingAverage:
    def __init__(self,decay: float =,variables_on_cpu: bool =) -> None:
        self.decay =
        self.ema = tf.train.ExponentialMovingAverage(decay=)
        self.var_device_name = '/cpu:
        self.train_mode =
    def build(self,minimize_op:,update_vars: List[] =,name: str =) -> tf.Tensor:
        with tf.variable_scope():
            if update_vars is None:
                update_vars = tf.get_collection()
            with tf.control_dependencies([]):
                minimize_op = self.ema.apply()
            with tf.device():
                with tf.variable_scope():
                    backup_vars = [tf.get_variable(var.op.name,dtype=var.value().dtype,trainable=,initializer=var.initialized_value())for var in update_vars]
                def ema_to_weights():
                    return tf.group(*(tf.assign(var, self.ema.average().read_value())for var in update_vars))
                def save_weight_backups():
                    return tf.group(*(tf.assign(bck, var.read_value())for var, bck in zip()))
                def restore_weight_backups():
                    return tf.group(*(tf.assign(var, bck.read_value())for var, bck in zip()))
                train_switch_op = restore_weight_backups()
                with tf.control_dependencies([save_weight_backups()]):
                    test_switch_op = ema_to_weights()
            self.train_switch_op =
            self.test_switch_op =
            self.do_nothing_op = tf.no_op()
        return minimize_op
    def init_op() -> tf.Operation:
        self.train_mode =
        return self.test_switch_op
    def switch_to_train_op() -> tf.Operation:
        if not self.train_mode:
            self.train_mode =
            return self.train_switch_op
        return self.do_nothing_op
    def switch_to_test_op() -> tf.Operation:
        if self.train_mode:
            self.train_mode =
            return self.test_switch_op
        return self.do_nothing_op
import json
import math
from logging import getLogger
from typing import List, Tuple, Optional, Dict
import numpy as np
import tensorflow as tf
from bert_dp.modeling import BertConfig, BertModel
from bert_dp.optimization import AdamWeightDecayOptimizer
from bert_dp.preprocessing import InputFeatures
from bert_dp.tokenization import FullTokenizer
from deeppavlov import build_model
from deeppavlov.core.commands.utils import expand_path
from deeppavlov.core.common.registry import register
from deeppavlov.core.models.estimator import Component
from deeppavlov.core.models.tf_model import LRScheduledTFModel
from deeppavlov.models.squad.utils import softmax_mask
logger = getLogger()
class BertSQuADModel():
    def __init__(self, bert_config_file:,keep_prob:,attention_probs_keep_prob: Optional[] =,hidden_keep_prob: Optional[] =,optimizer: Optional[] =,weight_decay_rate: Optional[] =,pretrained_bert: Optional[] =,min_learning_rate: float =, **kwargs) -> None:
        super().__init__()
        self.min_learning_rate =
        self.keep_prob =
        self.optimizer =
        self.weight_decay_rate =
        self.bert_config = BertConfig.from_json_file(str(expand_path()))
        if attention_probs_keep_prob is not None:
            self.bert_config.attention_probs_dropout_prob =
        if hidden_keep_prob is not None:
            self.bert_config.hidden_dropout_prob =
        self.sess_config = tf.ConfigProto(allow_soft_placement=)
        self.sess_config.gpu_options.allow_growth =
        self.sess = tf.Session(config=)
        self._init_graph()
        self._init_optimizer()
        self.sess.run(tf.global_variables_initializer())
        if pretrained_bert is not None:
            pretrained_bert = str(expand_path())
            if tf.train.checkpoint_exists() and not (self.load_path and tf.train.checkpoint_exists(str(self.load_path.resolve()))):
                var_list = self._get_saveable_variables(exclude_scopes=())
                saver = tf.train.Saver()
                saver.restore()
        if self.load_path is not None:
            self.load()
    def _init_graph():
        self._init_placeholders()
        seq_len = tf.shape()[]
        self.y_st = tf.one_hot(self.y_st_ph, depth=)
        self.y_end = tf.one_hot(self.y_end_ph, depth=)
        self.bert = BertModel(config=,is_training=,input_ids=,input_mask=,token_type_ids=,use_one_hot_embeddings=,)
        last_layer = self.bert.get_sequence_output()
        hidden_size = last_layer.get_shape().as_list()[]
        bs = tf.shape()[]
        with tf.variable_scope():
            output_weights = tf.get_variable("", [],initializer=tf.truncated_normal_initializer(stddev=))
            output_bias = tf.get_variable("", [], initializer=tf.zeros_initializer())
            last_layer_rs = tf.reshape(last_layer, [])
            logits = tf.matmul(last_layer_rs, output_weights, transpose_b=)
            logits = tf.nn.bias_add()
            logits = tf.reshape(logits, [])
            logits = tf.transpose(logits, [])
            logits_st, logits_end = tf.unstack(logits, axis=)
            logit_mask =
            mask = tf.concat([tf.ones((), dtype=), tf.zeros((), dtype=)], axis=)
            logit_mask =
            logits_st = softmax_mask()
            logits_end = softmax_mask()
            start_probs = tf.nn.softmax()
            end_probs = tf.nn.softmax()
            outer = tf.matmul(tf.expand_dims(start_probs, axis=), tf.expand_dims(end_probs, axis=))
            outer_logits = tf.exp(tf.expand_dims(logits_st, axis=) + tf.expand_dims(logits_end, axis=))
            context_max_len = tf.reduce_max(tf.reduce_sum(self.token_types_ph, axis=))
            max_ans_length = tf.cast(tf.minimum(), tf.int64)
            outer = tf.matrix_band_part()
            outer_logits = tf.matrix_band_part()
            self.yp_score = 1 - tf.nn.softmax()[:, 0] * tf.nn.softmax()[:, 0]
            self.start_probs =
            self.end_probs =
            self.start_pred = tf.argmax(tf.reduce_max(outer, axis=), axis=)
            self.end_pred = tf.argmax(tf.reduce_max(outer, axis=), axis=)
            self.yp_logits = tf.reduce_max(tf.reduce_max(outer_logits, axis=), axis=)
        with tf.variable_scope():
            loss_st = tf.nn.softmax_cross_entropy_with_logits(logits=, labels=)
            loss_end = tf.nn.softmax_cross_entropy_with_logits(logits=, labels=)
            self.loss = tf.reduce_mean()
    def _init_placeholders():
        self.input_ids_ph = tf.placeholder(shape=(), dtype=, name=)
        self.input_masks_ph = tf.placeholder(shape=(), dtype=, name=)
        self.token_types_ph = tf.placeholder(shape=(), dtype=, name=)
        self.y_st_ph = tf.placeholder(shape=(), dtype=, name=)
        self.y_end_ph = tf.placeholder(shape=(), dtype=, name=)
        self.learning_rate_ph = tf.placeholder_with_default(0.0, shape=[], name=)
        self.keep_prob_ph = tf.placeholder_with_default(1.0, shape=[], name=)
        self.is_train_ph = tf.placeholder_with_default(False, shape=[], name=)
    def _init_optimizer():
        with tf.variable_scope():
            self.global_step = tf.get_variable("", shape=[], dtype=,initializer=tf.constant_initializer(), trainable=)
            if self.optimizer is None:
                self.train_op = self.get_train_op(self.loss, learning_rate=,optimizer=,weight_decay_rate=,beta_1=,beta_2=,epsilon=,exclude_from_weight_decay=[])
            else:
                self.train_op = self.get_train_op(self.loss, learning_rate=)
            if self.optimizer is None:
                new_global_step =
                self.train_op = tf.group(self.train_op, [self.global_step.assign()])
    def _build_feed_dict(self, input_ids, input_masks, token_types, y_st=, y_end=):
        feed_dict = {self.input_ids_ph:,self.input_masks_ph:,self.token_types_ph:,}
        if y_st is not None and y_end is not None:
            feed_dict.update({self.y_st_ph:,self.y_end_ph:,self.learning_rate_ph:,,self.keep_prob_ph:,self.is_train_ph:,})
        return feed_dict
    def train_on_batch(self, features: List[], y_st: List[List[]], y_end: List[List[]]) -> Dict:
        input_ids = []
        input_masks = []
        input_type_ids = []
        y_st = [x[] for x in y_st]
        y_end = [x[] for x in y_end]
        feed_dict = self._build_feed_dict()
        _, loss = self.sess.run([], feed_dict=)
        return {'loss':, 'learning_rate':}
    def __call__(self, features: List[]) -> Tuple[List[], List[], List[], List[]]:
        input_ids = []
        input_masks = []
        input_type_ids = []
        feed_dict = self._build_feed_dict()
        st, end, logits, scores = self.sess.run([],feed_dict=)
        return st, end, logits.tolist(), scores.tolist()
class BertSQuADInferModel():
    def __init__(self, squad_model_config:,vocab_file:,do_lower_case:,max_seq_length: int =,batch_size: int =,lang=, **kwargs) -> None:
        config = json.load(open())
        config[][][][] =
        self.model = build_model()
        self.max_seq_length =
        vocab_file = str(expand_path())
        self.tokenizer = FullTokenizer(vocab_file=, do_lower_case=)
        self.batch_size =
        if lang == "":
            from nltk import sent_tokenize
            self.sent_tokenizer =
        elif lang == "":
            from ru_sent_tokenize import ru_sent_tokenize
            self.sent_tokenizer =
        else:
            raise RuntimeError()
    def __call__(self, contexts: List[], questions: List[], **kwargs) -> Tuple[List[], List[], List[]]:
        batch_indices = []
        contexts_to_predict = []
        questions_to_predict = []
        predictions = {}
        for i, () in enumerate(zip()):
            context_subtokens = self.tokenizer.tokenize()
            question_subtokens = self.tokenizer.tokenize()
            max_chunk_len = self.max_seq_length - len() - 3
            if 0 < max_chunk_len < len():
                number_of_chunks = math.ceil(len() / max_chunk_len)
                sentences = self.sent_tokenizer()
                for chunk in np.array_split():
                    contexts_to_predict += ["".join()]
                    questions_to_predict += []
                    batch_indices += []
            else:
                contexts_to_predict += []
                questions_to_predict += []
                batch_indices += []
        for j in range(0, len(), self.batch_size):
            c_batch = contexts_to_predict[j:]
            q_batch = questions_to_predict[j:]
            ind_batch = batch_indices[j:]
            a_batch, a_st_batch, logits_batch = self.model()
            for a, a_st, logits, ind in zip():
                if ind in predictions:
                    predictions[] += [()]
                else:
                    predictions[] = [()]
        answers, answer_starts, logits = [], [], []
        for ind in sorted(predictions.keys()):
            prediction = predictions[]
            best_answer_ind = np.argmax([p[] for p in prediction])
            answers += [prediction[][]]
            answer_starts += [prediction[][]]
            logits += [prediction[][]]
        return answers, answer_starts, logits
from logging import getLogger
from typing import Optional
import numpy as np
import tensorflow as tf
from deeppavlov.core.common.registry import register
from deeppavlov.models.ranking.matching_models.dam_utils import layers
from deeppavlov.models.ranking.matching_models.dam_utils import operations as op
from deeppavlov.models.ranking.tf_base_matching_model import TensorflowBaseMatchingModel
log = getLogger()
class DAMNetwork():
    def __init__(self,embedding_dim: int =,max_sequence_length: int =,learning_rate: float =,emb_matrix: Optional[] =,trainable_embeddings: bool =,is_positional: bool =,filters2_conv3d: int =,stack_num: int =,seed: int =,decay_steps: int =,*args,**kwargs):
        self.seed =
        tf.set_random_seed()
        self.max_sentence_len =
        self.word_embedding_size =
        self.trainable =
        self.is_positional =
        self.stack_num =
        self.filters2_conv3d =
        self.learning_rate =
        self.emb_matrix =
        self.decay_steps =
        super().__init__()
        self.sess_config = tf.ConfigProto(allow_soft_placement=)
        self.sess_config.gpu_options.allow_growth =
        self.sess = tf.Session(config=)
        self._init_graph()
        self.sess.run(tf.global_variables_initializer())
        if self.load_path is not None:
            self.load()
    def _init_placeholders():
        with tf.variable_scope():
            self.utterance_ph = tf.placeholder(tf.int32, shape=())
            self.all_utterance_len_ph = tf.placeholder(tf.int32, shape=())
            self.response_ph = tf.placeholder(tf.int32, shape=())
            self.response_len_ph = tf.placeholder(tf.int32, shape=())
            self.y_true = tf.placeholder(tf.int32, shape=())
    def _init_graph():
        self._init_placeholders()
        with tf.variable_scope():
            word_embeddings = tf.get_variable("",initializer=tf.constant(self.emb_matrix, dtype=),trainable=)
        with tf.variable_scope():
            response_embeddings = tf.nn.embedding_lookup()
        Hr =
        if self.is_positional and self.stack_num > 0:
            with tf.variable_scope():
                Hr = op.positional_encoding_vector(Hr, max_timescale=)
        Hr_stack = []
        for index in range():
            with tf.variable_scope("" + str()):
                Hr = layers.block(Hr, Hr, Hr,Q_lengths=, K_lengths=, attention_type=)
                Hr_stack.append()
        list_turn_t = tf.unstack(self.utterance_ph, axis=)
        list_turn_length = tf.unstack(self.all_utterance_len_ph, axis=)
        sim_turns = []
        for turn_t, t_turn_length in zip():
            Hu = tf.nn.embedding_lookup()
            if self.is_positional and self.stack_num > 0:
                with tf.variable_scope("", reuse=):
                    Hu = op.positional_encoding_vector(Hu, max_timescale=)
            Hu_stack = []
            for index in range():
                with tf.variable_scope("" + str(), reuse=):
                    Hu = layers.block(Hu, Hu, Hu,Q_lengths=, K_lengths=, attention_type=)
                    Hu_stack.append()
            r_a_t_stack = []
            t_a_r_stack = []
            for index in range():
                with tf.variable_scope("" + str()):
                    try:
                        t_a_r = layers.block(Hu_stack[], Hr_stack[], Hr_stack[],Q_lengths=, K_lengths=, attention_type=)
                    except ValueError:
                        tf.get_variable_scope().reuse_variables()
                        t_a_r = layers.block(Hu_stack[], Hr_stack[], Hr_stack[],Q_lengths=, K_lengths=, attention_type=)
                with tf.variable_scope("" + str()):
                    try:
                        r_a_t = layers.block(Hr_stack[], Hu_stack[], Hu_stack[],Q_lengths=, K_lengths=, attention_type=)
                    except ValueError:
                        tf.get_variable_scope().reuse_variables()
                        r_a_t = layers.block(Hr_stack[], Hu_stack[], Hu_stack[],Q_lengths=, K_lengths=, attention_type=)
                t_a_r_stack.append()
                r_a_t_stack.append()
            t_a_r_stack.extend()
            r_a_t_stack.extend()
            t_a_r = tf.stack(t_a_r_stack, axis=)
            r_a_t = tf.stack(r_a_t_stack, axis=)
            with tf.variable_scope():
                sim = tf.einsum() / tf.sqrt(float())
            sim_turns.append()
        sim = tf.stack(sim_turns, axis=)
        with tf.variable_scope():
            final_info = layers.CNN_3d()
        with tf.variable_scope():
            self.loss, self.logits = layers.loss(final_info, self.y_true, clip_value=)
            self.y_pred = tf.nn.softmax(self.logits, name=)
            tf.summary.scalar()
            self.global_step = tf.Variable(0, trainable=)
            initial_learning_rate =
            self.learning_rate = tf.train.exponential_decay(initial_learning_rate,global_step=,decay_steps=,decay_rate=,staircase=)
            Optimizer = tf.train.AdamOptimizer()
            self.grads_and_vars = Optimizer.compute_gradients()
            for grad, var in self.grads_and_vars:
                if grad is None:
            self.capped_gvs = [(tf.clip_by_value(), var) for grad, var in self.grads_and_vars]
            self.train_op = Optimizer.apply_gradients(self.capped_gvs,global_step=)
        self.print_number_of_parameters()
from logging import getLogger
from typing import List, Dict, Tuple, Optional
import numpy as np
import tensorflow as tf
import tensorflow_hub as hub
from deeppavlov.core.common.registry import register
from deeppavlov.models.ranking.matching_models.dam_utils import layers
from deeppavlov.models.ranking.matching_models.dam_utils import operations as op
from deeppavlov.models.ranking.tf_base_matching_model import TensorflowBaseMatchingModel
log = getLogger()
class DAMNetworkUSETransformer():
    def __init__(self,embedding_dim: int =,max_sequence_length: int =,learning_rate: float =,emb_matrix: Optional[] =,trainable_embeddings: bool =,is_positional: bool =,stack_num: int =,seed: int =,decay_steps: int =,*args,**kwargs):
        self.seed =
        tf.set_random_seed()
        self.max_sentence_len =
        self.word_embedding_size =
        self.trainable =
        self.is_positional =
        self.stack_num =
        self.learning_rate =
        self.emb_matrix =
        self.decay_steps =
        super().__init__()
        self._init_graph()
        self.sess_config = tf.ConfigProto(allow_soft_placement=)
        self.sess_config.gpu_options.allow_growth =
        self.sess = tf.Session(config=)
        self.sess.run([tf.global_variables_initializer(), tf.tables_initializer()])
        if self.load_path is not None:
            self.load()
    def _init_placeholders():
        with tf.variable_scope():
            self.utterance_ph = tf.placeholder(tf.int32, shape=())
            self.all_utterance_len_ph = tf.placeholder(tf.int32, shape=())
            self.response_ph = tf.placeholder(tf.int32, shape=())
            self.response_len_ph = tf.placeholder(tf.int32, shape=())
            self.y_true = tf.placeholder(tf.int32, shape=())
            self.context_sent_ph = tf.placeholder(tf.string,shape=(),name=)
            self.response_sent_ph = tf.placeholder(tf.string, shape=(), name=)
    def _init_sentence_encoder():
        self.embed = hub.Module("https:,trainable=)
        with tf.variable_scope():
            x = []
            for i in range():
                x.append(self.embed(tf.reshape(self.context_sent_ph[:, i], shape=(tf.shape()[],))))
            embed_context_turns = tf.stack(x, axis=)
            embed_response = self.embed()
            self.sent_embedder_context = tf.expand_dims(embed_context_turns, axis=)
            self.sent_embedder_response = tf.expand_dims(embed_response, axis=)
    def _init_graph():
        self._init_placeholders()
        self._init_sentence_encoder()
        with tf.variable_scope():
            dense_emb = tf.layers.Dense(200,kernel_initializer=tf.keras.initializers.glorot_uniform(seed=),kernel_regularizer=tf.keras.regularizers.l2(),bias_regularizer=tf.keras.regularizers.l2(),trainable=)
            a = []
            for i in range():
                a.append(dense_emb(self.sent_embedder_context[:, i]))
            sent_embedder_context = tf.stack(a, axis=)
            sent_embedder_response = dense_emb()
        with tf.variable_scope():
            word_embeddings = tf.get_variable("",initializer=tf.constant(self.emb_matrix, dtype=),trainable=)
        with tf.variable_scope():
            response_embeddings = tf.nn.embedding_lookup()
        Hr =
        if self.is_positional and self.stack_num > 0:
            with tf.variable_scope():
                Hr = op.positional_encoding_vector(Hr, max_timescale=)
        with tf.variable_scope():
            Hr = tf.concat([], axis=)
        Hr_stack = []
        for index in range():
            with tf.variable_scope("" + str()):
                Hr = layers.block(Hr, Hr, Hr,Q_lengths=, K_lengths=, attention_type=)
                Hr_stack.append()
        list_turn_t = tf.unstack(self.utterance_ph, axis=)
        list_turn_length = tf.unstack(self.all_utterance_len_ph, axis=)
        list_turn_t_sent = tf.unstack(sent_embedder_context, axis=)
        sim_turns = []
        for turn_t, t_turn_length, turn_t_sent in zip():
            Hu = tf.nn.embedding_lookup()
            if self.is_positional and self.stack_num > 0:
                with tf.variable_scope("", reuse=):
                    Hu = op.positional_encoding_vector(Hu, max_timescale=)
            with tf.variable_scope():
                Hu = tf.concat([], axis=)
            Hu_stack = []
            for index in range():
                with tf.variable_scope("" + str(), reuse=):
                    Hu = layers.block(Hu, Hu, Hu,Q_lengths=, K_lengths=, attention_type=)
                    Hu_stack.append()
            r_a_t_stack = []
            t_a_r_stack = []
            for index in range():
                with tf.variable_scope("" + str()):
                    try:
                        t_a_r = layers.block(Hu_stack[], Hr_stack[], Hr_stack[],Q_lengths=, K_lengths=, attention_type=)
                    except ValueError:
                        tf.get_variable_scope().reuse_variables()
                        t_a_r = layers.block(Hu_stack[], Hr_stack[], Hr_stack[],Q_lengths=, K_lengths=, attention_type=)
                with tf.variable_scope("" + str()):
                    try:
                        r_a_t = layers.block(Hr_stack[], Hu_stack[], Hu_stack[],Q_lengths=, K_lengths=, attention_type=)
                    except ValueError:
                        tf.get_variable_scope().reuse_variables()
                        r_a_t = layers.block(Hr_stack[], Hu_stack[], Hu_stack[],Q_lengths=, K_lengths=, attention_type=)
                t_a_r_stack.append()
                r_a_t_stack.append()
            t_a_r_stack.extend()
            r_a_t_stack.extend()
            t_a_r = tf.stack(t_a_r_stack, axis=)
            r_a_t = tf.stack(r_a_t_stack, axis=)
            with tf.variable_scope():
                sim = tf.einsum() / tf.sqrt(float())
            sim_turns.append()
        sim = tf.stack(sim_turns, axis=)
        with tf.variable_scope():
            final_info = layers.CNN_3d()
        with tf.variable_scope():
            self.loss, self.logits = layers.loss(final_info, self.y_true, clip_value=)
            self.y_pred = tf.nn.softmax(self.logits, name=)
            tf.summary.scalar()
            self.global_step = tf.Variable(0, trainable=)
            initial_learning_rate =
            self.learning_rate = tf.train.exponential_decay(initial_learning_rate,global_step=,decay_steps=,decay_rate=,staircase=)
            Optimizer = tf.train.AdamOptimizer()
            self.grads_and_vars = Optimizer.compute_gradients()
            for grad, var in self.grads_and_vars:
                if grad is None:
            self.capped_gvs = [(tf.clip_by_value(), var) for grad, var in self.grads_and_vars]
            self.train_op = Optimizer.apply_gradients(self.capped_gvs,global_step=)
        self.print_number_of_parameters()
    def _append_sample_to_batch_buffer(self, sample: List[], buf: List[]):
        sample_len = len()
        batch_buffer_context = []
        batch_buffer_context_len = []
        batch_buffer_response = []
        batch_buffer_response_len = []
        raw_batch_buffer_context = []
        raw_batch_buffer_response = []
        context_sentences = sample[:]
        response_sentences = sample[self.num_context_turns:]
        raw_context_sentences = sample[sample_len // 2:]
        raw_response_sentences = sample[sample_len // 2 + self.num_context_turns:]
        batch_buffer_context += []
        batch_buffer_response += []
        lens = []
        for context in []:
            context_sentences_lens = []
            for sent in context:
                sent_len = len(sent[sent !=)
                sent_len =
                context_sentences_lens.append()
            lens.append()
        batch_buffer_context_len +=
        lens = []
        for response in []:
            sent_len = len(response[response !=)
            sent_len =
            lens.append()
        batch_buffer_response_len +=
        raw_batch_buffer_context += []
        raw_batch_buffer_response += []
        for i in range(len()):
            buf.append(tuple((batch_buffer_context[],batch_buffer_context_len[],batch_buffer_response[],batch_buffer_response_len[],raw_batch_buffer_context[],raw_batch_buffer_response[])))
        return len()
    def _make_batch(self, batch: List[Tuple[]]) -> Dict:
        input_context = []
        input_context_len = []
        input_response = []
        input_response_len = []
        input_raw_context = []
        input_raw_response = []
        for sample in batch:
            input_context.append(sample[])
            input_context_len.append(sample[])
            input_response.append(sample[])
            input_response_len.append(sample[])
            input_raw_context.append(sample[])
            input_raw_response.append(sample[])
        return {self.utterance_ph:,self.all_utterance_len_ph:,self.response_ph:,self.response_len_ph:,self.context_sent_ph:,self.response_sent_ph:}
import tensorflow as tf
import matplotlib.pyplot as plt
import numpy as np
from tensorflow.examples.tutorials.mnist import input_data
mnist = input_data.read_data_sets("", one_hot=)
total_epoch =
batch_size =
learning_rate =
n_hidden =
n_input =
n_noise =
X = tf.placeholder(tf.float32, [])
Z = tf.placeholder(tf.float32, [])
G_W1 = tf.Variable(tf.random_normal([], stddev=))
G_b1 = tf.Variable(tf.zeros([]))
G_W2 = tf.Variable(tf.random_normal([], stddev=))
G_b2 = tf.Variable(tf.zeros([]))
D_W1 = tf.Variable(tf.random_normal([], stddev=))
D_b1 = tf.Variable(tf.zeros([]))
D_W2 = tf.Variable(tf.random_normal([], stddev=))
D_b2 = tf.Variable(tf.zeros([]))
def generator():
    hidden = tf.nn.relu(tf.matmul() + G_b1)
    output = tf.nn.sigmoid(tf.matmul() + G_b2)
    return output
def discriminator():
    hidden = tf.nn.relu(tf.matmul() + D_b1)
    output = tf.nn.sigmoid(tf.matmul() + D_b2)
    return output
def get_noise():
    return np.random.normal(size=())
G = generator()
D_gene = discriminator()
D_real = discriminator()
loss_D = tf.reduce_mean(tf.log() + tf.log())
loss_G = tf.reduce_mean(tf.log())
D_var_list = []
G_var_list = []
train_D = tf.train.AdamOptimizer().minimize(-loss_D,var_list=)
train_G = tf.train.AdamOptimizer().minimize(-loss_G,var_list=)
sess = tf.Session()
sess.run(tf.global_variables_initializer())
total_batch = int()
loss_val_D, loss_val_G =, 0
for epoch in range():
    for i in range():
        batch_xs, batch_ys = mnist.train.next_batch()
        noise = get_noise()
        _, loss_val_D = sess.run([],feed_dict={X:, Z:})
        _, loss_val_G = sess.run([],feed_dict={Z:})
    if epoch == 0 or () % 10 == 0:
        sample_size =
        noise = get_noise()
        samples = sess.run(G, feed_dict={Z:})
        fig, ax = plt.subplots(1, sample_size, figsize=())
        for i in range():
            ax[].set_axis_off()
            ax[].imshow(np.reshape(samples[], ()))
        plt.savefig("".zfill()), bbox_inches=)
        plt.close()
import copy
from abc import ABC, abstractmethod
from logging import getLogger
from typing import Any, Callable, Dict, List, Optional, Tuple, Union
import numpy as np
import tensorflow as tf
from bert_dp.modeling import BertConfig, BertModel
from bert_dp.optimization import AdamWeightDecayOptimizer
from bert_dp.preprocessing import InputFeatures
from overrides import overrides
from deeppavlov.core.commands.utils import expand_path
from deeppavlov.core.common.errors import ConfigError
from deeppavlov.core.common.registry import register
from deeppavlov.core.layers.tf_layers import bi_rnn
from deeppavlov.core.models.tf_model import LRScheduledTFModel
from deeppavlov.models.bert.bert_sequence_tagger import token_from_subtoken
log = getLogger()
class MTBertTask():
    def __init__(self,keep_prob: float =,return_probas: bool =,learning_rate: float =,):
        self.keep_prob =
        self.return_probas =
        self.init_head_learning_rate =
        self.min_body_learning_rate =
        self.head_learning_rate_multiplier =
        self.bert =
        self.optimizer_params =
        self.shared_ph =
        self.shared_feed_dict =
        self.sess =
        self.get_train_op_func =
        self.freeze_embeddings =
        self.bert_head_variable_scope =
    def build(self,bert_body:,optimizer_params: Dict[str, Union[]],shared_placeholders: Dict[],sess:,mode:,get_train_op_func:,freeze_embeddings:,bert_head_variable_scope:) -> None:
        self.bert_head_variable_scope =
        self.get_train_op_func =
        self.freeze_embeddings =
        self.bert =
        self.optimizer_params =
        if mode == "":
            self.head_learning_rate_multiplier = self.init_head_learning_rate / self.optimizer_params[]
        else:
            self.head_learning_rate_multiplier =
        mblr = self.optimizer_params.get()
        self.min_body_learning_rate =
        self.shared_ph =
        self.sess =
        self._init_graph()
        if mode == "":
            self._init_optimizer()
    def _init_graph() -> None:
        pass
    def get_train_op(self, loss:, body_learning_rate: Union[], **kwargs) -> tf.Operation:
        kwargs[] = ()
        if self.freeze_embeddings:
            kwargs[] = ()
        learning_rate =
        bert_train_op = self.get_train_op_func()
        kwargs[] = ()
        head_train_op = self.get_train_op_func()
        return tf.group()
    def _init_optimizer() -> None:
        with tf.variable_scope():
            with tf.variable_scope():
                self.global_step = tf.get_variable("",shape=[],dtype=,initializer=tf.constant_initializer(),trainable=)
            if self.optimizer_params.get() is None:
                self.train_op = self.get_train_op(self.loss,body_learning_rate=self.shared_ph[],optimizer=,weight_decay_rate=self.optimizer_params.get(),beta_1=,beta_2=,epsilon=,optimizer_scope_name=,exclude_from_weight_decay=[])
            else:
                self.train_op = self.get_train_op(self.loss,body_learning_rate=self.shared_ph[],optimizer_scope_name=)
            if self.optimizer_params.get() is None:
                with tf.variable_scope():
                    new_global_step =
                    self.train_op = tf.group(self.train_op, [self.global_step.assign()])
    def _build_feed_dict(self, input_ids, input_masks, token_types, y=, body_learning_rate=):
        sph =
        train =
        feed_dict = {sph[]:,sph[]:,sph[]:,sph[]:,}
        if train:
            feed_dict.update({sph[]:,self.y_ph:,sph[]:,})
        return feed_dict
    def train_on_batch() -> Dict[]:
        fetches, feed_dict = self.get_sess_run_train_args()
        _, loss = self.sess.run(fetches, feed_dict=)
        return {f'{self.bert_head_variable_scope}_loss': loss,f'{self.bert_head_variable_scope}_head_learning_rate':float(kwargs['body_learning_rate']) * self.head_learning_rate_multiplier,'bert_body_learning_rate': kwargs['body_learning_rate']}
    def get_sess_run_infer_args() -> Tuple[List[], Dict[]]:
        pass
    def get_sess_run_train_args() -> Tuple[List[], Dict[]]:
        pass
    def post_process_preds(self, sess_run_res:) -> list:
        pass
class MTBertSequenceTaggingTask():
    def __init__(self,n_tags: int =,use_crf: bool =,use_birnn: bool =,birnn_cell_type: str =,birnn_hidden_size: int =,keep_prob: float =,encoder_dropout: float =,return_probas: bool =,encoder_layer_ids: List[] =,learning_rate: float =,):
        super().__init__()
        self.n_tags =
        self.use_crf =
        self.use_birnn =
        self.birnn_cell_type =
        self.birnn_hidden_size =
        self.encoder_dropout =
        self.encoder_layer_ids =
    def _init_placeholders() -> None:
        self.y_ph = tf.placeholder(shape=(), dtype=, name=)
        self.y_masks_ph = tf.placeholder(shape=(),dtype=,name=)
        self.encoder_keep_prob = tf.placeholder_with_default(1.0, shape=[], name=)
    def _init_graph() -> None:
        with tf.variable_scope():
            self._init_placeholders()
            self.seq_lengths = tf.reduce_sum(self.y_masks_ph, axis=)
            layer_weights = tf.get_variable("",shape=len(),initializer=tf.ones_initializer(),trainable=)
            layer_mask = tf.ones_like()
            layer_mask = tf.nn.dropout()
            layer_weights *=
            mask_sum = tf.maximum(tf.reduce_sum(), 1.0)
            layer_weights = tf.unstack()
            units = sum(w * l for w, l in zip(layer_weights, self.encoder_layers()))
            units = tf.nn.dropout(units, keep_prob=self.shared_ph[])
            if self.use_birnn:
                units, _ = bi_rnn(units,self.birnn_hidden_size,cell_type=,seq_lengths=,name=)
                units = tf.concat()
            logits = tf.layers.dense(units, units=, name=)
            self.logits = token_from_subtoken()
            if self.use_crf:
                transition_params = tf.get_variable("",shape=[],initializer=tf.zeros_initializer())
                log_likelihood, transition_params = tf.contrib.crf.crf_log_likelihood()
                loss_tensor =
                self._transition_params =
            self.y_predictions = tf.argmax()
            self.y_probas = tf.nn.softmax(self.logits, axis=)
            with tf.variable_scope():
                tag_mask = self._get_tag_mask()
                y_mask = tf.cast()
                if self.use_crf:
                    self.loss = tf.reduce_mean()
                else:
                    self.loss = tf.losses.sparse_softmax_cross_entropy(labels=,logits=,weights=)
    def _get_tag_mask() -> tf.Tensor:
        max_length = tf.reduce_max()
        one_hot_max_len = tf.one_hot()
        tag_mask = tf.cumsum(one_hot_max_len[:, ::], axis=)[:, ::]
        return tag_mask
    def encoder_layers():
        return [self.bert.all_encoder_layers[] for i in self.encoder_layer_ids]
    def _build_feed_dict(self, input_ids, input_masks, y_masks, y=, body_learning_rate=):
        token_types = np.zeros(np.array().shape)
        sph =
        train =
        feed_dict = super()._build_feed_dict()
        if train:
            feed_dict[] =
        feed_dict[] =
        return feed_dict
    def _decode_crf(self, feed_dict: Dict[]) -> List[]:
        logits, trans_params, mask, seq_lengths = self.sess.run([],feed_dict=)
        y_pred = []
        for logit, sequence_length in zip():
            logit = logit[:int()]
            viterbi_seq, viterbi_score = tf.contrib.crf.viterbi_decode()
            y_pred += []
        return y_pred
    def get_sess_run_infer_args(self,input_ids: Union[List[List[]], np.ndarray],input_masks: Union[List[List[]], np.ndarray],y_masks: Union[List[List[]], np.ndarray],) -> Tuple[List[], Dict[]]:
        feed_dict = self._build_feed_dict()
        if self.return_probas:
            fetches =
        else:
            if self.use_crf:
                fetches = []
            else:
                fetches = []
        return fetches, feed_dict
    def get_sess_run_train_args(self,input_ids: Union[List[List[]], np.ndarray],input_masks: Union[List[List[]], np.ndarray],y_masks: Union[List[List[]], np.ndarray],y: Union[List[List[]], np.ndarray],body_learning_rate:) -> Tuple[List[], Dict[]]:
        feed_dict = self._build_feed_dict(input_ids, input_masks, y_masks, y=, body_learning_rate=)
        fetches = []
        return fetches, feed_dict
    def post_process_preds(self, sess_run_res: List[]) -> Union[List[List[]], List[]]:
        if self.return_probas:
            pred =
        else:
            if self.use_crf:
                logits, trans_params, mask, seq_lengths =
                pred = []
                for logit, sequence_length in zip():
                    logit = logit[:int()]
                    viterbi_seq, viterbi_score = tf.contrib.crf.viterbi_decode()
                    pred += []
            else:
                pred, seq_lengths =
                pred = [p[:] for l, p in zip()]
        return pred
class MTBertClassificationTask():
    def __init__(self,n_classes: int =,return_probas: bool =,one_hot_labels: bool =,keep_prob: float =,multilabel: bool =,learning_rate: float =,optimizer: str =,):
        super().__init__()
        self.n_classes =
        self.one_hot_labels =
        self.multilabel =
        if self.multilabel and not self.one_hot_labels:
            raise RuntimeError()
        if self.multilabel and not self.return_probas:
            raise RuntimeError()
    def _init_placeholders():
        if not self.one_hot_labels:
            self.y_ph = tf.placeholder(shape=(), dtype=, name=)
        else:
            self.y_ph = tf.placeholder(shape=(), dtype=, name=)
    def _init_graph():
        with tf.variable_scope():
            self._init_placeholders()
            output_layer = self.bert.get_pooled_output()
            hidden_size = output_layer.shape[].value
            output_weights = tf.get_variable("", [],initializer=tf.truncated_normal_initializer(stddev=))
            output_bias = tf.get_variable("", [], initializer=tf.zeros_initializer())
            with tf.variable_scope():
                output_layer = tf.nn.dropout(output_layer, keep_prob=self.shared_ph[])
                logits = tf.matmul(output_layer, output_weights, transpose_b=)
                logits = tf.nn.bias_add()
                if self.one_hot_labels:
                    one_hot_labels =
                else:
                    one_hot_labels = tf.one_hot(self.y_ph, depth=, dtype=)
                self.y_predictions = tf.argmax(logits, axis=)
                if not self.multilabel:
                    log_probs = tf.nn.log_softmax(logits, axis=)
                    self.y_probas = tf.nn.softmax(logits, axis=)
                    per_example_loss = -tf.reduce_sum(one_hot_labels * log_probs, axis=)
                    self.loss = tf.reduce_mean()
                else:
                    self.y_probas = tf.nn.sigmoid()
                    self.loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=, logits=))
    def get_sess_run_train_args(self,features: List[],y: Union[List[], List[List[]]],body_learning_rate:) -> Tuple[List[], Dict[]]:
        input_ids = []
        input_masks = []
        input_type_ids = []
        feed_dict = self._build_feed_dict(input_ids, input_masks, input_type_ids, y=,body_learning_rate=)
        fetches = []
        return fetches, feed_dict
    def get_sess_run_infer_args(self,features: List[]) -> Tuple[List[], Dict[]]:
        input_ids = []
        input_masks = []
        input_type_ids = []
        feed_dict = self._build_feed_dict()
        fetches =
        return fetches, feed_dict
    def post_process_preds():
        return sess_run_res
class MultiTaskBert():
    def __init__(self,tasks: Dict[],bert_config_file:,pretrained_bert: str =,attention_probs_keep_prob: float =,hidden_keep_prob: float =,optimizer: str =,weight_decay_rate: float =,body_learning_rate: float =,min_body_learning_rate: float =,learning_rate_drop_patience: int =,learning_rate_drop_div: float =,load_before_drop: bool =,clip_norm: float =,freeze_embeddings: bool =,inference_task_names: Optional[Union[str, List[Union[List[], str]]]] =,in_distribution: Optional[Dict[str, Union[int, List[]]]] =,in_y_distribution: Optional[Dict[str, Union[int, List[]]]] =,**kwargs) -> None:
        super().__init__(learning_rate=,learning_rate_drop_div=,learning_rate_drop_patience=,load_before_drop=,clip_norm=,**kwargs)
        self.optimizer_params = {"optimizer":,"body_learning_rate":,"min_body_learning_rate":,"weight_decay_rate":}
        self.freeze_embeddings =
        self.tasks =
        if inference_task_names is not None and isinstance():
            inference_task_names = []
        self.inference_task_names =
        self.mode =
        self.shared_ph =
        self.bert_config = BertConfig.from_json_file(str(expand_path()))
        if attention_probs_keep_prob is not None:
            self.bert_config.attention_probs_dropout_prob =
        if hidden_keep_prob is not None:
            self.bert_config.hidden_dropout_prob =
        self.sess_config = tf.ConfigProto(allow_soft_placement=)
        self.sess_config.gpu_options.allow_growth =
        self.sess = tf.Session(config=)
        self._init_bert_body_graph()
        self.build_tasks()
        self.sess.run(tf.global_variables_initializer())
        if pretrained_bert is not None:
            pretrained_bert = str(expand_path())
            if tf.train.checkpoint_exists() and not (self.load_path and tf.train.checkpoint_exists(str(self.load_path.resolve()))) and self.mode == "":
                var_list = self._get_saveable_variables(exclude_scopes=() + tuple(self.tasks.keys()))
                saver = tf.train.Saver()
                saver.restore()
        if self.load_path is not None:
            self.load()
        self.in_distribution =
        self.in_y_distribution =
    def build_tasks():
        def get_train_op():
            return self.get_train_op()
        for task_name, task_obj in self.tasks.items():
            task_obj.build(bert_body=,optimizer_params=,shared_placeholders=,sess=,mode=,get_train_op_func=,freeze_embeddings=,bert_head_variable_scope=)
    def _init_shared_placeholders() -> None:
        self.shared_ph = {'input_ids':,,,'input_masks':,,,'learning_rate':,,,'keep_prob':,,,'is_train':,,}
        self.shared_ph[] = tf.placeholder_with_default(tf.zeros_like(self.shared_ph[], dtype=),shape=self.shared_ph[].shape,name=)
    def _init_bert_body_graph() -> None:
        self._init_shared_placeholders()
        sph =
        self.bert = BertModel(config=,is_training=sph[],input_ids=sph[],input_mask=sph[],token_type_ids=sph[],use_one_hot_embeddings=)
    def save(self, exclude_scopes=()) -> None:
        return super().save(exclude_scopes=)
    def load(self,exclude_scopes=(),**kwargs) -> None:
        return super().load(exclude_scopes=, **kwargs)
    def train_on_batch() -> Dict[str, Dict[]]:
        if args and kwargs:
            raise ValueError()
        n_in = sum([len() if isinstance() else inp for inp in self.in_distribution.values()])
        if args:
            args_in, args_in_y = args[:], args[n_in:]
            in_by_tasks = self._distribute_arguments_by_tasks(args_in, {}, list(self.tasks.keys()), "")
            in_y_by_tasks = self._distribute_arguments_by_tasks(args_in_y, {}, list(self.tasks.keys()), "")
        else:
            kwargs_in, kwargs_in_y = {}, {}
            for i, () in enumerate(kwargs.items()):
                if i < n_in:
                    kwargs_in[] =
                else:
                    kwargs_in_y[] =
            in_by_tasks = self._distribute_arguments_by_tasks({}, kwargs_in, list(self.tasks.keys()), "")
            in_y_by_tasks = self._distribute_arguments_by_tasks({}, kwargs_in_y, list(self.tasks.keys()), "")
        train_on_batch_results = {}
        for task_name, task in self.tasks.items():
            train_on_batch_results.update(task.train_on_batch(*in_by_tasks[],*in_y_by_tasks[],body_learning_rate=max(self.get_learning_rate(), self.optimizer_params[])))
        for k, v in train_on_batch_results.items():
            train_on_batch_results[] = float(f"{v:}")
        return train_on_batch_results
    def _unite_task_feed_dicts():
        d = copy.copy()
        for k, v in d2.items():
            if k in d:
                comp = v != d[]
                if isinstance():
                    comp = comp.any()
                if comp:
                    raise ValueError()
            else:
                d[] =
        return d
    def _distribute_arguments_by_tasks(self, args, kwargs, task_names, what_to_distribute, in_distribution=):
        if args and kwargs:
            raise ValueError()
        if what_to_distribute == "":
            if in_distribution is not None:
                distribution =
            else:
                distribution =
        elif what_to_distribute == "":
            if in_distribution is not None:
                raise ValueError()
            distribution =
        else:
            raise ValueError()
        if distribution is None:
            if len() != 1:
                raise ValueError()
            return {task_names[]:}
        if all([isinstance() for task_distr in distribution.values()]):
            ints =
        elif all([isinstance() for task_distr in distribution.values()]):
            ints =
        else:
            raise ConfigError()
        args_by_task = {}
        flattened = []
        for task_name in task_names:
            if isinstance():
                flattened.append()
            else:
                flattened.extend()
        task_names =
        if args and not ints:
            ints =
            distribution = {task_name:,}
        if ints:
            if kwargs:
                values = list(kwargs.values())
            else:
                values =
            n_distributed = sum([n_args for n_args in distribution.values()])
            if len() != n_distributed:
                raise ConfigError()
            values_taken =
            for task_name in task_names:
                args_by_task[] = {}
                n_args = distribution[]
                args_by_task[] = [values[] for i in range()]
                values_taken +=
        else:
            arg_names_used = []
            for task_name in task_names:
                in_distr = distribution[]
                args_by_task[] = {}
                args_by_task[] = [kwargs[] for arg_name in in_distr]
                arg_names_used +=
            set_used = set()
            set_all = set(kwargs.keys())
            if set_used != set_all:
                raise ConfigError()
        return args_by_task
    def __call__():
        if self.inference_task_names is None:
            task_names = list(self.tasks.keys())
        else:
            task_names =
        if not task_names:
            raise ValueError()
        if args and kwargs:
            raise ValueError()
        return self.call()
    def call(self,args: Tuple[],kwargs: Dict[],task_names: Optional[Union[List[], str]],in_distribution: Optional[Union[Dict[], Dict[str, List[]]]] =,):
        args_by_task = self._distribute_arguments_by_tasks()
        results = []
        task_count =
        for elem in task_names:
            if isinstance():
                task_count +=
                task = self.tasks[]
                fetches, feed_dict = task.get_sess_run_infer_args(*args_by_task[])
                sess_run_res = self.sess.run(fetches, feed_dict=)
                results.append(task.post_process_preds())
            else:
                fetches = []
                for task_name in elem:
                    task_count +=
                    feed_dict = {}
                    task_fetches, task_feed_dict = self.tasks[].get_sess_run_infer_args(*args_by_task[])
                    fetches.append()
                    feed_dict = self._unite_task_feed_dicts()
                sess_run_res = self.sess.run(fetches, feed_dict=)
                for task_name, srs in zip():
                    task_results = self.tasks[].post_process_preds()
                    results.append()
        if task_count == 1:
            results = results[]
        return results
class MTBertReUser:
    def __init__(self,mt_bert:,task_names: Union[str, List[Union[str, List[]]]],in_distribution: Union[Dict[], Dict[str, List[]]] =,*args,**kwargs):
        self.mt_bert =
        if isinstance():
            task_names = []
        elif not task_names:
            raise ValueError()
        self.task_names =
        flattened = []
        for elem in self.task_names:
            if isinstance():
                flattened.append()
            else:
                flattened.extend()
        if in_distribution is None:
            if len() > 1:
                raise ValueError()
        self.in_distribution =
    def __call__() -> List[]:
        res = self.mt_bert.call(args, kwargs, task_names=, in_distribution=)
        return res
class InputSplitter:
    def __init__(self, keys_to_extract: Union[List[], Tuple[]], **kwargs):
        self.keys_to_extract =
    def __call__(self, inp: Union[List[], List[List[]], List[Tuple[]]]) -> List[]:
        extracted = [[] for _ in self.keys_to_extract]
        for item in inp:
            for i, key in enumerate():
                extracted[].append(item[])
        return extracted
import json
from typing import Tuple, Optional
from logging import getLogger
import numpy as np
import tensorflow as tf
from deeppavlov.core.common.errors import ConfigError
from deeppavlov.core.layers import tf_attention_mechanisms as am, tf_layers
from tensorflow.contrib.layers import xavier_initializer as xav
from deeppavlov.core.models.tf_model import LRScheduledTFModel
from deeppavlov.models.go_bot.nlu.dto.nlu_response import NLUResponse
from deeppavlov.models.go_bot.nlu.tokens_vectorizer import TokensVectorRepresentationParams
from deeppavlov.models.go_bot.dto.dataset_features import BatchDialoguesFeatures, BatchDialoguesTargets
from deeppavlov.models.go_bot.dto.shared_gobot_params import SharedGoBotParams
from deeppavlov.models.go_bot.policy.dto.attn_params import GobotAttnParams
from deeppavlov.models.go_bot.policy.dto.digitized_policy_features import DigitizedPolicyFeatures
from deeppavlov.models.go_bot.policy.dto.policy_network_params import PolicyNetworkParams
from deeppavlov.models.go_bot.policy.dto.policy_prediction import PolicyPrediction
from deeppavlov.models.go_bot.tracker.dto.dst_knowledge import DSTKnowledge
log = getLogger()
class PolicyNetwork():
    GRAPH_PARAMS = []
    SERIALIZABLE_FIELDS = []
    def __init__(self, network_params_passed:,tokens_dims:,features_params:,load_path,save_path,debug=,**kwargs):
        self.debug =
        if self.debug:
        if network_params_passed.get_learning_rate():
            kwargs[] = network_params_passed.get_learning_rate()
        super().__init__(load_path=, save_path=, **kwargs)
        self.hidden_size = network_params_passed.get_hidden_size()
        self.action_size =
        self.dropout_rate = network_params_passed.get_dropout_rate()
        self.l2_reg_coef = network_params_passed.get_l2_reg_coef()
        self.dense_size = network_params_passed.get_dense_size()
        attn_params_passed = network_params_passed.get_attn_params()
        self.attention_params = self.configure_attn()
        self.input_size = self.calc_input_size()
        if self.debug:
        self._build_graph()
        if self.debug:
        self.sess = tf.Session()
        self.sess.run(tf.global_variables_initializer())
        if self.debug:
        if self.train_checkpoint_exists():
            self.load()
        else:
        if self.debug:
    def calc_input_size(tokens_dims:,shared_go_bot_params:,attention_params: Optional[]) -> int:
        input_size =
        if tokens_dims.bow_dim:
            input_size +=
        if tokens_dims.embedding_dim:
            input_size +=
        if shared_go_bot_params.num_intents:
            input_size +=
        if attention_params is not None:
            input_size -=
        return input_size
    def configure_attn(attn:,tokens_dims:,features_params:):
        if not attn:
            return None
        token_size =
        action_as_key = attn.get()
        intent_as_key = attn.get()
        key_size = PolicyNetwork.calc_attn_key_size()
        gobot_attn_params = GobotAttnParams(max_num_tokens=attn.get(),hidden_size=attn.get(),token_size=,key_size=,type_=attn.get(),projected_align=attn.get(),depth=attn.get(),action_as_key=,intent_as_key=)
        return gobot_attn_params
    def calc_attn_key_size(shared_go_bot_params:, action_as_key:, intent_as_key:) -> int:
        possible_key_size =
        if action_as_key:
            possible_key_size +=
        if intent_as_key and shared_go_bot_params.num_intents:
            possible_key_size +=
        possible_key_size =
        return possible_key_size
    def calc_attn_key(self, nlu_response:, tracker_knowledge:):
        attn_key = np.array([], dtype=)
        if self.attention_params:
            if self.attention_params.action_as_key:
                attn_key = np.hstack(())
            if self.attention_params.intent_as_key:
                attn_key = np.hstack(())
            if len() == 0:
                attn_key = np.array([], dtype=)
        return attn_key
    def stack_features(nlu_response:,tracker_knowledge:):
        return np.hstack(())
    def calc_action_mask(tracker_knowledge:):
        mask = np.ones(tracker_knowledge.n_actions, dtype=)
        if np.any():
            prev_act_id = np.argmax()
            if prev_act_id == tracker_knowledge.api_call_id:
                mask[] =
        return mask
    def digitize_features(self,nlu_response:,tracker_knowledge:) -> DigitizedPolicyFeatures:
        attn_key = self.calc_attn_key()
        concat_feats = self.stack_features()
        action_mask =
        return DigitizedPolicyFeatures()
    def _build_graph() -> None:
        self._add_placeholders()
        _logits, self._state = self._build_body()
        _logits_exp = tf.multiply(tf.exp(), self._action_mask)
        _logits_exp_sum = tf.expand_dims(tf.reduce_sum(), -1)
        self._probs = tf.squeeze(_logits_exp / _logits_exp_sum, name=)
        self._prediction = tf.argmax(self._probs, axis=, name=)
        onehots = tf.one_hot()
        _loss_tensor = tf.nn.softmax_cross_entropy_with_logits_v2(logits=, labels=)
        _loss_tensor = tf.multiply()
        self._loss = tf.reduce_mean(_loss_tensor, name=)
        self._loss += self.l2_reg_coef * tf.losses.get_regularization_loss()
        self._train_op = self.get_train_op()
    def _add_placeholders() -> None:
        self._dropout_keep_prob = tf.placeholder_with_default(1.0, shape=[], name=)
        self._features = tf.placeholder(tf.float32, [], name=)
        self._action = tf.placeholder(tf.int32, [], name=)
        self._action_mask = tf.placeholder(tf.float32, [], name=)
        self._utterance_mask = tf.placeholder(tf.float32, shape=[], name=)
        self._batch_size = tf.shape()[]
        zero_state = tf.zeros([], dtype=)
        _initial_state_c = tf.placeholder_with_default(zero_state, shape=[])
        _initial_state_h = tf.placeholder_with_default(zero_state, shape=[])
        self._initial_state = tf.nn.rnn_cell.LSTMStateTuple()
        if self.attention_params:
            _emb_context_shape = []
            self._emb_context = tf.placeholder(tf.float32, _emb_context_shape, name=)
            self._key = tf.placeholder(tf.float32, [], name=)
    def _build_body() -> Tuple[]:
        _units = tf.layers.dense(self._features, self.dense_size,kernel_regularizer=, kernel_initializer=xav())
        if self.attention_params:
            _attn_output = self._build_attn_body()
            _units = tf.concat([], -1)
        _units = tf_layers.variational_dropout(_units, keep_prob=)
        _lstm_cell = tf.nn.rnn_cell.LSTMCell()
        _utter_lengths = tf.cast(tf.reduce_sum(self._utterance_mask, axis=), tf.int32)
        _output, _state = tf.nn.dynamic_rnn(_lstm_cell, _units,time_major=, initial_state=,sequence_length=)
        _output = tf.reshape(_output, ())
        _output = tf_layers.variational_dropout(_output, keep_prob=)
        _logits = tf.layers.dense(_output, self.action_size,kernel_regularizer=, kernel_initializer=xav(), name=)
        return _logits, _state
    def _build_attn_body():
        attn_scope = 
        with tf.variable_scope():
            if self.attention_params.type_ == "":
                _attn_output = am.general_attention(self._key, self._emb_context,hidden_size=,projected_align=)
            elif self.attention_params.type_ == "":
                _attn_output = am.bahdanau_attention(self._key, self._emb_context,hidden_size=,projected_align=)
            elif self.attention_params.type_ == "":
                _attn_output = am.cs_general_attention(self._key, self._emb_context,hidden_size=,depth=,projected_align=)
            elif self.attention_params.type_ == "":
                _attn_output = am.cs_bahdanau_attention(self._key, self._emb_context,hidden_size=,depth=,projected_align=)
            elif self.attention_params.type_ == "":
                _attn_output = am.light_general_attention(self._key, self._emb_context,hidden_size=,projected_align=)
            elif self.attention_params.type_ == "":
                _attn_output = am.light_bahdanau_attention(self._key, self._emb_context,hidden_size=,projected_align=)
            else:
                raise ValueError()
        return _attn_output
    def train_checkpoint_exists():
        return tf.train.checkpoint_exists(str(self.load_path.resolve()))
    def get_attn_hyperparams() -> Optional[]:
        attn_hyperparams =
        if self.attention_params:
            attn_hyperparams =
        return attn_hyperparams
    def has_attn():
        return self.attention_params is not None
    def get_attn_window_size():
        return self.attention_params.max_num_tokens if self.has_attn() else None
    def __call__(self, batch_dialogues_features:,states_c:, states_h:, prob: bool =,*args, **kwargs) -> PolicyPrediction:
        states_c = [[]]
        states_h = [[]]
        feed_dict = {self._dropout_keep_prob:,self._initial_state:,self._utterance_mask:,self._features:,self._action_mask:}
        if self.attention_params:
            feed_dict[] =
            feed_dict[] =
        probs, prediction, state = self.sess.run([], feed_dict=)
        policy_prediction = PolicyPrediction(probs, prediction, state[], state[])
        return policy_prediction
    def train_on_batch(self,batch_dialogues_features:,batch_dialogues_targets:) -> dict:
        feed_dict = {self._dropout_keep_prob:,self._utterance_mask:,self._features:,self._action:,self._action_mask:}
        if self.attention_params:
            feed_dict[] =
            feed_dict[] =
        _, loss_value, prediction = self.sess.run([], feed_dict=)
        return {'loss':,'learning_rate':,'momentum':}
    def load() -> None:
        self._load_nn_params()
        super().load()
    def _load_nn_params() -> None:
        if self.debug:
        path = str(self.load_path.with_suffix().resolve())
        if self.debug:
        with open(path, "", encoding=) as fp:
            params = json.load()
        if self.debug:
        for p in self.GRAPH_PARAMS:
            if self.__getattribute__() != params.get() and p not in {}:
                raise ConfigError()
        if self.debug:
    def save() -> None:
        super().save()
        self._save_nn_params()
    def _save_nn_params() -> None:
        if self.debug:
        path = str(self.save_path.with_suffix().resolve())
        if self.debug:
        nn_params = {opt:}
        if self.debug:
        with open(path, "", encoding=) as fp:
            json.dump()
        if self.debug:
from logging import getLogger
from typing import Optional
import numpy as np
import tensorflow as tf
from deeppavlov.core.common.registry import register
from deeppavlov.models.ranking.tf_base_matching_model import TensorflowBaseMatchingModel
log = getLogger()
class SMNNetwork():
    def __init__(self,embedding_dim: int =,max_sequence_length: int =,learning_rate: float =,emb_matrix: Optional[] =,trainable_embeddings: bool =,*args,**kwargs):
        self.max_sentence_len =
        self.word_embedding_size =
        self.trainable =
        self.learning_rate =
        self.emb_matrix =
        super().__init__()
        self.sess_config = tf.ConfigProto(allow_soft_placement=)
        self.sess_config.gpu_options.allow_growth =
        self.sess = tf.Session(config=)
        self._init_graph()
        self.sess.run(tf.global_variables_initializer())
        if self.load_path is not None:
            self.load()
    def _init_placeholders():
        with tf.variable_scope():
            self.utterance_ph = tf.placeholder(tf.int32, shape=())
            self.all_utterance_len_ph = tf.placeholder(tf.int32, shape=())
            self.response_ph = tf.placeholder(tf.int32, shape=())
            self.response_len_ph = tf.placeholder(tf.int32, shape=())
            self.y_true = tf.placeholder(tf.int32, shape=())
    def _init_graph():
        self._init_placeholders()
        word_embeddings = tf.get_variable("",initializer=tf.constant(self.emb_matrix, dtype=),trainable=)
        all_utterance_embeddings = tf.nn.embedding_lookup()
        response_embeddings = tf.nn.embedding_lookup()
        sentence_GRU = tf.nn.rnn_cell.GRUCell(self.word_embedding_size, kernel_initializer=tf.orthogonal_initializer())
        all_utterance_embeddings = tf.unstack(all_utterance_embeddings, num=,axis=)
        all_utterance_len = tf.unstack(self.all_utterance_len_ph, num=, axis=)
        A_matrix = tf.get_variable("", shape=(),initializer=tf.contrib.layers.xavier_initializer(), dtype=)
        final_GRU = tf.nn.rnn_cell.GRUCell(self.word_embedding_size, kernel_initializer=tf.orthogonal_initializer())
        reuse =
        response_GRU_embeddings, _ = tf.nn.dynamic_rnn(sentence_GRU,response_embeddings,sequence_length=,dtype=,scope=)
        response_embeddings = tf.transpose(response_embeddings, perm=[])
        response_GRU_embeddings = tf.transpose(response_GRU_embeddings, perm=[])
        matching_vectors = []
        for utterance_embeddings, utterance_len in zip():
            matrix1 = tf.matmul()
            utterance_GRU_embeddings, _ = tf.nn.dynamic_rnn(sentence_GRU,utterance_embeddings,sequence_length=,dtype=,scope=)
            matrix2 = tf.einsum()
            matrix2 = tf.matmul()
            matrix = tf.stack([], axis=, name=)
            conv_layer = tf.layers.conv2d(matrix, filters=, kernel_size=(), padding=,kernel_initializer=tf.contrib.keras.initializers.he_normal(),activation=, reuse=, name=)
            pooling_layer = tf.layers.max_pooling2d(conv_layer, (), strides=(),padding=, name=)
            matching_vector = tf.layers.dense(tf.contrib.layers.flatten(), 50,kernel_initializer=tf.contrib.layers.xavier_initializer(),activation=, reuse=,name=)
            if not reuse:
                reuse =
            matching_vectors.append()
        _, last_hidden = tf.nn.dynamic_rnn(final_GRU,tf.stack(matching_vectors, axis=, name=),dtype=,time_major=,scope=)
        logits = tf.layers.dense(last_hidden, 2, kernel_initializer=tf.contrib.layers.xavier_initializer(),name=)
        self.y_pred = tf.nn.softmax()
        self.logits =
        self.loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(labels=, logits=))
        optimizer = tf.train.AdamOptimizer(learning_rate=)
        self.train_op = optimizer.minimize()
        self.print_number_of_parameters()
import shutil
from functools import reduce
from pathlib import Path
import numpy as np
import pytest
import tensorflow as tf
from deeppavlov.core.layers.tf_layers import cudnn_lstm, cudnn_compatible_lstm, cudnn_gru, cudnn_compatible_gru
tests_dir = Path().parent
tf_layers_data_path =
def setup_module():
    shutil.rmtree(str(), ignore_errors=)
    tf_layers_data_path.mkdir(parents=)
def teardown_module():
    shutil.rmtree(str(), ignore_errors=)
class DPCudnnLSTMModel:
    def __init__():
        sess_config = tf.ConfigProto(allow_soft_placement=)
        sess_config.gpu_options.allow_growth =
        self.sess = tf.Session(config=)
        self.x = tf.placeholder(shape=(), dtype=)
        with tf.variable_scope():
            h, () = cudnn_lstm(self.x, num_units, num_layers, trainable_initial_states=)
            self.h =
            self.h_last =
        self.sess.run(tf.global_variables_initializer())
    def __call__():
        feed_dict = {self.x:,}
        return self.sess.run([], feed_dict=)
    def save(self, path=):
        saver = tf.train.Saver()
        saver.save()
    def load():
        saver = tf.train.Saver()
        saver.restore()
class DPLSTMModel:
    def __init__():
        sess_config = tf.ConfigProto(allow_soft_placement=)
        sess_config.gpu_options.allow_growth =
        self.sess = tf.Session(config=)
        self.x = tf.placeholder(shape=(), dtype=)
        with tf.variable_scope():
            h, () = cudnn_compatible_lstm(self.x, num_units, num_layers, trainable_initial_states=)
            self.h =
            self.h_last =
        self.sess.run(tf.global_variables_initializer())
    def __call__():
        feed_dict = {self.x:,}
        return self.sess.run([], feed_dict=)
    def save(self, path=):
        saver = tf.train.Saver()
        saver.save()
    def load():
        saver = tf.train.Saver()
        saver.restore()
class DPCudnnGRUModel:
    def __init__():
        sess_config = tf.ConfigProto(allow_soft_placement=)
        sess_config.gpu_options.allow_growth =
        self.sess = tf.Session(config=)
        self.x = tf.placeholder(shape=(), dtype=)
        with tf.variable_scope():
            h, h_last = cudnn_gru(self.x, num_units, num_layers, trainable_initial_states=)
            self.h =
            self.h_last =
        self.sess.run(tf.global_variables_initializer())
    def __call__():
        feed_dict = {self.x:,}
        return self.sess.run([], feed_dict=)
    def save(self, path=):
        saver = tf.train.Saver()
        saver.save()
    def load():
        saver = tf.train.Saver()
        saver.restore()
class DPGRUModel:
    def __init__():
        sess_config = tf.ConfigProto(allow_soft_placement=)
        sess_config.gpu_options.allow_growth =
        self.sess = tf.Session(config=)
        self.x = tf.placeholder(shape=(), dtype=)
        with tf.variable_scope():
            h, h_last = cudnn_compatible_gru(self.x, num_units, num_layers, trainable_initial_states=)
            self.h =
            self.h_last =
        self.sess.run(tf.global_variables_initializer())
    def __call__():
        feed_dict = {self.x:,}
        return self.sess.run([], feed_dict=)
    def save(self, path=):
        saver = tf.train.Saver()
        saver.save()
    def load():
        saver = tf.train.Saver()
        saver.restore()
class TestTFLayers:
    allowed_error_lvl =
    def equal_values(a, b, round=):
        a, b = np.round(), np.round()
        return np.sum(a ==) / reduce(lambda x, y:, a.shape)
    def test_cudnn_lstm_save_load():
        x = np.random.normal(size=())
        tf.reset_default_graph()
        cdnnlstmmodel = DPCudnnLSTMModel(num_layers=, num_units=)
        before_load_hidden, before_load_state = cdnnlstmmodel()[], cdnnlstmmodel()[]
        cdnnlstmmodel.save(str())
        tf.reset_default_graph()
        cdnnlstmmodel = DPCudnnLSTMModel(num_layers=, num_units=)
        cdnnlstmmodel.load(str())
        after_load_hidden, after_load_state = cdnnlstmmodel()[], cdnnlstmmodel()[]
        equal_hidden = self.equal_values()
        equal_state = self.equal_values()
    def test_cudnn_lstm_save_and_cudnn_compatible_load():
        x = np.random.normal(size=())
        tf.reset_default_graph()
        cdnnlstmmodel = DPCudnnLSTMModel(num_layers=, num_units=)
        before_load_hidden, before_load_state = cdnnlstmmodel()[], cdnnlstmmodel()[]
        cdnnlstmmodel.save(str())
        tf.reset_default_graph()
        cdnnlstmmodel = DPLSTMModel(num_layers=, num_units=)
        cdnnlstmmodel.load(str())
        after_load_hidden, after_load_state = cdnnlstmmodel()[], cdnnlstmmodel()[]
        equal_hidden = self.equal_values()
        equal_state = self.equal_values()
    def test_cudnn_gru_save_load():
        x = np.random.normal(size=())
        tf.reset_default_graph()
        cdnngrumodel = DPCudnnGRUModel(num_layers=, num_units=)
        before_load_hidden, before_load_state = cdnngrumodel()[], cdnngrumodel()[]
        cdnngrumodel.save(str())
        tf.reset_default_graph()
        cdnngrumodel = DPCudnnGRUModel(num_layers=, num_units=)
        cdnngrumodel.load(str())
        after_load_hidden, after_load_state = cdnngrumodel()[], cdnngrumodel()[]
        equal_hidden = self.equal_values()
        equal_state = self.equal_values()
    def test_cudnn_gru_save_and_cudnn_compatible_load():
        x = np.random.normal(size=())
        tf.reset_default_graph()
        cdnngrumodel = DPCudnnGRUModel(num_layers=, num_units=)
        before_load_hidden, before_load_state = cdnngrumodel()[], cdnngrumodel()[]
        cdnngrumodel.save(str())
        tf.reset_default_graph()
        cdnngrumodel = DPGRUModel(num_layers=, num_units=)
        cdnngrumodel.load(str())
        after_load_hidden, after_load_state = cdnngrumodel()[], cdnngrumodel()[]
        equal_hidden = self.equal_values()
        equal_state = self.equal_values()
from collections import defaultdict
from logging import getLogger
from pathlib import Path
from typing import Iterable, Union, Tuple, Optional
import numpy as np
import tensorflow as tf
from overrides import overrides
from tensorflow.python.ops import variables
from deeppavlov.core.common.errors import ConfigError
from deeppavlov.core.common.registry import cls_from_str
from deeppavlov.core.models.lr_scheduled_model import LRScheduledModel
from deeppavlov.core.models.nn_model import NNModel
from deeppavlov.core.models.tf_backend import TfModelMeta
log = getLogger()
class TFModel(NNModel, metaclass=):
    sess:
    def __init__() -> None:
        super().__init__()
    def load(self, exclude_scopes: tuple = (), path: Union[] =) -> None:
        if not hasattr():
            raise RuntimeError("")
        path =
        path = str(Path().resolve())
        if tf.train.checkpoint_exists():
            var_list = self._get_saveable_variables()
            saver = tf.train.Saver()
            saver.restore()
    def deserialize(self, weights: Iterable[Tuple[]]) -> None:
        assign_ops = []
        feed_dict = {}
        for var_name, value in weights:
            var = self.sess.graph.get_tensor_by_name()
            value = np.asarray()
            assign_placeholder = tf.placeholder(var.dtype, shape=)
            assign_op = tf.assign()
            assign_ops.append()
            feed_dict[] =
        self.sess.run(assign_ops, feed_dict=)
    def save(self, exclude_scopes: tuple = ()) -> None:
        if not hasattr():
            raise RuntimeError("")
        path = str(self.save_path.resolve())
        var_list = self._get_saveable_variables()
        saver = tf.train.Saver()
        saver.save()
    def serialize() -> Tuple[Tuple[], ...]:
        tf_vars = tf.global_variables()
        values = self.sess.run()
        return tuple(zip([], values))
    def _get_saveable_variables(exclude_scopes=tuple()):
        all_vars = variables._all_saveable_objects()
        vars_to_train = [var for var in all_vars if all()]
        return vars_to_train
    def _get_trainable_variables(exclude_scopes=tuple()):
        all_vars = tf.global_variables()
        vars_to_train = [var for var in all_vars if all()]
        return vars_to_train
    def get_train_op(self,loss,learning_rate,optimizer=,clip_norm=,learnable_scopes=,optimizer_scope_name=,**kwargs):
        if optimizer_scope_name is None:
            opt_scope = tf.variable_scope()
        else:
            opt_scope = tf.variable_scope()
        with opt_scope:
            if learnable_scopes is None:
                variables_to_train = tf.get_collection()
            else:
                variables_to_train = []
                for scope_name in learnable_scopes:
                    variables_to_train.extend(tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=))
            if optimizer is None:
                optimizer =
            extra_update_ops = tf.get_collection()
            with tf.control_dependencies():
                def clip_if_not_none():
                    if grad is not None:
                        return tf.clip_by_norm()
                opt = optimizer()
                grads_and_vars = opt.compute_gradients(loss, var_list=)
                if clip_norm is not None:
                    grads_and_vars = [(clip_if_not_none(), var)for grad, var in grads_and_vars]
                train_op = opt.apply_gradients()
        return train_op
    def print_number_of_parameters():
        variables = tf.trainable_variables()
        blocks = defaultdict()
        for var in variables:
            block_name = var.name.split()[]
            number_of_parameters = np.prod(var.get_shape().as_list())
            blocks[] +=
        for block_name, cnt in blocks.items():
        total_num_parameters = np.sum(list(blocks.values()))
    def destroy():
        if hasattr():
            for k in list(self.sess.graph.get_all_collection_keys()):
                self.sess.graph.clear_collection()
        super().destroy()
class LRScheduledTFModel():
    def __init__(self,optimizer: str =,clip_norm: float =,momentum: float =,**kwargs) -> None:
        TFModel.__init__()
        try:
            self._optimizer = cls_from_str()
        except Exception:
            self._optimizer = getattr(tf.train, optimizer.split(':)[])
        if not issubclass():
            raise ConfigError()
        self._clip_norm =
        LRScheduledModel.__init__(self, momentum=, **kwargs)
    def _init_learning_rate_variable():
        return tf.Variable(self._lr or 0., dtype=, name=)
    def _init_momentum_variable():
        return tf.Variable(self._mom or 0., dtype=, name=)
    def _update_graph_variables(self, learning_rate=, momentum=):
        if learning_rate is not None:
            self.sess.run(tf.assign())
        if momentum is not None:
            self.sess.run(tf.assign())
    def get_train_op(self,loss,learning_rate: Union[] =,optimizer: tf.train.Optimizer =,momentum: Union[] =,clip_norm: float =,**kwargs):
        if learning_rate is not None:
            kwargs[] =
        else:
            kwargs[] =
        kwargs[] = optimizer or self.get_optimizer()
        kwargs[] =
        momentum_param =
        if kwargs[] == tf.train.AdamOptimizer:
            momentum_param =
        elif kwargs[] == tf.train.AdadeltaOptimizer:
            momentum_param =
        if momentum is not None:
            kwargs[] =
        elif self.get_momentum() is not None:
            kwargs[] =
        return TFModel.get_train_op()
    def get_optimizer():
        return self._optimizer
    def load(self,exclude_scopes: Optional[] = (),**kwargs):
        return super().load(exclude_scopes=, **kwargs)
    def process_event():
        LRScheduledModel.process_event()
from __future__ import division
import os, scipy.io
import tensorflow as tf
import tensorflow.contrib.slim as slim
import numpy as np
import rawpy
import glob
input_dir =
gt_dir =
checkpoint_dir =
result_dir =
test_fns = glob.glob()
test_ids = [int(os.path.basename()[0:]) for test_fn in test_fns]
def lrelu():
    return tf.maximum()
def upsample_and_concat():
    pool_size =
    deconv_filter = tf.Variable(tf.truncated_normal([], stddev=))
    deconv = tf.nn.conv2d_transpose(x1, deconv_filter, tf.shape(), strides=[])
    deconv_output = tf.concat([], 3)
    deconv_output.set_shape([])
    return deconv_output
def network():
    conv1 = slim.conv2d(input, 32, [], rate=, activation_fn=, scope=)
    conv1 = slim.conv2d(conv1, 32, [], rate=, activation_fn=, scope=)
    pool1 = slim.max_pool2d(conv1, [], padding=)
    conv2 = slim.conv2d(pool1, 64, [], rate=, activation_fn=, scope=)
    conv2 = slim.conv2d(conv2, 64, [], rate=, activation_fn=, scope=)
    pool2 = slim.max_pool2d(conv2, [], padding=)
    conv3 = slim.conv2d(pool2, 128, [], rate=, activation_fn=, scope=)
    conv3 = slim.conv2d(conv3, 128, [], rate=, activation_fn=, scope=)
    pool3 = slim.max_pool2d(conv3, [], padding=)
    conv4 = slim.conv2d(pool3, 256, [], rate=, activation_fn=, scope=)
    conv4 = slim.conv2d(conv4, 256, [], rate=, activation_fn=, scope=)
    pool4 = slim.max_pool2d(conv4, [], padding=)
    conv5 = slim.conv2d(pool4, 512, [], rate=, activation_fn=, scope=)
    conv5 = slim.conv2d(conv5, 512, [], rate=, activation_fn=, scope=)
    up6 = upsample_and_concat()
    conv6 = slim.conv2d(up6, 256, [], rate=, activation_fn=, scope=)
    conv6 = slim.conv2d(conv6, 256, [], rate=, activation_fn=, scope=)
    up7 = upsample_and_concat()
    conv7 = slim.conv2d(up7, 128, [], rate=, activation_fn=, scope=)
    conv7 = slim.conv2d(conv7, 128, [], rate=, activation_fn=, scope=)
    up8 = upsample_and_concat()
    conv8 = slim.conv2d(up8, 64, [], rate=, activation_fn=, scope=)
    conv8 = slim.conv2d(conv8, 64, [], rate=, activation_fn=, scope=)
    up9 = upsample_and_concat()
    conv9 = slim.conv2d(up9, 32, [], rate=, activation_fn=, scope=)
    conv9 = slim.conv2d(conv9, 32, [], rate=, activation_fn=, scope=)
    conv10 = slim.conv2d(conv9, 27, [], rate=, activation_fn=, scope=)
    out = tf.depth_to_space()
    return out
def pack_raw():
    im = raw.raw_image_visible.astype()
    im = np.maximum() / ()
    img_shape =
    H = (img_shape[] // 6) * 6
    W = (img_shape[] // 6) * 6
    out = np.zeros(())
    out[0::, 0::, 0] = im[0:H:, 0:W:]
    out[0::, 1::, 0] = im[0:H:, 4:W:]
    out[1::, 0::, 0] = im[3:H:, 1:W:]
    out[1::, 1::, 0] = im[3:H:, 3:W:]
    out[0::, 0::, 1] = im[0:H:, 2:W:]
    out[0::, 1::, 1] = im[0:H:, 5:W:]
    out[1::, 0::, 1] = im[3:H:, 2:W:]
    out[1::, 1::, 1] = im[3:H:, 5:W:]
    out[0::, 0::, 2] = im[0:H:, 1:W:]
    out[0::, 1::, 2] = im[0:H:, 3:W:]
    out[1::, 0::, 2] = im[3:H:, 0:W:]
    out[1::, 1::, 2] = im[3:H:, 4:W:]
    out[0::, 0::, 3] = im[1:H:, 2:W:]
    out[0::, 1::, 3] = im[2:H:, 5:W:]
    out[1::, 0::, 3] = im[5:H:, 2:W:]
    out[1::, 1::, 3] = im[4:H:, 5:W:]
    out[0::, 0::, 4] = im[2:H:, 2:W:]
    out[0::, 1::, 4] = im[1:H:, 5:W:]
    out[1::, 0::, 4] = im[4:H:, 2:W:]
    out[1::, 1::, 4] = im[5:H:, 5:W:]
    out[:, :, 5] = im[1:H:, 0:W:]
    out[:, :, 6] = im[1:H:, 1:W:]
    out[:, :, 7] = im[2:H:, 0:W:]
    out[:, :, 8] = im[2:H:, 1:W:]
    return out
sess = tf.Session()
in_image = tf.placeholder(tf.float32, [])
gt_image = tf.placeholder(tf.float32, [])
out_image = network()
saver = tf.train.Saver()
sess.run(tf.global_variables_initializer())
ckpt = tf.train.get_checkpoint_state()
if ckpt:
    saver.restore()
if not os.path.isdir():
    os.makedirs()
for test_id in test_ids:
    in_files = glob.glob()
    for k in range(len()):
        in_path = in_files[]
        in_fn = os.path.basename()
        gt_files = glob.glob()
        gt_path = gt_files[]
        gt_fn = os.path.basename()
        in_exposure = float(in_fn[9:])
        gt_exposure = float(gt_fn[9:])
        ratio = min()
        raw = rawpy.imread()
        input_full = np.expand_dims(pack_raw(), axis=) * ratio
        im = raw.postprocess(use_camera_wb=, half_size=, no_auto_bright=, output_bps=)
        scale_full = np.expand_dims(np.float32(), axis=)
        gt_raw = rawpy.imread()
        im = gt_raw.postprocess(use_camera_wb=, half_size=, no_auto_bright=, output_bps=)
        gt_full = np.expand_dims(np.float32(), axis=)
        input_full = np.minimum()
        output = sess.run(out_image, feed_dict={in_image:})
        output = np.minimum(np.maximum(), 1)
        _, H, W, _ =
        output = output[0, :, :, :]
        gt_full = gt_full[0, 0:, 0:, :]
        scale_full = scale_full[0, 0:, 0:, :]
        scale_full = scale_full * np.mean() / np.mean()
        scipy.misc.toimage(output * 255, high=, low=, cmin=, cmax=).save(result_dir + "")
        scipy.misc.toimage(scale_full * 255, high=, low=, cmin=, cmax=).save(result_dir + "")
        scipy.misc.toimage(gt_full * 255, high=, low=, cmin=, cmax=).save(result_dir + "")
from __future__ import division
import os, scipy.io
import tensorflow as tf
import tensorflow.contrib.slim as slim
import numpy as np
import rawpy
import glob
input_dir =
gt_dir =
checkpoint_dir =
result_dir =
test_fns = glob.glob()
test_ids = [int(os.path.basename()[0:]) for test_fn in test_fns]
DEBUG =
if DEBUG == 1:
    save_freq =
    test_ids = test_ids[0:]
def lrelu():
    return tf.maximum()
def upsample_and_concat():
    pool_size =
    deconv_filter = tf.Variable(tf.truncated_normal([], stddev=))
    deconv = tf.nn.conv2d_transpose(x1, deconv_filter, tf.shape(), strides=[])
    deconv_output = tf.concat([], 3)
    deconv_output.set_shape([])
    return deconv_output
def network():
    conv1 = slim.conv2d(input, 32, [], rate=, activation_fn=, scope=)
    conv1 = slim.conv2d(conv1, 32, [], rate=, activation_fn=, scope=)
    pool1 = slim.max_pool2d(conv1, [], padding=)
    conv2 = slim.conv2d(pool1, 64, [], rate=, activation_fn=, scope=)
    conv2 = slim.conv2d(conv2, 64, [], rate=, activation_fn=, scope=)
    pool2 = slim.max_pool2d(conv2, [], padding=)
    conv3 = slim.conv2d(pool2, 128, [], rate=, activation_fn=, scope=)
    conv3 = slim.conv2d(conv3, 128, [], rate=, activation_fn=, scope=)
    pool3 = slim.max_pool2d(conv3, [], padding=)
    conv4 = slim.conv2d(pool3, 256, [], rate=, activation_fn=, scope=)
    conv4 = slim.conv2d(conv4, 256, [], rate=, activation_fn=, scope=)
    pool4 = slim.max_pool2d(conv4, [], padding=)
    conv5 = slim.conv2d(pool4, 512, [], rate=, activation_fn=, scope=)
    conv5 = slim.conv2d(conv5, 512, [], rate=, activation_fn=, scope=)
    up6 = upsample_and_concat()
    conv6 = slim.conv2d(up6, 256, [], rate=, activation_fn=, scope=)
    conv6 = slim.conv2d(conv6, 256, [], rate=, activation_fn=, scope=)
    up7 = upsample_and_concat()
    conv7 = slim.conv2d(up7, 128, [], rate=, activation_fn=, scope=)
    conv7 = slim.conv2d(conv7, 128, [], rate=, activation_fn=, scope=)
    up8 = upsample_and_concat()
    conv8 = slim.conv2d(up8, 64, [], rate=, activation_fn=, scope=)
    conv8 = slim.conv2d(conv8, 64, [], rate=, activation_fn=, scope=)
    up9 = upsample_and_concat()
    conv9 = slim.conv2d(up9, 32, [], rate=, activation_fn=, scope=)
    conv9 = slim.conv2d(conv9, 32, [], rate=, activation_fn=, scope=)
    conv10 = slim.conv2d(conv9, 12, [], rate=, activation_fn=, scope=)
    out = tf.depth_to_space()
    return out
def pack_raw():
    im = raw.raw_image_visible.astype()
    im = np.maximum() / ()
    im = np.expand_dims(im, axis=)
    img_shape =
    H = img_shape[]
    W = img_shape[]
    out = np.concatenate((im[0:H:, 0:W:, :],im[0:H:, 1:W:, :],im[1:H:, 1:W:, :],im[1:H:, 0:W:, :]), axis=)
    return out
sess = tf.Session()
in_image = tf.placeholder(tf.float32, [])
gt_image = tf.placeholder(tf.float32, [])
out_image = network()
saver = tf.train.Saver()
sess.run(tf.global_variables_initializer())
ckpt = tf.train.get_checkpoint_state()
if ckpt:
    saver.restore()
if not os.path.isdir():
    os.makedirs()
for test_id in test_ids:
    in_files = glob.glob()
    for k in range(len()):
        in_path = in_files[]
        in_fn = os.path.basename()
        gt_files = glob.glob()
        gt_path = gt_files[]
        gt_fn = os.path.basename()
        in_exposure = float(in_fn[9:])
        gt_exposure = float(gt_fn[9:])
        ratio = min()
        raw = rawpy.imread()
        input_full = np.expand_dims(pack_raw(), axis=) * ratio
        im = raw.postprocess(use_camera_wb=, half_size=, no_auto_bright=, output_bps=)
        scale_full = np.expand_dims(np.float32(), axis=)
        gt_raw = rawpy.imread()
        im = gt_raw.postprocess(use_camera_wb=, half_size=, no_auto_bright=, output_bps=)
        gt_full = np.expand_dims(np.float32(), axis=)
        input_full = np.minimum()
        output = sess.run(out_image, feed_dict={in_image:})
        output = np.minimum(np.maximum(), 1)
        output = output[0, :, :, :]
        gt_full = gt_full[0, :, :, :]
        scale_full = scale_full[0, :, :, :]
        scale_full = scale_full * np.mean() / np.mean()
        scipy.misc.toimage(output * 255, high=, low=, cmin=, cmax=).save(result_dir + "")
        scipy.misc.toimage(scale_full * 255, high=, low=, cmin=, cmax=).save(result_dir + "")
        scipy.misc.toimage(gt_full * 255, high=, low=, cmin=, cmax=).save(result_dir + "")
from __future__ import division
import os, time, scipy.io
import tensorflow as tf
import tensorflow.contrib.slim as slim
import numpy as np
import rawpy
import glob
input_dir =
gt_dir =
checkpoint_dir =
result_dir =
train_fns = glob.glob()
train_ids = [int(os.path.basename()[0:]) for train_fn in train_fns]
ps =
save_freq =
def lrelu():
    return tf.maximum()
def upsample_and_concat():
    pool_size =
    deconv_filter = tf.Variable(tf.truncated_normal([], stddev=))
    deconv = tf.nn.conv2d_transpose(x1, deconv_filter, tf.shape(), strides=[])
    deconv_output = tf.concat([], 3)
    deconv_output.set_shape([])
    return deconv_output
def network():
    conv1 = slim.conv2d(input, 32, [], rate=, activation_fn=, scope=)
    conv1 = slim.conv2d(conv1, 32, [], rate=, activation_fn=, scope=)
    pool1 = slim.max_pool2d(conv1, [], padding=)
    conv2 = slim.conv2d(pool1, 64, [], rate=, activation_fn=, scope=)
    conv2 = slim.conv2d(conv2, 64, [], rate=, activation_fn=, scope=)
    pool2 = slim.max_pool2d(conv2, [], padding=)
    conv3 = slim.conv2d(pool2, 128, [], rate=, activation_fn=, scope=)
    conv3 = slim.conv2d(conv3, 128, [], rate=, activation_fn=, scope=)
    pool3 = slim.max_pool2d(conv3, [], padding=)
    conv4 = slim.conv2d(pool3, 256, [], rate=, activation_fn=, scope=)
    conv4 = slim.conv2d(conv4, 256, [], rate=, activation_fn=, scope=)
    pool4 = slim.max_pool2d(conv4, [], padding=)
    conv5 = slim.conv2d(pool4, 512, [], rate=, activation_fn=, scope=)
    conv5 = slim.conv2d(conv5, 512, [], rate=, activation_fn=, scope=)
    up6 = upsample_and_concat()
    conv6 = slim.conv2d(up6, 256, [], rate=, activation_fn=, scope=)
    conv6 = slim.conv2d(conv6, 256, [], rate=, activation_fn=, scope=)
    up7 = upsample_and_concat()
    conv7 = slim.conv2d(up7, 128, [], rate=, activation_fn=, scope=)
    conv7 = slim.conv2d(conv7, 128, [], rate=, activation_fn=, scope=)
    up8 = upsample_and_concat()
    conv8 = slim.conv2d(up8, 64, [], rate=, activation_fn=, scope=)
    conv8 = slim.conv2d(conv8, 64, [], rate=, activation_fn=, scope=)
    up9 = upsample_and_concat()
    conv9 = slim.conv2d(up9, 32, [], rate=, activation_fn=, scope=)
    conv9 = slim.conv2d(conv9, 32, [], rate=, activation_fn=, scope=)
    conv10 = slim.conv2d(conv9, 27, [], rate=, activation_fn=, scope=)
    out = tf.depth_to_space()
    return out
def pack_raw():
    im = raw.raw_image_visible.astype()
    im = np.maximum() / ()
    img_shape =
    H = (img_shape[] // 6) * 6
    W = (img_shape[] // 6) * 6
    out = np.zeros(())
    out[0::, 0::, 0] = im[0:H:, 0:W:]
    out[0::, 1::, 0] = im[0:H:, 4:W:]
    out[1::, 0::, 0] = im[3:H:, 1:W:]
    out[1::, 1::, 0] = im[3:H:, 3:W:]
    out[0::, 0::, 1] = im[0:H:, 2:W:]
    out[0::, 1::, 1] = im[0:H:, 5:W:]
    out[1::, 0::, 1] = im[3:H:, 2:W:]
    out[1::, 1::, 1] = im[3:H:, 5:W:]
    out[0::, 0::, 2] = im[0:H:, 1:W:]
    out[0::, 1::, 2] = im[0:H:, 3:W:]
    out[1::, 0::, 2] = im[3:H:, 0:W:]
    out[1::, 1::, 2] = im[3:H:, 4:W:]
    out[0::, 0::, 3] = im[1:H:, 2:W:]
    out[0::, 1::, 3] = im[2:H:, 5:W:]
    out[1::, 0::, 3] = im[5:H:, 2:W:]
    out[1::, 1::, 3] = im[4:H:, 5:W:]
    out[0::, 0::, 4] = im[2:H:, 2:W:]
    out[0::, 1::, 4] = im[1:H:, 5:W:]
    out[1::, 0::, 4] = im[4:H:, 2:W:]
    out[1::, 1::, 4] = im[5:H:, 5:W:]
    out[:, :, 5] = im[1:H:, 0:W:]
    out[:, :, 6] = im[1:H:, 1:W:]
    out[:, :, 7] = im[2:H:, 0:W:]
    out[:, :, 8] = im[2:H:, 1:W:]
    return out
sess = tf.Session()
in_image = tf.placeholder(tf.float32, [])
gt_image = tf.placeholder(tf.float32, [])
out_image = network()
G_loss = tf.reduce_mean(tf.abs())
t_vars = tf.trainable_variables()
lr = tf.placeholder()
G_opt = tf.train.AdamOptimizer(learning_rate=).minimize()
saver = tf.train.Saver()
sess.run(tf.global_variables_initializer())
ckpt = tf.train.get_checkpoint_state()
if ckpt:
    saver.restore()
gt_images = [] * 6000
in_images = {}
in_images[] = [] * len()
in_images[] = [] * len()
in_images[] = [] * len()
g_loss = np.zeros(())
allfolders = glob.glob()
lastepoch =
for folder in allfolders:
    lastepoch = np.maximum(lastepoch, int(folder[-4:]))
learning_rate =
for epoch in range():
    if os.path.isdir():
        continue
    cnt =
    if epoch > 2000:
        learning_rate =
    for ind in np.random.permutation(len()):
        train_id = train_ids[]
        in_files = glob.glob()
        in_path = in_files[np.random.random_integers(0, len() - 1)]
        in_fn = os.path.basename()
        gt_files = glob.glob()
        gt_path = gt_files[]
        gt_fn = os.path.basename()
        in_exposure = float(in_fn[9:])
        gt_exposure = float(gt_fn[9:])
        ratio = min()
        st = time.time()
        cnt +=
        if in_images[str()[0:]][] is None:
            raw = rawpy.imread()
            in_images[str()[0:]][] = np.expand_dims(pack_raw(), axis=) * ratio
            gt_raw = rawpy.imread()
            im = gt_raw.postprocess(use_camera_wb=, half_size=, no_auto_bright=, output_bps=)
            gt_images[] = np.expand_dims(np.float32(), axis=)
        H = in_images[str()[0:]][].shape[]
        W = in_images[str()[0:]][].shape[]
        xx = np.random.randint()
        yy = np.random.randint()
        input_patch = in_images[str()[0:]][][:, yy:, xx:, :]
        gt_patch = gt_images[][:, yy * 3:, xx * 3:, :]
        if np.random.randint(2, size=)[] == 1:
            input_patch = np.flip(input_patch, axis=)
            gt_patch = np.flip(gt_patch, axis=)
        if np.random.randint(2, size=)[] == 1:
            input_patch = np.flip(input_patch, axis=)
            gt_patch = np.flip(gt_patch, axis=)
        if np.random.randint(2, size=)[] == 1:
            input_patch = np.transpose(input_patch, ())
            gt_patch = np.transpose(gt_patch, ())
        input_patch = np.minimum()
        _, G_current, output = sess.run([],feed_dict={in_image:, gt_image:, lr:})
        output = np.minimum(np.maximum(), 1)
        g_loss[] =
        if epoch % save_freq == 0:
            if not os.path.isdir():
                os.makedirs()
            temp = np.concatenate((gt_patch[0, :, :, :], output[0, :, :, :]), axis=)
            scipy.misc.toimage(temp * 255, high=, low=, cmin=, cmax=).save(result_dir + "")
    saver.save()
from __future__ import division
import os, time, scipy.io
import tensorflow as tf
import tensorflow.contrib.slim as slim
import numpy as np
import rawpy
import glob
input_dir =
gt_dir =
checkpoint_dir =
result_dir =
train_fns = glob.glob()
train_ids = [int(os.path.basename()[0:]) for train_fn in train_fns]
ps =
save_freq =
DEBUG =
if DEBUG == 1:
    save_freq =
    train_ids = train_ids[0:]
def lrelu():
    return tf.maximum()
def upsample_and_concat():
    pool_size =
    deconv_filter = tf.Variable(tf.truncated_normal([], stddev=))
    deconv = tf.nn.conv2d_transpose(x1, deconv_filter, tf.shape(), strides=[])
    deconv_output = tf.concat([], 3)
    deconv_output.set_shape([])
    return deconv_output
def network():
    conv1 = slim.conv2d(input, 32, [], rate=, activation_fn=, scope=)
    conv1 = slim.conv2d(conv1, 32, [], rate=, activation_fn=, scope=)
    pool1 = slim.max_pool2d(conv1, [], padding=)
    conv2 = slim.conv2d(pool1, 64, [], rate=, activation_fn=, scope=)
    conv2 = slim.conv2d(conv2, 64, [], rate=, activation_fn=, scope=)
    pool2 = slim.max_pool2d(conv2, [], padding=)
    conv3 = slim.conv2d(pool2, 128, [], rate=, activation_fn=, scope=)
    conv3 = slim.conv2d(conv3, 128, [], rate=, activation_fn=, scope=)
    pool3 = slim.max_pool2d(conv3, [], padding=)
    conv4 = slim.conv2d(pool3, 256, [], rate=, activation_fn=, scope=)
    conv4 = slim.conv2d(conv4, 256, [], rate=, activation_fn=, scope=)
    pool4 = slim.max_pool2d(conv4, [], padding=)
    conv5 = slim.conv2d(pool4, 512, [], rate=, activation_fn=, scope=)
    conv5 = slim.conv2d(conv5, 512, [], rate=, activation_fn=, scope=)
    up6 = upsample_and_concat()
    conv6 = slim.conv2d(up6, 256, [], rate=, activation_fn=, scope=)
    conv6 = slim.conv2d(conv6, 256, [], rate=, activation_fn=, scope=)
    up7 = upsample_and_concat()
    conv7 = slim.conv2d(up7, 128, [], rate=, activation_fn=, scope=)
    conv7 = slim.conv2d(conv7, 128, [], rate=, activation_fn=, scope=)
    up8 = upsample_and_concat()
    conv8 = slim.conv2d(up8, 64, [], rate=, activation_fn=, scope=)
    conv8 = slim.conv2d(conv8, 64, [], rate=, activation_fn=, scope=)
    up9 = upsample_and_concat()
    conv9 = slim.conv2d(up9, 32, [], rate=, activation_fn=, scope=)
    conv9 = slim.conv2d(conv9, 32, [], rate=, activation_fn=, scope=)
    conv10 = slim.conv2d(conv9, 12, [], rate=, activation_fn=, scope=)
    out = tf.depth_to_space()
    return out
def pack_raw():
    im = raw.raw_image_visible.astype()
    im = np.maximum() / ()
    im = np.expand_dims(im, axis=)
    img_shape =
    H = img_shape[]
    W = img_shape[]
    out = np.concatenate((im[0:H:, 0:W:, :],im[0:H:, 1:W:, :],im[1:H:, 1:W:, :],im[1:H:, 0:W:, :]), axis=)
    return out
sess = tf.Session()
in_image = tf.placeholder(tf.float32, [])
gt_image = tf.placeholder(tf.float32, [])
out_image = network()
G_loss = tf.reduce_mean(tf.abs())
t_vars = tf.trainable_variables()
lr = tf.placeholder()
G_opt = tf.train.AdamOptimizer(learning_rate=).minimize()
saver = tf.train.Saver()
sess.run(tf.global_variables_initializer())
ckpt = tf.train.get_checkpoint_state()
if ckpt:
    saver.restore()
gt_images = [] * 6000
input_images = {}
input_images[] = [] * len()
input_images[] = [] * len()
input_images[] = [] * len()
g_loss = np.zeros(())
allfolders = glob.glob()
lastepoch =
for folder in allfolders:
    lastepoch = np.maximum(lastepoch, int(folder[-4:]))
learning_rate =
for epoch in range():
    if os.path.isdir():
        continue
    cnt =
    if epoch > 2000:
        learning_rate =
    for ind in np.random.permutation(len()):
        train_id = train_ids[]
        in_files = glob.glob()
        in_path = in_files[np.random.random_integers(0, len() - 1)]
        in_fn = os.path.basename()
        gt_files = glob.glob()
        gt_path = gt_files[]
        gt_fn = os.path.basename()
        in_exposure = float(in_fn[9:])
        gt_exposure = float(gt_fn[9:])
        ratio = min()
        st = time.time()
        cnt +=
        if input_images[str()[0:]][] is None:
            raw = rawpy.imread()
            input_images[str()[0:]][] = np.expand_dims(pack_raw(), axis=) * ratio
            gt_raw = rawpy.imread()
            im = gt_raw.postprocess(use_camera_wb=, half_size=, no_auto_bright=, output_bps=)
            gt_images[] = np.expand_dims(np.float32(), axis=)
        H = input_images[str()[0:]][].shape[]
        W = input_images[str()[0:]][].shape[]
        xx = np.random.randint()
        yy = np.random.randint()
        input_patch = input_images[str()[0:]][][:, yy:, xx:, :]
        gt_patch = gt_images[][:, yy * 2:, xx * 2:, :]
        if np.random.randint(2, size=)[] == 1:
            input_patch = np.flip(input_patch, axis=)
            gt_patch = np.flip(gt_patch, axis=)
        if np.random.randint(2, size=)[] == 1:
            input_patch = np.flip(input_patch, axis=)
            gt_patch = np.flip(gt_patch, axis=)
        if np.random.randint(2, size=)[] == 1:
            input_patch = np.transpose(input_patch, ())
            gt_patch = np.transpose(gt_patch, ())
        input_patch = np.minimum()
        _, G_current, output = sess.run([],feed_dict={in_image:, gt_image:, lr:})
        output = np.minimum(np.maximum(), 1)
        g_loss[] =
        if epoch % save_freq == 0:
            if not os.path.isdir():
                os.makedirs()
            temp = np.concatenate((gt_patch[0, :, :, :], output[0, :, :, :]), axis=)
            scipy.misc.toimage(temp * 255, high=, low=, cmin=, cmax=).save(result_dir + "")
    saver.save()
from __future__ import division, print_function, absolute_import
import tensorflow.contrib.layers as lays
import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt
from skimage import transform
from tensorflow.examples.tutorials.mnist import input_data
batch_size =
epoch_num =
lr =
def resize_batch():
    imgs = imgs.reshape(())
    resized_imgs = np.zeros((imgs.shape[], 32, 32, 1))
    for i in range(imgs.shape[]):
        resized_imgs[] = transform.resize(imgs[], ())
    return resized_imgs
def autoencoder():
    net = lays.conv2d(inputs, 32, [], stride=, padding=)
    net = lays.conv2d(net, 16, [], stride=, padding=)
    net = lays.conv2d(net, 8, [], stride=, padding=)
    net = lays.conv2d_transpose(net, 16, [], stride=, padding=)
    net = lays.conv2d_transpose(net, 32, [], stride=, padding=)
    net = lays.conv2d_transpose(net, 1, [], stride=, padding=, activation_fn=)
    return net
mnist = input_data.read_data_sets("", one_hot=)
batch_per_ep =
ae_inputs = tf.placeholder(tf.float32, ())
ae_outputs = autoencoder()
loss = tf.reduce_mean(tf.square())
train_op = tf.train.AdamOptimizer(learning_rate=).minimize()
init = tf.global_variables_initializer()
with tf.Session() as sess:
    sess.run()
    for ep in range():
        for batch_n in range():
            batch_img, batch_label = mnist.train.next_batch()
            batch_img = batch_img.reshape(())
            batch_img = resize_batch()
            _, c = sess.run([], feed_dict={ae_inputs:})
    batch_img, batch_label = mnist.test.next_batch()
    batch_img = resize_batch()
    recon_img = sess.run([], feed_dict={ae_inputs:})[]
    plt.figure()
    plt.title()
    for i in range():
        plt.subplot()
        plt.imshow(recon_img[], cmap=)
    plt.figure()
    plt.title()
    for i in range():
        plt.subplot()
        plt.imshow(batch_img[], cmap=)
    plt.show()
from coremltools.converters.mil import testing_reqs
from coremltools.converters.mil.testing_reqs import *
from coremltools.converters.mil.frontend.tensorflow.test.testing_utils import ()
import math
import tempfile
import shutil
backends =
tf = pytest.importorskip()
class TestDebugging():
    def test_assert():
        input_shape = ()
        def build_model():
            tf.debugging.Assert(True, [])
            return tf.nn.relu()
        model, inputs, outputs =
        input_values = [random_gen()]
        input_dict = dict(zip())
        TensorFlowBaseTest.run_compare_tf(model,input_dict,outputs,use_cpu_only=,backend=,)
    def test_check_numerics():
        input_shape = ()
        def build_model():
            tf.debugging.check_numerics()
            return tf.nn.relu()
        model, inputs, outputs =
        input_values = [random_gen()]
        input_dict = dict(zip())
        TensorFlowBaseTest.run_compare_tf(model,input_dict,outputs,use_cpu_only=,backend=,)
    def test_print():
        input_shape = ()
        def build_model():
            tf.raw_ops.Print(input=, data=[], message='[]')
            return tf.nn.relu()
        model, inputs, outputs =
        input_values = [random_gen()]
        input_dict = dict(zip())
        TensorFlowBaseTest.run_compare_tf(model,input_dict,outputs,use_cpu_only=,backend=,)
class TestPlaceholderAsOutput():
    def test():
        input_shape = np.random.randint(low=, high=, size=)
        def build_model():
            return x, y, x + 1, x + y
        model, inputs, outputs =
        input_values = [random_gen(), random_gen()]
        input_dict = dict(zip())
        TensorFlowBaseTest.run_compare_tf(model,input_dict,outputs,use_cpu_only=,frontend_only=,backend=,)
class TestDuplicateOutputs():
    def test():
        input_shape = np.random.randint(low=, high=, size=)
        def build_model():
            b = tf.identity()
            c = tf.identity()
            d =
            return b, c, d
        model, inputs, outputs =
        input_values = [random_gen(), random_gen()]
        input_dict = dict(zip())
        TensorFlowBaseTest.run_compare_tf(model,input_dict,outputs,use_cpu_only=,frontend_only=,backend=,)
class TestIdentity():
    def test():
        input_shape = np.random.randint(low=, high=, size=)
        def build_model():
            return x
        model, inputs, outputs =
        input_values = [random_gen()]
        input_dict = dict(zip())
        TensorFlowBaseTest.run_compare_tf(model,input_dict,outputs,use_cpu_only=,frontend_only=,backend=,)
class TestActivationElu():
    def test():
        input_shape = np.random.randint(low=, high=, size=)
        def build_model():
            return tf.nn.elu()
        model, inputs, outputs =
        input_values = [random_gen()]
        input_dict = dict(zip())
        TensorFlowBaseTest.run_compare_tf(model,input_dict,outputs,use_cpu_only=,frontend_only=,backend=,)
class TestAddN():
    def test():
        if use_cpu_only is False and rank == 5 and num_inputs == 9:
            return
        input_shape = np.random.randint(low=, high=, size=)
        input_shapes = [input_shape[:] for _ in range()]
        def build_model():
            return tf.raw_ops.AddN(inputs=)
        model, inputs, outputs =
        input_values = [random_gen() for shape in input_shapes]
        input_dict = dict(zip())
        TensorFlowBaseTest.run_compare_tf(model,input_dict,outputs,use_cpu_only=,frontend_only=,backend=,)
class TestActivationLeakyReLU():
    def test():
        input_shape = np.random.randint(low=, high=, size=)
        def build_model():
            return tf.nn.leaky_relu()
        model, inputs, outputs =
        input_values = [random_gen()]
        input_dict = dict(zip())
        TensorFlowBaseTest.run_compare_tf(model,input_dict,outputs,use_cpu_only=,frontend_only=,backend=,)
class TestActivationReLU():
    def test():
        input_shape = np.random.randint(low=, high=, size=)
        def build_model():
            return tf.nn.relu()
        model, inputs, outputs =
        input_values = [random_gen()]
        input_dict = dict(zip())
        TensorFlowBaseTest.run_compare_tf(model,input_dict,outputs,use_cpu_only=,frontend_only=,backend=,)
class TestActivationReLU6():
    def test():
        input_shape = np.random.randint(low=, high=, size=)
        def build_model():
            return tf.nn.relu6()
        model, inputs, outputs =
        input_values = [random_gen()]
        input_dict = dict(zip())
        TensorFlowBaseTest.run_compare_tf(model,input_dict,outputs,use_cpu_only=,frontend_only=,backend=,)
class TestGeluTanhApproximation():
    def test():
        input_shape = np.random.randint(low=, high=, size=)
        def build_model():
            a = 0.5 * (1.0 + tf.tanh((math.sqrt() * (x + 0.044715 * tf.pow()))))
            return a * x
        model, inputs, outputs =
        input_values = [random_gen()]
        input_dict = dict(zip())
        spec, _, _, _, _, _ = TensorFlowBaseTest.run_compare_tf(model,input_dict,outputs,use_cpu_only=,frontend_only=,backend=,)
class TestActivationSigmoid():
    def test():
        input_shape = np.random.randint(low=, high=, size=)
        def build_model():
            return tf.math.sigmoid()
        model, inputs, outputs =
        input_values = [random_gen()]
        input_dict = dict(zip())
        TensorFlowBaseTest.run_compare_tf(model,input_dict,outputs,use_cpu_only=,frontend_only=,backend=,)
class TestActivationSoftPlus():
    def test():
        input_shape = np.random.randint(low=, high=, size=)
        def build_model():
            return tf.math.softplus()
        model, inputs, outputs =
        input_values = [random_gen()]
        input_dict = dict(zip())
        TensorFlowBaseTest.run_compare_tf(model,input_dict,outputs,use_cpu_only=,frontend_only=,backend=,)
class TestActivationSoftmax():
    def test():
        rank, axis =
        input_shape = np.random.randint(low=, high=, size=)
        def build_model():
            return tf.nn.softmax(x, axis=)
        model, inputs, outputs =
        input_values = [random_gen()]
        input_dict = dict(zip())
        TensorFlowBaseTest.run_compare_tf(model,input_dict,outputs,use_cpu_only=,frontend_only=,backend=,)
class TestActivationSoftSign():
    def test():
        input_shape = np.random.randint(low=, high=, size=)
        def build_model():
            return tf.math.softsign()
        model, inputs, outputs =
        input_values = [random_gen()]
        input_dict = dict(zip())
        TensorFlowBaseTest.run_compare_tf(model,input_dict,outputs,use_cpu_only=,frontend_only=,backend=,)
class TestActivationSelu():
    def test():
        input_shape = np.random.randint(low=, high=, size=)
        def build_model():
            return tf.nn.selu()
        model, inputs, outputs =
        input_values = [random_gen()]
        input_dict = dict(zip())
        TensorFlowBaseTest.run_compare_tf(model,input_dict,outputs,use_cpu_only=,frontend_only=,backend=,)
class TestSelect():
    def test_select():
        shape = np.random.randint(low=, high=, size=)
        cond_shape = np.array([shape[]]) if broadcast else shape
        cond_val = np.random.randint(low=, high=, size=).astype()
        a_val = random_gen(shape=, rand_min=, rand_max=)
        b_val = random_gen(shape=, rand_min=, rand_max=)
        if dynamic:
            cond_shape = [] * len() + []
            a_shape = [] * len() + []
            b_shape = [] * len() + []
        else:
            cond_shape = cond_shape.tolist() + []
            a_shape = shape.tolist() + []
            b_shape = shape.tolist() + []
        def build_model_select():
            return tf.raw_ops.Select(condition=, x=, y=)
        model, inputs, outputs =
        inputs_dic = dict(zip(inputs, []))
        TensorFlowBaseTest.run_compare_tf(model, inputs_dic, outputs, use_cpu_only=, backend=)
class TestWhere():
    def test_where_1_input():
        with tf.Graph().as_default() as graph:
            shape = np.random.randint(low=, high=, size=)
            x_val = np.random.randint(low=, high=, size=).astype()
            x = tf.placeholder(tf.float32, shape=)
            TensorFlowBaseTest.run_compare_tf(graph,{x:},tf.where(),use_cpu_only=,backend=,)
    def test_where():
        shape = np.random.randint(low=, high=, size=)
        cond_val = np.random.randint(low=, high=, size=).astype()
        a_val = random_gen(shape=, rand_min=, rand_max=)
        b_val = random_gen(shape=, rand_min=, rand_max=)
        with tf.Graph().as_default() as graph:
            cond = tf.placeholder(tf.bool, shape=)
            a = tf.placeholder(tf.float32, shape=)
            b = tf.placeholder(tf.float32, shape=)
            ref = tf.where()
            TensorFlowBaseTest.run_compare_tf(graph,{cond:, a:, b:},ref,use_cpu_only=,backend=,)
class TestCast():
    def test():
        shape = np.random.randint(low=, high=, size=)
        def build_model():
            return tf.cast(x, dtype=)
        model, inputs, outputs =
        input_values = [random_gen()]
        input_dict = dict(zip())
        TensorFlowBaseTest.run_compare_tf(model, input_dict, outputs,use_cpu_only=,backend=)
class TestCond():
    def test_cond_naive():
        def build_model():
            return tf.cond(tf.constant(), lambda:, lambda:)
        model, inputs, outputs =
        input_values = [np.array([], dtype=),np.array([], dtype=),]
        input_dict = dict(zip())
        TensorFlowBaseTest.run_compare_tf(model, input_dict, outputs, use_cpu_only=, backend=)
    def test_cond():
        def build_model():
            z = tf.multiply()
            pred = tf.less(tf.math.reduce_mean(), tf.math.reduce_mean())
            return tf.cond(pred, lambda: tf.add(), lambda: tf.square())
        model, inputs, outputs =
        input_values = [np.array([], dtype=),np.array([], dtype=),]
        input_dict = dict(zip())
        TensorFlowBaseTest.run_compare_tf(model, input_dict, outputs, use_cpu_only=, backend=)
    def test_cond_multi_returns():
        def build_model():
            z = tf.multiply()
            pred = tf.less(tf.math.reduce_mean(), tf.math.reduce_mean())
            def true_fn():
                return tf.add(), tf.math.multiply()
            def false_fn():
                return tf.square(), tf.sqrt()
            return tf.cond()
        model, inputs, outputs =
        input_values = [np.array([], dtype=),np.array([], dtype=),]
        input_dict = dict(zip())
        TensorFlowBaseTest.run_compare_tf(model, input_dict, outputs, use_cpu_only=, backend=)
    def test_cond_with_identity():
        def build_model():
            z = tf.multiply()
            pred = tf.less(tf.math.reduce_mean(), tf.math.reduce_mean())
            return tf.cond(pred, lambda:, lambda: tf.square())
        model, inputs, outputs =
        input_values = [np.array([], dtype=),np.array([], dtype=),]
        input_dict = dict(zip())
        TensorFlowBaseTest.run_compare_tf(model, input_dict, outputs, use_cpu_only=, backend=)
    def test_cond_multi_returns_with_identity():
        def build_model():
            z = tf.multiply()
            pred = tf.less(tf.math.reduce_mean(), tf.math.reduce_mean())
            def true_fn():
                return tf.add(), x
            def false_fn():
                return tf.square(), z
            return tf.cond()
        model, inputs, outputs =
        input_values = [np.array([], dtype=),np.array([], dtype=),]
        input_dict = dict(zip())
        TensorFlowBaseTest.run_compare_tf(model, input_dict, outputs, use_cpu_only=, backend=)
    def test_cond_nested_0():
        def build_model():
            z = tf.multiply()
            t = tf.less(tf.math.reduce_mean(), tf.math.reduce_mean())
            f = tf.less(tf.math.reduce_mean(), tf.math.reduce_mean())
            inner_cond = tf.cond(f, lambda: tf.pow(), lambda: tf.math.subtract())
            return tf.cond(t, lambda:, lambda: tf.square())
        model, inputs, outputs =
        input_values = [np.array([], dtype=),np.array([], dtype=),]
        input_dict = dict(zip())
        TensorFlowBaseTest.run_compare_tf(model, input_dict, outputs, use_cpu_only=, backend=)
    def test_cond_nested_1():
        def build_model():
            z = tf.multiply()
            t = tf.less(tf.math.reduce_mean(), tf.math.reduce_mean())
            f = tf.less(tf.math.reduce_mean(), tf.math.reduce_mean())
            cond_1 = tf.cond(f, lambda: tf.pow(), lambda: tf.math.subtract())
            cond_2 = tf.cond(t, lambda: tf.multiply(), lambda: tf.math.mod())
            cond_3 = tf.cond(f, lambda: tf.math.divide(), lambda:)
            return tf.cond(t, lambda:, lambda:)
        model, inputs, outputs =
        input_values = [np.array([], dtype=),np.array([], dtype=),]
        input_dict = dict(zip())
        TensorFlowBaseTest.run_compare_tf(model, input_dict, outputs, use_cpu_only=, backend=)
class TestWhileLoop():
    def test_while_loop_with_changing_shape():
        def build_model():
            c =,j: tf.less(tf.shape()[], 5)
            b =,j: (i, tf.concat([], axis=))
            return tf.while_loop(c, b, [], shape_invariants=[x.get_shape(), tf.TensorShape([])])
        model, inputs, outputs =
        input_values = [np.array([[],[]], dtype=),np.array([[],[]], dtype=)]
        input_dict = dict(zip())
        TensorFlowBaseTest.run_compare_tf(model, input_dict, outputs,use_cpu_only=,backend=)
    def test_while_loop_no_entry():
        def build_model():
            c = lambda i: tf.greater(tf.math.reduce_mean(), 5)
            b = lambda i:
            return tf.while_loop(c, b, [])
        model, inputs, outputs =
        input_values = [np.array([], dtype=)]
        input_dict = dict(zip())
        TensorFlowBaseTest.run_compare_tf(model, input_dict, outputs, use_cpu_only=, backend=)
    def test_while_loop_0():
        def build_model():
            c = lambda i: tf.greater(tf.math.reduce_mean(), 5)
            b = lambda i:
            return tf.while_loop(c, b, [])
        model, inputs, outputs =
        input_values = [np.array([], dtype=)]
        input_dict = dict(zip())
        TensorFlowBaseTest.run_compare_tf(model, input_dict, outputs, use_cpu_only=, backend=)
    def test_while_loop_1():
        def build_model():
            c =, j: tf.greater(tf.math.reduce_mean(), tf.math.reduce_mean())
            b =, j: (tf.add(), tf.square())
            return tf.while_loop(c, b, [])
        model, inputs, outputs =
        input_values = [np.array([], dtype=),np.array([], dtype=),]
        input_dict = dict(zip())
        TensorFlowBaseTest.run_compare_tf(model, input_dict, outputs, use_cpu_only=, backend=)
    def test_while_loop_2():
        def build_model():
            c =, j: tf.greater(tf.math.reduce_mean(), 5)
            b =, j: ()
            return tf.while_loop(c, b, [])
        model, inputs, outputs =
        input_values = [np.array([], dtype=),np.array([[]], dtype=),]
        input_dict = dict(zip())
        TensorFlowBaseTest.run_compare_tf(model, input_dict, outputs, use_cpu_only=, backend=)
    def test_while_loop_3():
        def build_model():
            c =, j, k: tf.greater(tf.math.reduce_mean(), tf.math.reduce_mean())
            b =, j, k: ()
            return tf.while_loop(c, b, [])
        model, inputs, outputs =
        input_values = [np.array([], dtype=),np.array([[]], dtype=),np.array([], dtype=),]
        input_dict = dict(zip())
        TensorFlowBaseTest.run_compare_tf(model, input_dict, outputs, use_cpu_only=, backend=)
    def test_while_loop_4():
        def build_model():
            c =, j, k, l: tf.greater(tf.math.reduce_mean(), tf.math.reduce_mean())
            b =, j, k, l: ()
            return tf.while_loop(c, b, [])
        model, inputs, outputs =
        input_values = [np.array([], dtype=),np.array([[]], dtype=),np.array([], dtype=),np.array([[], []], dtype=),]
        input_dict = dict(zip())
        TensorFlowBaseTest.run_compare_tf(model, input_dict, outputs, use_cpu_only=, backend=)
    def test_nested_while_body():
        def build_model():
            def cond2():
                return tf.less(2 * tf.math.reduce_mean(), tf.math.reduce_mean())
            def body2():
                return i + 1
            def cond1():
                return tf.less(tf.math.reduce_mean(), tf.math.reduce_mean())
            def body1():
                new_i = tf.while_loop(cond2, body2, [])
                return new_i + 2, j
            return tf.while_loop(cond1, body1, [])
        model, inputs, outputs =
        input_values = [np.array([], dtype=),np.array([], dtype=),]
        input_dict = dict(zip())
        TensorFlowBaseTest.run_compare_tf(model, input_dict, outputs, use_cpu_only=, backend=)
    def test_nested_while_cond():
        def build_model():
            def cond2():
                return tf.less(2 * tf.math.reduce_mean(), tf.math.reduce_mean())
            def body2():
                return i + 1
            def cond1():
                new_i = tf.while_loop(cond2, body2, [])
                return tf.less(tf.squeeze(), tf.squeeze())
            def body1():
                return i + 2, j + 1
            return tf.while_loop(cond1, body1, [])
        model, inputs, outputs =
        input_values = [np.array([], dtype=),np.array([], dtype=),]
        input_dict = dict(zip())
        TensorFlowBaseTest.run_compare_tf(model, input_dict, outputs, use_cpu_only=, backend=)
class TestConv():
    def test():
        H, W, kH, kW =
        N, C_in, C_out =, 2, 3
        if data_format == "":
            input_shape = () if conv_dim == "" else ()
            if isinstance():
                padding = [[]] + padding + [[]]
            if conv_dim == "":
                data_format =
                if isinstance():
                    return
        else:
            input_shape = () if conv_dim == "" else ()
            if isinstance():
                padding = [[], []] + padding
            if conv_dim == "":
                data_format =
                if isinstance():
                    return
        W_shape = () if conv_dim == "" else ()
        dilations = dilations[] if conv_dim ==
        strides = strides[] if conv_dim ==
        if dynamic_weights and dilations == ():
            def build_model_dynamic_weights():
                if conv_dim == "":
                    conv = tf.nn.conv1d(x,W,stride=,padding=,dilations=,data_format=,)
                else:
                    conv = tf.nn.conv2d(x,W,strides=,padding=,dilations=,data_format=,)
                return conv
            model, inputs, outputs =
            input_values = [random_gen(),random_gen(),]
            input_dict = dict(zip())
        else:
            def build_model_static_weights():
                W = tf.constant(np.random.rand(), tf.float32)
                if conv_dim == "":
                    conv = tf.nn.conv1d(x,W,stride=,padding=,dilations=,data_format=,)
                else:
                    conv = tf.nn.conv2d(x,W,strides=,padding=,dilations=,data_format=,)
                return conv
            model, inputs, outputs =
            input_values = [random_gen()]
            input_dict = dict(zip())
        TensorFlowBaseTest.run_compare_tf(model,input_dict,outputs,use_cpu_only=,frontend_only=,backend=,)
class TestConv3d():
    def test_tf():
        C_in = np.random.randint(low=, high=)
        C_out = np.random.randint(low=, high=())
        input_shape = [] + list() + []
        weights_shape = list() + []
        tf_strides = [] + list() + []
        tf_dilations = [] + list() + []
        def build_model_static_weights():
            W = tf.constant(np.random.rand(), tf.float32)
            return tf.nn.conv3d(x,W,strides=,padding=,data_format=,dilations=,)
        model, inputs, outputs =
        input_values = [random_gen()]
        input_dict = dict(zip())
        TensorFlowBaseTest.run_compare_tf(model,input_dict,outputs,use_cpu_only=,backend=,frontend_only=,atol=,rtol=,)
class TestDepthwiseConv():
    def test_depthwise_conv():
        if np.sum() != len() and np.sum() != len():
            return
        H, W, kH, kW =
        N, C_in, C_out =, 2, 6
        input_shape = ()
        data_format =
        multiplier = int()
        W_shape = ()
        def test_static_W():
            W = np.random.rand().astype()
            def build_model_static_weights():
                return tf.nn.depthwise_conv2d(x,W,strides=,padding=,dilations=,data_format=,)
            model, inputs, outputs =
            input_values = [(np.random.rand().astype())]
            input_dict = dict(zip())
            proto,_,_,_,_,_ = TensorFlowBaseTest.run_compare_tf(model,input_dict,outputs,use_cpu_only=,backend=,frontend_only=,)
            if backend == "":
        def test_dynamic_W():
            def build_model_dynamic_weights():
                return tf.nn.depthwise_conv2d(x,W,strides=,padding=,dilations=,data_format=,)
            model, inputs, outputs =
            input_values = [(np.random.rand().astype()),(np.random.rand().astype()),]
            input_dict = dict(zip())
            TensorFlowBaseTest.run_compare_tf(model,input_dict,outputs,use_cpu_only=,backend=,frontend_only=,)
        test_dynamic_W() if dynamic_weights and dilations == () else test_static_W()
class TestSeparableConv():
    def test_separable_conv():
        H, depthwise_filter, kH, kW =
        N, C_in, C_out =, 2, 6
        input_shape = ()
        data_format =
        multiplier = int()
        depthwise_filter_shape = ()
        pointwise_filter_shape = []
        if dilations != ():
            strides = ()
        def test_dynamic_W():
            def build_model_dynamic_weights():
                return tf.nn.separable_conv2d(x,depthwise_filter,pointwise_filter,strides=,padding=,dilations=,data_format=,)
            model, inputs, outputs =
            input_values = [(np.random.rand().astype()),(np.random.rand().astype()),(np.random.rand().astype()),]
            input_dict = dict(zip())
            TensorFlowBaseTest.run_compare_tf(model,input_dict,outputs,use_cpu_only=,backend=,frontend_only=,)
        def test_static_W():
            depthwise_filter = np.random.rand().astype()
            pointwise_filter = np.random.rand().astype()
            def build_model_static_weights():
                return tf.nn.separable_conv2d(x,depthwise_filter,pointwise_filter,strides=,padding=,dilations=,data_format=,)
            model, inputs, outputs =
            input_values = [(np.random.rand().astype())]
            input_dict = dict(zip())
            TensorFlowBaseTest.run_compare_tf(model,input_dict,outputs,use_cpu_only=,backend=,frontend_only=,)
        test_static_W()
        if not any([]):
            test_dynamic_W()
class TestConvTranspose():
    def test_conv_transpose():
        H, W, kH, kW =
        N, C_in, C_out =, 1, 2
        if padding == "":
            oH = H * strides[]
            oW = W * strides[]
        else:
            oH = () * strides[] + () * dilations[] + 1
            oW = () * strides[] + () * dilations[] + 1
        if data_format == "":
            input_shape = () if conv_dim == "" else ()
            if conv_dim == "":
                data_format =
            output_shape = ([] if conv_dim == "" else [])
        else:
            input_shape = () if conv_dim == "" else ()
            if conv_dim == "":
                data_format =
            output_shape = ([] if conv_dim == "" else [])
        w_shape = () if conv_dim == "" else ()
        def build_model():
            W = tf.constant(np.random.rand(), tf.float32)
            if conv_dim == "":
                return tf.nn.conv1d_transpose(x,W,output_shape=,strides=strides[],padding=,dilations=dilations[],data_format=,)
            elif conv_dim == "":
                return tf.nn.conv2d_transpose(x,W,output_shape=,strides=,padding=,dilations=,data_format=,)
        model, inputs, outputs =
        input_values = [(np.random.rand().astype())]
        input_dict = dict(zip())
        TensorFlowBaseTest.run_compare_tf(model,input_dict,outputs,use_cpu_only=,backend=,frontend_only=,)
    def test_conv3d_transpose():
        D, H, W, kD, kH, kW =
        N, C_in, C_out =, 1, 2
        if padding == "":
            oD = D * strides[]
            oH = H * strides[]
            oW = W * strides[]
        else:
            oD = () * strides[] + () * dilations[] + 1
            oH = () * strides[] + () * dilations[] + 1
            oW = () * strides[] + () * dilations[] + 1
        if data_format == "":
            input_shape = ()
            output_shape = []
        else:
            input_shape = ()
            output_shape = []
        w_shape = ()
        x_input = np.random.randn()
        w_val = np.random.randn()
        def build_model():
            w = tf.constant(np.random.rand(), tf.float32)
            return tf.nn.conv3d_transpose(x,w,output_shape=,strides=,padding=,dilations=,data_format=,)
        model, inputs, outputs =
        input_values = [(np.random.rand().astype())]
        input_dict = dict(zip())
        TensorFlowBaseTest.run_compare_tf(model,input_dict,outputs,use_cpu_only=,backend=,frontend_only=,)
class TestElementWiseBinary():
    def test_binary_math():
        x_shape = y_shape = list(np.random.randint(low=, high=, size=))
        case = np.random.choice([])
        if case == 0:
            y_shape = []
        elif case == 1:
            y_shape = [1 if np.random.randint() ==]
        elif case == 2:
            y_shape = [] + y_shape
        if np.random.randint() == 0:
            x_shape, y_shape =, x_shape
        dtype =
        if tf_op in {}:
            x_val = random_gen(x_shape, -100, 100, dtype=).astype()
            y_val = random_gen(y_shape, -100, 100, dtype=).astype()
        elif tf_op in {}:
            x_val = random_gen(x_shape, -100, 100, dtype=).astype()
            y_val = random_gen(y_shape, 1, 20, dtype=).astype()
        elif tf_op in {}:
            x_val = random_gen(x_shape, -10, 10, dtype=).astype()
            y_val = random_gen(y_shape, -10, 10, dtype=).astype()
        elif tf_op in {}:
            x_val = random_gen(x_shape, -5, 5, dtype=).astype()
            y_val = random_gen(y_shape, -5, 5, dtype=).astype()
        else:
            raise NotImplementedError()
        def build_model():
            return tf_op()
        model, inputs, outputs =
        input_values = []
        input_dict = dict(zip())
        TensorFlowBaseTest.run_compare_tf(model, input_dict, outputs, use_cpu_only=, backend=)
    def test_binary_compare():
        x_shape = y_shape = list(np.random.randint(low=, high=, size=))
        case = np.random.choice([])
        if case == 0:
            y_shape = []
        elif case == 1:
            y_shape = [1 if np.random.randint() ==]
        elif case == 2:
            y_shape = [] + y_shape
        if np.random.randint() == 0:
            x_shape, y_shape =, x_shape
        dtype =
        def build_model():
            return tf_op()
        model, inputs, outputs =
        input_values = [random_gen(x_shape, -5, 3, dtype=).astype(),random_gen(y_shape, -5, 3, dtype=).astype(),]
        input_dict = dict(zip())
        TensorFlowBaseTest.run_compare_tf(model, input_dict, outputs, use_cpu_only=, backend=)
    def test_binary_logical():
        x_shape = y_shape = list(np.random.randint(low=, high=, size=))
        case = np.random.choice([])
        if case == 0:
            y_shape = []
        elif case == 1:
            y_shape = [1 if np.random.randint() ==]
        elif case == 2:
            y_shape = [] + y_shape
        if np.random.randint() == 0:
            x_shape, y_shape =, x_shape
        def build_model():
            return tf_op()
        model, inputs, outputs =
        input_values = [random_gen(x_shape, 0, 2, dtype=).astype(),random_gen(y_shape, 0, 2, dtype=).astype(),]
        input_dict = dict(zip())
        TensorFlowBaseTest.run_compare_tf(model, input_dict, outputs, use_cpu_only=, backend=)
class TestElementWiseUnary():
    _FP16_UNSUPPORTED = {}
    def test_unary():
        if not use_cpu_only and mode in self._FP16_UNSUPPORTED:
            return
        atol, rtol =, 1e-5
        input_shape = np.random.randint(low=, high=, size=)
        if use_cpu_only:
            dtype =
            tf_dtype =
        else:
            dtype =
            tf_dtype =
        def cast_func():
            return tf.cast(x, dtype=)
        def clip_func():
            return tf.clip_by_value(x, clip_value_min=, clip_value_max=)
        def _get_test():
            if test_mode == "":
                res =
                val = random_gen(input_shape, rand_min=, rand_max=)
            elif test_mode == "":
                res =
                val = random_gen(input_shape, rand_min=, rand_max=)
            elif test_mode == "":
                res =
                val = random_gen(input_shape, rand_min=, rand_max=)
            elif test_mode == "":
                res =
                val = random_gen(input_shape, rand_min=, rand_max=)
            elif test_mode == "":
                res =
                val = random_gen(input_shape, rand_min=, rand_max=)
            elif test_mode == "":
                eps_from_int =
                if not use_cpu_only:
                    eps_from_int =
                res =
                val = random_gen(input_shape,rand_min=,rand_max=,eps_from_int=,dtype=,)
            elif test_mode == "":
                res =
                eps_from_int =
                if not use_cpu_only:
                    eps_from_int =
                val = random_gen(input_shape,rand_min=,rand_max=,eps_from_int=,dtype=,)
            elif test_mode == "":
                if use_cpu_only is False:
                    return None, None
                res =
                val = random_gen(input_shape, rand_min=, rand_max=)
            elif test_mode == "":
                res =
                rand_range =
                if not use_cpu_only:
                    rand_range =
                val = random_gen(input_shape, rand_min=, rand_max=)
            elif test_mode == "":
                res =
                val = random_gen(input_shape, rand_min=, rand_max=)
            elif test_mode == "":
                res =
                val = random_gen(input_shape, rand_min=, rand_max=)
            elif test_mode == "":
                if not use_cpu_only:
                    return None, None
                res =
                val = random_gen(input_shape, rand_min=, rand_max=)
            elif test_mode == "":
                res =
                eps_from_int =
                if not use_cpu_only:
                    eps_from_int =
                val = random_gen(input_shape,rand_min=,rand_max=,eps_from_int=,dtype=,)
            elif test_mode == "":
                res =
                val = random_gen(input_shape, rand_min=, rand_max=)
            elif test_mode == "":
                res =
                val = random_gen(input_shape, rand_min=, rand_max=)
            elif test_mode == "":
                res =
                val = random_gen(input_shape, rand_min=, rand_max=)
            elif test_mode == "":
                res =
                val = random_gen(input_shape, rand_min=, rand_max=, dtype=)
            elif test_mode == "":
                res =
                val = random_gen(input_shape, rand_min=, rand_max=)
            elif test_mode == "":
                res =
                val = random_gen(input_shape, rand_min=, rand_max=)
            elif test_mode == "":
                res =
                rand_range =
                if not use_cpu_only:
                    rand_range =
                val = random_gen(input_shape, rand_min=, rand_max=)
            elif test_mode == "":
                res =
                val = random_gen(input_shape, rand_min=, rand_max=)
            elif test_mode == "":
                res =
                val = random_gen(input_shape, rand_min=, rand_max=)
            elif test_mode == "":
                res =
                val = random_gen(input_shape, rand_min=, rand_max=)
            elif test_mode == "":
                res =
                val = random_gen(input_shape, rand_min=, rand_max=)
            elif test_mode == "":
                res =
                val = random_gen(input_shape, rand_min=, rand_max=)
            return res, val
        func, input_val = _get_test()
        if func is None:
            return
        input_type = list() + []
        def build_model():
            return func()
        model, inputs, outputs =
        input_dict = dict(zip(inputs, [input_val.astype()]))
        if mode == "" or mode == "":
            atol, rtol =, 1e-3
        TensorFlowBaseTest.run_compare_tf(model,input_dict,outputs,use_cpu_only=,backend=,atol=,rtol=)
class TestImageResizing():
    def test_resize_bilinear():
        if half_pixel_centers and align_corners:
            return
        def build_model():
            return tf.raw_ops.ResizeBilinear(images=,size=,half_pixel_centers=,align_corners=,)
        model, inputs, outputs =
        input_values = [random_gen()]
        input_dict = dict(zip())
        TensorFlowBaseTest.run_compare_tf(model,input_dict,outputs,use_cpu_only=,backend=,)
    def test_upsampling_2d():
        if data_format == "":
            input_shape = (input_shape[],input_shape[],input_shape[],input_shape[],)
        def build_model():
            return tf.keras.layers.UpSampling2D(size=, data_format=, interpolation=)()
        model, inputs, outputs =
        input_values = [random_gen()]
        input_dict = dict(zip())
        TensorFlowBaseTest.run_compare_tf(model,input_dict,outputs,use_cpu_only=,backend=,)
    def test_crop_and_resize():
        input = np.random.randn().astype()
        boxes = np.random.uniform(size=()).astype()
        box_indices = np.random.randint(size=(), low=, high=input_shape[]).astype()
        def test_static():
            def build_model():
                return tf.raw_ops.CropAndResize(image=,boxes=,box_ind=,crop_size=,method=,)
            model, inputs, outputs =
            input_values = []
            input_dict = dict(zip())
            TensorFlowBaseTest.run_compare_tf(model,input_dict,outputs,use_cpu_only=,backend=,)
        def test_dynamic():
            def build_model():
                return tf.raw_ops.CropAndResize(image=,boxes=,box_ind=,crop_size=,method=,)
            model, inputs, outputs =
            input_values = []
            input_dict = dict(zip())
            TensorFlowBaseTest.run_compare_tf(model,input_dict,outputs,use_cpu_only=,backend=,)
        test_dynamic() if dynamic else test_static()
    def test_extract_patches():
        input = np.random.rand().astype()
        if padding == "":
            size_h = min(sizes[], height)
            size_w = min(sizes[], width)
        else:
            size_h = sizes[]
            size_w = sizes[]
        def build_model():
            return tf.compat.v1.image.extract_image_patches(images=,ksizes=[],strides=[1, strides[], strides[], 1],rates=[],padding=,)
        model, inputs, outputs =
        input_values = []
        input_dict = dict(zip())
        TensorFlowBaseTest.run_compare_tf(model,input_dict,outputs,use_cpu_only=,backend=,)
class TestLinear():
    def test_matmul():
        shape_x = np.array([])
        shape_y = np.array([])
        flip = () or ()
        shape_y = np.flip() if flip else shape_y
        if not use_constant:
            def build_model():
                return tf.linalg.matmul(x, y, transpose_a=, transpose_b=)
            input_values = [random_gen(shape=, rand_min=, rand_max=),random_gen(shape=, rand_min=, rand_max=),]
        else:
            y = random_gen(shape=, rand_min=, rand_max=)
            def build_model():
                return tf.linalg.matmul(x, y, transpose_a=, transpose_b=)
            input_values = [random_gen(shape=, rand_min=, rand_max=)]
        model, inputs, outputs =
        input_dict = dict(zip())
        proto,_,_,_,_,_ = TensorFlowBaseTest.run_compare_tf(model, input_dict, outputs, use_cpu_only=, backend=)
        for layer in proto.neuralNetwork.layers:
            if layer.WhichOneof() == "":
                wp =
                if use_constant:
                else:
class TestBatchNormalization():
    def test_batch_norm():
        input_shape = np.random.randint(low=, high=, size=)
        if shape_mode:
            attr_shape = list()
            attr_shape[] =
            attr_shape[] =
        else:
            attr_shape = [list()[]]
        def build_model():
            return tf.nn.batch_normalization(x, mean=, variance=, offset=, scale=, variance_epsilon=)
        model, inputs, outputs =
        input_values = [random_gen(shape=, rand_min=, rand_max=),random_gen(shape=, rand_min=, rand_max=),random_gen(shape=, rand_min=, rand_max=),random_gen(shape=, rand_min=, rand_max=),random_gen(shape=, rand_min=, rand_max=),]
        input_dict = dict(zip())
        TensorFlowBaseTest.run_compare_tf(model,input_dict,outputs,use_cpu_only=,backend=,atol=,rtol=,)
    def test_batch_norm_with_global_normalization():
        input_shape = np.random.randint(low=, high=, size=)
        if shape_mode:
            attr_shape = list()
            attr_shape[] =
            attr_shape[] =
        else:
            attr_shape = [list()[]]
        if scale_after_normalization:
            def build_model():
                return tf.nn.batch_norm_with_global_normalization(x,mean=,variance=,beta=,gamma=,variance_epsilon=,scale_after_normalization=,)
        else:
            def build_model():
                return tf.nn.batch_norm_with_global_normalization(x,mean=,variance=,beta=,gamma=,variance_epsilon=,scale_after_normalization=,)
        model, inputs, outputs =
        input_values = [random_gen(shape=, rand_min=, rand_max=),random_gen(shape=, rand_min=, rand_max=),random_gen(shape=, rand_min=, rand_max=),random_gen(shape=, rand_min=, rand_max=),]
        if scale_after_normalization:
            input_values.append(random_gen(shape=, rand_min=, rand_max=))
        input_dict = dict(zip())
        TensorFlowBaseTest.run_compare_tf(model,input_dict,outputs,use_cpu_only=,backend=,atol=,rtol=,)
class TestNormalization():
    def test_fused_batch_norm():
        input_shape = np.random.randint(low=, high=, size=)
        attr_shape = [list()[]]
        m = random_gen(shape=, rand_min=, rand_max=)
        v = random_gen(shape=, rand_min=, rand_max=)
        o = random_gen(shape=, rand_min=, rand_max=)
        s = random_gen(shape=, rand_min=, rand_max=)
        def build_model():
            return tf.compat.v1.nn.fused_batch_norm(x,mean=,variance=,offset=,scale=,epsilon=,is_training=,)[]
        model, inputs, outputs =
        input_values = [random_gen(shape=, rand_min=, rand_max=)]
        input_dict = dict(zip())
        TensorFlowBaseTest.run_compare_tf(model,input_dict,outputs,use_cpu_only=,backend=,atol=,rtol=,)
class TestL2Normalization():
    def test_l2_normalize():
        input_shape = np.random.randint(low=, high=, size=)
        def build_model():
            return tf.math.l2_normalize(x, axis=, epsilon=)
        model, inputs, outputs =
        input_values = [random_gen(input_shape, rand_min=, rand_max=)]
        input_dict = dict(zip())
        TensorFlowBaseTest.run_compare_tf(model,input_dict,outputs,use_cpu_only=,backend=,atol=,rtol=,)
class TestLocalResponseNormalization():
    def test_local_response_normalization():
        input_shape = np.random.randint(low=, high=, size=)
        def build_model():
            return tf.nn.local_response_normalization(x, depth_radius=, bias=, alpha=, beta=)
        model, inputs, outputs =
        input_values = [random_gen(shape=, rand_min=, rand_max=)]
        input_dict = dict(zip())
        TensorFlowBaseTest.run_compare_tf(model,input_dict,outputs,use_cpu_only=,backend=,atol=,rtol=,)
class TestPool1d():
    def test_avg_pool_1d():
        input_shape = np.random.randint(low=, high=, size=)
        def build_model():
            return tf.nn.avg_pool1d(x, ksize=kernel_sizes[:], strides=strides[:], padding=pad_type.upper())
        model, inputs, outputs =
        input_values = [random_gen(shape=, rand_min=, rand_max=)]
        input_dict = dict(zip())
        TensorFlowBaseTest.run_compare_tf(model, input_dict, outputs, use_cpu_only=, backend=)
    def test_max_pool_1d():
        input_shape = np.random.randint(low=, high=, size=)
        def build_model():
            return tf.nn.max_pool1d(x, ksize=kernel_sizes[:], strides=strides[:], padding=pad_type.upper())
        model, inputs, outputs =
        input_values = [random_gen(shape=, rand_min=, rand_max=)]
        input_dict = dict(zip())
        TensorFlowBaseTest.run_compare_tf(model, input_dict, outputs, use_cpu_only=, backend=)
class TestPool2d():
    def test_avg_pool_2d():
        input_shape = np.random.randint(low=, high=, size=)
        def build_model():
            return tf.nn.avg_pool(x, ksize=kernel_sizes[:], strides=strides[:], padding=pad_type.upper())
        model, inputs, outputs =
        input_values = [random_gen(shape=, rand_min=, rand_max=)]
        input_dict = dict(zip())
        TensorFlowBaseTest.run_compare_tf(model, input_dict, outputs, use_cpu_only=, backend=)
    def test_max_pool_2d():
        input_shape = np.random.randint(low=, high=, size=)
        def build_model():
            return tf.nn.max_pool(x, ksize=kernel_sizes[:], strides=strides[:], padding=pad_type.upper())
        model, inputs, outputs =
        input_values = [random_gen(shape=, rand_min=, rand_max=)]
        input_dict = dict(zip())
        TensorFlowBaseTest.run_compare_tf(model, input_dict, outputs, use_cpu_only=, backend=)
class TestPool3d():
    def test_avg_pool_3d():
        input_shape = np.random.randint(low=, high=, size=)
        def build_model():
            return tf.nn.avg_pool3d(x, ksize=kernel_sizes[:], strides=strides[:], padding=pad_type.upper())
        model, inputs, outputs =
        input_values = [random_gen(shape=, rand_min=, rand_max=)]
        input_dict = dict(zip())
        TensorFlowBaseTest.run_compare_tf(model, input_dict, outputs, use_cpu_only=, backend=)
    def test_max_pool_3d():
        input_shape = np.random.randint(low=, high=, size=)
        def build_model():
            return tf.nn.max_pool3d(x, ksize=kernel_sizes[:], strides=strides[:], padding=pad_type.upper())
        model, inputs, outputs =
        input_values = [random_gen(shape=, rand_min=, rand_max=)]
        input_dict = dict(zip())
        TensorFlowBaseTest.run_compare_tf(model, input_dict, outputs, use_cpu_only=, backend=)
class TestPrint():
    def test_print():
        shape = np.random.randint(low=, high=, size=).astype()
        def build_model():
            res =
            return res
        model, inputs, outputs =
        input_value = [random_gen(shape=, rand_min=, rand_max=)]
        input_dict = dict(zip())
        TensorFlowBaseTest.run_compare_tf(model, input_dict, outputs, use_cpu_only=, backend=)
class TestRandom():
    def test_random_binomial():
        if not constant and backend != "":
            return
        shape = np.random.randint(low=, high=, size=).astype()
        with tf.Graph().as_default() as graph:
            x = tf.placeholder(tf.float32, shape=)
            if constant:
                ref = tf.add(x, tf.keras.backend.random_binomial(shape=, p=))
            else:
                ref = tf.add(x,tf.keras.backend.random_binomial(shape=tf.raw_ops.Shape(input=), p=),)
            TensorFlowBaseTest.run_compare_tf(graph,{x:},ref,use_cpu_only=,backend=,)
    def test_random_categorical():
        shape = np.random.randint(low=, high=, size=)
        with tf.Graph().as_default() as graph:
            x = tf.placeholder(tf.float32, shape=)
            ref = tf.random.categorical()
            TensorFlowBaseTest.run_compare_tf(graph,{x:},ref,use_cpu_only=,validate_shapes_only=,backend=,)
    def test_random_normal():
        if not constant and backend != "":
            return
        shape = np.random.randint(low=, high=, size=).astype()
        with tf.Graph().as_default() as graph:
            x = tf.placeholder(tf.float32, shape=)
            if constant:
                ref = tf.add(x, tf.random.normal(shape=, mean=, stddev=))
            else:
                ref = tf.add(x,tf.random.normal(shape=tf.raw_ops.Shape(input=), mean=, stddev=),)
            TensorFlowBaseTest.run_compare_tf(graph,{x:},ref,use_cpu_only=,backend=,)
    def test_keras_random_normal():
        if not constant and backend != "":
            return
        shape = np.random.randint(low=, high=, size=).astype()
        with tf.Graph().as_default() as graph:
            x = tf.placeholder(tf.float32, shape=)
            if constant:
                ref = tf.add(x,tf.keras.backend.random_normal(shape=, mean=, stddev=),)
            else:
                ref = tf.add(x,tf.keras.backend.random_normal(shape=tf.raw_ops.Shape(input=), mean=, stddev=),)
            TensorFlowBaseTest.run_compare_tf(graph,{x:},ref,use_cpu_only=,backend=,)
    def test_random_uniform():
        if not constant and backend != "":
            return
        shape = np.random.randint(low=, high=, size=).astype()
        with tf.Graph().as_default() as graph:
            x = tf.placeholder(tf.float32, shape=)
            if constant:
                ref = tf.add(x, tf.random.uniform(shape=, minval=, maxval=))
            else:
                ref = tf.add(x,tf.random.uniform(shape=tf.raw_ops.Shape(input=), minval=, maxval=),)
            TensorFlowBaseTest.run_compare_tf(graph,{x:},ref,use_cpu_only=,backend=,)
    def test_keras_random_uniform():
        if not constant and backend != "":
            return
        shape = np.random.randint(low=, high=, size=).astype()
        with tf.Graph().as_default() as graph:
            x = tf.placeholder(tf.float32, shape=)
            if constant:
                ref = tf.add(x,tf.keras.backend.random_uniform(shape=, minval=, maxval=),)
            else:
                ref = tf.add(x,tf.keras.backend.random_uniform(shape=tf.raw_ops.Shape(input=), minval=, maxval=),)
            TensorFlowBaseTest.run_compare_tf(graph,{x:},ref,use_cpu_only=,backend=,)
class TestReduction():
    def test_reduction():
        rank, axes =
        shape = np.random.randint(low=, high=, size=)
        def parse_axes():
            if axes is None:
                axes =
            elif isinstance(axes, ()):
                axes = axes[]
            return axes
        def test_tf_argmax():
            def build_model():
                return tf.math.argmax(x, axis=parse_axes())
            model, inputs, outputs =
            input_values = [random_gen(shape, rand_min=, rand_max=)]
            input_dict = dict(zip())
            TensorFlowBaseTest.run_compare_tf(model,input_dict,outputs,use_cpu_only=,backend=,)
        def test_tf_argmin():
            def build_model():
                return tf.math.argmin(x, axis=parse_axes())
            model, inputs, outputs =
            input_values = [random_gen(shape, rand_min=, rand_max=)]
            input_dict = dict(zip())
            TensorFlowBaseTest.run_compare_tf(model,input_dict,outputs,use_cpu_only=,backend=,)
        def test_tf_reduction():
            if isinstance() and axes and len() == rank and not keep_dims:
                return
            if tf_op in {}:
                return
            input_type = list()
            x_val = random_gen(shape=, rand_min=, rand_max=)
            if tf_op in {}:
                input_type += []
                x_val = np.random.randint(low=, high=, size=).astype()
            elif tf_op in {}:
                x_val = random_gen(shape=, rand_min=, rand_max=)
            elif tf_op in {}:
                x_val = random_gen(shape=, rand_min=, rand_max=)
            elif tf_op in {}:
                x_val = random_gen(shape=, rand_min=, rand_max=)
            def build_model():
                ref = tf_op(x, axis=, keepdims=)
                if tf_op == tf.reduce_any:
                    ref = tf.cast()
                return ref
            model, inputs, outputs =
            input_values = [random_gen(shape, rand_min=, rand_max=)]
            input_dict = dict(zip(inputs, []))
            TensorFlowBaseTest.run_compare_tf(model,input_dict,outputs,use_cpu_only=,backend=,)
        if tf_op in {}:
            test_tf_argmax()
        elif tf_op in {}:
            test_tf_argmin()
        else:
            test_tf_reduction()
class TestGather():
    def test_gather_function():
        x_rank, indices_rank, axis =
        x_shape = np.random.randint(low=, high=, size=)
        indices_shape = np.random.randint(low=, high=, size=)
        def build_model():
            if mode == "":
                res = tf.raw_ops.Gather(params=, indices=)
            elif mode == "":
                res = tf.raw_ops.GatherV2(params=, indices=, axis=)
            elif mode == "":
                res = tf.gather(x, indices, axis=)
            return res
        model, inputs, outputs =
        axis = 0 if mode ==
        input_dict = {inputs[]:,inputs[]:,,,}
        TensorFlowBaseTest.run_compare_tf(model,input_dict,outputs,use_cpu_only=,frontend_only=,backend=,)
    def test_gather_nd():
        x_rank, indices_rank =
        x_shape = np.random.randint(low=, high=, size=)
        indices_shape = np.random.randint(low=, high=, size=)
        indices_shape[] = np.random.randint(low=, high=)
        def build_model():
            return tf.gather_nd()
        model, inputs, outputs =
        a = np.random.rand().astype()
        indices_list = []
        for i in range(indices_shape[]):
            indices_list.append(np.random.randint(0, x_shape[], size=indices_shape[:]))
        input_dict = {inputs[]:,inputs[]:,,}
        TensorFlowBaseTest.run_compare_tf(model,input_dict,outputs,use_cpu_only=,frontend_only=,backend=,)
class TestScatter():
    def test_scatter_nd_with_zeros():
        shape = np.random.randint(low=, high=, size=).astype()
        indices_shape = np.random.randint(low=, high=, size=)
        indices_shape[] = np.random.randint(low=, high=)
        updates_shape = list(indices_shape[:]) + list(shape[indices_shape[] :])
        updates = np.random.rand().astype()
        indices_list = []
        for i in range(indices_shape[]):
            indices_list.append(np.random.randint(0, shape[], size=indices_shape[:]))
        indices = np.stack(indices_list, axis=).astype()
        def build_model():
            return tf.raw_ops.ScatterNd(indices=, updates=, shape=)
        model, inputs, outputs =
        input_values = []
        input_dict = dict(zip())
        TensorFlowBaseTest.run_compare_tf(model,input_dict,outputs,use_cpu_only=,frontend_only=,backend=,)
class TestSliceByIndex():
    def test_slice_by_index():
        input_shape = np.random.randint(low=, high=, size=)
        begin_val = np.array([np.random.randint(low=-input_shape[], high=input_shape[])for i in range()]).astype()
        end_val = np.array([np.random.randint(low=-input_shape[], high=input_shape[])for i in range()]).astype()
        stride_val = np.array([np.random.randint(low=-input_shape[], high=input_shape[])for i in range()]).astype()
        if not masking:
            begin_mask = [] * rank
            end_mask = [] * rank
            squeeze_mask = [] * rank
        else:
            begin_mask = np.array([np.random.choice([]) for i in range()]).astype()
            end_mask = np.array([np.random.choice([]) for i in range()]).astype()
            squeeze_flag =
            while squeeze_flag:
                squeeze_mask = np.array([np.random.choice([]) for i in range()]).astype()
                for i in range():
                    if begin_mask[] or end_mask[]:
                        squeeze_mask[] =
                for s in squeeze_mask:
                    if not s:
                        squeeze_flag =
        for i in range():
            if begin_mask[] or end_mask[]:
                stride =
                while stride == 0:
                    stride = np.random.randint(low=-input_shape[], high=input_shape[])
                stride_val[] =
                if not end_mask[]:
                    while True:
                        end = np.random.randint(low=-input_shape[], high=input_shape[])
                        normalized_end = input_shape[] + end if end < 0 else end
                        if normalized_end == 0 and stride_val[] > 0:
                            continue
                        elif normalized_end == input_shape[] - 1 and stride_val[] < 0:
                            continue
                        else:
                            end_val[] =
                            break
                continue
            if squeeze_mask[]:
                stride_val[] =
            while True:
                end = np.random.randint(low=-input_shape[], high=input_shape[])
                normalized_end = input_shape[] + end if end < 0 else end
                normalized_begin = (input_shape[] + begin_val[] if begin_val[] < 0 else begin_val[])
                if normalized_end == normalized_begin:
                    continue
                if begin_mask[] or end_mask[] or squeeze_mask[]:
                    stride =
                elif normalized_end < normalized_begin:
                    stride = -np.random.randint(low=, high=input_shape[])
                else:
                    stride = np.random.randint(low=, high=input_shape[])
                end_val[] =
                stride_val[] =
                break
        def _mask_to_bit():
            ret =
            for x in mask[::-1]:
                ret <<= 1
                if x:
                    ret += 1
            return ret
        def build_model():
            return tf.strided_slice(x,begin,end,stride_val,begin_mask=_mask_to_bit(),end_mask=_mask_to_bit(),shrink_axis_mask=_mask_to_bit(),)
        model, inputs, outputs =
        input_values = [np.array(list(range(np.prod()))).reshape().astype(),begin_val,end_val,]
        input_dict = dict(zip())
        TensorFlowBaseTest.run_compare_tf(model,input_dict,outputs,use_cpu_only=,frontend_only=,backend=,)
    def test_slice_by_index_from_scratch():
        input_shape = np.array([])
        def build_model():
            return x[]
        model, inputs, outputs =
        input_values = [np.array(list(range(np.prod()))).reshape().astype()]
        input_dict = dict(zip())
        TensorFlowBaseTest.run_compare_tf(model,input_dict,outputs,use_cpu_only=,frontend_only=,backend=,)
    def test_slice_by_index_smoke():
        input_shape = []
        x_val = np.random.rand().astype()
        y_val = np.random.rand().astype()
        def build_model():
            x_slice = x[:, :, 0]
            y_slice = y[:, :, 0]
            return ()
        model, inputs, outputs =
        input_values = []
        input_dict = dict(zip())
        TensorFlowBaseTest.run_compare_tf(model,input_dict,outputs,use_cpu_only=,frontend_only=,backend=,)
    def test_slice_by_index_with_new_axes():
        input_shape = []
        val = np.random.rand().astype()
        num_cases =
        def build_model():
            a, b, c, d, e, f, g, h =
            slice_0 = a[:, tf.newaxis, :, :]
            slice_1 = b[:, tf.newaxis]
            slice_2 = c[]
            slice_3 = d[..., tf.newaxis, :, 10]
            slice_4 = e[:, 2, tf.newaxis, ...]
            slice_5 = f[2, ..., :, tf.newaxis]
            slice_6 = g[]
            slice_7 = h[]
            return ()
        model, inputs, outputs =
        input_values = [] * num_cases
        input_dict = dict(zip())
        TensorFlowBaseTest.run_compare_tf(model,input_dict,outputs,use_cpu_only=,frontend_only=,backend=,)
class TestSliceBySize():
    def test_slice_by_size():
        input_shape = np.random.randint(low=, high=, size=)
        begin_val = np.array([np.random.randint(input_shape[]) for i in range()]).astype()
        size_val = np.array([np.random.randint(input_shape[] - begin_val[]) + 1 for i in range()])
        if single_size:
            for r in range():
                size_val_r = np.array([s if i ==, s in enumerate()]).astype()
                def build_model():
                    return tf.slice()
                def build_model_dynamic_size():
                    return tf.slice()
                if dynamic_size:
                    model, inputs, outputs =
                    input_values = [random_gen(input_shape, rand_min=, rand_max=),begin_val,size_val_r,]
                else:
                    model, inputs, outputs =
                    input_values = [random_gen(input_shape, rand_min=, rand_max=),begin_val,]
                input_dict = dict(zip())
                TensorFlowBaseTest.run_compare_tf(model,input_dict,outputs,use_cpu_only=,frontend_only=,backend=,)
        else:
            size_val = np.array([s if np.random.randint() ==).astype()
            def build_model():
                return tf.slice()
            def build_model_dynamic_size():
                return tf.slice()
            if dynamic_size:
                model, inputs, outputs =
                input_values = [random_gen(input_shape, rand_min=, rand_max=),begin_val,size_val,]
            else:
                model, inputs, outputs =
                input_values = [random_gen(input_shape, rand_min=, rand_max=),begin_val,]
            input_dict = dict(zip())
            TensorFlowBaseTest.run_compare_tf(model,input_dict,outputs,use_cpu_only=,frontend_only=,backend=,)
class TestMatrixBandPart():
    def test_matrix_band_part():
        lower, upper =
        shape = np.random.randint(low=, high=, size=)
        def build_model():
            return tf.raw_ops.MatrixBandPart(input=, num_lower=, num_upper=)
        model, inputs, outputs =
        TensorFlowBaseTest.run_compare_tf(model,{inputs[]:,,},outputs,use_cpu_only=,backend=,)
class TestCumSum():
    def test_cumsum():
        input_shape = np.random.randint(low=, high=, size=)
        for axis in range():
            def build_model():
                return tf.math.cumsum(x, axis=, reverse=, exclusive=)
            model, inputs, outputs =
            input_values = [random_gen(input_shape, rand_min=, rand_max=)]
            input_dict = dict(zip())
            TensorFlowBaseTest.run_compare_tf(model,input_dict,outputs,use_cpu_only=,frontend_only=,backend=)
class TestFakeQuant():
    def test_fake_quant_weight_quantization_with_conv():
        tf.reset_default_graph()
        filter_width =
        filter_height =
        spatial_size =
        input_channels =
        output_channels =
        input_tensor = tf.placeholder(tf.float32, [], name=)
        output_tensor = tf.placeholder(tf.float32, [], name=)
        kernel_in = random_gen((), weight_boundaries[], weight_boundaries[])
        init = tf.constant_initializer()
        def model():
            with tf.compat.v1.variable_scope():
                x = tf.layers.conv2d(x, filters=, kernel_size=, strides=, kernel_initializer=)
                return x
        with tf.compat.v1.variable_scope():
            output = model(x=)
        tf.contrib.quantize.experimental_create_training_graph(quant_delay=, weight_bits=,activation_bits=)
        loss = tf.losses.mean_squared_error(labels=, predictions=)
        saver = tf.train.Saver()
        update_ops = tf.get_collection()
        with tf.control_dependencies():
            optimizer = tf.train.AdamOptimizer().minimize()
        checkpoint_dir = tempfile.mkdtemp()
        with tf.Session() as sess:
            tf.global_variables_initializer().run()
            for iter in range():
                image = np.random.rand().astype() * 255
                label = np.random.rand().astype() * 255
                training_loss, _ = sess.run([], feed_dict={input_tensor:,output_tensor:})
            saver.save(sess=, save_path=os.path.join())
        with tf.Graph().as_default() as g:
            input_tensor = tf.placeholder(tf.float32, [], name=)
            with tf.variable_scope():
                output = model(x=)
            tf.contrib.quantize.experimental_create_eval_graph(input_graph=, weight_bits=,activation_bits=)
            with open() as f:
                f.write(g.as_graph_def().SerializeToString())
            freeze_g(input_graph=,input_saver=,input_binary=,input_checkpoint=os.path.join(),output_node_names=,restore_op_name=,filename_tensor_name="save/Const:,output_graph=,clear_devices=,initializer_nodes=)
            shutil.rmtree()
        graph = load_tf_pb()
        tf.reset_default_graph()
        graphdef = tf.GraphDef()
        input_dict = {}
        with open() as f:
            graphdef.ParseFromString(f.read())
        with tf.Graph().as_default(), tf.Session(config=) as sess:
            tf.graph_util.import_graph_def(graphdef, name=)
            input_dict[sess.graph.get_tensor_by_name('input:)] = (np.random.rand().astype())
            outputs = []
            outputs.append(sess.graph.get_tensor_by_name('quantize/quantized_model/conv2d/Conv2D:))
            tf_outs = sess.run(outputs, feed_dict=)
        TensorFlowBaseTest.run_compare_tf(graph,input_dict,[],use_cpu_only=,frontend_only=,backend=,tf_outputs=,rtol=,)
class TestFill():
    def test_fill():
        def test_tf_static():
            shape = np.random.randint(low=, high=, size=)
            def build_model():
                return tf.add(x, tf.fill(dims=np.array(shape, dtype=), value=))
            model, inputs, outputs =
            input_values = [np.random.rand().astype()]
            input_dict = dict(zip())
            TensorFlowBaseTest.run_compare_tf(model,input_dict,outputs,use_cpu_only=,frontend_only=,backend=)
        def test_tf_dynamic():
            shape = np.random.randint(low=, high=, size=)
            def build_model():
                return tf.fill(dims=, value=)
            model, inputs, outputs =
            input_values = [np.array(shape, dtype=)]
            input_dict = dict(zip())
            TensorFlowBaseTest.run_compare_tf(model,input_dict,outputs,use_cpu_only=,frontend_only=,backend=)
        test_tf_static()
        test_tf_dynamic()
class TestNonMaximumSuppression():
    def test_non_max_suppression():
        boxes_val = random_gen(shape=(), rand_min=, rand_max=)
        scores_val = random_gen(shape=(), rand_min=, rand_max=)
        def build_model():
            ret = tf.image.non_max_suppression(boxes=,scores=,max_output_size=,iou_threshold=,score_threshold=,)
            return ret
        model, inputs, outputs =
        input_dict = dict(zip(inputs, []))
        TensorFlowBaseTest.run_compare_tf(model,input_dict,outputs,use_cpu_only=,backend=,)
class TestOneHot():
    def test_one_hot():
        rank, axis =
        depth, on_value, off_value =, 28.0, -4.0
        x_shape = np.random.randint(low=, high=, size=)
        axis = (axis if axis >=)
        if not dynamic:
            def build_model():
                return tf.one_hot(x, axis=, depth=, on_value=, off_value=)
            model, inputs, outputs =
            input_values = [np.random.randint(0, depth, size=).astype()]
            input_dict = dict(zip())
        else:
            def build_model():
                return tf.one_hot(x, axis=, depth=, on_value=, off_value=)
            model, inputs, outputs =
            input_values = [np.random.randint(0, depth, size=).astype(), depth]
            input_dict = dict(zip())
        TensorFlowBaseTest.run_compare_tf(model, input_dict, outputs,use_cpu_only=,frontend_only=, backend=)
class TestPad():
    def test():
        input_shape = np.random.randint(low=, high=, size=)
        min_input_dim_size = input_shape.min()
        padding_val = np.random.randint(low=, high=, size=(), dtype=)
        perm = list(range())
        import random
        random.shuffle()
        if mode != "":
            padding_val[perm[:]] =
        tf_mode = mode.upper()
        if dynamic:
            if mode != "":
                return
            padding_shape =
            def build_model():
                return tf.pad(x, paddings=, mode=)
            model, inputs, outputs =
            input_values = [random_gen(input_shape, rand_min=, rand_max=), padding_val]
            input_dict = dict(zip())
        else:
            def build_model():
                return tf.pad(x, paddings=, mode=)
            model, inputs, outputs =
            input_values = [random_gen(input_shape, rand_min=, rand_max=)]
            input_dict = dict(zip())
        TensorFlowBaseTest.run_compare_tf(model, input_dict, outputs,use_cpu_only=,frontend_only=, backend=)
class TestPadV2():
    def test():
        input_shape = np.random.randint(low=, high=, size=)
        paddings = np.random.randint(low=, high=, size=).astype()
        padding_val = paddings.reshape()
        if dynamic:
            padding_shape =
            def build_model():
                return tf.raw_ops.PadV2(input=, paddings=, constant_values=)
            model, inputs, outputs =
            input_values = [random_gen(input_shape, rand_min=, rand_max=), padding_val]
            input_dict = dict(zip())
        else:
            def build_model():
                return tf.raw_ops.PadV2(input=, paddings=, constant_values=)
            model, inputs, outputs =
            input_values = [random_gen(input_shape, rand_min=, rand_max=)]
            input_dict = dict(zip())
        TensorFlowBaseTest.run_compare_tf(model, input_dict, outputs,use_cpu_only=,frontend_only=, backend=)
class TestRange():
    def test_range():
        start, end, step = np.array().astype()
        def build_model():
            return tf.range(start=, limit=, delta=)
        model, inputs, outputs =
        input_values = []
        input_dict = dict(zip())
        TensorFlowBaseTest.run_compare_tf(model,input_dict,outputs,use_cpu_only=,backend=,)
        def build_model():
            return tf.range(start=, limit=, delta=)
        model, inputs, outputs =
        input_values = []
        input_dict = dict(zip())
        TensorFlowBaseTest.run_compare_tf(model,input_dict,outputs,use_cpu_only=,backend=,)
        def build_model():
            return tf.range(start=, limit=, delta=)
        model, inputs, outputs =
        input_values = []
        input_dict = dict(zip())
        TensorFlowBaseTest.run_compare_tf(model,input_dict,outputs,use_cpu_only=,backend=,)
class TestTile():
    def test_tile():
        rank, reps =
        x_shape = np.random.randint(low=, high=, size=)
        def build_model():
            return tf.tile(x, multiples=)
        model, inputs, outputs =
        input_values = [random_gen()]
        input_dict = dict(zip())
        TensorFlowBaseTest.run_compare_tf(model,input_dict,outputs,use_cpu_only=,backend=,)
class TestDynamicTile():
    def test_tile():
        x_shape = np.random.randint(low=, high=, size=)
        reps_val = np.random.randint(low=, high=, size=)
        with tf.Graph().as_default() as graph:
            x = tf.placeholder(tf.float32, shape=)
            reps = tf.placeholder(tf.int32, shape=)
            res = tf.tile(x, multiples=)
            TensorFlowBaseTest.run_compare_tf(graph,{x:, reps:},res,use_cpu_only=,frontend_only=,backend=,)
class TestTopK():
    def test_top_k():
        shape = np.random.randint(low=, high=, size=)
        def build_model():
            ref = tf.math.top_k(x, k=, sorted=)
            return (ref[], ref[])
        model, inputs, outputs =
        input_values = [random_gen(shape, rand_min=, rand_max=)]
        input_dict = dict(zip())
        TensorFlowBaseTest.run_compare_tf(model,input_dict,outputs,use_cpu_only=,backend=,)
class TestConcat():
    def test_concat():
        import random
        for axis in range():
            input_shape = np.random.randint(low=, high=, size=)
            input_shapes = [input_shape.copy() for _ in range()]
            concat_axis_value = np.random.randint(low=, high=, size=)
            for i, v in enumerate():
                input_shapes[][] = concat_axis_value[]
            def build_model():
                zero_shape = input_shape.copy()
                zero_shape[] =
                const = [tf.constant([], shape=) for _ in range()]
                values = inputs + tuple()
                values = list()
                random.shuffle()
                values = tuple()
                if op_version == "":
                    res = tf.raw_ops.Concat(concat_dim=, values=)
                elif op_version == "":
                    res = tf.raw_ops.ConcatV2(values=, axis=)
                return res
            model, inputs, outputs =
            input_values = [random_gen() for shape in input_shapes]
            input_dict = dict(zip())
            TensorFlowBaseTest.run_compare_tf(model, input_dict, outputs,use_cpu_only=,frontend_only=, backend=)
class TestSplit():
    def test_split():
        input_shape1 = np.random.randint(low=, high=, size=)
        for axis in range():
            for split_num in range(2, input_shape1[] + 1, 2):
                if input_shape1[] % split_num != 0:
                    continue
                tf_input_shape = list()
                if dynamic:
                    axis1 = np.random.randint(low=, high=)
                    tf_input_shape[] =
                def build_model():
                    res = tf.split(x, split_num, axis=)
                    import random
                    random.shuffle()
                    return tuple()
                model, inputs, outputs =
                input_values = [random_gen()]
                input_dict = dict(zip())
                TensorFlowBaseTest.run_compare_tf(model,input_dict,outputs,use_cpu_only=,backend=,)
    def test_split_with_sizes():
        input_shape = ()
        def build_model():
            res = tf.split(x, sizes, axis=)
            return tuple([res[] for i in range(len()) if sizes[] !=)
        model, inputs, outputs =
        input_values = [random_gen()]
        input_dict = dict(zip())
        TensorFlowBaseTest.run_compare_tf(model,input_dict,outputs,use_cpu_only=,backend=,)
    def test_splitv():
        input_shape = []
        def build_model():
            res = tf.split(x, [], axis=)
            return res[], res[]
        model, inputs, outputs =
        input_values = [random_gen()]
        input_dict = dict(zip())
        TensorFlowBaseTest.run_compare_tf(model,input_dict,outputs,use_cpu_only=,backend=,)
class TestStack():
    def test_stack():
        input_shape1 = []
        input_shape2 = []
        def build_model():
            return [tf.stack((), axis=), tf.stack((), axis=)]
        model, inputs, outputs =
        input_values = [random_gen(), random_gen()]
        input_dict = dict(zip())
        TensorFlowBaseTest.run_compare_tf(model,input_dict,outputs,use_cpu_only=,backend=,)
class TestUnstack():
    def test_unstack():
        def build_model():
            return tf.unstack(x, axis=)
        model, inputs, outputs =
        input_values = [random_gen()]
        input_dict = dict(zip())
        TensorFlowBaseTest.run_compare_tf(model,input_dict,outputs,use_cpu_only=,backend=,)
    def test_unstack_and_stack():
        def build_model():
            x = tf.unstack(x, axis=)
            return tf.stack()
        model, inputs, outputs =
        input_values = [random_gen()]
        input_dict = dict(zip())
        TensorFlowBaseTest.run_compare_tf(model,input_dict,outputs,use_cpu_only=,backend=,)
class TestPack():
    def test_pack():
        shape = np.random.randint(low=, high=, size=)
        input_shapes = [shape[:] for _ in range()]
        def build_model():
            return tf.raw_ops.Pack(values=, axis=)
        model, inputs, outputs =
        input_values = [random_gen(shape, rand_min=, rand_max=) for shape in input_shapes]
        input_dict = dict(zip())
        TensorFlowBaseTest.run_compare_tf(model,input_dict,outputs,use_cpu_only=,frontend_only=,backend=,)
class TestArgSort():
    def test_argsort():
        shape = np.random.randint(low=, high=, size=)
        if use_cpu_only:
            dtype =
            tf_dtype =
        else:
            dtype =
            tf_dtype =
        def build_model():
            return tf.argsort(x, axis=, direction=direction.upper())
        model, inputs, outputs =
        input_values = [random_gen(shape, rand_min=, rand_max=, allow_duplicate=, dtype=)]
        input_dict = dict(zip())
        TensorFlowBaseTest.run_compare_tf(model,input_dict,outputs,use_cpu_only=,backend=)
class TestDepthToSpace():
    def test_depth_to_space():
        def build_model():
            return tf.nn.depth_to_space()
        model, inputs, outputs =
        input_values = [random_gen()]
        input_dict = dict(zip())
        TensorFlowBaseTest.run_compare_tf(model,input_dict,outputs,use_cpu_only=,backend=,)
class TestExpandDims():
    def test_expand_dims():
        rank, axis =
        input_shape = np.random.randint(low=, high=, size=)
        def build_model():
            return tf.expand_dims(x, axis=)
        model, inputs, outputs =
        input_values = [np.random.rand().astype()]
        input_dict = dict(zip())
        TensorFlowBaseTest.run_compare_tf(model,input_dict,outputs,use_cpu_only=,frontend_only=,backend=,)
class TestReshape():
    def test_flatten():
        shapes = [[], [], []]
        for input_shape in shapes:
            def build_model():
                return tf.keras.backend.flatten()
            model, inputs, outputs =
            input_values = [np.random.rand().astype()]
            input_dict = dict(zip())
            TensorFlowBaseTest.run_compare_tf(model,input_dict,outputs,use_cpu_only=,frontend_only=,backend=,)
    def test_reshape_static():
        def build_model():
            return tf.reshape(x, shape=input_shape[])
        model, inputs, outputs =
        input_values = [np.random.rand(*input_shape[]).astype()]
        input_dict = dict(zip())
        TensorFlowBaseTest.run_compare_tf(model,input_dict,outputs,use_cpu_only=,frontend_only=,backend=,)
    def test_reshape_dynamic():
        def build_model():
            return tf.reshape(x, shape=)
        model, inputs, outputs =
        input_values = [np.random.rand(*input_shape[]).astype(),np.array(input_shape[], dtype=),]
        input_dict = dict(zip())
        TensorFlowBaseTest.run_compare_tf(model,input_dict,outputs,use_cpu_only=,frontend_only=,backend=,)
    def test_reshape_scalar():
        input_shape = ()
        def build_model():
            return tf.raw_ops.Reshape(tensor=, shape=)
        model, inputs, outputs =
        input_values = [np.random.rand()]
        input_dict = dict(zip())
        TensorFlowBaseTest.run_compare_tf(model,input_dict,outputs,use_cpu_only=,frontend_only=,backend=,)
class TestShape():
    def test_shape():
        shape = np.random.randint(low=, high=, size=)
        shape_holder = [] * rank
        def build_model():
            return tf.shape()
        model, inputs, outputs =
        input_values = [random_gen(shape, rand_min=, rand_max=)]
        input_dict = dict(zip())
        TensorFlowBaseTest.run_compare_tf(model,input_dict,outputs,use_cpu_only=,frontend_only=,backend=,)
class TestMatrixDiag():
    def test():
        if dynamic:
            return
            input_shape = np.random.randint(low=, high=, size=)
            a, b = np.prod(input_shape[:]), np.prod(input_shape[2:])
            size = np.array([]).astype()
            reshape_shape = []
            def build_model():
                x = tf.reshape()
                x = tf.reshape(x, [])
                return tf.raw_ops.MatrixDiag(diagonal=)
            model, inputs, outputs =
            input_values = [random_gen(), size]
        else:
            input_shape = []
            def build_model():
                return tf.raw_ops.MatrixDiag(diagonal=)
            model, inputs, outputs =
            input_values = [random_gen()]
        input_dict = dict(zip())
        TensorFlowBaseTest.run_compare_tf(model, input_dict, outputs,use_cpu_only=,frontend_only=, backend=)
class TestReverse():
    def test_reverse():
        rank, axes =
        shape = np.random.randint(low=, high=, size=)
        def build_model():
            return tf.reverse(x, axis=)
        model, inputs, outputs =
        input_values = [random_gen()]
        input_dict = dict(zip())
        TensorFlowBaseTest.run_compare_tf(model,input_dict,outputs,use_cpu_only=,backend=,)
class TestReverseSequence():
    def test_reverse_sequence():
        shape = np.random.randint(low=, high=, size=)
        seq_axis = np.random.randint(low=, high=)
        batch_axis = np.random.randint(low=, high=)
        lengths = np.random.randint(low=, high=shape[], size=shape[])
        def build_model():
            return tf.reverse_sequence(x, seq_lengths=, seq_axis=, batch_axis=)
        model, inputs, outputs =
        input_values = [random_gen()]
        input_dict = dict(zip())
        TensorFlowBaseTest.run_compare_tf(model,input_dict,outputs,use_cpu_only=,backend=,)
class TestSpaceToDepth():
    def test_space_to_depth():
        def build_model():
            return tf.nn.space_to_depth()
        model, inputs, outputs =
        input_values = [random_gen()]
        input_dict = dict(zip())
        TensorFlowBaseTest.run_compare_tf(model,input_dict,outputs,use_cpu_only=,backend=,)
class TestSqueeze():
    def test_squeeze():
        rank, axes =
        x_shape = np.random.randint(low=, high=, size=)
        for axis in axes:
            x_shape[] =
        def build_model():
            return tf.squeeze(x, axis=)
        model, inputs, outputs =
        input_values = [np.random.rand().astype()]
        input_dict = dict(zip())
        TensorFlowBaseTest.run_compare_tf(model,input_dict,outputs,use_cpu_only=,frontend_only=,backend=,)
class TestTranspose():
    def test_transpose_1():
        rank, perm =
        x_shape = np.random.randint(low=, high=, size=)
        def build_model():
            return tf.transpose(x, perm=)
        model, inputs, outputs =
        input_values = [random_gen()]
        input_dict = dict(zip())
        TensorFlowBaseTest.run_compare_tf(model,input_dict,outputs,use_cpu_only=,backend=,)
    def test_transpose_2():
        input_shape = np.random.randint(low=, high=, size=)
        perm = np.random.permutation()
        def static_perm():
            def build_model():
                return tf.transpose(x, perm=)
            model, inputs, outputs =
            input_values = [random_gen()]
            input_dict = dict(zip())
            TensorFlowBaseTest.run_compare_tf(model,input_dict,outputs,use_cpu_only=,backend=,)
        def dynamic_perm():
            def build_model():
                return tf.transpose(x, perm=)
            model, inputs, outputs =
            input_values = [random_gen(), perm.astype()]
            input_dict = dict(zip())
            TensorFlowBaseTest.run_compare_tf(model,input_dict,outputs,use_cpu_only=,backend=,)
        static_perm()
        with pytest.raises(ValueError, match=):
            dynamic_perm()
    def test_redundant_transpose():
        import random
        input_shape = np.random.randint(low=, high=, size=)
        num_layers =
        perms = []
        for _ in range():
            perm = list(range())
            random.shuffle()
            perms.append()
        def build_model():
            net =
            for perm in perms:
                net = tf.transpose(net, perm=)
            return net
        model, inputs, outputs =
        input_values = [random_gen()]
        input_dict = dict(zip())
        TensorFlowBaseTest.run_compare_tf(model,input_dict,outputs,use_cpu_only=,frontend_only=,backend=,)
class TestSpaceToBatchND():
    def test_smoke():
        def build_model():
            return tf.raw_ops.SpaceToBatchND(input=, block_shape=, paddings=)
        model, inputs, outputs =
        input_values = [random_gen()]
        input_dict = dict(zip())
        TensorFlowBaseTest.run_compare_tf(model,input_dict,outputs,use_cpu_only=,frontend_only=,backend=,)
    def test_programmatic():
        input_rank, block_rank =
        input_shape = np.random.randint(low=, high=, size=)
        block_shape = np.random.randint(low=, high=, size=)
        paddings = []
        for i in range():
            while True:
                temp = np.random.randint(low=, high=, size=)
                if (np.sum() + input_shape[]) % block_shape[] == 0:
                    paddings.append()
                    break
        paddings = np.array()
        if not dynamic:
            def build_model():
                return tf.raw_ops.SpaceToBatchND(input=, block_shape=, paddings=)
        else:
            def build_model():
                return tf.raw_ops.SpaceToBatchND(input=, block_shape=, paddings=)
        model, inputs, outputs =
        input_values = [random_gen()]
        input_dict = dict(zip())
        TensorFlowBaseTest.run_compare_tf(model,input_dict,outputs,use_cpu_only=,frontend_only=,backend=,)
class TestBatchToSpaceND():
    def test_smoke():
        def build_model():
            return tf.raw_ops.BatchToSpaceND(input=, block_shape=, crops=)
        model, inputs, outputs =
        input_values = [random_gen()]
        input_dict = dict(zip())
        TensorFlowBaseTest.run_compare_tf(model,input_dict,outputs,use_cpu_only=,frontend_only=,backend=,)
    def test_programmatic():
        input_rank, block_rank =
        input_shape = np.random.randint(low=, high=, size=)
        block_shape = np.random.randint(low=, high=, size=)
        input_shape[] = input_shape[] * np.prod()
        crops = []
        for i in range():
            while True:
                temp = np.random.randint(low=, high=, size=)
                if np.sum() < input_shape[] * block_shape[]:
                    crops.append()
                    break
        crops = np.array()
        if not dynamic:
            def build_model():
                return tf.raw_ops.BatchToSpaceND(input=, block_shape=, crops=)
        else:
            def build_model():
                return tf.raw_ops.BatchToSpaceND(input=, block_shape=, crops=)
        model, inputs, outputs =
        input_values = [random_gen()]
        input_dict = dict(zip())
        TensorFlowBaseTest.run_compare_tf(model,input_dict,outputs,use_cpu_only=,frontend_only=,backend=,)
class TestTensorArray():
    def test_tf_basic():
        elem_shape = ()
        def build_model():
            ta = tf.TensorArray(dtype=, size=, dynamic_size=)
            ta = ta.write()
            ta = ta.scatter([], tf.expand_dims())
            ta = ta.scatter([], tf.expand_dims())
            return ta.stack()
        model, inputs, outputs =
        input_values = [random_gen()]
        input_dict = dict(zip())
        TensorFlowBaseTest.run_compare_tf(model,input_dict,outputs,use_cpu_only=,frontend_only=,backend=,)
    def test_tf_dynamic_elem_shape():
        if backend != "":
            return
        elem_shape = ()
        def build_model():
            ta = tf.TensorArray(dtype=, size=, dynamic_size=)
            ta = ta.write()
            ta = ta.write()
            ta = ta.scatter([], tf.expand_dims())
            ta = ta.scatter([], tf.expand_dims())
            return ta.stack()
        model, inputs, outputs =
        input_values = [random_gen(())]
        input_dict = dict(zip())
        TensorFlowBaseTest.run_compare_tf(model,input_dict, outputs,use_cpu_only=,frontend_only=, backend=)
    def test_tf_while_loop():
        def build_model():
            def body():
                return i + 1, num_iters, array.write(), update
            def cond():
                return i < num_iters
            i =
            max_iters =
            ta = tf.TensorArray(dtype=, size=, dynamic_size=)
            _, _, new_ta, _ = tf.while_loop(cond, body, [])
            new_ta = new_ta.scatter([], tf.expand_dims())
            return new_ta.stack()
        model, inputs, outputs =
        input_values = [random_gen(shape=())]
        input_dict = dict(zip())
        TensorFlowBaseTest.run_compare_tf(model, input_dict, outputs, use_cpu_only=, backend=)
class TestBroadcastTo():
    def test():
        input_shape, output_shape =
        if is_dynamic is False:
            def build_model():
                return tf.broadcast_to()
        else:
            def build_model():
                return tf.broadcast_to()
        model, inputs, outputs =
        if is_dynamic is False:
            input_values = [random_gen()]
        else:
            input_values = [random_gen(),np.array(output_shape, dtype=),]
        input_dict = dict(zip())
        TensorFlowBaseTest.run_compare_tf(model, input_dict, outputs, use_cpu_only=, backend=)
class TestLSTMBlockCell():
    def test_tf_no_variable():
        from tensorflow.contrib.rnn.python.ops.lstm_ops import _lstm_block_cell
        actual_len, padded_len =, 4
        input_dim, hidden_dim =, 3
        x_shape = ()
        init_h = np.random.rand().astype()
        init_c = np.random.rand().astype()
        with tf.Graph().as_default() as graph:
            x = tf.placeholder(tf.float32, shape=)
            res = _lstm_block_cell(x,tf.constant(),tf.constant(),w=tf.constant(np.random.rand().astype()),b=tf.constant(np.random.rand().astype()),use_peephole=,wci=tf.constant(np.random.rand().astype()),wcf=tf.constant(np.random.rand().astype()),wco=tf.constant(np.random.rand().astype()),forget_bias=np.random.rand(),cell_clip=np.random.rand() if has_clip else -1,)
            if return_hc_only:
                res = res[], res[]
            TensorFlowBaseTest.run_compare_tf(graph,{x:,},res,use_cpu_only=,frontend_only=,backend=,)
    def test_tf_lstm_block_cell():
        actual_len, padded_len =, 4
        input_dim, hidden_dim =, 3
        x_shape = ()
        init_h = np.random.rand().astype()
        init_c = np.random.rand().astype()
        with tf.Graph().as_default() as graph:
            x = tf.placeholder(tf.float32, shape=)
            rnn_cell = tf.contrib.rnn.LSTMBlockCell(hidden_dim, use_peephole=, forget_bias=np.random.rand())
            res = rnn_cell(x, ())
            cs_new, h_new = res[][], res[][]
            res = []
            TensorFlowBaseTest.run_compare_tf(graph,{x:,},res,use_cpu_only=,frontend_only=,backend=,freeze_graph=,)
class TestVariable():
    def test_tf_no_variable():
        with tf.Graph().as_default() as graph:
            x = tf.placeholder(tf.float32, shape=[], name=)
            y = tf.Variable([], dtype=, name=)
            assign_op = tf.assign()
            with tf.control_dependencies([]):
                res = tf.multiply(x, y, name=)
            TensorFlowBaseTest.run_compare_tf(graph,{x:,},res,use_cpu_only=,frontend_only=,backend=,)
class TestZerosLike():
    def test():
        input_shape = np.random.randint(low=, high=, size=)
        input_value = random_gen(input_shape, rand_min=, rand_max=)
        if dynamic:
            a, b = np.prod(input_shape[:]), np.prod(input_shape[2:])
            reshape_vals = np.array([], dtype=)
            reshape_input_shape = np.array([], dtype=)
            def build_model():
                x = tf.reshape(x, shape=)
                return tf.raw_ops.ZerosLike(x=)
            model, inputs, outputs =
            input_values = []
        else:
            def build_model():
                return tf.raw_ops.ZerosLike(x=)
            model, inputs, outputs =
            input_values = []
        input_dict = dict(zip())
        TensorFlowBaseTest.run_compare_tf(model,input_dict,outputs,use_cpu_only=,frontend_only=,backend=,)
class TestIsFinite():
    def test():
        def _generate_num_with_inf():
            res = random_gen(input_shape, rand_min=, rand_max=)
            random_map = np.random.choice([], size=)
            if len() == 0:
                return random_map.astype()
            res[np.where(random_map ==)] =
            res[np.where(random_map ==)] =
            return res.astype()
        input_shape = np.random.randint(low=, high=, size=)
        input_value = _generate_num_with_inf()
        if dynamic:
            reshape_shape = []
            if len() == 0:
                reshape_value = np.array([], dtype=)
            else:
                reshape_value = np.array([input_shape[], np.prod(input_shape[1:])], dtype=)
            def build_model():
                x = tf.reshape()
                x = tf.raw_ops.IsFinite(x=)
                return tf.raw_ops.Cast(x=, DstT=)
            model, inputs, outputs =
            input_values = []
        else:
            def build_model():
                x = tf.raw_ops.IsFinite(x=)
                return tf.raw_ops.Cast(x=, DstT=)
            model, inputs, outputs =
            input_values = []
        input_dict = dict(zip())
        TensorFlowBaseTest.run_compare_tf(model,input_dict,outputs,use_cpu_only=,frontend_only=,backend=,)
class TestLogSoftMax():
    def test():
        input_shape = ()
        input_value = random_gen(input_shape, rand_min=, rand_max=)
        def build_model():
            return tf.math.log_softmax()
        model, inputs, outputs =
        input_values = []
        input_dict = dict(zip())
        TensorFlowBaseTest.run_compare_tf(model, input_dict, outputs,use_cpu_only=,frontend_only=, backend=)
class TestClipByValue():
    def test():
        input_shape = np.random.randint(low=, high=, size=)
        min_val, max_val =
        input_value = random_gen(input_shape, rand_min=, rand_max=)
        def build_model():
            return tf.raw_ops.ClipByValue(t=, clip_value_min=, clip_value_max=)
        model, inputs, outputs =
        input_values = []
        input_dict = dict(zip())
        TensorFlowBaseTest.run_compare_tf(model, input_dict, outputs,use_cpu_only=,frontend_only=, backend=)
class TestSize():
    def test():
        input_shape = np.random.randint(low=, high=, size=)
        input_value = random_gen(input_shape, rand_min=, rand_max=)
        if dynamic:
            a, b = np.prod(input_shape[:]), np.prod(input_shape[2:])
            reshape_vals = np.array([], dtype=)
            reshape_input_shape = np.array([], dtype=)
            def build_model():
                x = tf.reshape(x, shape=)
                return tf.raw_ops.Size(input=)
            model, inputs, outputs =
            input_values = []
        else:
            def build_model():
                return tf.raw_ops.Size(input=)
            model, inputs, outputs =
            input_values = []
        input_dict = dict(zip())
        TensorFlowBaseTest.run_compare_tf(model, input_dict, outputs,use_cpu_only=,frontend_only=, backend=)
class TestAudioSpectrogram():
    def test_audio_spectrogram():
        input_shape = params[]
        window_size = params[]
        stride = params[]
        def build_model():
            y = tf.raw_ops.AudioSpectrogram(input=,window_size=,stride=,magnitude_squared=)
            return y
        model, inputs, outputs =
        input_values = [(2 * np.random.rand() - 1).astype()]
        input_dict = dict(zip())
        TensorFlowBaseTest.run_compare_tf(model,input_dict,outputs,use_cpu_only=,frontend_only=,backend=,)
class TestMfcc():
    def test_mfcc():
        input_shape = params[]
        window_size = params[]
        stride = params[]
        sample_rate = params[]
        lower_frequency_limit, upper_frequency_limit = params[]
        filterbank_channel_count = params[]
        dct_coefficient_count = params[]
        def build_model():
            y = tf.raw_ops.AudioSpectrogram(input=,window_size=,stride=,magnitude_squared=)
            y_out = tf.raw_ops.Mfcc(spectrogram=,sample_rate=,upper_frequency_limit=,lower_frequency_limit=,filterbank_channel_count=,dct_coefficient_count=)
            return y_out
        model, inputs, outputs =
        input_values = [(2 * np.random.rand() - 1).astype()]
        input_dict = dict(zip())
        TensorFlowBaseTest.run_compare_tf(model,input_dict,outputs,use_cpu_only=,frontend_only=,backend=,)
import tensorflow as tf
from tensorflow.examples.tutorials.mnist import input_data
mnist = input_data.read_data_sets("", one_hot=)
learning_rate =
total_epoch =
batch_size =
n_input =
n_step =
n_hidden =
n_class =
X = tf.placeholder(tf.float32, [])
Y = tf.placeholder(tf.float32, [])
W = tf.Variable(tf.random_normal([]))
b = tf.Variable(tf.random_normal([]))
cell = tf.nn.rnn_cell.BasicRNNCell()
outputs, states = tf.nn.dynamic_rnn(cell, X, dtype=)
outputs = tf.transpose(outputs, [])
outputs = outputs[]
model = tf.matmul() + b
cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=, labels=))
optimizer = tf.train.AdamOptimizer().minimize()
sess = tf.Session()
sess.run(tf.global_variables_initializer())
total_batch = int()
for epoch in range():
    total_cost =
    for i in range():
        batch_xs, batch_ys = mnist.train.next_batch()
        batch_xs = batch_xs.reshape(())
        _, cost_val = sess.run([],feed_dict={X:, Y:})
        total_cost +=
is_correct = tf.equal(tf.argmax(), tf.argmax())
accuracy = tf.reduce_mean(tf.cast())
test_batch_size = len()
test_xs = mnist.test.images.reshape()
test_ys =
import numpy as np
import tensorflow as tf
import xlrd
import matplotlib.pyplot as plt
import os
from sklearn.utils import check_random_state
n =
XX = np.arange()
rs = check_random_state()
YY = rs.randint(-20, 20, size=()) + 2.0 * XX
data = np.stack([], axis=)
tf.app.flags.DEFINE_integer("", 50, "")
FLAGS =
W = tf.Variable(0.0, name=)
b = tf.Variable(0.0, name=)
def inputs():
    X = tf.placeholder(tf.float32, name=)
    Y = tf.placeholder(tf.float32, name=)
    return X,Y
def inference():
    return X * W + b
def loss():
    Y_predicted = inference()
    return tf.reduce_sum(tf.squared_difference())/(2*data.shape[])
def train():
    learning_rate =
    return tf.train.GradientDescentOptimizer().minimize()
with tf.Session() as sess:
    sess.run(tf.global_variables_initializer())
    X, Y = inputs()
    train_loss = loss()
    train_op = train()
    for epoch_num in range():
        loss_value, _ = sess.run([],feed_dict={X: data[:,, Y: data[:,})
        wcoeff, bias = sess.run([])
Input_values = data[:,0]
Labels = data[:,1]
Prediction_values = data[:,0] * wcoeff + bias
import matplotlib.pyplot as plt
import numpy as np
import tensorflow as tf
from sklearn import datasets
import random
import sys
tf.app.flags.DEFINE_integer()
tf.app.flags.DEFINE_integer()
tf.app.flags.DEFINE_boolean()
tf.app.flags.DEFINE_float()
tf.app.flags.DEFINE_float()
tf.app.flags.DEFINE_float()
tf.app.flags.DEFINE_float()
FLAGS =
def loss_fn():
    logits = tf.subtract(tf.matmul(),b)
    norm_term = tf.divide(tf.reduce_sum(tf.multiply(tf.transpose(),W)),2)
    classification_loss = tf.reduce_mean(tf.maximum(0., tf.subtract(FLAGS.delta, tf.multiply())))
    total_loss = tf.add(tf.multiply(), tf.multiply())
    return total_loss
def inference_fn():
    prediction = tf.sign(tf.subtract(tf.matmul(), b))
    accuracy = tf.reduce_mean(tf.cast(tf.equal(), tf.float32))
    return accuracy
def next_batch_fn(x_train,y_train,num_samples=):
    index = np.random.choice(len(), size=)
    X_batch = x_train[]
    y_batch = np.transpose([y_train[]])
    return X_batch, y_batch
iris = datasets.load_iris()
X = iris.data[:, :]
y = np.array([1 if label==)
my_randoms = np.random.choice(X.shape[], X.shape[], replace=)
train_indices = my_randoms[0:int(0.5 * X.shape[])]
test_indices = my_randoms[int(0.5 * X.shape[]):]
x_train = X[]
y_train = y[]
x_test = X[]
y_test = y[]
x_data = tf.placeholder(shape=[None, X.shape[]], dtype=)
y_target = tf.placeholder(shape=[], dtype=)
W = tf.Variable(tf.random_normal(shape=[X.shape[],1]))
b = tf.Variable(tf.random_normal(shape=[]))
total_loss = loss_fn()
accuracy = inference_fn()
train_op = tf.train.GradientDescentOptimizer().minimize()
sess = tf.Session()
init = tf.initialize_all_variables()
sess.run()
for step_idx in range():
    X_batch, y_batch = next_batch_fn(x_train, y_train, num_samples=)
    sess.run(train_op, feed_dict={x_data:, y_target:})
    loss_step = sess.run(total_loss, feed_dict={x_data:, y_target:})
    train_acc_step = sess.run(accuracy, feed_dict={x_data:, y_target:})
    test_acc_step = sess.run(accuracy, feed_dict={x_data:, y_target:})
    if step_idx % 100 == 0:
if FLAGS.is_evaluation:
    [[], []] = sess.run()
    [[]] = sess.run()
    x_line = [data[] for data in X]
    line = []
    line = []
    for index, data in enumerate():
        if y[] == 1:
            positive_X = data[]
            positive_y = data[]
        elif y[] == -1:
            negative_X = data[]
            negative_y = data[]
        else:
            sys.exit()
import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
import tempfile
import urllib
import pandas as pd
import os
from tensorflow.examples.tutorials.mnist import input_data
tf.app.flags.DEFINE_string("", os.path.dirname(os.path.abspath()) + "","")
tf.app.flags.DEFINE_string("",os.path.dirname(os.path.abspath()) + "","")
tf.app.flags.DEFINE_integer()
tf.app.flags.DEFINE_integer()
tf.app.flags.DEFINE_integer("", np.power(),"")
tf.app.flags.DEFINE_integer()
tf.app.flags.DEFINE_float()
tf.app.flags.DEFINE_float()
tf.app.flags.DEFINE_float()
tf.app.flags.DEFINE_boolean()
tf.app.flags.DEFINE_boolean()
tf.app.flags.DEFINE_boolean()
tf.app.flags.DEFINE_boolean()
tf.app.flags.DEFINE_boolean()
FLAGS =
if not os.path.isabs():
    raise ValueError()
if not os.path.isabs():
    raise ValueError()
mnist = input_data.read_data_sets("", reshape=, one_hot=)
data={}
data[] =
data[] =
data[] =
data[] =
def extract_samples_Fn():
    index_list = []
    for sample_index in range(data.shape[]):
        label = data[]
        if label == 1 or label == 0:
            index_list.append()
    return index_list
index_list_train = extract_samples_Fn(data[])
index_list_test = extract_samples_Fn(data[])
data[] = mnist.train.images[]
data[] = mnist.train.labels[]
data[] = mnist.test.images[]
data[] = mnist.test.labels[]
dimensionality_train = data[].shape
num_train_samples = dimensionality_train[]
num_features = dimensionality_train[]
graph = tf.Graph()
with graph.as_default():
    global_step = tf.Variable(0, name=, trainable=)
    decay_steps = int()
    learning_rate = tf.train.exponential_decay(FLAGS.initial_learning_rate,global_step,decay_steps,FLAGS.learning_rate_decay_factor,staircase=,name=)
    image_place = tf.placeholder(tf.float32, shape=([]), name=)
    label_place = tf.placeholder(tf.int32, shape=([]), name=)
    label_one_hot = tf.one_hot(label_place, depth=, axis=)
    dropout_param = tf.placeholder()
    logits = tf.contrib.layers.fully_connected(inputs=, num_outputs =, scope=)
    with tf.name_scope():
        loss_tensor = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=, labels=))
    prediction_correct = tf.equal(tf.argmax(), tf.argmax())
    accuracy = tf.reduce_mean(tf.cast())
    optimizer = tf.train.AdamOptimizer(learning_rate=)
    with tf.name_scope():
        gradients_and_variables = optimizer.compute_gradients()
        train_op = optimizer.apply_gradients(gradients_and_variables, global_step=)
    session_conf = tf.ConfigProto(allow_soft_placement=,log_device_placement=)
    sess = tf.Session(graph=, config=)
    with sess.as_default():
        saver = tf.train.Saver()
        sess.run(tf.global_variables_initializer())
        checkpoint_prefix =
        if FLAGS.fine_tuning:
            saver.restore(sess, os.path.join())
        test_accuracy =
        for epoch in range():
            total_batch_training = int(data[].shape[] / FLAGS.batch_size)
            for batch_num in range():
                start_idx =
                end_idx = () * FLAGS.batch_size
                train_batch_data, train_batch_label = data[][start_idx:], data[][start_idx:]
                batch_loss, _, training_step = sess.run([],feed_dict={image_place:,label_place:,dropout_param:})
        if not os.path.exists():
            os.makedirs()
        save_path = saver.save(sess, os.path.join())
        checkpoint_prefix =
        saver.restore(sess, os.path.join())
        test_accuracy = 100 * sess.run(accuracy, feed_dict={image_place:,label_place:,dropout_param:})
import matplotlib.pyplot as plt
import numpy as np
import tensorflow as tf
from sklearn import datasets
from tensorflow.python.framework import ops
from tensorflow.examples.tutorials.mnist import input_data
from sklearn.decomposition import PCA
tf.app.flags.DEFINE_integer()
tf.app.flags.DEFINE_integer()
tf.app.flags.DEFINE_integer()
tf.app.flags.DEFINE_boolean()
tf.app.flags.DEFINE_float()
tf.app.flags.DEFINE_float()
FLAGS =
def cross_class_label_fn():
    label_class_i = tf.reshape(A, [])
    label_class_j = tf.reshape(label_class_i, [])
    returned_mat = tf.matmul()
    return returned_mat
def loss_fn():
    term_1 = tf.reduce_sum()
    alpha_cross = tf.matmul(tf.transpose(), alpha)
    cross_class_label = cross_class_label_fn()
    term_2 = tf.reduce_sum(tf.multiply(my_kernel, tf.multiply()), [])
    return tf.reduce_sum(tf.subtract())
def kernel_pred():
    A = tf.reshape(tf.reduce_sum(tf.square(), 1), [])
    B = tf.reshape(tf.reduce_sum(tf.square(), 1), [])
    square_distance = tf.add(tf.subtract(A, tf.multiply(2., tf.matmul(x_data, tf.transpose()))),tf.transpose())
    return tf.exp(tf.multiply(gamma, tf.abs()))
def kernel_fn():
    square_distance = tf.multiply(2., tf.matmul(x_data, tf.transpose()))
    kernel = tf.exp(tf.multiply(gamma, tf.abs()))
    return kernel
def prepare_label_fn():
    labels =
    labels[labels == 0] =
    labels = np.transpose()
    return labels
def next_batch():
    idx = np.random.choice(len(), size=)
    X_batch = X[]
    y_batch = y[:, idx]
    return X_batch, y_batch
mnist = input_data.read_data_sets("", reshape=, one_hot=)
y_train = prepare_label_fn()
y_test = prepare_label_fn()
num_classes = y_train.shape[]
pca = PCA(n_components=)
pca.fit()
x_train = pca.transform()
x_test = pca.transform()
num_fetures = x_train.shape[]
sess = tf.Session()
data_placeholder = tf.placeholder(shape=[], dtype=)
label_placeholder = tf.placeholder(shape=[], dtype=)
pred_placeholder = tf.placeholder(shape=[], dtype=)
alpha = tf.Variable(tf.random_normal(shape=[]))
gamma = tf.constant()
my_kernel = kernel_fn()
loss = loss_fn()
pred_kernel = kernel_pred()
prediction_output = tf.matmul(tf.multiply(), pred_kernel)
prediction = tf.arg_max(prediction_output - tf.expand_dims(tf.reduce_mean(), 1), 0)
accuracy = tf.reduce_mean(tf.cast(tf.equal(prediction, tf.argmax()), tf.float32))
train_op = tf.train.AdamOptimizer().minimize()
init = tf.global_variables_initializer()
sess.run()
for i in range():
    batch_X, batch_y = next_batch()
    sess.run(train_op, feed_dict={data_placeholder:, label_placeholder:})
    temp_loss = sess.run(loss, feed_dict={data_placeholder:, label_placeholder:})
    acc_train_batch = sess.run(accuracy, feed_dict={data_placeholder:,label_placeholder:,pred_placeholder:})
    batch_X_test, batch_y_test = next_batch()
    acc_test_batch = sess.run(accuracy, feed_dict={data_placeholder:,label_placeholder:,pred_placeholder:})
import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt
import argparse
def str2bool():
    return v.lower() in ()
parser = argparse.ArgumentParser(description=)
tf.app.flags.DEFINE_float("", default=, help=)
tf.app.flags.DEFINE_integer("", default=, help=)
tf.app.flags.DEFINE_integer("", default=, help=)
tf.app.flags.DEFINE_integer("", default=, help=)
tf.app.flags.DEFINE_integer("", default=, help=)
tf.app.flags.DEFINE_integer("", default=, help=)
args =
tf.reset_default_graph()
tf.set_random_seed()
np.random.seed()
step_size =
input_size =
output_size =
X = tf.placeholder(tf.float32, [])
y = tf.placeholder(tf.int32, [])
cell = tf.nn.rnn_cell.BasicRNNCell(num_units=)
output, state = tf.nn.dynamic_rnn(cell, X, dtype=)
logits = tf.layers.dense()
cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=, logits=)
loss = tf.reduce_mean()
optimizer = tf.train.AdamOptimizer(learning_rate=).minimize()
prediction = tf.nn.in_top_k()
accuracy = tf.reduce_mean(tf.cast())
from tensorflow.examples.tutorials.mnist import input_data
mnist = input_data.read_data_sets()
X_test =
X_test = X_test.reshape([])
y_test =
init = tf.global_variables_initializer()
loss_train_list = []
acc_train_list = []
with tf.Session() as sess:
    sess.run()
    n_batches =
    for epoch in range():
        for batch in range():
            X_train, y_train = mnist.train.next_batch()
            X_train = X_train.reshape([])
            sess.run(optimizer, feed_dict={X:, y:})
        loss_train, acc_train = sess.run([], feed_dict={X:, y:})
        loss_train_list.append()
        acc_train_list.append()
    loss_test, acc_test = sess.run([], feed_dict={X:, y:})
from __future__ import print_function
from tensorflow.examples.tutorials.mnist import input_data
import tensorflow as tf
import numpy as np
import os
import sys
tf.app.flags.DEFINE_string("", os.path.dirname(os.path.abspath()) + "","")
tf.app.flags.DEFINE_string("",os.path.dirname(os.path.abspath()) + "","")
tf.app.flags.DEFINE_integer()
tf.app.flags.DEFINE_integer("", np.power(),"")
tf.app.flags.DEFINE_boolean()
tf.app.flags.DEFINE_boolean()
tf.app.flags.DEFINE_boolean()
FLAGS =
if not os.path.isabs():
    raise ValueError()
mnist = input_data.read_data_sets("", reshape=, one_hot=)
dimensionality =
num_train_samples = dimensionality[]
num_features = dimensionality[]
graph = tf.Graph()
with graph.as_default():
    global_step = tf.Variable(0, name=, trainable=)
    image_place = tf.placeholder(tf.float32, shape=([]), name=)
    label_place = tf.placeholder(tf.float32, shape=([]), name=)
    dropout_param = tf.placeholder()
    net = tf.contrib.layers.fully_connected(inputs=, num_outputs=, scope=)
    net = tf.contrib.layers.fully_connected(inputs=, num_outputs=, scope=)
    logits_last = tf.contrib.layers.fully_connected(inputs=, num_outputs=, scope=)
    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=, labels=))
    pred_classifier = tf.equal(tf.argmax(), tf.argmax())
    accuracy = tf.reduce_mean(tf.cast())
    arr = np.random.randint(mnist.test.images.shape[], size=())
    tf.summary.image("", mnist.test.images[], max_outputs=,collections=[])
    tf.summary.scalar("", loss, collections=[])
    tf.summary.scalar("", accuracy, collections=[])
    tf.summary.scalar("", global_step, collections=[])
    summary_test_op = tf.summary.merge_all()
    session_conf = tf.ConfigProto(allow_soft_placement=,log_device_placement=)
    sess = tf.Session(graph=, config=)
    with sess.as_default():
        saver = tf.train.Saver()
        sess.run(tf.global_variables_initializer())
        test_summary_dir = os.path.join()
        test_summary_writer = tf.summary.FileWriter()
        test_summary_writer.add_graph()
        checkpoint_prefix =
        saver.restore(sess, os.path.join())
        total_batch_test = int(mnist.test.images.shape[] / FLAGS.batch_size)
        test_accuracy =
        for batch_num in range():
            start_idx =
            end_idx = () * FLAGS.batch_size
            test_batch_data, test_batch_label = mnist.test.images[start_idx:], mnist.test.labels[start_idx:]
            test_batch_accuracy, batch_loss, test_summaries, test_step = sess.run([],feed_dict={image_place:,label_place:})
            test_accuracy +=
            test_summary_writer.add_summary(test_summaries, global_step=)
        test_accuracy_total = test_accuracy / float()
from __future__ import print_function
from tensorflow.examples.tutorials.mnist import input_data
import tensorflow as tf
import numpy as np
from net_structure import net
from input_function import input
import os
import train_evaluation
tf.app.flags.DEFINE_string("", os.path.dirname(os.path.abspath()) + "","")
tf.app.flags.DEFINE_string("",os.path.dirname(os.path.abspath()) + "","")
tf.app.flags.DEFINE_integer()
tf.app.flags.DEFINE_integer()
tf.app.flags.DEFINE_integer("", np.power(),"")
tf.app.flags.DEFINE_integer()
tf.app.flags.DEFINE_float()
tf.app.flags.DEFINE_float()
tf.app.flags.DEFINE_float()
tf.app.flags.DEFINE_boolean()
tf.app.flags.DEFINE_boolean()
tf.app.flags.DEFINE_boolean()
tf.app.flags.DEFINE_boolean()
tf.app.flags.DEFINE_boolean()
FLAGS =
if not os.path.isabs():
    raise ValueError()
if not os.path.isabs():
    raise ValueError()
mnist = input_data.read_data_sets("", reshape=, one_hot=)
data = input.provide_data()
dimensionality_train =
num_train_samples = dimensionality_train[]
height = dimensionality_train[]
width = dimensionality_train[]
num_channels = dimensionality_train[]
graph = tf.Graph()
with graph.as_default():
    global_step = tf.Variable(0, name=, trainable=)
    decay_steps = int()
    learning_rate = tf.train.exponential_decay(FLAGS.initial_learning_rate,global_step,decay_steps,FLAGS.learning_rate_decay_factor,staircase=,name=)
    image_place = tf.placeholder(tf.float32, shape=([]), name=)
    label_place = tf.placeholder(tf.float32, shape=([]), name=)
    dropout_param = tf.placeholder()
    arg_scope = net.net_arg_scope(weight_decay=, is_training=)
    with tf.contrib.framework.arg_scope():
        logits, end_points = net.net_architecture(image_place, num_classes=,dropout_keep_prob=,is_training=)
    with tf.name_scope():
        loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=, labels=))
    with tf.name_scope():
        correct_pred = tf.equal(tf.argmax(), tf.argmax())
        accuracy = tf.reduce_mean(tf.cast())
    optimizer = tf.train.AdamOptimizer(learning_rate=)
    with tf.name_scope():
        grads_and_vars = optimizer.compute_gradients()
        train_op = optimizer.apply_gradients(grads_and_vars, global_step=)
    arr = np.random.randint(data.train.images.shape[], size=())
    tf.summary.image("", data.train.images[], max_outputs=,collections=[])
    for end_point in end_points:
        x = end_points[]
        tf.summary.scalar("" + end_point,tf.nn.zero_fraction(), collections=[])
        tf.summary.histogram("" + end_point, x, collections=[])
    tf.summary.scalar("", loss, collections=[])
    tf.summary.scalar("", accuracy, collections=[])
    tf.summary.scalar("", global_step, collections=[])
    tf.summary.scalar("", learning_rate, collections=[])
    summary_train_op = tf.summary.merge_all()
    summary_test_op = tf.summary.merge_all()
    summary_epoch_train_op = tf.summary.merge_all()
    tensors_key = []
    tensors = []
    tensors_dictionary = dict(zip())
    session_conf = tf.ConfigProto(allow_soft_placement=,log_device_placement=)
    sess = tf.Session(graph=, config=)
    with sess.as_default():
        saver = tf.train.Saver(max_to_keep=)
        sess.run(tf.global_variables_initializer())
        train_evaluation.train(sess=, saver=, tensors=, data=,train_dir=,finetuning=, online_test=,num_epochs=, checkpoint_dir=,batch_size=)
        train_evaluation.evaluation(sess=, saver=, tensors=, data=,checkpoint_dir=)
from __future__ import print_function
from tensorflow.examples.tutorials.mnist import input_data
import tensorflow as tf
import numpy as np
import os
tf.app.flags.DEFINE_string("", os.path.dirname(os.path.abspath()) + "","")
tf.app.flags.DEFINE_string("",os.path.dirname(os.path.abspath()) + "","")
tf.app.flags.DEFINE_integer()
tf.app.flags.DEFINE_integer()
tf.app.flags.DEFINE_integer("", np.power(),"")
tf.app.flags.DEFINE_integer()
tf.app.flags.DEFINE_float()
tf.app.flags.DEFINE_float()
tf.app.flags.DEFINE_float()
tf.app.flags.DEFINE_boolean()
tf.app.flags.DEFINE_boolean()
tf.app.flags.DEFINE_boolean()
tf.app.flags.DEFINE_boolean()
tf.app.flags.DEFINE_boolean()
FLAGS =
if not os.path.isabs():
    raise ValueError()
if not os.path.isabs():
    raise ValueError()
mnist = input_data.read_data_sets("", reshape=, one_hot=)
train_data =
train_label =
test_data =
test_label =
dimensionality_train =
num_train_samples = dimensionality_train[]
num_features = dimensionality_train[]
graph = tf.Graph()
with graph.as_default():
    global_step = tf.Variable(0, name=, trainable=)
    decay_steps = int()
    learning_rate = tf.train.exponential_decay(FLAGS.initial_learning_rate,global_step,decay_steps,FLAGS.learning_rate_decay_factor,staircase=,name=)
    image_place = tf.placeholder(tf.float32, shape=([]), name=)
    label_place = tf.placeholder(tf.float32, shape=([]), name=)
    dropout_param = tf.placeholder()
    net = tf.contrib.layers.fully_connected(inputs=, num_outputs=, scope=)
    net = tf.contrib.layers.fully_connected(inputs=, num_outputs=, scope=)
    logits_pre_softmax = tf.contrib.layers.fully_connected(inputs=, num_outputs=, scope=)
    softmax_loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=, labels=))
    accuracy = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(), tf.argmax()), tf.float32))
    optimizer = tf.train.AdamOptimizer(learning_rate=)
    with tf.name_scope():
        grads = optimizer.compute_gradients()
        train_op = optimizer.apply_gradients(grads, global_step=)
    tf.summary.scalar("", softmax_loss, collections=[])
    tf.summary.scalar("", accuracy, collections=[])
    tf.summary.scalar("", global_step, collections=[])
    tf.summary.scalar("", learning_rate, collections=[])
    summary_train_op = tf.summary.merge_all()
    summary_test_op = tf.summary.merge_all()
    session_conf = tf.ConfigProto(allow_soft_placement=,log_device_placement=)
    sess = tf.Session(graph=, config=)
    with sess.as_default():
        saver = tf.train.Saver(max_to_keep=)
        sess.run(tf.global_variables_initializer())
        checkpoint_prefix =
        train_summary_dir = os.path.join()
        train_summary_writer = tf.summary.FileWriter()
        train_summary_writer.add_graph()
        test_summary_dir = os.path.join()
        test_summary_writer = tf.summary.FileWriter()
        test_summary_writer.add_graph()
        if FLAGS.fine_tuning:
            saver.restore(sess, os.path.join())
        for epoch in range():
            total_batch_training = int(train_data.shape[] / FLAGS.batch_size)
            for batch_num in range():
                start_idx =
                end_idx = () * FLAGS.batch_size
                train_batch_data, train_batch_label = train_data[start_idx:], train_label[start_idx:]
                batch_loss, _, train_summaries, training_step = sess.run([],feed_dict={image_place:,label_place:,dropout_param:})
                train_summary_writer.add_summary(train_summaries, global_step=)
            if FLAGS.online_test:
                test_accuracy_epoch, test_summaries = sess.run([],feed_dict={image_place:,label_place:,dropout_param:})
                current_step = tf.train.global_step()
                test_summary_writer.add_summary(test_summaries, global_step=)
        if not os.path.exists():
            os.makedirs()
        save_path = saver.save(sess, os.path.join())
        checkpoint_prefix =
        saver.restore(sess, os.path.join())
        total_test_accuracy = sess.run(accuracy, feed_dict={image_place:,label_place:,dropout_param:})
import sugartensor as tf
import numpy as np
import librosa
from model import *
import data
__author__ =
tf.sg_verbosity()
batch_size =
voca_size =
x = tf.placeholder(dtype=, shape=())
seq_len = tf.not_equal(x.sg_sum(axis=), 0.).sg_int().sg_sum(axis=)
logit = get_logit(x, voca_size=)
decoded, _ = tf.nn.ctc_beam_search_decoder(logit.sg_transpose(perm=[]), seq_len, merge_repeated=)
y = tf.sparse_to_dense(decoded[].indices, decoded[].dense_shape, decoded[].values) + 1
tf.sg_arg_def(file=())
wav, _ = librosa.load(tf.sg_arg().file, mono=, sr=)
mfcc = np.transpose(np.expand_dims(librosa.feature.mfcc(), axis=), [])
with tf.Session() as sess:
    tf.sg_init()
    saver = tf.train.Saver()
    saver.restore(sess, tf.train.latest_checkpoint())
    label = sess.run(y, feed_dict={x:})
    data.print_index()
import contextlib
import json
import os
from enum import Enum
from termcolor import colored
from .helper import import_tf, set_logger
import sys
sys.path.append()
from bert_base.bert import modeling
__all__ = []
class PoolingStrategy():
    NONE =
    REDUCE_MAX =
    REDUCE_MEAN =
    REDUCE_MEAN_MAX =
    FIRST_TOKEN =
    LAST_TOKEN =
    CLS_TOKEN =
    SEP_TOKEN =
    def __str__():
        return self.name
    def from_string():
        try:
            return PoolingStrategy[]
        except KeyError:
            raise ValueError()
def optimize_bert_graph(args, logger=):
    if not logger:
        logger = set_logger(colored(), args.verbose)
    try:
        if not os.path.exists():
            os.mkdir()
        pb_file = os.path.join()
        if os.path.exists():
            return pb_file
        tf = import_tf(verbose=)
        from tensorflow.python.tools.optimize_for_inference_lib import optimize_for_inference
        config = tf.ConfigProto(device_count={'GPU':}, allow_soft_placement=)
        config_fp = os.path.join()
        init_checkpoint = os.path.join()
        if args.fp16:
        with tf.gfile.GFile() as f:
            bert_config = modeling.BertConfig.from_dict(json.load())
        input_ids = tf.placeholder(tf.int32, (), "")
        input_mask = tf.placeholder(tf.int32, (), "")
        input_type_ids = tf.placeholder(tf.int32, (), "")
        jit_scope =
        with jit_scope():
            input_tensors = []
            model = modeling.BertModel(config=,is_training=,input_ids=,input_mask=,token_type_ids=,use_one_hot_embeddings=)
            tvars = tf.trainable_variables()
            () = modeling.get_assignment_map_from_checkpoint()
            tf.train.init_from_checkpoint()
            minus_mask =, m: x - tf.expand_dims(1.0 - m, axis=) * 1e30
            mul_mask =, m: x * tf.expand_dims(m, axis=)
            masked_reduce_max =, m: tf.reduce_max(minus_mask(), axis=)
            masked_reduce_mean =, m: tf.reduce_sum(mul_mask(), axis=) / (tf.reduce_sum(m, axis=, keepdims=) + 1e-10)
            with tf.variable_scope():
                if len() == 1:
                    encoder_layer = model.all_encoder_layers[args.pooling_layer[]]
                else:
                    all_layers = [model.all_encoder_layers[] for l in args.pooling_layer]
                    encoder_layer = tf.concat()
                input_mask = tf.cast()
                if args.pooling_strategy == PoolingStrategy.REDUCE_MEAN:
                    pooled = masked_reduce_mean()
                elif args.pooling_strategy == PoolingStrategy.REDUCE_MAX:
                    pooled = masked_reduce_max()
                elif args.pooling_strategy == PoolingStrategy.REDUCE_MEAN_MAX:
                    pooled = tf.concat([masked_reduce_mean(),masked_reduce_max()], axis=)
                elif args.pooling_strategy == PoolingStrategy.FIRST_TOKEN or args.pooling_strategy == PoolingStrategy.CLS_TOKEN:
                    pooled = tf.squeeze(encoder_layer[:, 0:, :], axis=)
                elif args.pooling_strategy == PoolingStrategy.LAST_TOKEN or args.pooling_strategy == PoolingStrategy.SEP_TOKEN:
                    seq_len = tf.cast(tf.reduce_sum(input_mask, axis=), tf.int32)
                    rng = tf.range(0, tf.shape()[])
                    indexes = tf.stack([], 1)
                    pooled = tf.gather_nd()
                elif args.pooling_strategy == PoolingStrategy.NONE:
                    pooled = mul_mask()
                else:
                    raise NotImplementedError()
            if args.fp16:
                pooled = tf.cast()
            pooled = tf.identity()
            output_tensors = []
            tmp_g = tf.get_default_graph().as_graph_def()
        with tf.Session(config=) as sess:
            sess.run(tf.global_variables_initializer())
            dtypes = []
            tmp_g = optimize_for_inference(tmp_g,[n.name[:] for n in input_tensors],[n.name[:] for n in output_tensors],[],False)
            tmp_g = convert_variables_to_constants(sess, tmp_g, [n.name[:] for n in output_tensors],use_fp16=)
        with tf.gfile.GFile() as f:
            f.write(tmp_g.SerializeToString())
    except Exception:
def convert_variables_to_constants(sess,input_graph_def,output_node_names,variable_names_whitelist=,variable_names_blacklist=,use_fp16=):
    from tensorflow.python.framework.graph_util_impl import extract_sub_graph
    from tensorflow.core.framework import graph_pb2
    from tensorflow.core.framework import node_def_pb2
    from tensorflow.core.framework import attr_value_pb2
    from tensorflow.core.framework import types_pb2
    from tensorflow.python.framework import tensor_util
    def patch_dtype():
        if use_fp16 and () and (input_node.attr[].type ==):
            output_node.attr[].CopyFrom(attr_value_pb2.AttrValue(type=))
    inference_graph = extract_sub_graph()
    variable_names = []
    variable_dict_names = []
    for node in inference_graph.node:
        if node.op in []:
            variable_name =
            if (() or()):
                continue
            variable_dict_names.append()
            if node.op == "":
                variable_names.append(variable_name + "")
            else:
                variable_names.append(variable_name + "")
    if variable_names:
        returned_variables = sess.run()
    else:
        returned_variables = []
    found_variables = dict(zip())
    output_graph_def = graph_pb2.GraphDef()
    how_many_converted =
    for input_node in inference_graph.node:
        output_node = node_def_pb2.NodeDef()
        if input_node.name in found_variables:
            output_node.op =
            output_node.name =
            dtype = input_node.attr[]
            data = found_variables[]
            if use_fp16 and dtype.type == types_pb2.DT_FLOAT:
                output_node.attr[].CopyFrom(attr_value_pb2.AttrValue(tensor=tensor_util.make_tensor_proto(data.astype(),dtype=,shape=)))
            else:
                output_node.attr[].CopyFrom()
                output_node.attr[].CopyFrom(attr_value_pb2.AttrValue(tensor=tensor_util.make_tensor_proto(data, dtype=,shape=)))
            how_many_converted +=
        elif input_node.op == "" and (input_node.input[] in found_variables):
            output_node.op =
            output_node.name =
            output_node.input.extend([input_node.input[]])
            output_node.attr[].CopyFrom(input_node.attr[])
            if "" in input_node.attr:
                output_node.attr[].CopyFrom(input_node.attr[])
        else:
            output_node.CopyFrom()
        patch_dtype()
        patch_dtype()
        patch_dtype()
        patch_dtype()
        patch_dtype()
        if use_fp16 and () and (output_node.attr[].tensor.dtype ==):
            output_node.attr[].CopyFrom(attr_value_pb2.AttrValue(tensor=tensor_util.make_tensor_proto(output_node.attr[].tensor.float_val[],dtype=)))
        output_graph_def.node.extend([])
    output_graph_def.library.CopyFrom()
    return output_graph_def
def optimize_ner_model(args, num_labels,  logger=):
    if not logger:
        logger = set_logger(colored(), args.verbose)
    try:
        if args.model_pb_dir is None:
            tmp_file = os.path.join(os.getcwd(), "")
            if not os.path.exists():
                os.mkdir()
        else:
            tmp_file =
        pb_file = os.path.join()
        if os.path.exists():
            return pb_file
        import tensorflow as tf
        graph = tf.Graph()
        with graph.as_default():
            with tf.Session() as sess:
                input_ids = tf.placeholder(tf.int32, (), "")
                input_mask = tf.placeholder(tf.int32, (), "")
                bert_config = modeling.BertConfig.from_json_file(os.path.join())
                from bert_base.train.models import create_model
                () = create_model(bert_config=, is_training=, input_ids=, input_mask=, segment_ids=,labels=, num_labels=, use_one_hot_embeddings=, dropout_rate=, lstm_size=)
                pred_ids = tf.identity()
                saver = tf.train.Saver()
            with tf.Session() as sess:
                sess.run(tf.global_variables_initializer())
                saver.restore(sess, tf.train.latest_checkpoint())
                from tensorflow.python.framework import graph_util
                tmp_g = graph_util.convert_variables_to_constants(sess, graph.as_graph_def(), [])
        with tf.gfile.GFile() as f:
            f.write(tmp_g.SerializeToString())
        return pb_file
    except Exception as e:
def optimize_class_model(args, num_labels,  logger=):
    if not logger:
        logger = set_logger(colored(), args.verbose)
    try:
        if args.model_pb_dir is None:
            tmp_file = os.path.join(os.getcwd(), "")
            if not os.path.exists():
                os.mkdir()
        else:
            tmp_file =
        pb_file = os.path.join()
        if os.path.exists():
            return pb_file
        import tensorflow as tf
        graph = tf.Graph()
        with graph.as_default():
            with tf.Session() as sess:
                input_ids = tf.placeholder(tf.int32, (), "")
                input_mask = tf.placeholder(tf.int32, (), "")
                bert_config = modeling.BertConfig.from_json_file(os.path.join())
                from bert_base.train.models import create_classification_model
                segment_ids = tf.placeholder(tf.int32, (), "")
                loss, per_example_loss, logits, probabilities = create_classification_model(bert_config=, is_training=, input_ids=, input_mask=, segment_ids=, labels=, num_labels=)
                probabilities = tf.identity()
                saver = tf.train.Saver()
            with tf.Session() as sess:
                sess.run(tf.global_variables_initializer())
                saver.restore(sess, tf.train.latest_checkpoint())
                from tensorflow.python.framework import graph_util
                tmp_g = graph_util.convert_variables_to_constants(sess, graph.as_graph_def(), [])
        with tf.gfile.GFile() as f:
            f.write(tmp_g.SerializeToString())
        return pb_file
    except Exception as e:
import tensorflow as tf
import numpy as np
data = np.loadtxt("", delimiter=,',unpack=, dtype=)
x_data = np.transpose(data[0:])
y_data = np.transpose(data[2:])
global_step = tf.Variable(0, trainable=, name=)
X = tf.placeholder()
Y = tf.placeholder()
W1 = tf.Variable(tf.random_uniform([], -1., 1.))
L1 = tf.nn.relu(tf.matmul())
W2 = tf.Variable(tf.random_uniform([], -1., 1.))
L2 = tf.nn.relu(tf.matmul())
W3 = tf.Variable(tf.random_uniform([], -1., 1.))
model = tf.matmul()
cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=, logits=))
optimizer = tf.train.AdamOptimizer(learning_rate=)
train_op = optimizer.minimize(cost, global_step=)
sess = tf.Session()
saver = tf.train.Saver(tf.global_variables())
ckpt = tf.train.get_checkpoint_state()
if ckpt and tf.train.checkpoint_exists():
    saver.restore()
else:
    sess.run(tf.global_variables_initializer())
for step in range():
    sess.run(train_op, feed_dict={X:, Y:})
saver.save(sess, "", global_step=)
prediction = tf.argmax()
target = tf.argmax()
is_correct = tf.equal()
accuracy = tf.reduce_mean(tf.cast())
from __future__ import absolute_import
from __future__ import division
from __future__ import print_function
import os
import flask
from flask import request, jsonify
import json
import pickle
from datetime import datetime
import tensorflow as tf
from tensorflow import keras as K
import numpy as np
import sys
sys.path.append()
from bert_base.train.models import create_model, InputFeatures
from bert_base.bert import tokenization, modeling
model_dir =
bert_dir = 'H:
is_training=
use_one_hot_embeddings=
batch_size=
max_seq_length =
gpu_config = tf.ConfigProto()
gpu_config.gpu_options.allow_growth =
sess=tf.Session(config=)
model=
global graph
input_ids_p, input_mask_p, label_ids_p, segment_ids_p =, None, None, None
if not os.path.exists(os.path.join()):
    raise Exception()
with open(os.path.join(), "") as rf:
    label2id = pickle.load()
    id2label = {value:,}
with open(os.path.join(), "") as rf:
    label_list = pickle.load()
num_labels = len() + 1
graph = tf.get_default_graph()
with graph.as_default():
    input_ids_p = tf.placeholder(tf.int32, [], name=)
    input_mask_p = tf.placeholder(tf.int32, [], name=)
    bert_config = modeling.BertConfig.from_json_file(os.path.join())
    () = create_model(bert_config=, is_training=, input_ids=, input_mask=, segment_ids=,labels=, num_labels=, use_one_hot_embeddings=, dropout_rate=)
    saver = tf.train.Saver()
    saver.restore(sess, tf.train.latest_checkpoint())
tokenizer = tokenization.FullTokenizer(vocab_file=os.path.join(), do_lower_case=)
app = flask.Flask()
def ner_predict_service():
    def convert():
        feature = convert_single_example()
        input_ids = np.reshape([],())
        input_mask = np.reshape([],())
        segment_ids = np.reshape([],())
        label_ids =np.reshape([],())
        return input_ids, input_mask, segment_ids, label_ids
    global graph
    with graph.as_default():
        result = {}
        result[] =
        try:
            sentence = request.args[]
            result[] =
            start = datetime.now()
            if len() < 2:
                result[] = [] * len()
                return json.dumps()
            sentence = tokenizer.tokenize()
            input_ids, input_mask, segment_ids, label_ids = convert()
            feed_dict = {input_ids_p:,input_mask_p:}
            pred_ids_result = sess.run([], feed_dict)
            pred_label_result = convert_id_to_label()
            result[] =
            return json.dumps()
        except:
            result[] =
            result[] =
            return json.dumps()
def online_predict():
    def convert():
        feature = convert_single_example()
        input_ids = np.reshape([],())
        input_mask = np.reshape([],())
        segment_ids = np.reshape([],())
        label_ids =np.reshape([],())
        return input_ids, input_mask, segment_ids, label_ids
    global graph
    with graph.as_default():
        sentence =
        start = datetime.now()
        if len() < 2:
        sentence = tokenizer.tokenize()
        input_ids, input_mask, segment_ids, label_ids = convert()
        feed_dict = {input_ids_p:,input_mask_p:}
        pred_ids_result = sess.run([], feed_dict)
        pred_label_result = convert_id_to_label()
def convert_id_to_label():
    result = []
    for row in range():
        curr_seq = []
        for ids in pred_ids_result[][]:
            if ids == 0:
                break
            curr_label = idx2label[]
            if curr_label in ['[CLS]', '[SEP]']:
                continue
            curr_seq.append()
        result.append()
    return result
def convert_single_example():
    label_map = {}
    for () in enumerate():
        label_map[] =
    if not os.path.exists(os.path.join()):
        with open(os.path.join(), "") as w:
            pickle.dump()
    tokens =
    if len() >= max_seq_length - 1:
        tokens = tokens[0:()]
    ntokens = []
    segment_ids = []
    label_ids = []
    ntokens.append("[]")
    segment_ids.append()
    label_ids.append(label_map["[]"])
    for i, token in enumerate():
        ntokens.append()
        segment_ids.append()
        label_ids.append()
    ntokens.append("[]")
    segment_ids.append()
    label_ids.append(label_map["[]"])
    input_ids = tokenizer.convert_tokens_to_ids()
    input_mask = [] * len()
    while len() < max_seq_length:
        input_ids.append()
        input_mask.append()
        segment_ids.append()
        label_ids.append()
        ntokens.append()
    feature = InputFeatures(input_ids=,input_mask=,segment_ids=,label_ids=,)
    return feature
if __name__ == "__main__":
    app.run(host=, port=)
import tensorflow as tf
import numpy as np
import codecs
import pickle
import os
from datetime import datetime
from bert_base.train.models import create_model, InputFeatures
from bert_base.bert import tokenization, modeling
from bert_base.train.train_helper import get_args_parser
args = get_args_parser()
model_dir = r'C:
bert_dir = 'F:
is_training=
use_one_hot_embeddings=
batch_size=
gpu_config = tf.ConfigProto()
gpu_config.gpu_options.allow_growth =
sess=tf.Session(config=)
model=
global graph
input_ids_p, input_mask_p, label_ids_p, segment_ids_p =, None, None, None
if not os.path.exists(os.path.join()):
    raise Exception()
with codecs.open(os.path.join(), "") as rf:
    label2id = pickle.load()
    id2label = {value:,}
with codecs.open(os.path.join(), "") as rf:
    label_list = pickle.load()
num_labels = len() + 1
graph = tf.get_default_graph()
with graph.as_default():
    input_ids_p = tf.placeholder(tf.int32, [], name=)
    input_mask_p = tf.placeholder(tf.int32, [], name=)
    bert_config = modeling.BertConfig.from_json_file(os.path.join())
    () = create_model(bert_config=, is_training=, input_ids=, input_mask=, segment_ids=,labels=, num_labels=, use_one_hot_embeddings=, dropout_rate=)
    saver = tf.train.Saver()
    saver.restore(sess, tf.train.latest_checkpoint())
tokenizer = tokenization.FullTokenizer(vocab_file=os.path.join(), do_lower_case=)
def predict_online():
    def convert():
        feature = convert_single_example()
        input_ids = np.reshape([],())
        input_mask = np.reshape([],())
        segment_ids = np.reshape([],())
        label_ids =np.reshape([],())
        return input_ids, input_mask, segment_ids, label_ids
    global graph
    with graph.as_default():
        while True:
            sentence = str(input())
            start = datetime.now()
            if len() < 2:
                continue
            sentence = tokenizer.tokenize()
            input_ids, input_mask, segment_ids, label_ids = convert()
            feed_dict = {input_ids_p:,input_mask_p:}
            pred_ids_result = sess.run([], feed_dict)
            pred_label_result = convert_id_to_label()
            result = strage_combined_link_org_loc(sentence, pred_label_result[])
def convert_id_to_label():
    result = []
    for row in range():
        curr_seq = []
        for ids in pred_ids_result[][]:
            if ids == 0:
                break
            curr_label = idx2label[]
            if curr_label in ['[CLS]', '[SEP]']:
                continue
            curr_seq.append()
        result.append()
    return result
def strage_combined_link_org_loc():
    def print_output():
        line = []
        line.append()
        for i in data:
            line.append()
    params =
    eval = Result()
    if len() > len():
        tokens = tokens[:len()]
    person, loc, org = eval.get_result()
def convert_single_example():
    label_map = {}
    for () in enumerate():
        label_map[] =
    if not os.path.exists(os.path.join()):
        with codecs.open(os.path.join(), "") as w:
            pickle.dump()
    tokens =
    if len() >= max_seq_length - 1:
        tokens = tokens[0:()]
    ntokens = []
    segment_ids = []
    label_ids = []
    ntokens.append("[]")
    segment_ids.append()
    label_ids.append(label_map["[]"])
    for i, token in enumerate():
        ntokens.append()
        segment_ids.append()
        label_ids.append()
    ntokens.append("[]")
    segment_ids.append()
    label_ids.append(label_map["[]"])
    input_ids = tokenizer.convert_tokens_to_ids()
    input_mask = [] * len()
    while len() < max_seq_length:
        input_ids.append()
        input_mask.append()
        segment_ids.append()
        label_ids.append()
        ntokens.append()
    feature = InputFeatures(input_ids=,input_mask=,segment_ids=,label_ids=,)
    return feature
class Pair():
    def __init__(self, word, start, end, type, merge=):
        self.__word =
        self.__start =
        self.__end =
        self.__merge =
        self.__types =
    def start():
        return self.__start
    def end():
        return self.__end
    def merge():
        return self.__merge
    def word():
        return self.__word
    def types():
        return self.__types
    def word():
        self.__word =
    def start():
        self.__start =
    def end():
        self.__end =
    def merge():
        self.__merge =
    def types():
        self.__types =
    def __str__() -> str:
        line = []
        line.append("")
        return "".join()
class Result():
    def __init__():
        self.config =
        self.person = []
        self.loc = []
        self.org = []
        self.others = []
    def get_result(self, tokens, tags, config=):
        self.result_to_json()
        return self.person, self.loc, self.org
    def result_to_json():
        item = {"entities":}
        entity_name =
        entity_start =
        idx =
        last_tag =
        for char, tag in zip():
            if tag[] == "":
                self.append(char, idx, idx+1, tag[2:])
                item[].append({"word":, "start":, "end":, "type":tag[2:})
            elif tag[] == "":
                if entity_name != "":
                    self.append(entity_name, entity_start, idx, last_tag[2:])
                    item[].append({"word":, "start":, "end":, "type": last_tag[2:})
                    entity_name =
                entity_name +=
                entity_start =
            elif tag[] == "":
                entity_name +=
            elif tag[] == "":
                if entity_name != "":
                    self.append(entity_name, entity_start, idx, last_tag[2:])
                    item[].append({"word":, "start":, "end":, "type": last_tag[2:})
                    entity_name =
            else:
                entity_name =
                entity_start =
            idx +=
            last_tag =
        if entity_name != "":
            self.append(entity_name, entity_start, idx, last_tag[2:])
            item[].append({"word":, "start":, "end":, "type": last_tag[2:})
        return item
    def append():
        if tag == "":
            self.loc.append(Pair())
        elif tag == "":
            self.person.append(Pair())
        elif tag == "":
            self.org.append(Pair())
        else:
            self.others.append(Pair())
if __name__ == "__main__":
    predict_online()
import argparse
import tensorflow as tf
from core.yolov3 import YOLOV3
from core.config import cfg
parser = argparse.ArgumentParser()
parser.add_argument("", action=)
flag = parser.parse_args()
org_weights_path =
cur_weights_path =
preserve_cur_names = []
preserve_org_names = []
org_weights_mess = []
tf.Graph().as_default()
load = tf.train.import_meta_graph()
with tf.Session() as sess:
    load.restore()
    for var in tf.global_variables():
        var_name =
        var_name_mess = str().split()
        var_shape =
        if flag.train_from_coco:
            if (var_name_mess[] not in []) or (var_name_mess[] == "" and (var_name_mess[] in preserve_org_names)):
        org_weights_mess.append([])
tf.reset_default_graph()
cur_weights_mess = []
tf.Graph().as_default()
with tf.name_scope():
    input_data = tf.placeholder(dtype=, shape=(), name=)
    training = tf.placeholder(dtype=, name=)
model = YOLOV3()
for var in tf.global_variables():
    var_name =
    var_name_mess = str().split()
    var_shape =
    if flag.train_from_coco:
        if var_name_mess[] in preserve_cur_names:
    cur_weights_mess.append([])
org_weights_num = len()
cur_weights_num = len()
if cur_weights_num != org_weights_num:
    raise RuntimeError
cur_to_org_dict = {}
for index in range():
    org_name, org_shape = org_weights_mess[]
    cur_name, cur_shape = cur_weights_mess[]
    if cur_shape != org_shape:
        raise RuntimeError
    cur_to_org_dict[] =
with tf.name_scope():
    name_to_var_dict = {var.op.name:}
    restore_dict = {cur_to_org_dict[]:}
    load = tf.train.Saver()
    save = tf.train.Saver(tf.global_variables())
    for var in tf.global_variables():
with tf.Session() as sess:
    sess.run(tf.global_variables_initializer())
    load.restore()
    save.save()
tf.reset_default_graph()
import cv2
import os
import shutil
import numpy as np
import tensorflow as tf
import core.utils as utils
from core.config import cfg
from core.yolov3 import YOLOV3
class YoloTest():
    def __init__():
        self.input_size       =
        self.anchor_per_scale =
        self.classes          = utils.read_class_names()
        self.num_classes      = 
        self.anchors          = np.array(utils.get_anchors())
        self.score_threshold  =
        self.iou_threshold    =
        self.moving_ave_decay =
        self.annotation_path  =
        self.weight_file      =
        self.write_image      =
        self.write_image_path =
        self.show_label       =
        with tf.name_scope():
            self.input_data = tf.placeholder(dtype=, name=)
            self.trainable  = tf.placeholder(dtype=,    name=)
        model = YOLOV3()
        self.pred_sbbox, self.pred_mbbox, self.pred_lbbox =, model.pred_mbbox, model.pred_lbbox
        with tf.name_scope():
            ema_obj = tf.train.ExponentialMovingAverage()
        self.sess  = tf.Session(config=tf.ConfigProto(allow_soft_placement=))
        self.saver = tf.train.Saver(ema_obj.variables_to_restore())
        self.saver.restore()
    def predict():
        org_image = np.copy()
        org_h, org_w, _ =
        image_data = utils.image_preporcess(image, [])
        image_data = image_data[]
        pred_sbbox, pred_mbbox, pred_lbbox = self.sess.run([],feed_dict={self.input_data:,self.trainable:})
        pred_bbox = np.concatenate([np.reshape(pred_sbbox, ()),np.reshape(pred_mbbox, ()),np.reshape(pred_lbbox, ())], axis=)
        bboxes = utils.postprocess_boxes(pred_bbox, (), self.input_size, self.score_threshold)
        bboxes = utils.nms()
        return bboxes
    def evaluate():
        predicted_dir_path =
        ground_truth_dir_path =
        if os.path.exists(): shutil.rmtree()
        if os.path.exists(): shutil.rmtree()
        if os.path.exists(): shutil.rmtree()
        os.mkdir()
        os.mkdir()
        os.mkdir()
        with open() as annotation_file:
            for num, line in enumerate():
                annotation = line.strip().split()
                image_path = annotation[]
                image_name = image_path.split()[]
                image = cv2.imread()
                bbox_data_gt = np.array([list(map(int, box.split())) for box in annotation[1:]])
                if len() == 0:
                    bboxes_gt=[]
                    classes_gt=[]
                else:
                    bboxes_gt, classes_gt = bbox_data_gt[:, :], bbox_data_gt[:, 4]
                ground_truth_path = os.path.join(ground_truth_dir_path, str() + "")
                num_bbox_gt = len()
                with open() as f:
                    for i in range():
                        class_name = self.classes[classes_gt[]]
                        xmin, ymin, xmax, ymax = list(map(str, bboxes_gt[]))
                        bbox_mess = "".join([]) + ""
                        f.write()
                predict_result_path = os.path.join(predicted_dir_path, str() + "")
                bboxes_pr = self.predict()
                if self.write_image:
                    image = utils.draw_bbox(image, bboxes_pr, show_label=)
                    cv2.imwrite()
                with open() as f:
                    for bbox in bboxes_pr:
                        coor = np.array(bbox[:], dtype=)
                        score = bbox[]
                        class_ind = int(bbox[])
                        class_name = self.classes[]
                        score =
                        xmin, ymin, xmax, ymax = list(map())
                        bbox_mess = "".join([]) + ""
                        f.write()
    def voc_2012_test():
        img_inds_file = os.path.join()
        with open() as f:
            txt = f.readlines()
            image_inds = [line.strip() for line in txt]
        results_path =
        if os.path.exists():
            shutil.rmtree()
        os.makedirs()
        for image_ind in image_inds:
            image_path = os.path.join()
            image = cv2.imread()
            bboxes_pr = self.predict()
            for bbox in bboxes_pr:
                coor = np.array(bbox[:], dtype=)
                score = bbox[]
                class_ind = int(bbox[])
                class_name = self.classes[]
                score =
                xmin, ymin, xmax, ymax = list(map())
                bbox_mess = "".join([]) + ""
                with open(os.path.join(), "") as f:
                    f.write()
if __name__ == "__main__": YoloTest().evaluate()
import tensorflow as tf
from core.yolov3 import YOLOV3
pb_file =
ckpt_file =
output_node_names = []
with tf.name_scope():
    input_data = tf.placeholder(dtype=, name=)
model = YOLOV3(input_data, trainable=)
sess  = tf.Session(config=tf.ConfigProto(allow_soft_placement=))
saver = tf.train.Saver()
saver.restore()
converted_graph_def = tf.graph_util.convert_variables_to_constants(sess,input_graph_def  = sess.graph.as_graph_def(),output_node_names =)
with tf.gfile.GFile() as f:
    f.write(converted_graph_def.SerializeToString())
import tensorflow as tf
from core.yolov3 import YOLOV3
iput_size =
darknet_weights =
ckpt_file =
def load_weights():
    with open() as fp:
        _ = np.fromfile(fp, dtype=, count=)
        weights = np.fromfile(fp, dtype=)
    ptr =
    i =
    assign_ops = []
    while i < len() - 1:
        var1 = var_list[]
        var2 = var_list[]
        if "" in var1.name.split()[]:
            if "" in var2.name.split()[]:
                gamma, beta, mean, var = var_list[i + 1:]
                batch_norm_vars = []
                for vari in batch_norm_vars:
                    shape = vari.shape.as_list()
                    num_params = np.prod()
                    vari_weights = weights[ptr:].reshape()
                    ptr +=
                    assign_ops.append(tf.assign(vari, vari_weights, validate_shape=))
                i +=
            elif "" in var2.name.split()[]:
                bias =
                bias_shape = bias.shape.as_list()
                bias_params = np.prod()
                bias_weights = weights[ptr:].reshape()
                ptr +=
                assign_ops.append(tf.assign(bias, bias_weights, validate_shape=))
                i +=
            shape = var1.shape.as_list()
            num_params = np.prod()
            var_weights = weights[ptr:].reshape((shape[], shape[], shape[], shape[]))
            var_weights = np.transpose(var_weights, ())
            ptr +=
            assign_ops.append(tf.assign(var1, var_weights, validate_shape=))
            i +=
    return assign_ops
with tf.name_scope():
    input_data = tf.placeholder(dtype=,shape=(), name=)
model = YOLOV3(input_data, trainable=)
load_ops = load_weights(tf.global_variables(), darknet_weights)
saver = tf.train.Saver(tf.global_variables())
with tf.Session() as sess:
    sess.run()
    save_path = saver.save(sess, save_path=)
import os
import time
import shutil
import numpy as np
import tensorflow as tf
import core.utils as utils
from tqdm import tqdm
from core.dataset import Dataset
from core.yolov3 import YOLOV3
from core.config import cfg
class YoloTrain():
    def __init__():
        self.anchor_per_scale    =
        self.classes             = utils.read_class_names()
        self.num_classes         = len()
        self.learn_rate_init     =
        self.learn_rate_end      =
        self.first_stage_epochs  =
        self.second_stage_epochs =
        self.warmup_periods      =
        self.initial_weight      =
        self.time                = time.strftime('%Y-%m-%d-%H-%M-%S', time.localtime(time.time()))
        self.moving_ave_decay    =
        self.max_bbox_per_scale  =
        self.train_logdir        =
        self.trainset            = Dataset()
        self.testset             = Dataset()
        self.steps_per_period    = len()
        self.sess                = tf.Session(config=tf.ConfigProto(allow_soft_placement=))
        with tf.name_scope():
            self.input_data   = tf.placeholder(dtype=, name=)
            self.label_sbbox  = tf.placeholder(dtype=, name=)
            self.label_mbbox  = tf.placeholder(dtype=, name=)
            self.label_lbbox  = tf.placeholder(dtype=, name=)
            self.true_sbboxes = tf.placeholder(dtype=, name=)
            self.true_mbboxes = tf.placeholder(dtype=, name=)
            self.true_lbboxes = tf.placeholder(dtype=, name=)
            self.trainable     = tf.placeholder(dtype=, name=)
        with tf.name_scope():
            self.model = YOLOV3()
            self.net_var = tf.global_variables()
            self.giou_loss, self.conf_loss, self.prob_loss = self.model.compute_loss()
            self.loss =
        with tf.name_scope():
            self.global_step = tf.Variable(1.0, dtype=, trainable=, name=)
            warmup_steps = tf.constant(self.warmup_periods * self.steps_per_period,dtype=, name=)
            train_steps = tf.constant( ()* self.steps_per_period,dtype=, name=)
            self.learn_rate = tf.cond(pred=,true_fn=lambda:,false_fn=lambda: self.learn_rate_end + 0.5 * () *(1 + tf.cos(() / () * np.pi)))
            global_step_update = tf.assign_add()
        with tf.name_scope():
            moving_ave = tf.train.ExponentialMovingAverage().apply(tf.trainable_variables())
        with tf.name_scope():
            self.first_stage_trainable_var_list = []
            for var in tf.trainable_variables():
                var_name =
                var_name_mess = str().split()
                if var_name_mess[] in []:
                    self.first_stage_trainable_var_list.append()
            first_stage_optimizer = tf.train.AdamOptimizer().minimize(self.loss,var_list=)
            with tf.control_dependencies(tf.get_collection()):
                with tf.control_dependencies([]):
                    with tf.control_dependencies([]):
                        self.train_op_with_frozen_variables = tf.no_op()
        with tf.name_scope():
            second_stage_trainable_var_list = tf.trainable_variables()
            second_stage_optimizer = tf.train.AdamOptimizer().minimize(self.loss,var_list=)
            with tf.control_dependencies(tf.get_collection()):
                with tf.control_dependencies([]):
                    with tf.control_dependencies([]):
                        self.train_op_with_all_variables = tf.no_op()
        with tf.name_scope():
            self.loader = tf.train.Saver()
            self.saver  = tf.train.Saver(tf.global_variables(), max_to_keep=)
        with tf.name_scope():
            tf.summary.scalar()
            tf.summary.scalar()
            tf.summary.scalar()
            tf.summary.scalar()
            tf.summary.scalar()
            logdir =
            if os.path.exists(): shutil.rmtree()
            os.mkdir()
            self.write_op = tf.summary.merge_all()
            self.summary_writer  = tf.summary.FileWriter(logdir, graph=)
    def train():
        self.sess.run(tf.global_variables_initializer())
        try:
            self.loader.restore()
        except:
            self.first_stage_epochs =
        for epoch in range():
            if epoch <= self.first_stage_epochs:
                train_op =
            else:
                train_op =
            pbar = tqdm()
            train_epoch_loss, test_epoch_loss = [], []
            for train_data in pbar:
                _, summary, train_step_loss, global_step_val = self.sess.run([],feed_dict={self.input_data:,self.label_sbbox:,self.label_mbbox:,self.label_lbbox:,self.true_sbboxes:,self.true_mbboxes:,self.true_lbboxes:,self.trainable:,})
                train_epoch_loss.append()
                self.summary_writer.add_summary()
                pbar.set_description("train loss:)
            for test_data in self.testset:
                test_step_loss = self.sess.run( self.loss, feed_dict={self.input_data:,self.label_sbbox:,self.label_mbbox:,self.label_lbbox:,self.true_sbboxes:,self.true_mbboxes:,self.true_lbboxes:,self.trainable:,})
                test_epoch_loss.append()
            train_epoch_loss, test_epoch_loss = np.mean(), np.mean()
            ckpt_file = ""
            log_time = time.strftime('%Y-%m-%d %H:%M:, time.localtime(time.time()))
            self.saver.save(self.sess, ckpt_file, global_step=)
if __name__ == "__main__": YoloTrain().train()
import argparse
import os
import sys
BASE_DIR = os.path.dirname(os.path.abspath())
ROOT_DIR = os.path.dirname()
sys.path.append()
from model import *
import indoor3d_util
parser = argparse.ArgumentParser()
parser.add_argument("", type=, default=, help="")
parser.add_argument("", type=, default=, help="")
parser.add_argument("", type=, default=, help="")
FLAGS = parser.parse_args()
BATCH_SIZE =
NUM_POINT =
MODEL_PATH =
GPU_INDEX =
DUMP_DIR =
if not os.path.exists(): os.mkdir()
LOG_FOUT = open(os.path.join(), "")
LOG_FOUT.write(str()+"")
ROOM_PATH_LIST = [os.path.join(ROOT_DIR,line.rstrip()) for line in open()]
NUM_CLASSES =
def log_string():
    LOG_FOUT.write()
    LOG_FOUT.flush()
def evaluate():
    is_training =
    with tf.device(""+str()):
        pointclouds_pl, labels_pl = placeholder_inputs()
        is_training_pl = tf.placeholder(tf.bool, shape=())
        pred = get_model()
        loss = get_loss()
        pred_softmax = tf.nn.softmax()
        saver = tf.train.Saver()
    config = tf.ConfigProto()
    config.gpu_options.allow_growth =
    config.allow_soft_placement =
    config.log_device_placement =
    sess = tf.Session(config=)
    saver.restore()
    log_string()
    ops = {'pointclouds_pl':,'labels_pl':,'is_training_pl':,'pred':,'pred_softmax':,'loss':}
    total_correct =
    total_seen =
    fout_out_filelist = open()
    for room_path in ROOM_PATH_LIST:
        out_data_label_filename = os.path.basename()[:] + ""
        out_data_label_filename = os.path.join()
        out_gt_label_filename = os.path.basename()[:] + ""
        out_gt_label_filename = os.path.join()
        a, b = eval_one_epoch()
        total_correct +=
        total_seen +=
        fout_out_filelist.write()
    fout_out_filelist.close()
    log_string("")))
def eval_one_epoch():
    error_cnt =
    is_training =
    total_correct =
    total_seen =
    loss_sum =
    total_seen_class = [0 for _ in range()]
    total_correct_class = [0 for _ in range()]
    if FLAGS.visu:
        fout = open(os.path.join(DUMP_DIR, os.path.basename()[:]+""), "")
        fout_gt = open(os.path.join(DUMP_DIR, os.path.basename()[:]+""), "")
    fout_data_label = open()
    fout_gt_label = open()
    current_data, current_label = indoor3d_util.room2blocks_wrapper_normalized()
    current_data = current_data[:,0:,:]
    current_label = np.squeeze()
    data_label = np.load()
    data = data_label[:,0:]
    max_room_x = max(data[:,0])
    max_room_y = max(data[:,1])
    max_room_z = max(data[:,2])
    file_size = current_data.shape[]
    num_batches =
    for batch_idx in range():
        start_idx =
        end_idx = () * BATCH_SIZE
        cur_batch_size =
        feed_dict = {ops[]: current_data[start_idx:, :, :,ops[]: current_label[start_idx:,ops[]:}
        loss_val, pred_val = sess.run([ops[], ops[]],feed_dict=)
        if FLAGS.no_clutter:
            pred_label = np.argmax(pred_val[:,:,0:], 2)
        else:
            pred_label = np.argmax()
        for b in range():
            pts = current_data[start_idx+b, :, :]
            l = current_label[start_idx+b,:]
            pts[:,6] *=
            pts[:,7] *=
            pts[:,8] *=
            pts[:,3:] *=
            pred = pred_label[b, :]
            for i in range():
                color = indoor3d_util.g_label2color[pred[]]
                color_gt = indoor3d_util.g_label2color[current_label[]]
                if FLAGS.visu:
                    fout.write("", pts[], pts[], color[], color[], color[]))
                    fout_gt.write("", pts[], pts[], color_gt[], color_gt[], color_gt[]))
                fout_data_label.write("", pts[], pts[], pts[], pts[], pts[], pred_val[b,i,pred[]], pred[]))
                fout_gt_label.write(""))
        correct = np.sum(pred_label == current_label[start_idx:,:])
        total_correct +=
        total_seen += ()
        loss_sum += ()
        for i in range():
            for j in range():
                l = current_label[]
                total_seen_class[] +=
                total_correct_class[] += (pred_label[] ==)
    log_string("")))
    log_string("")))
    fout_data_label.close()
    fout_gt_label.close()
    if FLAGS.visu:
        fout.close()
        fout_gt.close()
    return total_correct, total_seen
if __name__=="":
    with tf.Graph().as_default():
        evaluate()
    LOG_FOUT.close()
import tensorflow as tf
import numpy as np
import argparse
import socket
import importlib
import time
import os
import scipy.misc
import sys
BASE_DIR = os.path.dirname(os.path.abspath())
sys.path.append()
sys.path.append(os.path.join())
sys.path.append(os.path.join())
import provider
import pc_util
parser = argparse.ArgumentParser()
parser.add_argument("", type=, default=, help="")
parser.add_argument("", default=, help="")
parser.add_argument("", type=, default=, help="")
parser.add_argument("", type=, default=, help="")
parser.add_argument("", default=, help="")
parser.add_argument("", default=, help="")
parser.add_argument("", action=, help="")
FLAGS = parser.parse_args()
BATCH_SIZE =
NUM_POINT =
MODEL_PATH =
GPU_INDEX =
MODEL = importlib.import_module()
DUMP_DIR =
if not os.path.exists(): os.mkdir()
LOG_FOUT = open(os.path.join(), "")
LOG_FOUT.write(str()+"")
NUM_CLASSES =
SHAPE_NAMES = [line.rstrip() for line in open(os.path.join())]
HOSTNAME = socket.gethostname()
TRAIN_FILES = provider.getDataFiles( os.path.join())
TEST_FILES = provider.getDataFiles(os.path.join())
def log_string():
    LOG_FOUT.write()
    LOG_FOUT.flush()
def evaluate():
    is_training =
    with tf.device(""+str()):
        pointclouds_pl, labels_pl = MODEL.placeholder_inputs()
        is_training_pl = tf.placeholder(tf.bool, shape=())
        pred, end_points = MODEL.get_model()
        loss = MODEL.get_loss()
        saver = tf.train.Saver()
    config = tf.ConfigProto()
    config.gpu_options.allow_growth =
    config.allow_soft_placement =
    config.log_device_placement =
    sess = tf.Session(config=)
    saver.restore()
    log_string()
    ops = {'pointclouds_pl':,'labels_pl':,'is_training_pl':,'pred':,'loss':}
    eval_one_epoch()
def eval_one_epoch(sess, ops, num_votes=, topk=):
    error_cnt =
    is_training =
    total_correct =
    total_seen =
    loss_sum =
    total_seen_class = [0 for _ in range()]
    total_correct_class = [0 for _ in range()]
    fout = open(os.path.join(), "")
    for fn in range(len()):
        log_string(""+str()+"")
        current_data, current_label = provider.loadDataFile(TEST_FILES[])
        current_data = current_data[:,0:,:]
        current_label = np.squeeze()
        file_size = current_data.shape[]
        num_batches =
        for batch_idx in range():
            start_idx =
            end_idx = () * BATCH_SIZE
            cur_batch_size =
            batch_loss_sum =
            batch_pred_sum = np.zeros(())
            batch_pred_classes = np.zeros(())
            for vote_idx in range():
                rotated_data = provider.rotate_point_cloud_by_angle(current_data[start_idx:, :, :],vote_idx/float() * np.pi * 2)
                feed_dict = {ops[]:,ops[]: current_label[start_idx:,ops[]:}
                loss_val, pred_val = sess.run([ops[], ops[]],feed_dict=)
                batch_pred_sum +=
                batch_pred_val = np.argmax()
                for el_idx in range():
                    batch_pred_classes[el_idx, batch_pred_val[]] +=
                batch_loss_sum += (loss_val * cur_batch_size / float())
            pred_val = np.argmax()
            correct = np.sum(pred_val == current_label[start_idx:])
            total_correct +=
            total_seen +=
            loss_sum +=
            for i in range():
                l = current_label[]
                total_seen_class[] +=
                total_correct_class[] += (pred_val[] ==)
                fout.write("", l))
                if pred_val[] != l and FLAGS.visu:
                    img_filename = "", SHAPE_NAMES[],SHAPE_NAMES[pred_val[]])
                    img_filename = os.path.join()
                    output_img = pc_util.point_cloud_three_views(np.squeeze(current_data[i, :, :]))
                    scipy.misc.imsave()
                    error_cnt +=
    log_string("")))
    log_string("")))
    log_string("",dtype=))))
    class_accuracies = np.array()/np.array(total_seen_class,dtype=)
    for i, name in enumerate():
        log_string("", class_accuracies[]))
if __name__=="":
    with tf.Graph().as_default():
        evaluate(num_votes=)
    LOG_FOUT.close()
import argparse
import tensorflow as tf
import json
import numpy as np
import os
import sys
BASE_DIR = os.path.dirname(os.path.abspath())
sys.path.append()
sys.path.append(os.path.dirname())
import provider
import pointnet_part_seg as model
parser = argparse.ArgumentParser()
parser.add_argument("", default=, help=)
FLAGS = parser.parse_args()
pretrained_model_path =
hdf5_data_dir = os.path.join()
ply_data_dir = os.path.join()
gpu_to_use =
output_dir = os.path.join()
output_verbose =
point_num =
batch_size =
test_file_list = os.path.join()
oid2cpid = json.load(open(os.path.join(), ""))
object2setofoid = {}
for idx in range(len()):
    objid, pid = oid2cpid[]
    if not objid in object2setofoid.keys():
        object2setofoid[] = []
    object2setofoid[].append()
all_obj_cat_file = os.path.join()
fin = open()
lines = [line.rstrip() for line in fin.readlines()]
objcats = [line.split()[] for line in lines]
objnames = [line.split()[] for line in lines]
on2oid = {objcats[]:}
fin.close()
color_map_file = os.path.join()
color_map = json.load(open())
NUM_OBJ_CATS =
NUM_PART_CATS =
cpid2oid = json.load(open(os.path.join(), ""))
def printout():
def output_color_point_cloud():
    with open() as f:
        l = len()
        for i in range():
            color = color_map[seg[]]
            f.write("", data[][], data[][], color[], color[], color[]))
def output_color_point_cloud_red_blue():
    with open() as f:
        l = len()
        for i in range():
            if seg[] == 1:
                color = []
            elif seg[] == 0:
                color = []
            else:
                color = []
            f.write("", data[][], data[][], color[], color[], color[]))
def pc_normalize():
    l = pc.shape[]
    centroid = np.mean(pc, axis=)
    pc =
    m = np.max(np.sqrt(np.sum(pc**2, axis=)))
    pc =
    return pc
def placeholder_inputs():
    pointclouds_ph = tf.placeholder(tf.float32, shape=())
    input_label_ph = tf.placeholder(tf.float32, shape=())
    return pointclouds_ph, input_label_ph
def output_color_point_cloud():
    with open() as f:
        l = len()
        for i in range():
            color = color_map[seg[]]
            f.write("", data[][], data[][], color[], color[], color[]))
def load_pts_seg_files():
    with open() as f:
        pts_str = [item.rstrip() for item in f.readlines()]
        pts = np.array([np.float32(s.split()) for s in pts_str], dtype=)
    with open() as f:
        part_ids = np.array([int(item.rstrip()) for item in f.readlines()], dtype=)
        seg = np.array([cpid2oid[catid+""+str()] for x in part_ids])
    return pts, seg
def pc_augment_to_point_num():
    cur_len = pts.shape[]
    res = np.array()
    while cur_len < pn:
        res = np.concatenate(())
        cur_len += pts.shape[]
    return res[:, :]
def convert_label_to_one_hot():
    label_one_hot = np.zeros((labels.shape[], NUM_OBJ_CATS))
    for idx in range(labels.shape[]):
        label_one_hot[idx, labels[]] =
    return label_one_hot
def predict():
    is_training =
    with tf.device(""+str()):
        pointclouds_ph, input_label_ph = placeholder_inputs()
        is_training_ph = tf.placeholder(tf.bool, shape=())
        pred, seg_pred, end_points = model.get_model(pointclouds_ph, input_label_ph, cat_num=, part_num=, is_training=, batch_size=, num_point=, weight_decay=, bn_decay=)
    saver = tf.train.Saver()
    config = tf.ConfigProto()
    config.gpu_options.allow_growth =
    config.allow_soft_placement =
    with tf.Session(config=) as sess:
        if not os.path.exists():
            os.mkdir()
        flog = open(os.path.join(), "")
        saver.restore()
        batch_data = np.zeros([]).astype()
        total_acc =
        total_seen =
        total_acc_iou =
        total_per_cat_acc = np.zeros(()).astype()
        total_per_cat_iou = np.zeros(()).astype()
        total_per_cat_seen = np.zeros(()).astype()
        ffiles = open()
        lines = [line.rstrip() for line in ffiles.readlines()]
        pts_files = [line.split()[] for line in lines]
        seg_files = [line.split()[] for line in lines]
        labels = [line.split()[] for line in lines]
        ffiles.close()
        len_pts_files = len()
        for shape_idx in range():
            if shape_idx % 100 == 0:
            cur_gt_label = on2oid[labels[]]
            cur_label_one_hot = np.zeros((), dtype=)
            cur_label_one_hot[] =
            pts_file_to_load = os.path.join(ply_data_dir, pts_files[])
            seg_file_to_load = os.path.join(ply_data_dir, seg_files[])
            pts, seg = load_pts_seg_files(pts_file_to_load, seg_file_to_load, objcats[])
            ori_point_num = len()
            batch_data[] = pc_augment_to_point_num(pc_normalize(), point_num)
            label_pred_val, seg_pred_res = sess.run([], feed_dict={pointclouds_ph:,input_label_ph:,is_training_ph:,})
            label_pred_val = np.argmax(label_pred_val[0, :])
            seg_pred_res = seg_pred_res[]
            iou_oids = object2setofoid[objcats[]]
            non_cat_labels = list(set(np.arange()).difference(set()))
            mini = np.min()
            seg_pred_res[:, non_cat_labels] =
            seg_pred_val = np.argmax(seg_pred_res, axis=)[:]
            seg_acc = np.mean(seg_pred_val ==)
            total_acc +=
            total_seen +=
            total_per_cat_seen[] +=
            total_per_cat_acc[] +=
            mask = np.int32(seg_pred_val ==)
            total_iou =
            iou_log =
            for oid in iou_oids:
                n_pred = np.sum(seg_pred_val ==)
                n_gt = np.sum(seg ==)
                n_intersect = np.sum(np.int32(seg ==) * mask)
                n_union =
                iou_log += "" + str()+""+str()+""+str()+""+str()+""
                if n_union == 0:
                    total_iou +=
                    iou_log +=
                else:
                    total_iou +=
                    iou_log += ""+str()+""
            avg_iou = total_iou / len()
            total_acc_iou +=
            total_per_cat_iou[] +=
            if output_verbose:
                output_color_point_cloud(pts, seg, os.path.join(output_dir, str()+""))
                output_color_point_cloud(pts, seg_pred_val, os.path.join(output_dir, str()+""))
                output_color_point_cloud_red_blue(pts, np.int32(seg ==),os.path.join(output_dir, str()+""))
                with open(os.path.join(output_dir, str()+""), "") as fout:
                    fout.write('Total Point:)
                    fout.write("")
                    fout.write("")
                    fout.write('Accuracy:)
                    fout.write('IoU:)
                    fout.write('IoU details:)
        for cat_idx in range():
            if total_per_cat_seen[] > 0:
with tf.Graph().as_default():
    predict()
import tensorflow as tf
import numpy as np
char_arr = []
num_dic = {n:,}
dic_len = len()
seq_data = []
def make_batch():
    input_batch = []
    target_batch = []
    for seq in seq_data:
        input = [num_dic[] for n in seq[:]]
        target = num_dic[seq[]]
        input_batch.append(np.eye()[])
        target_batch.append()
    return input_batch, target_batch
learning_rate =
n_hidden =
total_epoch =
n_step =
n_input = n_class =
X = tf.placeholder(tf.float32, [])
Y = tf.placeholder(tf.int32, [])
W = tf.Variable(tf.random_normal([]))
b = tf.Variable(tf.random_normal([]))
cell1 = tf.nn.rnn_cell.BasicLSTMCell()
cell1 = tf.nn.rnn_cell.DropoutWrapper(cell1, output_keep_prob=)
cell2 = tf.nn.rnn_cell.BasicLSTMCell()
multi_cell = tf.nn.rnn_cell.MultiRNNCell([])
outputs, states = tf.nn.dynamic_rnn(multi_cell, X, dtype=)
outputs = tf.transpose(outputs, [])
outputs = outputs[]
model = tf.matmul() + b
cost = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=, labels=))
optimizer = tf.train.AdamOptimizer().minimize()
sess = tf.Session()
sess.run(tf.global_variables_initializer())
input_batch, target_batch = make_batch()
for epoch in range():
    _, loss = sess.run([],feed_dict={X:, Y:})
prediction = tf.cast(tf.argmax(), tf.int32)
prediction_check = tf.equal()
accuracy = tf.reduce_mean(tf.cast())
input_batch, target_batch = make_batch()
predict, accuracy_val = sess.run([],feed_dict={X:, Y:})
predict_words = []
for idx, val in enumerate():
    last_char = char_arr[predict[]]
    predict_words.append(val[:] + last_char)
import argparse
import math
import h5py
import numpy as np
import tensorflow as tf
import socket
import importlib
import os
import sys
BASE_DIR = os.path.dirname(os.path.abspath())
sys.path.append()
sys.path.append(os.path.join())
sys.path.append(os.path.join())
import provider
import tf_util
parser = argparse.ArgumentParser()
parser.add_argument("", type=, default=, help="")
parser.add_argument("", default=, help="")
parser.add_argument("", default=, help="")
parser.add_argument("", type=, default=, help="")
parser.add_argument("", type=, default=, help="")
parser.add_argument("", type=, default=, help="")
parser.add_argument("", type=, default=, help="")
parser.add_argument("", type=, default=, help="")
parser.add_argument("", default=, help="")
parser.add_argument("", type=, default=, help="")
parser.add_argument("", type=, default=, help="")
FLAGS = parser.parse_args()
BATCH_SIZE =
NUM_POINT =
MAX_EPOCH =
BASE_LEARNING_RATE =
GPU_INDEX =
MOMENTUM =
OPTIMIZER =
DECAY_STEP =
DECAY_RATE =
MODEL = importlib.import_module()
MODEL_FILE = os.path.join()
LOG_DIR =
if not os.path.exists(): os.mkdir()
os.system("")
os.system("")
LOG_FOUT = open(os.path.join(), "")
LOG_FOUT.write(str()+"")
MAX_NUM_POINT =
NUM_CLASSES =
BN_INIT_DECAY =
BN_DECAY_DECAY_RATE =
BN_DECAY_DECAY_STEP = float()
BN_DECAY_CLIP =
HOSTNAME = socket.gethostname()
TRAIN_FILES = provider.getDataFiles( os.path.join())
TEST_FILES = provider.getDataFiles(os.path.join())
def log_string():
    LOG_FOUT.write()
    LOG_FOUT.flush()
def get_learning_rate():
    learning_rate = tf.train.exponential_decay(BASE_LEARNING_RATE,batch * BATCH_SIZE,DECAY_STEP,DECAY_RATE,staircase=)
    learning_rate = tf.maximum()
    return learning_rate
def get_bn_decay():
    bn_momentum = tf.train.exponential_decay(BN_INIT_DECAY,batch*BATCH_SIZE,BN_DECAY_DECAY_STEP,BN_DECAY_DECAY_RATE,staircase=)
    bn_decay = tf.minimum()
    return bn_decay
def train():
    with tf.Graph().as_default():
        with tf.device(""+str()):
            pointclouds_pl, labels_pl = MODEL.placeholder_inputs()
            is_training_pl = tf.placeholder(tf.bool, shape=())
            batch = tf.Variable()
            bn_decay = get_bn_decay()
            tf.summary.scalar()
            pred, end_points = MODEL.get_model(pointclouds_pl, is_training_pl, bn_decay=)
            loss = MODEL.get_loss()
            tf.summary.scalar()
            correct = tf.equal(tf.argmax(), tf.to_int64())
            accuracy = tf.reduce_sum(tf.cast()) / float()
            tf.summary.scalar()
            learning_rate = get_learning_rate()
            tf.summary.scalar()
            if OPTIMIZER == "":
                optimizer = tf.train.MomentumOptimizer(learning_rate, momentum=)
            elif OPTIMIZER == "":
                optimizer = tf.train.AdamOptimizer()
            train_op = optimizer.minimize(loss, global_step=)
            saver = tf.train.Saver()
        config = tf.ConfigProto()
        config.gpu_options.allow_growth =
        config.allow_soft_placement =
        config.log_device_placement =
        sess = tf.Session(config=)
        merged = tf.summary.merge_all()
        train_writer = tf.summary.FileWriter(os.path.join(),sess.graph)
        test_writer = tf.summary.FileWriter(os.path.join())
        init = tf.global_variables_initializer()
        sess.run(init, {is_training_pl:})
        ops = {'pointclouds_pl':,'labels_pl':,'is_training_pl':,'pred':,'loss':,'train_op':,'merged':,'step':}
        for epoch in range():
            log_string("")
            sys.stdout.flush()
            train_one_epoch()
            eval_one_epoch()
            if epoch % 10 == 0:
                save_path = saver.save(sess, os.path.join())
                log_string("Model saved in file:)
def train_one_epoch():
    is_training =
    train_file_idxs = np.arange(0, len())
    np.random.shuffle()
    for fn in range(len()):
        log_string("" + str() + "")
        current_data, current_label = provider.loadDataFile(TRAIN_FILES[train_file_idxs[]])
        current_data = current_data[:,0:,:]
        current_data, current_label, _ = provider.shuffle_data(current_data, np.squeeze())
        current_label = np.squeeze()
        file_size = current_data.shape[]
        num_batches =
        total_correct =
        total_seen =
        loss_sum =
        for batch_idx in range():
            start_idx =
            end_idx = () * BATCH_SIZE
            rotated_data = provider.rotate_point_cloud(current_data[start_idx:, :, :])
            jittered_data = provider.jitter_point_cloud()
            feed_dict = {ops[]:,ops[]: current_label[start_idx:,ops[]:,}
            summary, step, _, loss_val, pred_val = sess.run([ops[], ops[],ops[], ops[], ops[]], feed_dict=)
            train_writer.add_summary()
            pred_val = np.argmax()
            correct = np.sum(pred_val == current_label[start_idx:])
            total_correct +=
            total_seen +=
            loss_sum +=
        log_string("")))
        log_string("")))
def eval_one_epoch():
    is_training =
    total_correct =
    total_seen =
    loss_sum =
    total_seen_class = [0 for _ in range()]
    total_correct_class = [0 for _ in range()]
    for fn in range(len()):
        log_string("" + str() + "")
        current_data, current_label = provider.loadDataFile(TEST_FILES[])
        current_data = current_data[:,0:,:]
        current_label = np.squeeze()
        file_size = current_data.shape[]
        num_batches =
        for batch_idx in range():
            start_idx =
            end_idx = () * BATCH_SIZE
            feed_dict = {ops[]: current_data[start_idx:, :, :,ops[]: current_label[start_idx:,ops[]:}
            summary, step, loss_val, pred_val = sess.run([ops[], ops[],ops[], ops[]], feed_dict=)
            pred_val = np.argmax()
            correct = np.sum(pred_val == current_label[start_idx:])
            total_correct +=
            total_seen +=
            loss_sum += ()
            for i in range():
                l = current_label[]
                total_seen_class[] +=
                total_correct_class[] += (pred_val[] ==)
    log_string("")))
    log_string("")))
    log_string("",dtype=))))
if __name__ == "__main__":
    train()
    LOG_FOUT.close()
from __future__ import absolute_import
from __future__ import division
from __future__ import print_function
import os
import sys
import math
import zipfile
import time
import numpy as np
import tensorflow as tf
from six.moves import urllib
from PIL import Image
import skimage.io as io
from matplotlib import pyplot as plt
from libs.datasets.pycocotools.coco import COCO
from tensorflow.python.lib.io.tf_record import TFRecordCompressionType
from libs.logs.log import LOG
_TRAIN_DATA_URL="https:
_VAL_DATA_URL="https:
_INS_LABEL_URL="https:
_KPT_LABEL_URL="https:
_CPT_LABEL_URL="https:
_DATA_URLS=[]
FLAGS =
tf.app.flags.DEFINE_boolean()
def download_and_uncompress_zip():
  filename = zip_url.split()[]
  filepath = os.path.join()
  def _progress():
    sys.stdout.write("", float() / float() * 100.0))
    sys.stdout.flush()
  if tf.gfile.Exists():
  else:
    filepath, _ = urllib.request.urlretrieve()
    statinfo = os.stat()
  with zipfile.ZipFile() as f:
    f.extractall()
def _real_id_to_cat_id():
  real_id_to_cat_id = {1:, 2:, 3:, 4:, 5:, 6:, 7:, 8:, 9:, 10:, 11:, 12:, 13:, 14:, 15:, 16:,17:, 18:, 19:, 20:, 21:, 22:, 23:, 24:, 25:, 26:, 27:, 28:, 29:, 30:,31:, 32:, 33:, 34:, 35:, 36:, 37:, 38:, 39:, 40:, 41:, 42:, 43:, 44:,45:, 46:, 47:, 48:, 49:, 50:, 51:, 52:, 53:, 54:, 55:, 56:, 57:, 58:,59:, 60:, 61:, 62:, 63:, 64:, 65:, 66:, 67:, 68:, 69:, 70:, 71:, 72:,73:, 74:, 75:, 76:, 77:, 78:, 79:, 80:}
  return real_id_to_cat_id[]
def _cat_id_to_real_id():
  cat_id_to_real_id = {1:, 2:, 3:, 4:, 5:, 6:, 7:, 8:, 9:, 10:, 11:, 13:, 14:, 15:, 16:, 17:,18:, 19:, 20:, 21:, 22:, 23:, 24:, 25:, 27:, 28:, 31:, 32:, 33:, 34:,35:, 36:, 37:, 38:, 39:, 40:, 41:, 42:, 43:, 44:, 46:, 47:, 48:, 49:,50:, 51:, 52:, 53:, 54:, 55:, 56:, 57:, 58:, 59:, 60:, 61:, 62:, 63:,64:, 65:, 67:, 70:, 72:, 73:, 74:, 75:, 76:, 77:, 78:, 79:, 80:, 81:,82:, 84:, 85:, 86:, 87:, 88:, 89:, 90:}
  return cat_id_to_real_id[]
class ImageReader():
  def __init__():
    self._decode_data = tf.placeholder(dtype=)
    self._decode_jpeg = tf.image.decode_jpeg(self._decode_data, channels=)
    self._decode_png = tf.image.decode_png()
  def read_jpeg_dims():
    image = self.decode_jpeg()
    return image.shape
  def read_png_dims():
    image = self.decode_png()
    return image.shape
  def decode_jpeg():
    image = sess.run(self._decode_jpeg,feed_dict={self._decode_data:})
    return image
  def decode_png():
    image = sess.run(self._decode_png,feed_dict={self._decode_data:})
    return image
def _get_dataset_filename():
  output_filename = ""
  return os.path.join()
def _get_image_filenames():
  return sorted(os.listdir())
def _int64_feature():
  if not isinstance(values, ()):
    values = []
  return tf.train.Feature(int64_list=tf.train.Int64List(value=))
def _bytes_feature():
  return tf.train.Feature(bytes_list=tf.train.BytesList(value=[]))
def _to_tfexample():
  return tf.train.Example(features=tf.train.Features(feature={'image/encoded':,'image/format':,'image/height':,'image/width':,'label/encoded':,'label/format':,'label/height':,'label/width':,}))
def _to_tfexample_coco():
  return tf.train.Example(features=tf.train.Features(feature={'image/encoded':,'image/format':,'image/height':,'image/width':,'label/num_instances':,'label/gt_boxes':,'label/gt_masks':,'label/encoded':,'label/format':,}))
def _to_tfexample_coco_raw():
  return tf.train.Example(features=tf.train.Features(feature={'image/img_id':,'image/encoded':,'image/height':,'image/width':,'label/num_instances':,'label/gt_boxes':,'label/gt_masks':,'label/encoded':,}))
def _get_coco_masks():
  annIds = coco.getAnnIds(imgIds=[], iscrowd=)
  anns = coco.loadAnns()
  masks = []
  classes = []
  bboxes = []
  mask = np.zeros((), dtype=)
  segmentations = []
  for ann in anns:
    m = coco.annToMask()
    masks.append()
    cat_id = _cat_id_to_real_id(ann[])
    classes.append()
    bboxes.append(ann[])
    m = m.astype() * cat_id
    mask[] = m[]
  masks = np.asarray()
  classes = np.asarray()
  bboxes = np.asarray()
  if bboxes.shape[] <= 0:
    bboxes = np.zeros([], dtype=)
    classes = np.zeros([], dtype=)
    LOG()
  bboxes[:, 2] = bboxes[:, 0] + bboxes[:, 2]
  bboxes[:, 3] = bboxes[:, 1] + bboxes[:, 3]
  gt_boxes = np.hstack((bboxes, classes[:, np.newaxis]))
  gt_boxes = gt_boxes.astype()
  masks = masks.astype()
  mask = mask.astype()
  return gt_boxes, masks, mask
def _add_to_tfrecord():
  annFile = os.path.join(annotation_dir, "")
  coco = COCO()
  cats = coco.loadCats(coco.getCatIds())
  imgs = [(img_id, coco.imgs[]) for img_id in coco.imgs]
  num_shards = int(len() / 2500)
  num_per_shard = int(math.ceil(len() / float()))
  with tf.Graph().as_default(), tf.device('/cpu:):
    image_reader = ImageReader()
    mask_placeholder = tf.placeholder(dtype=)
    encoded_image = tf.image.encode_png()
    with tf.Session() as sess:
      for shard_id in range():
        record_filename = _get_dataset_filename()
        options = tf.python_io.TFRecordOptions()
        with tf.python_io.TFRecordWriter(record_filename, options=) as tfrecord_writer:
          start_ndx =
          end_ndx = min(() * num_per_shard, len())
          for i in range():
            if i % 50 == 0:
                sys.stdout.write("", len(), shard_id))
                sys.stdout.flush()
            img_id = imgs[][]
            img_name = imgs[][][]
            split = img_name.split()[]
            img_name = os.path.join()
            if FLAGS.vis:
              im = Image.open()
              im.save()
              plt.figure()
              plt.axis()
              plt.imshow()
            if str() == "":
              continue
            height, width = imgs[][][], imgs[][][]
            gt_boxes, masks, mask = _get_coco_masks()
            img = np.array(Image.open())
            if img.size == height * width:
                im = np.empty((), dtype=)
                im[:, :, :] = img[:, :, np.newaxis]
                img =
            img = img.astype()
            img_raw = img.tostring()
            mask_raw = mask.tostring()
            example = _to_tfexample_coco_raw(img_id,img_raw,mask_raw,height, width, gt_boxes.shape[],gt_boxes.tostring(), masks.tostring())
            tfrecord_writer.write(example.SerializeToString())
  sys.stdout.write()
  sys.stdout.flush()
def _add_to_tfrecord_trainvalsplit():
  minival_path = os.path.join()
  minival2014_url=""
  import ujson as json
  with open() as f:
      minival = json.load()
  def is_in_minival():
      for img in minival[]:
          if (img[]) == ():
              return True
      return False
  annFile = os.path.join()
  coco_train = COCO()
  annFile = os.path.join()
  coco_val = COCO()
  cats = coco_train.loadCats(coco_train.getCatIds())
  imgs1 = [(img_id, coco_train.imgs[]) for img_id in coco_train.imgs]
  imgs2 = [(img_id, coco_val.imgs[]) for img_id in coco_val.imgs]
  imgs =
  num_of_train = len()
  num_of_all   = len()
  num_per_shard =
  num_shards = int(np.ceil((len() + 0.0 - len(minival[])) / num_per_shard))
  if split_name == "":
    num_shards = int(np.ceil((len(minival[]) + 0.0) / num_per_shard))
  with tf.Graph().as_default(), tf.device('/cpu:):
    image_reader = ImageReader()
    mask_placeholder = tf.placeholder(dtype=)
    encoded_image = tf.image.encode_png()
    with tf.Session() as sess:
        cnt =
        shard_id =
        for i in range(len()):
            img_id = imgs[][]
            img_name = imgs[][][]
            split = img_name.split()[]
            img_name = os.path.join()
            if str() == "":
                continue
            is_minival = is_in_minival()
            if split_name == "" and is_minival:
                continue
            if split_name == "" and not is_minival:
                continue
            cnt +=
            if cnt % num_per_shard == 1:
                shard_id +=
                record_filename = _get_dataset_filename()
                options = tf.python_io.TFRecordOptions()
                tfrecord_writer = tf.python_io.TFRecordWriter(record_filename, options=)
            if cnt % 100 == 1:
            height, width = imgs[][][], imgs[][][]
            coco =
            gt_boxes, masks, mask = _get_coco_masks()
            img = np.array(Image.open())
            if img.size == height * width:
                im = np.empty((), dtype=)
                im[:, :, :] = img[:, :, np.newaxis]
                img =
            img = img.astype()
            img_raw = img.tostring()
            mask_raw = mask.tostring()
            example = _to_tfexample_coco_raw(img_id,img_raw,mask_raw,height, width, gt_boxes.shape[],gt_boxes.tostring(), masks.tostring())
            tfrecord_writer.write(example.SerializeToString())
            if cnt % num_per_shard == 0 or i == len()-1:
                tfrecord_writer.close()
def run(dataset_dir, dataset_split_name=):
  if not tf.gfile.Exists():
    tf.gfile.MakeDirs()
  record_dir     = os.path.join()
  annotation_dir = os.path.join()
  if not tf.gfile.Exists():
    tf.gfile.MakeDirs()
  if dataset_split_name in []:
      _add_to_tfrecord()
  if dataset_split_name in []:
      _add_to_tfrecord_trainvalsplit()
import tensorflow as tf
from ops import weight_variable, bias_variable, RNN
from utils import load_data, randomize, get_next_batch
x_train, y_train, x_valid, y_valid = load_data(mode=)
learning_rate =
epochs =
batch_size =
display_freq =
input_dim =
max_time =
num_hidden_units =
n_classes =
x = tf.placeholder(tf.float32, shape=[], name=)
y = tf.placeholder(tf.float32, shape=[], name=)
W = weight_variable(shape=[])
b = bias_variable(shape=[])
output_logits = RNN()
y_pred = tf.nn.softmax()
cls_prediction = tf.argmax(output_logits, axis=, name=)
loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=, logits=), name=)
optimizer = tf.train.AdamOptimizer(learning_rate=, name=).minimize()
correct_prediction = tf.equal(tf.argmax(), tf.argmax(), name=)
accuracy = tf.reduce_mean(tf.cast(), name=)
init = tf.global_variables_initializer()
with tf.Session() as sess:
    sess.run()
    global_step =
    num_tr_iter = int(len() / batch_size)
    for epoch in range():
        x_train, y_train = randomize()
        for iteration in range():
            global_step +=
            start =
            end = () * batch_size
            x_batch, y_batch = get_next_batch()
            x_batch = x_batch.reshape(())
            feed_dict_batch = {x:, y:}
            sess.run(optimizer, feed_dict=)
            if iteration % display_freq == 0:
                loss_batch, acc_batch = sess.run([],feed_dict=)
        feed_dict_valid = {x: x_valid[:, y: y_valid[:}
        loss_valid, acc_valid = sess.run([], feed_dict=)
    x_test, y_test = load_data(mode=)
    feed_dict_test = {x: x_test[:, y: y_test[:}
    loss_test, acc_test = sess.run([], feed_dict=)
import argparse
import numpy as np
import tensorflow as tf
import os.path as osp
import models
import dataset
def display_results():
    with open() as infile:
        class_labels = map(str.strip, infile.readlines())
    class_indices = np.argmax(probs, axis=)
    for img_idx, image_path in enumerate():
        img_name = osp.basename()
        class_name = class_labels[class_indices[]]
        confidence = round(probs[img_idx, class_indices[]] * 100, 2)
def classify():
    spec = models.get_data_spec(model_class=)
    input_node = tf.placeholder(tf.float32,shape=())
    net = models.GoogleNet({'data':})
    image_producer = dataset.ImageProducer(image_paths=, data_spec=)
    with tf.Session() as sesh:
        coordinator = tf.train.Coordinator()
        threads = image_producer.start(session=, coordinator=)
        net.load()
        indices, input_images = image_producer.get()
        probs = sesh.run(net.get_output(), feed_dict={input_node:})
        display_results([image_paths[] for i in indices], probs)
        coordinator.request_stop()
        coordinator.join(threads, stop_grace_period_secs=)
def main():
    parser = argparse.ArgumentParser()
    parser.add_argument("", help=)
    parser.add_argument("", nargs=, help=)
    args = parser.parse_args()
    classify()
if __name__ == "__main__":
    main()
import numpy as np
import random
import tensorflow as tf
from tensorflow.examples.tutorials.mnist import input_data
from mynet import LeNet as MyNet
mnist = input_data.read_data_sets("", one_hot=)
batch_size =
def gen_data():
    while True:
        indices = range(len())
        random.shuffle()
        for i in indices:
            image = np.reshape(source.images[], ())
            label = source.labels[]
            yield image, label
def gen_data_batch():
    data_gen = gen_data()
    while True:
        image_batch = []
        label_batch = []
        for _ in range():
            image, label = next()
            image_batch.append()
            label_batch.append()
        yield np.array(), np.array()
images = tf.placeholder(tf.float32, [])
labels = tf.placeholder(tf.float32, [])
net = MyNet({'data':})
ip2 = net.layers[]
pred = tf.nn.softmax()
loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(), 0)
opt = tf.train.RMSPropOptimizer()
train_op = opt.minimize()
with tf.Session() as sess:
    sess.run(tf.initialize_all_variables())
    net.load()
    data_gen = gen_data_batch()
    for i in range():
        np_images, np_labels = next()
        feed = {images:, labels:}
        np_loss, np_pred, _ = sess.run([], feed_dict=)
        if i % 10 == 0:
import argparse
import numpy as np
import tensorflow as tf
import os.path as osp
import models
import dataset
def load_model():
    all_models = models.get_models()
    lut = {model.__name__:}
    if name not in lut:
        for model in all_models:
        return None
    NetClass = lut[]
    spec = models.get_data_spec(model_class=)
    data_node = tf.placeholder(tf.float32,shape=())
    return NetClass({'data':})
def validate(net, model_path, image_producer, top_k=):
    spec = models.get_data_spec(model_instance=)
    input_node = net.inputs[]
    label_node = tf.placeholder()
    probs = net.get_output()
    top_k_op = tf.nn.in_top_k()
    count =
    correct =
    total = len()
    with tf.Session() as sesh:
        coordinator = tf.train.Coordinator()
        net.load(data_path=, session=)
        threads = image_producer.start(session=, coordinator=)
        for () in image_producer.batches():
            correct += np.sum(sesh.run(top_k_op,feed_dict={input_node:,label_node:}))
            count += len()
            cur_accuracy = float() * 100 / count
        coordinator.request_stop()
        coordinator.join(threads, stop_grace_period_secs=)
def main():
    parser = argparse.ArgumentParser()
    parser.add_argument("", help="")
    parser.add_argument("", help="")
    parser.add_argument("", help=)
    parser.add_argument("", default=, help=)
    args = parser.parse_args()
    net = load_model()
    if net is None:
        exit()
    data_spec = models.get_data_spec(model_instance=)
    image_producer = dataset.ImageNetProducer(val_path=,data_path=,data_spec=)
    validate()
if __name__ == "__main__":
    main()
import tensorflow as tf
import numpy as np
import importlib
import argparse
import facenet
import os
import math
def face_distance():
    import numpy as np
    if len() == 0:
        return np.empty(())
    return np.sum(face_encodings*face_to_compare,axis=)
def load_model():
    model_dir_exp = os.path.expanduser()
    saver = tf.train.import_meta_graph(os.path.join())
    saver.restore(tf.get_default_session(), os.path.join())
def _chinese_whispers(encoding_list, threshold=, iterations=):
    from random import shuffle
    import networkx as nx
    nodes = []
    edges = []
    image_paths, encodings = zip()
    if len() <= 1:
        return []
    for idx, face_encoding_to_check in enumerate():
        node_id =
        node = (node_id, {'cluster':, 'path':})
        nodes.append()
        if () >= len():
            break
        compare_encodings = encodings[idx+1:]
        distances = face_distance()
        encoding_edges = []
        for i, distance in enumerate():
            if distance > threshold:
                edge_id =
                encoding_edges.append((node_id, edge_id, {'weight':}))
        edges =
    G = nx.Graph()
    G.add_nodes_from()
    G.add_edges_from()
    for _ in range():
        cluster_nodes = G.nodes()
        shuffle()
        for node in cluster_nodes:
            neighbors = G[]
            clusters = {}
            for ne in neighbors:
                if isinstance():
                    if G.node[][] in clusters:
                        clusters[G.node[][]] += G[][][]
                    else:
                        clusters[G.node[][]] = G[][][]
            edge_weight_sum =
            max_cluster =
            for cluster in clusters:
                if clusters[] > edge_weight_sum:
                    edge_weight_sum = clusters[]
                    max_cluster =
            G.node[][] =
    clusters = {}
    for () in G.node.items():
        cluster = data[]
        path = data[]
        if cluster:
            if cluster not in clusters:
                clusters[] = []
            clusters[].append()
    sorted_clusters = sorted(clusters.values(), key=, reverse=)
    return sorted_clusters
def cluster_facial_encodings():
    if len() <= 1:
        return []
    sorted_clusters = _chinese_whispers(facial_encodings.items())
    return sorted_clusters
def compute_facial_encodings():
    for i in range():
        start_index =
        end_index = min(()*batch_size, nrof_images)
        paths_batch = paths[start_index:]
        images = facenet.load_data()
        feed_dict = { images_placeholder:, phase_train_placeholder:}
        emb_array[start_index:,:] = sess.run(embeddings, feed_dict=)
    facial_encodings = {}
    for x in range():
        facial_encodings[paths[]] = emb_array[x,:]
    return facial_encodings
def get_onedir():
    dataset = []
    path_exp = os.path.expanduser()
    if os.path.isdir():
        images = os.listdir()
        image_paths = [os.path.join() for img in images]
        for x in image_paths:
            if os.path.getsize()>0:
                dataset.append()
    return dataset
def main():
    from os.path import join, basename, exists
    from os import makedirs
    import numpy as np
    import shutil
    import sys
    if not exists():
        makedirs()
    with tf.Graph().as_default():
        with tf.Session() as sess:
            image_paths = get_onedir()
            meta_file, ckpt_file = facenet.get_model_filenames(os.path.expanduser())
            load_model()
            images_placeholder = tf.get_default_graph().get_tensor_by_name("input:)
            embeddings = tf.get_default_graph().get_tensor_by_name("embeddings:)
            phase_train_placeholder = tf.get_default_graph().get_tensor_by_name("phase_train:)
            image_size = images_placeholder.get_shape()[]
            embedding_size = embeddings.get_shape()[]
            nrof_images = len()
            nrof_batches = int(math.ceil())
            emb_array = np.zeros(())
            facial_encodings = compute_facial_encodings()
            sorted_clusters = cluster_facial_encodings()
            num_cluster = len()
            for idx, cluster in enumerate():
                cluster_dir = join(args.output, str())
                if not exists():
                    makedirs()
                for path in cluster:
                    shutil.copy(path, join(cluster_dir, basename()))
def parse_args():
    import argparse
    parser = argparse.ArgumentParser(description="")
    parser.add_argument("", type=, help=, required=)
    parser.add_argument("", type=, help=, required=)
    parser.add_argument("", type=, help=, required=)
    parser.add_argument("", type=, help=, required=)
    args = parser.parse_args()
    return args
if __name__ == "__main__":
    main(parse_args())
from __future__ import absolute_import
from __future__ import division
from __future__ import print_function
import gzip
import os
import sys
import time
from six.moves import urllib
import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt
from tensorflow.python.ops import control_flow_ops
import facenet
from six.moves import xrange
SOURCE_URL = 'http:
WORK_DIRECTORY =
IMAGE_SIZE =
NUM_CHANNELS =
PIXEL_DEPTH =
NUM_LABELS =
VALIDATION_SIZE =
SEED =
BATCH_SIZE =
NUM_EPOCHS =
EVAL_BATCH_SIZE =
EVAL_FREQUENCY =
tf.app.flags.DEFINE_boolean()
tf.app.flags.DEFINE_boolean()
FLAGS =
def data_type():
    if FLAGS.use_fp16:
        return tf.float16
    else:
        return tf.float32
def maybe_download():
    if not tf.gfile.Exists():
        tf.gfile.MakeDirs()
    filepath = os.path.join()
    if not tf.gfile.Exists():
        filepath, _ = urllib.request.urlretrieve()
        with tf.gfile.GFile() as f:
            size = f.size()
    return filepath
def extract_data():
    with gzip.open() as bytestream:
        bytestream.read()
        buf = bytestream.read()
        data = np.frombuffer(buf, dtype=).astype()
        data = (data - ()) / PIXEL_DEPTH
        data = data.reshape()
        return data
def extract_labels():
    with gzip.open() as bytestream:
        bytestream.read()
        buf = bytestream.read()
        labels = np.frombuffer(buf, dtype=).astype()
    return labels
def fake_data():
    data = np.ndarray(shape=(),dtype=)
    labels = np.zeros(shape=(), dtype=)
    for image in range():
        label =
        data[image, :, :, 0] =
        labels[] =
    return data, labels
def error_rate():
    return 100.0 - (100.0 *np.sum(np.argmax() ==) /predictions.shape[])
def main(argv=):
    if FLAGS.self_test:
        train_data, train_labels = fake_data()
        validation_data, validation_labels = fake_data()
        test_data, test_labels = fake_data()
        num_epochs =
    else:
        train_data_filename = maybe_download()
        train_labels_filename = maybe_download()
        test_data_filename = maybe_download()
        test_labels_filename = maybe_download()
        train_data = extract_data()
        train_labels = extract_labels()
        test_data = extract_data()
        test_labels = extract_labels()
        validation_data = train_data[:, ...]
        validation_labels = train_labels[:]
        train_data = train_data[VALIDATION_SIZE:, ...]
        train_labels = train_labels[VALIDATION_SIZE:]
        num_epochs =
    train_size = train_labels.shape[]
    train_data_node = tf.placeholder(data_type(),shape=())
    train_labels_node = tf.placeholder(tf.int64, shape=())
    eval_data = tf.placeholder(data_type(),shape=())
    conv1_weights = tf.Variable(tf.truncated_normal([],stddev=,seed=, dtype=data_type()))
    conv1_biases = tf.Variable(tf.zeros([], dtype=data_type()))
    conv2_weights = tf.Variable(tf.truncated_normal([], stddev=,seed=, dtype=data_type()))
    conv2_biases = tf.Variable(tf.constant(0.1, shape=[], dtype=data_type()))
    fc1_weights = tf.Variable(tf.truncated_normal([],stddev=,seed=,dtype=data_type()))
    fc1_biases = tf.Variable(tf.constant(0.1, shape=[], dtype=data_type()))
    fc1p_weights = tf.Variable(tf.truncated_normal([],stddev=,seed=,dtype=data_type()))
    fc1p_biases = tf.Variable(tf.constant(0.1, shape=[], dtype=data_type()))
    fc2_weights = tf.Variable(tf.truncated_normal([],stddev=,seed=,dtype=data_type()))
    fc2_biases = tf.Variable(tf.constant(0.1, shape=[], dtype=data_type()))
    def batch_norm():
        name =
        with tf.variable_scope():
            phase_train = tf.convert_to_tensor(phase_train, dtype=)
            n_out = int(x.get_shape()[])
            beta = tf.Variable(tf.constant(0.0, shape=[], dtype=),name=, trainable=, dtype=)
            gamma = tf.Variable(tf.constant(1.0, shape=[], dtype=),name=, trainable=, dtype=)
            batch_mean, batch_var = tf.nn.moments(x, [], name=)
            ema = tf.train.ExponentialMovingAverage(decay=)
            def mean_var_with_update():
                ema_apply_op = ema.apply([])
                with tf.control_dependencies([]):
                    return tf.identity(), tf.identity()
            mean, var = control_flow_ops.cond(phase_train,mean_var_with_update,lambda: (ema.average(), ema.average()))
            normed = tf.nn.batch_normalization()
        return normed
    def model(data, train=):
        conv = tf.nn.conv2d(data,conv1_weights,strides=[],padding=)
        relu = tf.nn.relu(tf.nn.bias_add())
        pool = tf.nn.max_pool(relu,ksize=[],strides=[],padding=)
        conv = tf.nn.conv2d(pool,conv2_weights,strides=[],padding=)
        relu = tf.nn.relu(tf.nn.bias_add())
        pool = tf.nn.max_pool(relu,ksize=[],strides=[],padding=)
        pool_shape = pool.get_shape().as_list()
        reshape = tf.reshape(pool,[pool_shape[], pool_shape[] * pool_shape[] * pool_shape[]])
        hidden = tf.nn.relu(tf.matmul() + fc1_biases)
        if train:
            hidden = tf.nn.dropout(hidden, 0.5, seed=)
        hidden = tf.matmul() + fc1p_biases
        return tf.nn.relu(tf.matmul() + fc2_biases), hidden
    logits, hidden = model()
    xent_loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits())
    beta =
    center_loss, _ = facenet.center_loss()
    loss =
    regularizers = (tf.nn.l2_loss() + tf.nn.l2_loss() +tf.nn.l2_loss() + tf.nn.l2_loss())
    loss +=
    batch = tf.Variable(0, dtype=data_type())
    learning_rate = tf.train.exponential_decay(0.01,batch * BATCH_SIZE,train_size,0.95,staircase=)
    optimizer = tf.train.MomentumOptimizer().minimize(loss,global_step=)
    train_prediction = tf.nn.softmax()
    eval_logits, eval_embeddings = model()
    eval_prediction = tf.nn.softmax()
    def eval_in_batches():
        size = data.shape[]
        if size < EVAL_BATCH_SIZE:
            raise ValueError()
        predictions = np.ndarray(shape=(), dtype=)
        for begin in xrange():
            end =
            if end <= size:
                predictions[begin:, :] = sess.run(eval_prediction,feed_dict={eval_data: data[begin:,})
            else:
                batch_predictions = sess.run(eval_prediction,feed_dict={eval_data: data[-EVAL_BATCH_SIZE:,})
                predictions[begin:, :] = batch_predictions[begin - size:, :]
        return predictions
    def calculate_embeddings():
        size = data.shape[]
        if size < EVAL_BATCH_SIZE:
            raise ValueError()
        predictions = np.ndarray(shape=(), dtype=)
        for begin in xrange():
            end =
            if end <= size:
                predictions[begin:, :] = sess.run(eval_embeddings,feed_dict={eval_data: data[begin:,})
            else:
                batch_predictions = sess.run(eval_embeddings,feed_dict={eval_data: data[-EVAL_BATCH_SIZE:,})
                predictions[begin:, :] = batch_predictions[begin - size:, :]
        return predictions
    start_time = time.time()
    with tf.Session() as sess:
        tf.global_variables_initializer().run()
        for step in xrange(int() // BATCH_SIZE):
            offset = () % ()
            batch_data = train_data[offset:(), ...]
            batch_labels = train_labels[offset:()]
            feed_dict = {train_data_node:,train_labels_node:}
            _, cl, l, lr, predictions = sess.run([], feed_dict=)
            if step % EVAL_FREQUENCY == 0:
                elapsed_time = time.time() - start_time
                start_time = time.time()
                sys.stdout.flush()
        test_error = error_rate(eval_in_batches(), test_labels)
        if FLAGS.self_test:
        train_embeddings = calculate_embeddings()
        color_list = []
        plt.figure()
        for n in range():
            idx = np.where(train_labels[0:]==)
            plt.plot(train_embeddings[], train_embeddings[], color_list[]+"")
        plt.show()
if __name__ == "__main__":
    tf.app.run()
from __future__ import absolute_import
from __future__ import division
from __future__ import print_function
import gzip
import os
import sys
import time
from six.moves import urllib
import tensorflow as tf
import numpy as np
from six.moves import xrange
SOURCE_URL = 'http:
WORK_DIRECTORY =
IMAGE_SIZE =
NUM_CHANNELS =
PIXEL_DEPTH =
NUM_LABELS =
VALIDATION_SIZE =
SEED =
BATCH_SIZE =
NUM_EPOCHS =
EVAL_BATCH_SIZE =
EVAL_FREQUENCY =
NOISE_FACTOR =
BETA =
tf.app.flags.DEFINE_boolean()
tf.app.flags.DEFINE_boolean()
FLAGS =
def data_type():
    if FLAGS.use_fp16:
        return tf.float16
    else:
        return tf.float32
def maybe_download():
    if not tf.gfile.Exists():
        tf.gfile.MakeDirs()
    filepath = os.path.join()
    if not tf.gfile.Exists():
        filepath, _ = urllib.request.urlretrieve()
        with tf.gfile.GFile() as f:
            size = f.size()
    return filepath
def extract_data():
    with gzip.open() as bytestream:
        bytestream.read()
        buf = bytestream.read()
        data = np.frombuffer(buf, dtype=).astype()
        data = (data - ()) / PIXEL_DEPTH
        data = data.reshape()
        return data
def extract_labels():
    with gzip.open() as bytestream:
        bytestream.read()
        buf = bytestream.read()
        labels = np.frombuffer(buf, dtype=).astype()
    return labels
def fake_data():
    data = np.ndarray(shape=(),dtype=)
    labels = np.zeros(shape=(), dtype=)
    for image in range():
        label =
        data[image, :, :, 0] =
        labels[] =
    return data, labels
def error_rate():
    return 100.0 - (100.0 *np.sum(np.argmax() ==) /predictions.shape[])
def main(argv=):
    if FLAGS.self_test:
        train_data, train_labels = fake_data()
        validation_data, validation_labels = fake_data()
        test_data, test_labels = fake_data()
        num_epochs =
    else:
        train_data_filename = maybe_download()
        train_labels_filename = maybe_download()
        test_data_filename = maybe_download()
        test_labels_filename = maybe_download()
        train_data = extract_data()
        train_labels = extract_labels()
        test_data = extract_data()
        test_labels = extract_labels()
        validation_data = train_data[:, ...]
        validation_labels = train_labels[:]
        train_data = train_data[VALIDATION_SIZE:, ...]
        train_labels = train_labels[VALIDATION_SIZE:]
        nrof_training_examples = train_labels.shape[]
        nrof_changed_labels = int()
        shuf = np.arange()
        np.random.shuffle()
        change_idx = shuf[0:]
        train_labels[] = (train_labels[] + np.random.randint(1,9,size=())) % NUM_LABELS
        num_epochs =
    train_size = train_labels.shape[]
    train_data_node = tf.placeholder(data_type(),shape=())
    train_labels_node = tf.placeholder(tf.int64, shape=())
    eval_data = tf.placeholder(data_type(),shape=())
    conv1_weights = tf.Variable(tf.truncated_normal([],stddev=,seed=, dtype=data_type()))
    conv1_biases = tf.Variable(tf.zeros([], dtype=data_type()))
    conv2_weights = tf.Variable(tf.truncated_normal([], stddev=,seed=, dtype=data_type()))
    conv2_biases = tf.Variable(tf.constant(0.1, shape=[], dtype=data_type()))
    fc1_weights = tf.Variable(tf.truncated_normal([],stddev=,seed=,dtype=data_type()))
    fc1_biases = tf.Variable(tf.constant(0.1, shape=[], dtype=data_type()))
    fc2_weights = tf.Variable(tf.truncated_normal([],stddev=,seed=,dtype=data_type()))
    fc2_biases = tf.Variable(tf.constant(0.1, shape=[], dtype=data_type()))
    def model(data, train=):
        conv = tf.nn.conv2d(data,conv1_weights,strides=[],padding=)
        relu = tf.nn.relu(tf.nn.bias_add())
        pool = tf.nn.max_pool(relu,ksize=[],strides=[],padding=)
        conv = tf.nn.conv2d(pool,conv2_weights,strides=[],padding=)
        relu = tf.nn.relu(tf.nn.bias_add())
        pool = tf.nn.max_pool(relu,ksize=[],strides=[],padding=)
        pool_shape = pool.get_shape().as_list()
        reshape = tf.reshape(pool,[pool_shape[], pool_shape[] * pool_shape[] * pool_shape[]])
        hidden = tf.nn.relu(tf.matmul() + fc1_biases)
        if train:
            hidden = tf.nn.dropout(hidden, 0.5, seed=)
        return tf.matmul() + fc2_biases
    logits = model()
    t = tf.one_hot()
    q = tf.nn.softmax()
    qqq = tf.arg_max(q, dimension=)
    z = tf.one_hot()
    cross_entropy = -tf.reduce_sum((BETA*t+()*z)*tf.log(),reduction_indices=)
    loss = tf.reduce_mean()
    regularizers = (tf.nn.l2_loss() + tf.nn.l2_loss() +tf.nn.l2_loss() + tf.nn.l2_loss())
    loss +=
    batch = tf.Variable(0, dtype=data_type())
    learning_rate = tf.train.exponential_decay(0.01,batch * BATCH_SIZE,train_size,0.95,staircase=)
    optimizer = tf.train.MomentumOptimizer().minimize(loss,global_step=)
    train_prediction = tf.nn.softmax()
    eval_prediction = tf.nn.softmax(model())
    def eval_in_batches():
        size = data.shape[]
        if size < EVAL_BATCH_SIZE:
            raise ValueError()
        predictions = np.ndarray(shape=(), dtype=)
        for begin in xrange():
            end =
            if end <= size:
                predictions[begin:, :] = sess.run(eval_prediction,feed_dict={eval_data: data[begin:,})
            else:
                batch_predictions = sess.run(eval_prediction,feed_dict={eval_data: data[-EVAL_BATCH_SIZE:,})
                predictions[begin:, :] = batch_predictions[begin - size:, :]
        return predictions
    start_time = time.time()
    with tf.Session() as sess:
        tf.global_variables_initializer().run()
        for step in xrange(int() // BATCH_SIZE):
            offset = () % ()
            batch_data = train_data[offset:(), ...]
            batch_labels = train_labels[offset:()]
            feed_dict = {train_data_node:,train_labels_node:}
            _, l, lr, predictions = sess.run([],feed_dict=)
            if step % EVAL_FREQUENCY == 0:
                elapsed_time = time.time() - start_time
                start_time = time.time()
                sys.stdout.flush()
        test_error = error_rate(eval_in_batches(), test_labels)
        if FLAGS.self_test:
if __name__ == "__main__":
    tf.app.run()
from __future__ import absolute_import
from __future__ import division
from __future__ import print_function
import tensorflow as tf
import sys
import argparse
import importlib
import facenet
import os
import numpy as np
import h5py
import math
from scipy import misc
def main():
    img_mean = np.array([])
    img_stddev = np.sqrt(np.array([]))
    vae_def = importlib.import_module()
    vae = vae_def.Vae()
    gen_image_size = vae.get_image_size()
    with tf.Graph().as_default():
        tf.set_random_seed()
        images = tf.placeholder(tf.float32, shape=(), name=)
        images_norm = () / img_stddev
        images_norm_resize = tf.image.resize_images(images_norm, ())
        mean, log_variance = vae.encoder()
        epsilon = tf.random_normal((tf.shape()[], args.latent_var_size))
        std = tf.exp()
        latent_var =
        reconstructed_norm = vae.decoder()
        reconstructed = () + img_mean
        saver = tf.train.Saver(tf.trainable_variables(), max_to_keep=)
        gpu_memory_fraction =
        gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=)
        sess = tf.Session(config=tf.ConfigProto(gpu_options=, log_device_placement=))
        sess.run(tf.global_variables_initializer())
        sess.run(tf.local_variables_initializer())
        coord = tf.train.Coordinator()
        tf.train.start_queue_runners(coord=, sess=)
        with sess.as_default():
            vae_checkpoint = os.path.expanduser()
            saver.restore()
            filename = os.path.expanduser()
            with h5py.File() as f:
                latent_vars = np.array(f.get())
                attributes = np.array(f.get())
                attribute_vectors = np.array(f.get())
            attribute_index =
            image_indices = []
            nrof_images = len()
            nrof_interp_steps =
            sweep_latent_var = np.zeros((), np.float32)
            for j in range():
                image_index = image_indices[]
                idx = np.argwhere(attributes[:,attribute_index]==)[]
                for i in range():
                    sweep_latent_var[i+nrof_interp_steps*j,:] = latent_vars[idx,:] + 5.0*i/nrof_interp_steps*attribute_vectors[attribute_index,:]
            recon = sess.run(reconstructed, feed_dict={latent_var:})
            img = facenet.put_images_on_grid(recon, shape=(nrof_interp_steps*2,int(math.ceil())))
            image_filename = os.path.expanduser()
            misc.imsave()
def parse_arguments():
    parser = argparse.ArgumentParser()
    parser.add_argument("", type=,help=)
    parser.add_argument("", type=,help=)
    parser.add_argument("", type=,help=)
    parser.add_argument("", type=,help=)
    parser.add_argument("", type=,help=, default=)
    parser.add_argument("", type=,help=, default=)
    return parser.parse_args()
if __name__ == "__main__":
    main(parse_arguments(sys.argv[1:]))
import tensorflow as tf
import numpy as np
x_data = np.array([[], [], [], [], [], []])
y_data = np.array([[],[],[],[],[],[]])
X = tf.placeholder()
Y = tf.placeholder()
W1 = tf.Variable(tf.random_uniform([], -1., 1.))
W2 = tf.Variable(tf.random_uniform([], -1., 1.))
b1 = tf.Variable(tf.zeros([]))
b2 = tf.Variable(tf.zeros([]))
L1 = tf.add(tf.matmul(), b1)
L1 = tf.nn.relu()
model = tf.add(tf.matmul(), b2)
cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=, logits=))
optimizer = tf.train.AdamOptimizer(learning_rate=)
train_op = optimizer.minimize()
init = tf.global_variables_initializer()
sess = tf.Session()
sess.run()
for step in range():
    sess.run(train_op, feed_dict={X:, Y:})
    if () % 10 == 0:
prediction = tf.argmax()
target = tf.argmax()
is_correct = tf.equal()
accuracy = tf.reduce_mean(tf.cast())
import tensorflow as tf
import numpy as np
import sys
import time
sys.path.append()
import facenet
from tensorflow.python.ops import control_flow_ops
from tensorflow.python.ops import array_ops
from six.moves import xrange
from __future__ import absolute_import
from __future__ import division
from __future__ import print_function
from datetime import datetime
import os.path
import time
import sys
import random
import tensorflow as tf
import numpy as np
import importlib
import argparse
import facenet
import lfw
import h5py
import math
import tensorflow.contrib.slim as slim
from tensorflow.python.ops import data_flow_ops
from tensorflow.python.framework import ops
from tensorflow.python.ops import array_ops
def main():
    network = importlib.import_module()
    image_size = ()
    subdir = datetime.strftime(datetime.now(), '%Y%m%d-%H%M%S')
    log_dir = os.path.join(os.path.expanduser(), subdir)
    if not os.path.isdir():
        os.makedirs()
    model_dir = os.path.join(os.path.expanduser(), subdir)
    if not os.path.isdir():
        os.makedirs()
    stat_file_name = os.path.join()
    facenet.write_arguments_to_file(args, os.path.join())
    src_path,_ = os.path.split(os.path.realpath())
    facenet.store_revision_info(src_path, log_dir, "".join())
    np.random.seed(seed=)
    random.seed()
    dataset = facenet.get_dataset()
    if args.filter_filename:
        dataset = filter_dataset(dataset, os.path.expanduser(),args.filter_percentile, args.filter_min_nrof_images_per_class)
    if args.validation_set_split_ratio>0.0:
        train_set, val_set = facenet.split_dataset()
    else:
        train_set, val_set =, []
    nrof_classes = len()
    pretrained_model =
    if args.pretrained_model:
        pretrained_model = os.path.expanduser()
    if args.lfw_dir:
        pairs = lfw.read_pairs(os.path.expanduser())
        lfw_paths, actual_issame = lfw.get_paths(os.path.expanduser(), pairs)
    with tf.Graph().as_default():
        tf.set_random_seed()
        global_step = tf.Variable(0, trainable=)
        image_list, label_list = facenet.get_image_paths_and_labels()
        val_image_list, val_label_list = facenet.get_image_paths_and_labels()
        labels = ops.convert_to_tensor(label_list, dtype=)
        range_size = array_ops.shape()[]
        index_queue = tf.train.range_input_producer(range_size, num_epochs=,shuffle=, seed=, capacity=)
        index_dequeue_op = index_queue.dequeue_many()
        learning_rate_placeholder = tf.placeholder(tf.float32, name=)
        batch_size_placeholder = tf.placeholder(tf.int32, name=)
        phase_train_placeholder = tf.placeholder(tf.bool, name=)
        image_paths_placeholder = tf.placeholder(tf.string, shape=(), name=)
        labels_placeholder = tf.placeholder(tf.int32, shape=(), name=)
        control_placeholder = tf.placeholder(tf.int32, shape=(), name=)
        nrof_preprocess_threads =
        input_queue = data_flow_ops.FIFOQueue(capacity=,dtypes=[],shapes=[(), (), ()],shared_name=, name=)
        enqueue_op = input_queue.enqueue_many([], name=)
        image_batch, label_batch = facenet.create_input_pipeline()
        image_batch = tf.identity()
        image_batch = tf.identity()
        label_batch = tf.identity()
        prelogits, _ = network.inference(image_batch, args.keep_probability,phase_train=, bottleneck_layer_size=,weight_decay=)
        logits = slim.fully_connected(prelogits, len(), activation_fn=,weights_initializer=slim.initializers.xavier_initializer(),weights_regularizer=slim.l2_regularizer(),scope=, reuse=)
        embeddings = tf.nn.l2_normalize(prelogits, 1, 1e-10, name=)
        eps =
        prelogits_norm = tf.reduce_mean(tf.norm(tf.abs()+eps, ord=, axis=))
        tf.add_to_collection()
        prelogits_center_loss, _ = facenet.center_loss()
        tf.add_to_collection()
        learning_rate = tf.train.exponential_decay(learning_rate_placeholder, global_step,args.learning_rate_decay_epochs*args.epoch_size, args.learning_rate_decay_factor, staircase=)
        tf.summary.scalar()
        cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=, logits=, name=)
        cross_entropy_mean = tf.reduce_mean(cross_entropy, name=)
        tf.add_to_collection()
        correct_prediction = tf.cast(tf.equal(tf.argmax(), tf.cast()), tf.float32)
        accuracy = tf.reduce_mean()
        regularization_losses = tf.get_collection()
        total_loss = tf.add_n([] + regularization_losses, name=)
        train_op = facenet.train(total_loss, global_step, args.optimizer,learning_rate, args.moving_average_decay, tf.global_variables(), args.log_histograms)
        saver = tf.train.Saver(tf.trainable_variables(), max_to_keep=)
        summary_op = tf.summary.merge_all()
        gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=)
        sess = tf.Session(config=tf.ConfigProto(gpu_options=, log_device_placement=))
        sess.run(tf.global_variables_initializer())
        sess.run(tf.local_variables_initializer())
        summary_writer = tf.summary.FileWriter()
        coord = tf.train.Coordinator()
        tf.train.start_queue_runners(coord=, sess=)
        with sess.as_default():
            if pretrained_model:
                saver.restore()
            nrof_steps =
            nrof_val_samples = int(math.ceil())
            stat = {'loss':,'center_loss':,'reg_loss':,'xent_loss':,'prelogits_norm':,'accuracy':,'val_loss':,'val_xent_loss':,'val_accuracy':,'lfw_accuracy':,'lfw_valrate':,'learning_rate':,'time_train':,'time_validate':,'time_evaluate':,'prelogits_hist':,}
            for epoch in range():
                step = sess.run(global_step, feed_dict=)
                t = time.time()
                cont = train()
                stat[][] = time.time() - t
                if not cont:
                    break
                t = time.time()
                if len()>0 and (() % args.validate_every_n_epochs == args.validate_every_n_epochs-1 or epoch==):
                    validate()
                stat[][] = time.time() - t
                save_variables_and_metagraph()
                t = time.time()
                if args.lfw_dir:
                    evaluate()
                stat[][] = time.time() - t
                with h5py.File() as f:
                    for key, value in stat.iteritems():
                        f.create_dataset(key, data=)
    return model_dir
def find_threshold():
    hist, bin_edges = np.histogram()
    cdf = np.float32(np.cumsum()) / np.sum()
    bin_centers = (bin_edges[:]+bin_edges[1:])/2
    threshold = np.interp()
    return threshold
def filter_dataset():
    with h5py.File() as f:
        distance_to_center = np.array(f.get())
        label_list = np.array(f.get())
        image_list = np.array(f.get())
        distance_to_center_threshold = find_threshold()
        indices = np.where(distance_to_center>=)[]
        filtered_dataset =
        removelist = []
        for i in indices:
            label = label_list[]
            image = image_list[]
            if image in filtered_dataset[].image_paths:
                filtered_dataset[].image_paths.remove()
            if len(filtered_dataset[].image_paths)<min_nrof_images_per_class:
                removelist.append()
        ix = sorted(list(set()), reverse=)
        for i in ix:
            del(filtered_dataset[])
    return filtered_dataset
def train():
    batch_number =
    if args.learning_rate>0.0:
        lr =
    else:
        lr = facenet.get_learning_rate_from_file()
    if lr<=0:
        return False
    index_epoch = sess.run()
    label_epoch = np.array()[]
    image_epoch = np.array()[]
    labels_array = np.expand_dims(np.array(),1)
    image_paths_array = np.expand_dims(np.array(),1)
    control_value =
    control_array = np.ones_like() * control_value
    sess.run(enqueue_op, {image_paths_placeholder:, labels_placeholder:, control_placeholder:})
    train_time =
    while batch_number < args.epoch_size:
        start_time = time.time()
        feed_dict = {learning_rate_placeholder:, phase_train_placeholder:, batch_size_placeholder:}
        tensor_list = []
        if batch_number % 100 == 0:
            loss_, _, step_, reg_losses_, prelogits_, cross_entropy_mean_, lr_, prelogits_norm_, accuracy_, center_loss_, summary_str = sess.run(tensor_list + [], feed_dict=)
            summary_writer.add_summary(summary_str, global_step=)
        else:
            loss_, _, step_, reg_losses_, prelogits_, cross_entropy_mean_, lr_, prelogits_norm_, accuracy_, center_loss_ = sess.run(tensor_list, feed_dict=)
        duration = time.time() - start_time
        stat[][] =
        stat[][] =
        stat[][] = np.sum()
        stat[][] =
        stat[][] =
        stat[][] =
        stat[][] =
        stat[][epoch-1,:] += np.histogram(np.minimum(np.abs(), prelogits_hist_max), bins=, range=())[]
        duration = time.time() - start_time
        batch_number +=
        train_time +=
    summary = tf.Summary()
    summary.value.add(tag=, simple_value=)
    summary_writer.add_summary(summary, global_step=)
    return True
def validate():
    nrof_batches = len() // args.lfw_batch_size
    nrof_images =
    labels_array = np.expand_dims(np.array(label_list[:]),1)
    image_paths_array = np.expand_dims(np.array(image_list[:]),1)
    control_array = np.ones_like()*facenet.FIXED_STANDARDIZATION * use_fixed_image_standardization
    sess.run(enqueue_op, {image_paths_placeholder:, labels_placeholder:, control_placeholder:})
    loss_array = np.zeros((), np.float32)
    xent_array = np.zeros((), np.float32)
    accuracy_array = np.zeros((), np.float32)
    start_time = time.time()
    for i in range():
        feed_dict = {phase_train_placeholder:, batch_size_placeholder:}
        loss_, cross_entropy_mean_, accuracy_ = sess.run([], feed_dict=)
        loss_array[], xent_array[], accuracy_array[] = ()
        if i % 10 == 9:
            sys.stdout.flush()
    duration = time.time() - start_time
    val_index = ()//validate_every_n_epochs
    stat[][] = np.mean()
    stat[][] = np.mean()
    stat[][] = np.mean()
def evaluate():
    start_time = time.time()
    nrof_embeddings = len()*2
    nrof_flips =
    nrof_images =
    labels_array = np.expand_dims(np.arange(),1)
    image_paths_array = np.expand_dims(np.repeat(np.array(),nrof_flips),1)
    control_array = np.zeros_like()
    if use_fixed_image_standardization:
        control_array += np.ones_like()*facenet.FIXED_STANDARDIZATION
    if use_flipped_images:
        control_array += ()*facenet.FLIP
    sess.run(enqueue_op, {image_paths_placeholder:, labels_placeholder:, control_placeholder:})
    embedding_size = int(embeddings.get_shape()[])
    nrof_batches =
    emb_array = np.zeros(())
    lab_array = np.zeros(())
    for i in range():
        feed_dict = {phase_train_placeholder:, batch_size_placeholder:}
        emb, lab = sess.run([], feed_dict=)
        lab_array[] =
        emb_array[lab, :] =
        if i % 10 == 9:
            sys.stdout.flush()
    embeddings = np.zeros(())
    if use_flipped_images:
        embeddings[:,:] = emb_array[0::,:]
        embeddings[:,embedding_size:] = emb_array[1::,:]
    else:
        embeddings =
    _, _, accuracy, val, val_std, far = lfw.evaluate(embeddings, actual_issame, nrof_folds=, distance_metric=, subtract_mean=)
    lfw_time = time.time() - start_time
    summary = tf.Summary()
    summary.value.add(tag=, simple_value=np.mean())
    summary.value.add(tag=, simple_value=)
    summary.value.add(tag=, simple_value=)
    summary_writer.add_summary()
    with open(os.path.join(),"") as f:
        f.write()
    stat[][] = np.mean()
    stat[][] =
def save_variables_and_metagraph():
    start_time = time.time()
    checkpoint_path = os.path.join()
    saver.save(sess, checkpoint_path, global_step=, write_meta_graph=)
    save_time_variables = time.time() - start_time
    metagraph_filename = os.path.join()
    save_time_metagraph =
    if not os.path.exists():
        start_time = time.time()
        saver.export_meta_graph()
        save_time_metagraph = time.time() - start_time
    summary = tf.Summary()
    summary.value.add(tag=, simple_value=)
    summary.value.add(tag=, simple_value=)
    summary_writer.add_summary()
def parse_arguments():
    parser = argparse.ArgumentParser()
    parser.add_argument("", type=,help=, default=)
    parser.add_argument("", type=,help=, default=)
    parser.add_argument("", type=,help=, default=)
    parser.add_argument("", type=,help=)
    parser.add_argument("", type=,help=,default=)
    parser.add_argument("", type=,help=, default=)
    parser.add_argument("", type=,help=, default=)
    parser.add_argument("", type=,help=, default=)
    parser.add_argument("", type=,help=, default=)
    parser.add_argument("", type=,help=, default=)
    parser.add_argument("", type=,help=, default=)
    parser.add_argument("",help=, action=)
	parser.add_argument("",help=, action=)
    parser.add_argument("",help=, action=)
    parser.add_argument("",help=, action=)
    parser.add_argument("", type=,help=, default=)
	parser.add_argument("", type=,help=, default=)
    parser.add_argument("", type=,help=, default=)
    parser.add_argument("", type=,help=, default=)
    parser.add_argument("", type=,help=, default=)
    parser.add_argument("", type=,help=, default=)
    parser.add_argument("", type=,help=, default=)
    parser.add_argument("", type=, choices=[],help=, default=)
    parser.add_argument("", type=,help=, default=)
    parser.add_argument("", type=,help=, default=)
    parser.add_argument("", type=,help=, default=)
    parser.add_argument("", type=,help=, default=)
    parser.add_argument("", type=,help=, default=)
    parser.add_argument("", type=,help=, default=)
    parser.add_argument("",help=, action=)
    parser.add_argument("", type=,help=, default=)
    parser.add_argument("", type=,help=, default=)
    parser.add_argument("", type=,help=, default=)
    parser.add_argument("", type=,help=, default=)
    parser.add_argument("", type=,help=, default=)
    parser.add_argument("", type=,help=, default=)
    parser.add_argument("", type=,help=, default=)
    parser.add_argument("", type=,help=, default=)
    parser.add_argument("", type=,help=, default=)
    parser.add_argument("", type=,help=, default=)
    parser.add_argument("", type=,help=, default=)
    parser.add_argument("", type=,help=, default=)
    parser.add_argument("",help=, action=)
    parser.add_argument("",help=, action=)
    return parser.parse_args()
if __name__ == "__main__":
    main(parse_arguments(sys.argv[1:]))
from __future__ import absolute_import
from __future__ import division
from __future__ import print_function
from datetime import datetime
import os.path
import time
import sys
import tensorflow as tf
import numpy as np
import importlib
import itertools
import argparse
import facenet
import lfw
from tensorflow.python.ops import data_flow_ops
from six.moves import xrange
def main():
    network = importlib.import_module()
    subdir = datetime.strftime(datetime.now(), '%Y%m%d-%H%M%S')
    log_dir = os.path.join(os.path.expanduser(), subdir)
    if not os.path.isdir():
        os.makedirs()
    model_dir = os.path.join(os.path.expanduser(), subdir)
    if not os.path.isdir():
        os.makedirs()
    facenet.write_arguments_to_file(args, os.path.join())
    src_path,_ = os.path.split(os.path.realpath())
    facenet.store_revision_info(src_path, log_dir, "".join())
    np.random.seed(seed=)
    train_set = facenet.get_dataset()
    if args.pretrained_model:
    if args.lfw_dir:
        pairs = lfw.read_pairs(os.path.expanduser())
        lfw_paths, actual_issame = lfw.get_paths(os.path.expanduser(), pairs)
    with tf.Graph().as_default():
        tf.set_random_seed()
        global_step = tf.Variable(0, trainable=)
        learning_rate_placeholder = tf.placeholder(tf.float32, name=)
        batch_size_placeholder = tf.placeholder(tf.int32, name=)
        phase_train_placeholder = tf.placeholder(tf.bool, name=)
        image_paths_placeholder = tf.placeholder(tf.string, shape=(), name=)
        labels_placeholder = tf.placeholder(tf.int64, shape=(), name=)
        input_queue = data_flow_ops.FIFOQueue(capacity=,dtypes=[],shapes=[(), ()],shared_name=, name=)
        enqueue_op = input_queue.enqueue_many([])
        nrof_preprocess_threads =
        images_and_labels = []
        for _ in range():
            filenames, label = input_queue.dequeue()
            images = []
            for filename in tf.unstack():
                file_contents = tf.read_file()
                image = tf.image.decode_image(file_contents, channels=)
                if args.random_crop:
                    image = tf.random_crop(image, [])
                else:
                    image = tf.image.resize_image_with_crop_or_pad()
                if args.random_flip:
                    image = tf.image.random_flip_left_right()
                image.set_shape(())
                images.append(tf.image.per_image_standardization())
            images_and_labels.append([])
        image_batch, labels_batch = tf.train.batch_join(images_and_labels, batch_size=,shapes=[(), ()], enqueue_many=,capacity=,allow_smaller_final_batch=)
        image_batch = tf.identity()
        image_batch = tf.identity()
        labels_batch = tf.identity()
        prelogits, _ = network.inference(image_batch, args.keep_probability,phase_train=, bottleneck_layer_size=,weight_decay=)
        embeddings = tf.nn.l2_normalize(prelogits, 1, 1e-10, name=)
        anchor, positive, negative = tf.unstack(tf.reshape(embeddings, []), 3, 1)
        triplet_loss = facenet.triplet_loss()
        learning_rate = tf.train.exponential_decay(learning_rate_placeholder, global_step,args.learning_rate_decay_epochs*args.epoch_size, args.learning_rate_decay_factor, staircase=)
        tf.summary.scalar()
        regularization_losses = tf.get_collection()
        total_loss = tf.add_n([] + regularization_losses, name=)
        train_op = facenet.train(total_loss, global_step, args.optimizer,learning_rate, args.moving_average_decay, tf.global_variables())
        saver = tf.train.Saver(tf.trainable_variables(), max_to_keep=)
        summary_op = tf.summary.merge_all()
        gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=)
        sess = tf.Session(config=tf.ConfigProto(gpu_options=))
        sess.run(tf.global_variables_initializer(), feed_dict={phase_train_placeholder:})
        sess.run(tf.local_variables_initializer(), feed_dict={phase_train_placeholder:})
        summary_writer = tf.summary.FileWriter()
        coord = tf.train.Coordinator()
        tf.train.start_queue_runners(coord=, sess=)
        with sess.as_default():
            if args.pretrained_model:
                saver.restore(sess, os.path.expanduser())
            epoch =
            while epoch < args.max_nrof_epochs:
                step = sess.run(global_step, feed_dict=)
                epoch =
                train()
                save_variables_and_metagraph()
                if args.lfw_dir:
                    evaluate()
    return model_dir
def train():
    batch_number =
    if args.learning_rate>0.0:
        lr =
    else:
        lr = facenet.get_learning_rate_from_file()
    while batch_number < args.epoch_size:
        image_paths, num_per_class = sample_people()
        start_time = time.time()
        nrof_examples =
        labels_array = np.reshape(np.arange(),())
        image_paths_array = np.reshape(np.expand_dims(np.array(),1), ())
        sess.run(enqueue_op, {image_paths_placeholder:, labels_placeholder:})
        emb_array = np.zeros(())
        nrof_batches = int(np.ceil())
        for i in range():
            batch_size = min()
            emb, lab = sess.run([], feed_dict={batch_size_placeholder:,learning_rate_placeholder:, phase_train_placeholder:})
            emb_array[lab,:] =
        triplets, nrof_random_negs, nrof_triplets = select_triplets()
        selection_time = time.time() - start_time
        nrof_batches = int(np.ceil())
        triplet_paths = list(itertools.chain())
        labels_array = np.reshape(np.arange(len()),())
        triplet_paths_array = np.reshape(np.expand_dims(np.array(),1), ())
        sess.run(enqueue_op, {image_paths_placeholder:, labels_placeholder:})
        nrof_examples = len()
        train_time =
        i =
        emb_array = np.zeros(())
        loss_array = np.zeros(())
        summary = tf.Summary()
        step =
        while i < nrof_batches:
            start_time = time.time()
            batch_size = min()
            feed_dict = {batch_size_placeholder:, learning_rate_placeholder:, phase_train_placeholder:}
            err, _, step, emb, lab = sess.run([], feed_dict=)
            emb_array[lab,:] =
            loss_array[] =
            duration = time.time() - start_time
            batch_number +=
            i +=
            train_time +=
            summary.value.add(tag=, simple_value=)
        summary.value.add(tag=, simple_value=)
        summary_writer.add_summary()
    return step
def select_triplets():
    trip_idx =
    emb_start_idx =
    num_trips =
    triplets = []
    for i in xrange():
        nrof_images = int(nrof_images_per_class[])
        for j in xrange():
            a_idx =
            neg_dists_sqr = np.sum(np.square(embeddings[] - embeddings), 1)
            for pair in xrange():
                p_idx =
                pos_dist_sqr = np.sum(np.square(embeddings[]-embeddings[]))
                neg_dists_sqr[emb_start_idx:] =
                all_neg = np.where()[]
                nrof_random_negs = all_neg.shape[]
                if nrof_random_negs>0:
                    rnd_idx = np.random.randint()
                    n_idx = all_neg[]
                    triplets.append((image_paths[], image_paths[], image_paths[]))
                    trip_idx +=
                num_trips +=
        emb_start_idx +=
    np.random.shuffle()
    return triplets, num_trips, len()
def sample_people():
    nrof_images =
    nrof_classes = len()
    class_indices = np.arange()
    np.random.shuffle()
    i =
    image_paths = []
    num_per_class = []
    sampled_class_indices = []
    while len()<nrof_images:
        class_index = class_indices[]
        nrof_images_in_class = len(dataset[])
        image_indices = np.arange()
        np.random.shuffle()
        nrof_images_from_class = min(nrof_images_in_class, images_per_person, nrof_images-len())
        idx = image_indices[0:]
        image_paths_for_class = [dataset[].image_paths[] for j in idx]
        sampled_class_indices += []*nrof_images_from_class
        image_paths +=
        num_per_class.append()
        i+=
    return image_paths, num_per_class
def evaluate():
    start_time = time.time()
    nrof_images = len()*2
    labels_array = np.reshape(np.arange(),())
    image_paths_array = np.reshape(np.expand_dims(np.array(),1), ())
    sess.run(enqueue_op, {image_paths_placeholder:, labels_placeholder:})
    emb_array = np.zeros(())
    nrof_batches = int(np.ceil())
    label_check_array = np.zeros(())
    for i in xrange():
        batch_size = min()
        emb, lab = sess.run([], feed_dict={batch_size_placeholder:,learning_rate_placeholder:, phase_train_placeholder:})
        emb_array[lab,:] =
        label_check_array[] =
    _, _, accuracy, val, val_std, far = lfw.evaluate(emb_array, actual_issame, nrof_folds=)
    lfw_time = time.time() - start_time
    summary = tf.Summary()
    summary.value.add(tag=, simple_value=np.mean())
    summary.value.add(tag=, simple_value=)
    summary.value.add(tag=, simple_value=)
    summary_writer.add_summary()
    with open(os.path.join(),"") as f:
        f.write("", np.mean(), val))
def save_variables_and_metagraph():
    start_time = time.time()
    checkpoint_path = os.path.join()
    saver.save(sess, checkpoint_path, global_step=, write_meta_graph=)
    save_time_variables = time.time() - start_time
    metagraph_filename = os.path.join()
    save_time_metagraph =
    if not os.path.exists():
        start_time = time.time()
        saver.export_meta_graph()
        save_time_metagraph = time.time() - start_time
    summary = tf.Summary()
    summary.value.add(tag=, simple_value=)
    summary.value.add(tag=, simple_value=)
    summary_writer.add_summary()
def get_learning_rate_from_file():
    with open() as f:
        for line in f.readlines():
            line = line.split()[]
            if line:
                par = line.strip().split(':)
                e = int(par[])
                lr = float(par[])
                if e <= epoch:
                    learning_rate =
                else:
                    return learning_rate
def parse_arguments():
    parser = argparse.ArgumentParser()
    parser.add_argument("", type=,help=, default=)
    parser.add_argument("", type=,help=, default=)
    parser.add_argument("", type=,help=, default=)
    parser.add_argument("", type=,help=)
    parser.add_argument("", type=,help=,default=)
    return parser.parse_args()
if __name__ == "__main__":
    main(parse_arguments(sys.argv[1:]))
from __future__ import absolute_import
from __future__ import division
from __future__ import print_function
import tensorflow as tf
import numpy as np
import argparse
import facenet
import lfw
import os
import sys
from tensorflow.python.ops import data_flow_ops
from sklearn import metrics
from scipy.optimize import brentq
from scipy import interpolate
def main():
    with tf.Graph().as_default():
        with tf.Session() as sess:
            pairs = lfw.read_pairs(os.path.expanduser())
            paths, actual_issame = lfw.get_paths(os.path.expanduser(), pairs)
            image_paths_placeholder = tf.placeholder(tf.string, shape=(), name=)
            labels_placeholder = tf.placeholder(tf.int32, shape=(), name=)
            batch_size_placeholder = tf.placeholder(tf.int32, name=)
            control_placeholder = tf.placeholder(tf.int32, shape=(), name=)
            phase_train_placeholder = tf.placeholder(tf.bool, name=)
            nrof_preprocess_threads =
            image_size = ()
            eval_input_queue = data_flow_ops.FIFOQueue(capacity=,dtypes=[],shapes=[(), (), ()],shared_name=, name=)
            eval_enqueue_op = eval_input_queue.enqueue_many([], name=)
            image_batch, label_batch = facenet.create_input_pipeline()
            input_map = {'image_batch':, 'label_batch':, 'phase_train':}
            facenet.load_model(args.model, input_map=)
            embeddings = tf.get_default_graph().get_tensor_by_name("embeddings:)
            coord = tf.train.Coordinator()
            tf.train.start_queue_runners(coord=, sess=)
            evaluate()
def evaluate():
    nrof_embeddings = len()*2
    nrof_flips =
    nrof_images =
    labels_array = np.expand_dims(np.arange(),1)
    image_paths_array = np.expand_dims(np.repeat(np.array(),nrof_flips),1)
    control_array = np.zeros_like()
    if use_fixed_image_standardization:
        control_array += np.ones_like()*facenet.FIXED_STANDARDIZATION
    if use_flipped_images:
        control_array += ()*facenet.FLIP
    sess.run(enqueue_op, {image_paths_placeholder:, labels_placeholder:, control_placeholder:})
    embedding_size = int(embeddings.get_shape()[])
    nrof_batches =
    emb_array = np.zeros(())
    lab_array = np.zeros(())
    for i in range():
        feed_dict = {phase_train_placeholder:, batch_size_placeholder:}
        emb, lab = sess.run([], feed_dict=)
        lab_array[] =
        emb_array[lab, :] =
        if i % 10 == 9:
            sys.stdout.flush()
    embeddings = np.zeros(())
    if use_flipped_images:
        embeddings[:,:] = emb_array[0::,:]
        embeddings[:,embedding_size:] = emb_array[1::,:]
    else:
        embeddings =
    tpr, fpr, accuracy, val, val_std, far = lfw.evaluate(embeddings, actual_issame, nrof_folds=, distance_metric=, subtract_mean=)
    auc = metrics.auc()
    eer = brentq(lambda x: 1. - x - interpolate.interp1d()(), 0., 1.)
def parse_arguments():
    parser = argparse.ArgumentParser()
    parser.add_argument("", type=,help=)
    parser.add_argument("", type=,help=, default=)
    parser.add_argument("",help=, action=)
    parser.add_argument("",help=, action=)
    parser.add_argument("",help=, action=)
    return parser.parse_args()
if __name__ == "__main__":
    main(parse_arguments(sys.argv[1:]))
from __future__ import absolute_import
from __future__ import division
from __future__ import print_function
import os
import numpy as np
import sys
import argparse
import tensorflow as tf
import importlib
from scipy import misc
def main():
    network = importlib.import_module()
    np.random.seed(seed=)
    img_noise = np.random.uniform(size=()) + 100.0
    sess = tf.Session()
    t_input = tf.placeholder(np.float32, shape=(), name=)
    image_mean =
    t_preprocessed = tf.expand_dims()
    network.inference(t_preprocessed, 1.0,phase_train=, weight_decay=)
    saver = tf.train.Saver(tf.global_variables())
    saver.restore()
    layers = [op.name for op in tf.get_default_graph().get_operations() if op.type==]
    feature_nums = {layer:}
    for layer in sorted(feature_nums.keys()):
    layer =
    result_dir =
    channels = range(feature_nums[])
    np.random.shuffle()
    for i in range():
        channel = channels[]
        img = render_naive(sess, t_input, T()[:,:,:,channel], img_noise)
        filename = "", channel)
        misc.imsave(os.path.join(), img)
def T():
    return tf.get_default_graph().get_tensor_by_name('%s:)
def visstd(a, s=):
    return (a-a.mean())/max(a.std(), 1e-4)*s + 0.5
def render_naive(sess, t_input, t_obj, img0, iter_n=, step=):
    t_score = tf.reduce_mean()
    t_grad = tf.gradients()[]
    img = img0.copy()
    for _ in range():
        g, _ = sess.run([], {t_input:})
        g /= g.std()+1e-8
        img +=
    return visstd()
def parse_arguments():
    parser = argparse.ArgumentParser()
    parser.add_argument("", type=,help=)
    parser.add_argument("", type=,help=,default=)
    parser.add_argument("", type=,help=, default=)
    return parser.parse_args()
if __name__ == "__main__":
    main(parse_arguments(sys.argv[1:]))
def get_image_path():
  if label_name not in image_lists:
    logging.fatal()
  label_lists = image_lists[]
  if category not in label_lists:
    logging.fatal()
  category_list = label_lists[]
  if not category_list:
    logging.fatal()
  mod_index = index % len()
  base_name = category_list[]
  sub_dir = label_lists[]
  full_path = os.path.join()
  return full_path
def get_bottleneck_path():
  module_name = 
  return get_image_path() + "" + module_name + ""
def create_module_graph():
  height, width = hub.get_expected_image_size()
  with tf.Graph().as_default() as graph:
    resized_input_tensor = tf.placeholder(tf.float32, [])
    m = hub.Module()
    bottleneck_tensor = m()
    wants_quantization = any(node.op in FAKE_QUANT_OPSfor node in graph.as_graph_def().node)
  return graph, bottleneck_tensor, resized_input_tensor, wants_quantization
def run_bottleneck_on_image():
  resized_input_values = sess.run(decoded_image_tensor,{image_data_tensor:})
  bottleneck_values = sess.run(bottleneck_tensor,{resized_input_tensor:})
  bottleneck_values = np.squeeze()
  return bottleneck_values
def ensure_dir_exists():
  if not os.path.exists():
    os.makedirs()
def create_bottleneck_file():
  image_path = get_image_path()
  if not tf.gfile.Exists():
    logging.fatal()
  image_data = tf.gfile.GFile().read()
  try:
    bottleneck_values = run_bottleneck_on_image()
  except Exception as e:
    raise RuntimeError()
  bottleneck_string =','.join(str() for x in bottleneck_values)
  with tf.gfile.GFile() as bottleneck_file:
    bottleneck_file.write()
def get_or_create_bottleneck():
  label_lists = image_lists[]
  sub_dir = label_lists[]
  sub_dir_path = os.path.join()
  ensure_dir_exists()
  bottleneck_path = get_bottleneck_path()
  if not os.path.exists():
    create_bottleneck_file()
  with tf.gfile.GFile() as bottleneck_file:
    bottleneck_string = bottleneck_file.read()
  did_hit_error =
  try:
    bottleneck_values = [float() for x in bottleneck_string.split()]
  except ValueError:
    did_hit_error =
  if did_hit_error:
    create_bottleneck_file()
    with tf.gfile.GFile() as bottleneck_file:
      bottleneck_string = bottleneck_file.read()
    bottleneck_values = [float() for x in bottleneck_string.split()]
  return bottleneck_values
def cache_bottlenecks():
  how_many_bottlenecks =
  ensure_dir_exists()
  for label_name, label_lists in image_lists.items():
    for category in []:
      category_list = label_lists[]
      for index, unused_base_name in enumerate():
        get_or_create_bottleneck()
        how_many_bottlenecks +=
        if how_many_bottlenecks % 100 == 0:
def get_random_cached_bottlenecks():
  class_count = len(image_lists.keys())
  bottlenecks = []
  ground_truths = []
  filenames = []
  if how_many >= 0:
    for unused_i in range():
      label_index = random.randrange()
      label_name = list(image_lists.keys())[]
      image_index = random.randrange()
      image_name = get_image_path()
      bottleneck = get_or_create_bottleneck()
      bottlenecks.append()
      ground_truths.append()
      filenames.append()
  else:
    for label_index, label_name in enumerate(image_lists.keys()):
      for image_index, image_name in enumerate(image_lists[][]):
        image_name = get_image_path()
        bottleneck = get_or_create_bottleneck()
        bottlenecks.append()
        ground_truths.append()
        filenames.append()
  return bottlenecks, ground_truths, filenames
def get_random_distorted_bottlenecks():
  class_count = len(image_lists.keys())
  bottlenecks = []
  ground_truths = []
  for unused_i in range():
    label_index = random.randrange()
    label_name = list(image_lists.keys())[]
    image_index = random.randrange()
    image_path = get_image_path()
    if not tf.gfile.Exists():
      logging.fatal()
    jpeg_data = tf.gfile.GFile().read()
    distorted_image_data = sess.run(distorted_image,{input_jpeg_tensor:})
    bottleneck_values = sess.run(bottleneck_tensor,{resized_input_tensor:})
    bottleneck_values = np.squeeze()
    bottlenecks.append()
    ground_truths.append()
  return bottlenecks, ground_truths
def should_distort_images():
  return (flip_left_right or (random_crop !=) or (random_scale !=) or(random_brightness !=))
def add_input_distortions():
  input_height, input_width = hub.get_expected_image_size()
  input_depth = hub.get_num_image_channels()
  jpeg_data = tf.placeholder(tf.string, name=)
  decoded_image = tf.image.decode_jpeg(jpeg_data, channels=)
  decoded_image_as_float = tf.image.convert_image_dtype()
  decoded_image_4d = tf.expand_dims()
  margin_scale = 1.0 + ()
  resize_scale = 1.0 + ()
  margin_scale_value = tf.constant()
  resize_scale_value = tf.random_uniform(shape=[],minval=,maxval=)
  scale_value = tf.multiply()
  precrop_width = tf.multiply()
  precrop_height = tf.multiply()
  precrop_shape = tf.stack([])
  precrop_shape_as_int = tf.cast(precrop_shape, dtype=)
  precropped_image = tf.image.resize_bilinear()
  precropped_image_3d = tf.squeeze(precropped_image, axis=[])
  cropped_image = tf.random_crop(precropped_image_3d,[])
  if flip_left_right:
    flipped_image = tf.image.random_flip_left_right()
  else:
    flipped_image =
  brightness_min = 1.0 - ()
  brightness_max = 1.0 + ()
  brightness_value = tf.random_uniform(shape=[],minval=,maxval=)
  brightened_image = tf.multiply()
  distort_result = tf.expand_dims(brightened_image, 0, name=)
  return jpeg_data, distort_result
def variable_summaries():
  with tf.name_scope():
    mean = tf.reduce_mean()
    tf.summary.scalar()
    with tf.name_scope():
      stddev = tf.sqrt(tf.reduce_mean(tf.square()))
    tf.summary.scalar()
    tf.summary.scalar("", tf.reduce_max())
    tf.summary.scalar("", tf.reduce_min())
    tf.summary.histogram()
def add_final_retrain_ops():
  batch_size, bottleneck_tensor_size = bottleneck_tensor.get_shape().as_list()
  with tf.name_scope():
    bottleneck_input = tf.placeholder_with_default(bottleneck_tensor,shape=[],name=)
    ground_truth_input = tf.placeholder(tf.int64, [], name=)
  layer_name =
  with tf.name_scope():
    with tf.name_scope():
      initial_value = tf.truncated_normal([], stddev=)
      layer_weights = tf.Variable(initial_value, name=)
      variable_summaries()
    with tf.name_scope():
      layer_biases = tf.Variable(tf.zeros([]), name=)
      variable_summaries()
    with tf.name_scope():
      logits = tf.matmul() + layer_biases
      tf.summary.histogram()
  final_tensor = tf.nn.softmax(logits, name=)
  if quantize_layer:
    if is_training:
      contrib_quantize.create_training_graph()
    else:
      contrib_quantize.create_eval_graph()
  tf.summary.histogram()
  if not is_training:
    return None, None, bottleneck_input, ground_truth_input, final_tensor
  with tf.name_scope():
    cross_entropy_mean = tf.losses.sparse_softmax_cross_entropy(labels=, logits=)
  tf.summary.scalar()
  with tf.name_scope():
    optimizer = tf.train.GradientDescentOptimizer()
    train_step = optimizer.minimize()
  return ()
def add_evaluation_step():
  with tf.name_scope():
    with tf.name_scope():
      prediction = tf.argmax()
      correct_prediction = tf.equal()
    with tf.name_scope():
      evaluation_step = tf.reduce_mean(tf.cast())
  tf.summary.scalar()
  return evaluation_step, prediction
def run_final_eval():
  test_bottlenecks, test_ground_truth, test_filenames = (get_random_cached_bottlenecks())
  () = build_eval_session()
  test_accuracy, predictions = eval_session.run([],feed_dict={bottleneck_input:,ground_truth_input:})
  if FLAGS.print_misclassified_test_images:
    for i, test_filename in enumerate():
      if predictions[] != test_ground_truth[]:
def build_eval_session():
  eval_graph, bottleneck_tensor, resized_input_tensor, wants_quantization = (create_module_graph())
  eval_sess = tf.Session(graph=)
  with eval_graph.as_default():
    () = add_final_retrain_ops(class_count, FLAGS.final_tensor_name, bottleneck_tensor,wants_quantization, is_training=)
    tf.train.Saver().restore()
    evaluation_step, prediction = add_evaluation_step()
  return ()
def save_graph_to_file():
  sess, _, _, _, _, _ = build_eval_session()
  graph =
  output_graph_def = tf.graph_util.convert_variables_to_constants(sess, graph.as_graph_def(), [])
  with tf.gfile.GFile() as f:
    f.write(output_graph_def.SerializeToString())
def prepare_file_system():
  if tf.gfile.Exists():
    tf.gfile.DeleteRecursively()
  tf.gfile.MakeDirs()
  if FLAGS.intermediate_store_frequency > 0:
    ensure_dir_exists()
  return
def add_jpeg_decoding():
  input_height, input_width = hub.get_expected_image_size()
  input_depth = hub.get_num_image_channels()
  jpeg_data = tf.placeholder(tf.string, name=)
  decoded_image = tf.image.decode_jpeg(jpeg_data, channels=)
  decoded_image_as_float = tf.image.convert_image_dtype()
  decoded_image_4d = tf.expand_dims()
  resize_shape = tf.stack([])
  resize_shape_as_int = tf.cast(resize_shape, dtype=)
  resized_image = tf.image.resize_bilinear()
  return jpeg_data, resized_image
def export_model():
  sess, in_image, _, _, _, _ = build_eval_session()
  with sess.graph.as_default() as graph:
    tf.saved_model.simple_save(sess,saved_model_dir,inputs={'image':},outputs={'prediction': graph.get_tensor_by_name('final_result:},legacy_init_op=tf.group(tf.tables_initializer(), name=))
def logging_level_verbosity():
  name_to_level = {'FATAL':,'ERROR':,'WARN':,'INFO':,'DEBUG':}
  try:
    return name_to_level[]
  except Exception as e:
    raise RuntimeError()
def main():
  logging_verbosity = logging_level_verbosity()
  logging.set_verbosity()
  if not FLAGS.image_dir:
    return -1
  prepare_file_system()
  image_lists = create_image_lists()
  class_count = len(image_lists.keys())
  if class_count == 0:
    return -1
  if class_count == 1:
    return -1
  do_distort_images = should_distort_images()
  module_spec = hub.load_module_spec()
  graph, bottleneck_tensor, resized_image_tensor, wants_quantization = (create_module_graph())
  with graph.as_default():
    () = add_final_retrain_ops(class_count, FLAGS.final_tensor_name, bottleneck_tensor,wants_quantization, is_training=)
  with tf.Session(graph=) as sess:
    init = tf.global_variables_initializer()
    sess.run()
    jpeg_data_tensor, decoded_image_tensor = add_jpeg_decoding()
    if do_distort_images:
      () = add_input_distortions()
    else:
      cache_bottlenecks()
    evaluation_step, _ = add_evaluation_step()
    merged = tf.summary.merge_all()
    train_writer = tf.summary.FileWriter()
    validation_writer = tf.summary.FileWriter()
    train_saver = tf.train.Saver()
    for i in range():
      if do_distort_images:
        () = get_random_distorted_bottlenecks()
      else:
        () = get_random_cached_bottlenecks()
      train_summary, _ = sess.run([],feed_dict={bottleneck_input:,ground_truth_input:})
      train_writer.add_summary()
      is_last_step = (i + 1 ==)
      if () == 0 or is_last_step:
        train_accuracy, cross_entropy_value = sess.run([],feed_dict={bottleneck_input:,ground_truth_input:})
        validation_bottlenecks, validation_ground_truth, _ = (get_random_cached_bottlenecks())
        validation_summary, validation_accuracy = sess.run([],feed_dict={bottleneck_input:,ground_truth_input:})
        validation_writer.add_summary()
      intermediate_frequency =
      if (intermediate_frequency > 0 and (i % intermediate_frequency ==)and i > 0):
        train_saver.save()
        intermediate_file_name = (FLAGS.intermediate_output_graphs_dir +"" + str() + "")
        save_graph_to_file()
    train_saver.save()
    run_final_eval()
    if wants_quantization:
    save_graph_to_file()
    with tf.gfile.GFile() as f:
      f.write('\n'.join(image_lists.keys()) + "")
    if FLAGS.saved_model_dir:
      export_model()
if __name__ == "__main__":
  parser = argparse.ArgumentParser()
  parser.add_argument("",type=,default=,help=)
  parser.add_argument("",type=,default=,help=)
  parser.add_argument("",type=,default=,help=)
  parser.add_argument("",type=,default=,help=)
  parser.add_argument("",default=,help=)
  parser.add_argument("",type=,default=,help=)
import time
from functools import wraps
import os
from glob import glob
import numpy as np
import tensorflow as tf
import math
def describe():
    def wrapper():
        start = time.time()
        result = func()
        end = time.time()
        return result
    return wrapper
def getAttrs():
    value = []
    for n in name:
        value.append(getattr())
    return value
def setAttrs():
    for name, value in zip():
        object.__dict__[] =
def output_to_sequence(lmt, type=):
    phn = []
    sequences = []
    start =
    sequences.append([])
    for i in range(len(lmt[])):
        if lmt[][][] == start:
            sequences[].append(lmt[][])
        else:
            start =
            sequences.append([])
    indexes = sequences[]
    if type == "":
        seq = []
        for ind in indexes:
            if ind == len():
                pass
            else:
                seq.append(phn[])
        seq = "".join()
        return seq
    elif type == "":
        seq = []
        for ind in indexes:
            if ind == 0:
                seq.append()
            elif ind == 27:
                seq.append()
            elif ind == 28:
                pass
            else:
                seq.append(chr())
        seq = "".join()
        return seq
    else:
        raise TypeError()
def target2phoneme():
    seq = []
    for t in target:
        if t == len():
            pass
        else:
            seq.append(phn[])
    seq = "".join()
    return seq
def logging(model,logfile,errorRate,epoch=,delta_time=,mode=):
    if mode != "" and mode != "" and mode != "" and mode != "":
        raise TypeError()
    logfile =
    if mode == "":
        with open() as myfile:
            myfile.write(str()+"")
    elif mode == "":
        with open() as myfile:
            myfile.write(str(time.strftime())+"")
            myfile.write(""+str()+""+""+str()+"")
            myfile.write(""+str()+""+""+str()+"")
    elif mode == "":
        logfile =
        with open() as myfile:
            myfile.write(str()+"")
            myfile.write(str(time.strftime())+"")
            myfile.write(""+str()+"")
    elif mode == "":
        logfile =
        with open() as myfile:
            myfile.write(str()+"")
            myfile.write(str(time.strftime())+"")
            myfile.write(""+str()+"")
def count_params(model, mode=):
    if mode == "":
        num = np.sum([np.product([xi.value for xi in x.get_shape()]) for x in model.var_op])
    elif mode == "":
        num = np.sum([np.product([xi.value for xi in x.get_shape()]) for x in model.var_trainable_op])
    else:
        raise TypeError()
    return num
def list_to_sparse_tensor():
    indices = []
    vals = []
    phn = []
    mapping = {}
    group_phn = []
    mapping = {}
    group_phn = []
    if level == "":
        for tI, target in enumerate():
            for seqI, val in enumerate():
                indices.append([])
                vals.append()
        shape = [len(), np.asarray().max(axis=)[]+1]
        return (np.array(), np.array(), np.array())
    elif level == "":
        for tI, target in enumerate():
            for seqI, val in enumerate():
                if val < len() and (phn[] in mapping.keys()):
                    val = group_phn.index(mapping[phn[]])
                indices.append([])
                vals.append()
        shape = [len(), np.asarray().max()[]+1]
        return (np.array(), np.array(), np.array())
    else:
        raise ValueError()
def get_edit_distance():
    graph = tf.Graph()
    with graph.as_default():
        truth = tf.sparse_placeholder()
        hyp = tf.sparse_placeholder()
        editDist = tf.reduce_sum(tf.edit_distance(hyp, truth, normalize=))
    with tf.Session(graph=) as session:
        truthTest = list_to_sparse_tensor()
        hypTest = list_to_sparse_tensor()
        feedDict = {truth:, hyp:}
        dist = session.run(editDist, feed_dict=)
    return dist
def data_lists_to_batches():
    nFeatures = inputList[].shape[]
    maxLength =
    for inp in inputList:
        maxLength = max(maxLength, inp.shape[])
    randIxs = np.random.permutation(len())
    start, end = ()
    dataBatches = []
    while end <= len():
        batchSeqLengths = np.zeros()
        for batchI, origI in enumerate(randIxs[start:]):
            batchSeqLengths[] = inputList[].shape[]
        batchInputs = np.zeros(())
        batchTargetList = []
        for batchI, origI in enumerate(randIxs[start:]):
            padSecs = maxLength - inputList[].shape[]
            batchInputs[:,batchI,:] = np.pad(inputList[].T, ((),()), "", constant_values=)
            batchTargetList.append(targetList[])
        dataBatches.append((batchInputs, list_to_sparse_tensor(), batchSeqLengths))
        start +=
        end +=
    return ()
def load_batched_data():
    return data_lists_to_batches([np.load(os.path.join()) for fn in os.listdir()],[np.load(os.path.join()) for fn in os.listdir()],batchSize, level) + (len(os.listdir()),)
def list_dirs():
    mfcc_dirs = glob()
    label_dirs = glob()
    for mfcc,label in zip():
        yield ()
def batch_norm(x, is_training=):
    with tf.variable_scope():
        inputs_shape = x.get_shape()
        axis = list(range(len() - 1))
        param_shape = inputs_shape[-1:]
        beta = tf.get_variable("", param_shape, initializer=tf.constant_initializer())
        gamma = tf.get_variable("", param_shape, initializer=tf.constant_initializer())
        batch_mean, batch_var = tf.nn.moments()
        ema = tf.train.ExponentialMovingAverage(decay=)
        def mean_var_with_update():
            ema_apply_op = ema.apply([])
            with tf.control_dependencies([]):
                return tf.identity(), tf.identity()
        mean, var = tf.cond(is_training,mean_var_with_update,lambda: (ema.average(), ema.average()))
        normed = tf.nn.batch_normalization()
    return normed
def _get_dims():
    fan_in = shape[] if len() == 2 else np.prod(shape[:])
    fan_out = shape[] if len() == 2 else shape[]
    return fan_in, fan_out
def dropout():
    return tf.contrib.layers.dropout(x, keep_prob=, is_training=)
import argparse
from tools.utils import *
import os
from net import generator
os.environ[] =
def parse_args():
    desc =
    parser = argparse.ArgumentParser(description=)
    parser.add_argument("", type=, default=,help=)
    parser.add_argument("", type=, default=,help=)
    return parser.parse_args()
def save():
    save_path = os.path.join()
    saver.save(sess, save_path, write_meta_graph=)
    return  save_path
def main():
    ckpt_dir =
    check_folder()
    placeholder = tf.placeholder(tf.float32, [], name=)
    with tf.variable_scope("", reuse=):
        _ = generator.G_net().fake
    generator_var = [var for var in tf.trainable_variables() if var.name.startswith()]
    saver = tf.train.Saver()
    gpu_options = tf.GPUOptions(allow_growth=)
    with tf.Session(config=tf.ConfigProto(allow_soft_placement=, gpu_options=)) as sess:
        sess.run(tf.global_variables_initializer())
        ckpt = tf.train.get_checkpoint_state()
        if ckpt and ckpt.model_checkpoint_path:
            ckpt_name = os.path.basename()
            saver.restore(sess, os.path.join())
            counter = ckpt_name.split()[]
        else:
            return
        info = save()
if __name__ == "__main__":
    arg = parse_args()
    main()
import argparse
from tools.utils import *
import os
from tqdm import tqdm
from glob import glob
import time
import numpy as np
from net import generator
os.environ[] =
def parse_args():
    desc =
    parser = argparse.ArgumentParser(description=)
    parser.add_argument("", type=, default=,help=)
    parser.add_argument("", type=, default=,help=)
    parser.add_argument("", type=, default=,help=)
    parser.add_argument("", type=, default=,help=)
    return parser.parse_args()
def stats_graph():
    flops = tf.profiler.profile(graph, options=tf.profiler.ProfileOptionBuilder.float_operation())
def test(checkpoint_dir, style_name, test_dir, if_adjust_brightness, img_size=[]):
    test_files = glob("")
    result_dir =
    check_folder()
    test_real = tf.placeholder(tf.float32, [], name=)
    with tf.variable_scope("", reuse=):
        test_generated = generator.G_net().fake
    generator_var = [var for var in tf.trainable_variables() if var.name.startswith()]
    saver = tf.train.Saver()
    gpu_options = tf.GPUOptions(allow_growth=)
    with tf.Session(config=tf.ConfigProto(allow_soft_placement=, gpu_options=)) as sess:
        ckpt = tf.train.get_checkpoint_state()
        if ckpt and ckpt.model_checkpoint_path:
            ckpt_name = os.path.basename()
            saver.restore(sess, os.path.join())
        else:
            return
        begin = time.time()
        for sample_file  in tqdm() :
            sample_image = np.asarray(load_test_data())
            image_path = os.path.join(result_dir,""))
            fake_img = sess.run(test_generated, feed_dict = {test_real :})
            if if_adjust_brightness:
                save_images()
            else:
                save_images()
        end = time.time()
if __name__ == "__main__":
    arg = parse_args()
    test()
import tarfile
import os
import json
import requests
import sys
import shutil
import re
from tqdm import tqdm, trange
import numpy as np
import tensorflow as tf
from tensorflow.core.protobuf import rewriter_config_pb2
from tensorflow.python.client import device_lib
import time
from datetime import datetime
import csv
import argparse
try:
    from google.colab import drive
except:
    pass
from gpt_2_simple.src import model, sample, encoder, memory_saving_gradients
from gpt_2_simple.src.load_dataset import load_dataset, Sampler
from gpt_2_simple.src.accumulate import AccumulatingOptimizer
def download_file_with_progress():
    DOWNLOAD_CHUNK_SIZE =
    r = requests.get(url_base + "" + model_name + "" + file_name, stream=)
    with open(os.path.join(), "") as f:
        file_size = int(r.headers[])
        with tqdm(ncols=, desc=,total=, unit_scale=) as pbar:
            for chunk in r.iter_content(chunk_size=):
                f.write()
                pbar.update()
def download_gpt2(model_dir=, model_name=):
    sub_dir = os.path.join()
    if not os.path.exists():
        os.makedirs()
    sub_dir = sub_dir.replace()
    for file_name in []:
        download_file_with_progress(url_base="https:,sub_dir=,model_name=,file_name=)
def start_tf_sess(threads=, server=):
    config = tf.compat.v1.ConfigProto()
    config.gpu_options.allow_growth =
    config.graph_options.rewrite_options.layout_optimizer =
    if threads > 0:
        config.intra_op_parallelism_threads =
        config.inter_op_parallelism_threads =
    if server is not None:
        return tf.compat.v1.Session(target=, config=)
    return tf.compat.v1.Session(config=)
def reset_session(sess, threads=, server=):
    tf.compat.v1.reset_default_graph()
    sess.close()
    sess = start_tf_sess()
    return sess
def get_available_gpus():
    local_device_protos = device_lib.list_local_devices()
    return [x.name for x in local_device_protos if x.device_type ==]
def finetune(sess,dataset,steps=,model_name=,model_dir=,combine=,batch_size=,learning_rate=,accumulate_gradients=,restore_from=,run_name=,checkpoint_dir=,sample_every=,sample_length=,sample_num=,multi_gpu=,save_every=,print_every=,max_checkpoints=,use_memory_saving_gradients=,only_train_transformer_layers=,optimizer=,overwrite=):
    SAMPLE_DIR =
    checkpoint_path = os.path.join()
    def maketree():
        try:
            os.makedirs()
        except:
            pass
    maketree()
    files = [f for f in os.listdir()]
    for file in []:
        try:
            shutil.copyfile(os.path.join(),os.path.join())
        except FileNotFoundError as fnf_error:
            raise()
    enc = encoder.get_encoder()
    hparams = model.default_hparams()
    with open(os.path.join()) as f:
        hparams.override_from_dict(json.load())
    if sample_length > hparams.n_ctx:
        raise ValueError()
    if model_name not in []:
        use_memory_saving_gradients =
        only_train_transformer_layers =
        accumulate_gradients =
    context = tf.compat.v1.placeholder(tf.int32, [])
    gpus = []
    if multi_gpu:
        gpus = get_available_gpus()
    output = model.model(hparams=, X=, gpus=)
    loss = tf.reduce_mean(input_tensor=tf.nn.sparse_softmax_cross_entropy_with_logits(labels=context[:, 1:], logits=output[][:, :]))
    tf_sample = sample.sample_sequence(hparams=,length=,context=,batch_size=,temperature=,top_k=)
    all_vars = [v for v in tf.compat.v1.trainable_variables() if "" in v.name]
    train_vars = [] if only_train_transformer_layers else all_vars
    if optimizer == "":
        opt = tf.compat.v1.train.AdamOptimizer(learning_rate=)
    elif optimizer == "":
        opt = tf.compat.v1.train.GradientDescentOptimizer(learning_rate=)
    if accumulate_gradients > 1:
        if use_memory_saving_gradients:
            exit()
        opt = AccumulatingOptimizer(opt=,var_list=)
        opt_reset = opt.reset()
        opt_compute = opt.compute_gradients()
        opt_apply = opt.apply_gradients()
        summary_loss = tf.compat.v1.summary.scalar()
    else:
        if use_memory_saving_gradients:
            opt_grads = memory_saving_gradients.gradients()
        else:
            opt_grads = tf.gradients(ys=, xs=)
        opt_grads = list(zip())
        opt_apply = opt.apply_gradients()
        summary_loss = tf.compat.v1.summary.scalar()
    summary_log = tf.compat.v1.summary.FileWriter()
    saver = tf.compat.v1.train.Saver(var_list=,max_to_keep=)
    sess.run(tf.compat.v1.global_variables_initializer())
    if restore_from == "":
        ckpt = tf.train.latest_checkpoint()
        if ckpt is None:
            ckpt = tf.train.latest_checkpoint(os.path.join())
    elif restore_from == "":
        ckpt = tf.train.latest_checkpoint(os.path.join())
    else:
        ckpt = tf.train.latest_checkpoint()
    saver.restore()
    chunks = load_dataset()
    data_sampler = Sampler()
    counter =
    counter_path = os.path.join()
    if os.path.exists() and restore_from == "":
        with open() as fp:
            counter = int(fp.read()) + 1
    counter_base =
    def save():
        maketree()
        saver.save(sess,os.path.join(),global_step=)
        with open() as fp:
            fp.write(str() + "")
    def generate_samples():
        context_tokens = data_sampler.sample()
        all_text = []
        index =
        while index < sample_num:
            out = sess.run(tf_sample,feed_dict={context:})
            for i in range(min()):
                text = enc.decode(out[])
                text = ""
                all_text.append()
                index +=
        maketree(os.path.join())
        with open(os.path.join(SAMPLE_DIR, run_name,'samples-{}').format(), "") as fp:
            fp.write("".join())
    def sample_batch():
        return [data_sampler.sample() for _ in range()]
    if overwrite and restore_from == "":
        for file in files:
            if file.startswith() or file.startswith():
                os.remove(os.path.join())
        save()
    avg_loss = ()
    start_time = time.time()
    if steps:
        steps = int()
    try:
        while True:
            if steps > 0 and counter == ():
                save()
                return
            if () % save_every == 0 and counter > 1:
                save()
            if () % sample_every == 0 and counter > 1:
                generate_samples()
            if accumulate_gradients > 1:
                sess.run()
                for _ in range():
                    sess.run(opt_compute, feed_dict={context:})
                () = sess.run(())
            else:
                () = sess.run((),feed_dict={context:})
            summary_log.add_summary()
            if counter % print_every == 0:
                avg_loss = (avg_loss[] * 0.99 + v_loss,avg_loss[] * 0.99 + 1.0)
            counter +=
    except KeyboardInterrupt:
        save()
def load_gpt2(sess,checkpoint=,run_name=,checkpoint_dir=,model_name=,model_dir=,multi_gpu=):
    if model_name:
        checkpoint_path = os.path.join()
    else:
        checkpoint_path = os.path.join()
    hparams = model.default_hparams()
    with open(os.path.join()) as f:
        hparams.override_from_dict(json.load())
    context = tf.compat.v1.placeholder(tf.int32, [])
    gpus = []
    if multi_gpu:
        gpus = get_available_gpus()
    output = model.model(hparams=, X=, gpus=)
    if checkpoint=="":
        ckpt = tf.train.latest_checkpoint()
    else:
        ckpt = os.path.join()
    saver = tf.compat.v1.train.Saver(allow_empty=)
    sess.run(tf.compat.v1.global_variables_initializer())
    if model_name:
    else:
    saver.restore()
def generate(sess,run_name=,checkpoint_dir=,model_name=,model_dir=,sample_dir=,return_as_list=,truncate=,destination_path=,sample_delim='=,prefix=,seed=,nsamples=,batch_size=,length=,temperature=,top_k=,top_p=,include_prefix=):
    if batch_size is None:
        batch_size =
    if nsamples == 1:
        sample_delim =
    if prefix == "":
        prefix =
    if model_name:
        checkpoint_path = os.path.join()
    else:
        checkpoint_path = os.path.join()
    enc = encoder.get_encoder()
    hparams = model.default_hparams()
    with open(os.path.join()) as f:
        hparams.override_from_dict(json.load())
    if prefix:
        context = tf.compat.v1.placeholder(tf.int32, [])
        context_tokens = enc.encode()
    np.random.seed()
    tf.compat.v1.set_random_seed()
    output = sample.sample_sequence(hparams=,length=min(length, 1023 - (len() if prefix else 0)),start_token=enc.encoder[] if not prefix else None,context=,batch_size=,temperature=, top_k=, top_p=)[:, 1:]
    if destination_path:
        f = open()
    generated =
    gen_texts = []
    while generated < nsamples:
        if not prefix:
            out = sess.run()
        else:
            out = sess.run(output, feed_dict={context:})
        for i in range():
            generated +=
            gen_text = enc.decode(out[])
            if prefix:
                gen_text = enc.decode(context_tokens[:]) + gen_text
            if truncate:
                truncate_esc = re.escape()
                if prefix and not include_prefix:
                    prefix_esc = re.escape()
                    pattern = ""
                else:
                    pattern = ""
                trunc_text = re.search()
                if trunc_text:
                    gen_text = trunc_text.group()
            gen_text = gen_text.lstrip()
            if destination_path:
                f.write("")
            if not return_as_list and not destination_path:
            gen_texts.append()
    if destination_path:
        f.close()
    if return_as_list:
        return gen_texts
def generate_to_file(sess,run_name=,checkpoint_dir=,model_name=,model_dir=,truncate=,destination_path=,sample_delim='=,prefix=,seed=,nsamples=,batch_size=,length=,temperature=,top_k=,top_p=,include_prefix=):
    generate(sess=,run_name=,checkpoint_dir=,model_name=,model_dir=,return_as_list=,truncate=,destination_path=,sample_delim=,prefix=,seed=,nsamples=,batch_size=,length=,temperature=,top_k=,top_p=,include_prefix=)
def mount_gdrive():
    drive.mount()
def is_mounted():
def get_tarfile_name():
    tarfile_name = checkpoint_folder.replace() + ""
    return tarfile_name
def copy_checkpoint_to_gdrive(run_name=, copy_folder=):
    is_mounted()
    checkpoint_folder = os.path.join()
    if copy_folder:
        shutil.copytree()
    else:
        file_path = get_tarfile_name()
        with tarfile.open() as tar:
            tar.add()
        shutil.copyfile()
def copy_checkpoint_from_gdrive(run_name=, copy_folder=):
    is_mounted()
    checkpoint_folder = os.path.join()
    if copy_folder:
        shutil.copytree()
    else:
        file_path = get_tarfile_name()
        shutil.copyfile()
        with tarfile.open() as tar:
            tar.extractall()
def copy_file_to_gdrive():
    is_mounted()
    shutil.copyfile()
def copy_file_from_gdrive():
    is_mounted()
    shutil.copyfile()
def is_gpt2_downloaded(model_dir=, model_name=):
    for filename in []:
        if not os.path.isfile(os.path.join()):
            return False
    return True
def encode_csv(csv_path, out_path=, header=,start_token=,end_token=):
    with open(csv_path, "", encoding=, errors=) as f:
        with open(out_path, "", encoding=, errors=) as w:
            if header:
                f.readline()
            reader = csv.reader()
            for row in reader:
                w.write(start_token + row[] + end_token + "")
def encode_dataset(file_path, model_dir=, out_path=,model_name=,combine=):
    model_path = os.path.join()
    enc = encoder.get_encoder()
    chunks = load_dataset()
    np.savez_compressed()
def cmd():
    parser = argparse.ArgumentParser(description=""s GPT-2 text-generating model on new texts. (https:)")
    parser.add_argument("", nargs=)
    parser.add_argument("", nargs=)
    args = parser.parse_args()
    if args.mode == "":
        cmd_finetune(dataset=, run_name=,checkpoint_dir=,model_name=,model_dir=,steps=, restore_from=,sample_every=,save_every=,print_every=,optimizer=,overwrite=,multi_gpu=)
    if args.mode == "":
        cmd_generate(nfiles=, nsamples=,folder=, length=,temperature=, batch_size=,prefix=, truncate=,include_prefix=,sample_delim=, run_name=,checkpoint_dir=,top_k=, top_p=, multi_gpu=)
def cmd_finetune():
    if not is_gpt2_downloaded(model_dir=, model_name=):
        download_gpt2(model_dir=, model_name=)
    sess = start_tf_sess()
    finetune(sess, dataset=, run_name=,checkpoint_dir=,model_name=,model_dir=,steps=, restore_from=,sample_every=, save_every=,print_every=,optimizer=,overwrite=,multi_gpu=)
def cmd_generate():
    sess = start_tf_sess()
    load_gpt2(sess, run_name=, checkpoint_dir=, multi_gpu=)
    try:
        os.mkdir()
    except:
        shutil.rmtree()
        os.mkdir()
    for _ in trange():
        gen_file = os.path.join(folder,""))
        generate_to_file(sess,run_name=,checkpoint_dir=,destination_path=,length=,temperature=,nsamples=,batch_size=,prefix=,truncate=,include_prefix=,sample_delim=,top_k=,top_p=)
import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt
from tensorflow.examples.tutorials.mnist import input_data
mnist = input_data.read_data_sets("", one_hot=)
X = tf.placeholder(tf.float32, [])
Y = tf.placeholder(tf.float32, [])
keep_prob = tf.placeholder()
W1 = tf.Variable(tf.random_normal([], stddev=))
L1 = tf.nn.relu(tf.matmul())
L1 = tf.nn.dropout()
W2 = tf.Variable(tf.random_normal([], stddev=))
L2 = tf.nn.relu(tf.matmul())
L2 = tf.nn.dropout()
W3 = tf.Variable(tf.random_normal([], stddev=))
model = tf.matmul()
cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=, labels=))
optimizer = tf.train.AdamOptimizer().minimize()
init = tf.global_variables_initializer()
sess = tf.Session()
sess.run()
batch_size =
total_batch = int()
for epoch in range():
    total_cost =
    for i in range():
        batch_xs, batch_ys = mnist.train.next_batch()
        _, cost_val = sess.run([],feed_dict={X:,Y:,keep_prob:})
        total_cost +=
is_correct = tf.equal(tf.argmax(), tf.argmax())
accuracy = tf.reduce_mean(tf.cast())
labels = sess.run(model,feed_dict={X:,Y:,keep_prob:})
fig = plt.figure()
for i in range():
    subplot = fig.add_subplot()
    subplot.set_xticks([])
    subplot.set_yticks([])
    subplot.set_title(""))
    subplot.imshow(mnist.test.images[].reshape(()),cmap=)
plt.show()
import collections
import math
import os
import random
import urllib
import zipfile
import numpy as np
import tensorflow as tf
import horovod.tensorflow as hvd
hvd.init()
url = 'http:
def maybe_download():
    if not os.path.exists():
        filename, _ = urllib.request.urlretrieve()
    statinfo = os.stat()
    if statinfo.st_size == expected_bytes:
    else:
        raise Exception()
    return filename
filename = maybe_download("", 31344016)
def read_data():
    with zipfile.ZipFile() as f:
        data = tf.compat.as_str(f.read(f.namelist()[])).split()
    return data
vocabulary = read_data()
vocabulary_size =
def build_dataset():
    count = [[]]
    count.extend(collections.Counter().most_common())
    dictionary = dict()
    for word, _ in count:
        dictionary[] = len()
    data = list()
    unk_count =
    for word in words:
        if word in dictionary:
            index = dictionary[]
        else:
            index =
            unk_count +=
        data.append()
    count[][] =
    reversed_dictionary = dict(zip(dictionary.values(), dictionary.keys()))
    return data, count, dictionary, reversed_dictionary
data, count, dictionary, reverse_dictionary = build_dataset()
del vocabulary
def generate_batch():
    batch_size =
    span =
    data_index = random.randint(0, len() - span - 1)
    batch = np.ndarray(shape=(), dtype=)
    labels = np.ndarray(shape=(), dtype=)
    buffer = collections.deque(maxlen=)
    for _ in range():
        buffer.append(data[])
        data_index = () % len()
    for i in range():
        target =
        targets_to_avoid = []
        for j in range():
            while target in targets_to_avoid:
                target = random.randint()
            targets_to_avoid.append()
            batch[] = buffer[]
            labels[] = buffer[]
        buffer.append(data[])
        data_index = () % len()
    return batch, labels
batch, labels = generate_batch(batch_size=, num_skips=, skip_window=)
for i in range():
max_batch_size =
embedding_size =
skip_window =
num_skips =
valid_size =
valid_window =
valid_examples = np.random.choice(valid_window, valid_size, replace=)
num_sampled =
graph = tf.Graph()
with graph.as_default():
    train_inputs = tf.placeholder(tf.int32, shape=[])
    train_labels = tf.placeholder(tf.int32, shape=[])
    valid_dataset = tf.constant(valid_examples, dtype=)
    embeddings = tf.Variable(tf.random_uniform([], -1.0, 1.0))
    embed = tf.nn.embedding_lookup()
    nce_weights = tf.Variable(tf.truncated_normal([],stddev=1.0 / math.sqrt()))
    nce_biases = tf.Variable(tf.zeros([]))
    loss = tf.reduce_mean(tf.nn.nce_loss(weights=,biases=,labels=,inputs=,num_sampled=,num_classes=))
    optimizer = tf.train.GradientDescentOptimizer(1.0 * hvd.size())
    optimizer = hvd.DistributedOptimizer()
    train_op = optimizer.minimize()
    norm = tf.sqrt(tf.reduce_sum(tf.square(), 1, keep_dims=))
    normalized_embeddings =
    valid_embeddings = tf.nn.embedding_lookup()
    similarity = tf.matmul(valid_embeddings, normalized_embeddings, transpose_b=)
    init = tf.global_variables_initializer()
    bcast = hvd.broadcast_global_variables()
num_steps = 100000 // hvd.size() + 1
config = tf.ConfigProto()
config.gpu_options.allow_growth =
config.gpu_options.visible_device_list = str(hvd.local_rank())
with tf.Session(graph=, config=) as session:
    init.run()
    bcast.run()
    average_loss =
    for step in range():
        batch_size = random.randint()
        batch_inputs, batch_labels = generate_batch()
        feed_dict = {train_inputs:, train_labels:}
        _, loss_val = session.run([], feed_dict=)
        average_loss +=
        if step % 2000 == 0:
            if step > 0:
                average_loss /=
            average_loss =
    final_embeddings = normalized_embeddings.eval()
    if hvd.rank() == 0:
        sim = similarity.eval()
        for i in range():
            valid_word = reverse_dictionary[valid_examples[]]
            top_k =
            nearest = (-sim[i, :]).argsort()[1:]
            log_str = 'Nearest to %s:
            for k in range():
                close_word = reverse_dictionary[nearest[]]
                log_str =
import tensorflow as tf
import numpy as np
xs = np.linspace()
ys = 0.3*xs-0.8+np.random.normal(scale=, size=len())
m_initial =
b_initial =
m = tf.Variable()
b = tf.Variable()
_BATCH =
xs_placeholder = tf.placeholder(tf.float32, [])
ys_placeholder = tf.placeholder(tf.float32, [])
ys_model =
total_error = tf.reduce_sum(()**2)
optimizer_operation = tf.train.GradientDescentOptimizer(learning_rate=).minimize()
initializer_operation = tf.global_variables_initializer()
with tf.Session() as session:
	session.run()
	_EPOCHS =
	for iteration in range():
		random_indices = np.random.randint(len(), size=)
		feed = {xs_placeholder:,ys_placeholder:}
		session.run(optimizer_operation, feed_dict=)
	slope, intercept = session.run(())
from os import path
import numpy as np
import tensorflow.compat.v1 as tf
from tensorflow_graphics.projects.nasa.lib import datasets
from tensorflow_graphics.projects.nasa.lib import models
from tensorflow_graphics.projects.nasa.lib import utils
tf.disable_eager_execution()
flags =
logging =
tf.logging.set_verbosity()
utils.define_flags()
FLAGS =
def build_eval_graph():
  dataset = input_fn()
  batch = dataset.make_one_shot_iterator().get_next()
  batch_holder = {"transform":,"joint":,"point":,"label":,}
  latent_holder, latent, occ = model_fn()
  iou_holder = tf.placeholder(tf.float32, [])
  best_holder = tf.placeholder(tf.float32, [])
  tf.summary.scalar()
  tf.summary.scalar()
  return {"batch_holder":,"latent_holder":,"latent":,"occ":,"batch":,"iou_holder":,"best_holder":,"merged_summary":,}
def evaluate():
  batch = hook_dict[]
  merged_summary = hook_dict[]
  iou_holder = hook_dict[]
  best_holder = hook_dict[]
  batch_holder = hook_dict[]
  latent_holder = hook_dict[]
  latent = hook_dict[]
  occ = hook_dict[]
  global_step = utils.parse_global_step()
  assignment_map = {"shape/":,}
  tf.train.init_from_checkpoint()
  init_op = tf.global_variables_initializer()
  with tf.Session() as sess:
    sess.run()
    accum_iou =
    example_cnt =
    while True:
      try:
        batch_val = sess.run()
        feed_dict = {batch_holder[]:,batch_holder[]:,}
        iou = utils.compute_iou(sess, feed_dict, latent_holder,batch_holder[], latent, occ[:, -1:],batch_val[], batch_val[],hparams)
        accum_iou +=
        example_cnt +=
        if hparams.gen_mesh_only > 0:
          unused_var = utils.save_mesh(sess,feed_dict,latent_holder,batch_holder[],latent,occ,batch_val,hparams,)
      except tf.errors.OutOfRangeError:
        accum_iou /=
        if best_iou < accum_iou:
          best_iou =
          saver.save(sess, path.join(),global_step)
        summary = sess.run(merged_summary,utils.make_summary_feed_dict())
        if hparams.gen_mesh_only:
          exit()
        break
  return summary, global_step
def main():
  tf.random.set_random_seed()
  np.random.seed()
  input_fn = datasets.get_dataset()
  model_fn = models.get_model()
  best_iou =
  with tf.summary.FileWriter(path.join()) as eval_writer:
    hook_dict = build_eval_graph()
    saver = tf.train.Saver()
    for ckpt in tf.train.checkpoints_iterator(FLAGS.train_dir, timeout=):
      summary, global_step = evaluate()
      eval_writer.add_summary()
      eval_writer.flush()
if __name__ == "__main__":
  tf.app.run()
from __future__ import absolute_import
from __future__ import division
from __future__ import print_function
import ast
import numpy as np
import tensorflow.compat.v1 as tf
from tensorflow.compat.v1.io import gfile
from tensorflow_graphics.projects.local_implicit_grid.core import implicit_nets as im
from tensorflow_graphics.projects.local_implicit_grid.core import local_implicit_grid_layer as lig
from tensorflow_graphics.projects.local_implicit_grid.core import model_g2g as g2g
from tensorflow_graphics.projects.local_implicit_grid.core import model_g2v as g2v
tf.logging.set_verbosity()
def parse_param_file():
  with gfile.GFile() as fh:
    lines = fh.readlines()
  d = {}
  for l in lines:
    l = l.rstrip()
    splits = l.split(':)
    key = splits[]
    val_ = splits[].strip()
    if not val_:
      val =
    else:
      try:
        val = ast.literal_eval()
      except ():
        val = str()
    d[] =
  return d
class RefinerEvaluator():
  def __init__(self, ckpt, codelen, dim=, out_features=, num_filters=,point_batch=):
    self.ckpt =
    self.codelen =
    self.dim =
    self.out_features =
    self.num_filters =
    self.point_batch =
    self.graph = tf.Graph()
    self._init_graph()
    self.global_step_ = self.global_step.eval(session=)
  def _init_graph():
    with self.graph.as_default():
      self.refiner = im.ImNet(dim=,in_features=,out_features=,num_filters=)
      self.global_step = tf.get_variable("", shape=[],dtype=)
      self.pts_ph = tf.placeholder(tf.float32, shape=[])
      self.lat_ph = tf.placeholder(tf.float32, shape=[])
      lat = tf.broadcast_to(self.lat_ph[],[])
      code = tf.concat((), axis=)
      vals = self.refiner(code, training=)
      self.vals = tf.squeeze(vals, axis=)
      self.saver = tf.train.Saver()
      self.sess = tf.Session()
      self.saver.restore()
  def _get_grid_points():
    x = np.linspace()
    xyz = np.meshgrid(*tuple([] * self.dim), indexing=)
    xyz = np.stack(xyz, axis=)
    xyz = xyz.reshape([])
    return xyz
  def eval_points():
    npt = points.shape[]
    npb = int(np.ceil(float()/self.point_batch))
    all_vals = np.zeros([], dtype=)
    for idx in range():
      sid = int()
      eid = int(min())
      pts = points[sid:]
      pad_w = self.point_batch - ()
      pts = np.pad(pts, ((), ()), mode=)
      with self.graph.as_default():
        val = self.sess.run(self.vals, feed_dict={self.pts_ph:,self.lat_ph:})
      all_vals[sid:] = val[:()]
    return all_vals
  def eval_grid(self, lat, xmin=, xmax=, res=):
    grid_points = self._get_grid_points(xmin=, xmax=, res=)
    point_val = self.eval_points()
    grid_val = point_val.reshape([])
    return grid_val
class EncoderEvaluator():
  def __init__(self,ckpt,in_grid_res=,encoder_nf=,codelen=,grid_batch=):
    self.ckpt =
    self.codelen =
    self.grid_batch =
    self.in_grid_res =
    self.encoder_nf =
    self.graph = tf.Graph()
    self._init_graph()
  def _init_graph():
    with self.graph.as_default():
      self.encoder = g2v.GridEncoder(in_grid_res=,num_filters=,codelen=,name=)
      self.grid_ph = tf.placeholder(tf.float32,shape=[])
      self.lats = self.encoder(self.grid_ph, training=)
      self.saver = tf.train.Saver()
      self.sess = tf.Session()
      self.saver.restore()
  def eval_grid():
    niters = int(np.ceil(grid.shape[] / self.grid_batch))
    codes = []
    for idx in range():
      sid =
      eid = min(sid+self.grid_batch, grid.shape[])
      c = self.sess.run(self.lats,feed_dict={self.grid_ph: grid[sid:})
      codes.append()
    codes = np.concatenate(codes, axis=)
    return codes.astype()
class FullGridEncoderEvaluator():
  def __init__(self,ckpt,in_grid_res=,num_filters=,codelen=,grid_batch=,gres=,overlap=):
    self.ckpt =
    self.codelen =
    self.grid_batch =
    self.in_grid_res =
    self.gres =
    self.num_filters =
    self.graph = tf.Graph()
    self._init_graph()
    self.global_step_ = self.global_step.eval(session=)
    if overlap:
      ijk = np.arange(0, gres-int(), int())
      self.out_grid_res = ijk.shape[]
    else:
      ijk = np.arange()
      self.out_grid_res = ijk.shape[]
    self.ijk = np.meshgrid(ijk, ijk, ijk, indexing=)
    self.ijk = np.stack(self.ijk, axis=).reshape([])
  def _init_graph():
    with self.graph.as_default():
      self.encoder = g2v.GridEncoder(in_grid_res=,num_filters=,codelen=,name=)
      self.global_step = tf.get_variable("", shape=[], dtype=)
      self.grid_ph = tf.placeholder(tf.float32, shape=[])
      self.start_ph = tf.placeholder(tf.int32, shape=[])
      self.ingrid = self._batch_slice()
      self.ingrid = self.ingrid[]
      self.lats = self.encoder(self.ingrid, training=)
      self.saver = tf.train.Saver()
      self.sess = tf.Session()
      self.saver.restore()
  def _batch_slice():
    batch_size = start_ijk.shape[]
    ijk = tf.range(w, dtype=)
    slice_idx = tf.meshgrid(ijk, ijk, ijk, indexing=)
    slice_idx = tf.stack(slice_idx, axis=)
    slice_idx = tf.broadcast_to(slice_idx[], [])
    offset = tf.broadcast_to(start_ijk[:, tf.newaxis, tf.newaxis, tf.newaxis, :],[])
    slice_idx +=
    batched_slices = tf.gather_nd()
    return batched_slices
  def eval_grid():
    ogrid = np.zeros([self.ijk.shape[], self.codelen])
    niters = np.ceil(self.ijk.shape[] / self.grid_batch).astype()
    for idx in range():
      sid =
      eid = min(sid + self.grid_batch, self.ijk.shape[])
      start_ijk = self.ijk[sid:]
      pad_w = self.grid_batch - start_ijk.shape[]
      start_ijk = np.pad(start_ijk, ((), ()), mode=)
      lats = self.sess.run(self.lats, feed_dict={self.grid_ph:,self.start_ph:})
      ogrid[sid:] = lats[:]
    ogrid = ogrid.reshape([])
    return ogrid.astype()
class LIGEvaluator():
  def __init__(self,ckpt,size=(),in_features=,out_features=,x_location_max=,num_filters=,min_grid_value=(),max_grid_value=(),net_type=,method=,point_batch=,scope=):
    self.dim =
    self.ckpt =
    self.size =
    self.x_location_max =
    self.num_filters =
    self.in_features =
    self.out_features =
    self.net_type =
    self.method =
    self.point_batch =
    self.scope =
    self.min_grid_value =
    self.max_grid_value =
    self.graph = tf.Graph()
    self._init_graph()
  def _init_graph():
    with self.graph.as_default():
      self.lig = lig.LocalImplicitGrid(size=,in_features=,out_features=,num_filters=,net_type=,method=,x_location_max=,min_grid_value=,max_grid_value=,name=)
      self.pts_ph = tf.placeholder(tf.float32, shape=[])
      self.latgrid_ph = tf.placeholder(tf.float32,shape=[self.size[],self.size[],self.size[],self.in_features])
      self.latgrid = self.latgrid_ph[]
      self.points = self.pts_ph[]
      vals = self.lig(self.latgrid, self.points, training=)
      self.vals = tf.squeeze(vals, axis=[])
      self.map_dict = self._get_var_mapping(model=)
      self.saver = tf.train.Saver()
      self.sess = tf.Session()
      self.saver.restore()
  def _get_grid_points():
    x = np.linspace()
    xyz = np.meshgrid(*tuple([] * self.dim), indexing=)
    xyz = np.stack(xyz, axis=)
    xyz = xyz.reshape([])
    return xyz
  def eval_points():
    npt = points.shape[]
    npb = int(np.ceil(float()/self.point_batch))
    all_vals = np.zeros([], dtype=)
    for idx in range():
      sid = int()
      eid = int(min())
      pts = points[sid:]
      pad_w = self.point_batch - ()
      if pts.shape[] < self.point_batch:
        pts_pad = np.tile(pts[0:], ())
        pts = np.concatenate([], axis=)
      with self.graph.as_default():
        val = self.sess.run(self.vals, feed_dict={self.pts_ph:,self.latgrid_ph:})
      all_vals[sid:] = val[:()]
    return all_vals
  def eval_grid(self, latgrid, xmin=, xmax=, res=):
    grid_points = self._get_grid_points(xmin=, xmax=, res=)
    point_val = self.eval_points()
    grid_val = point_val.reshape([])
    return grid_val
  def _get_var_mapping():
    vars_ =
    varnames = []
    varnames = [self.scope+v.replace().strip(':) for v in varnames]
    map_dict = dict(zip())
    return map_dict
class UNetEvaluator():
  def __init__(self,ckpt,in_grid_res,out_grid_res,num_filters,max_filters,out_features,sph_norm=):
    self.ckpt =
    self.in_grid_res =
    self.out_grid_res =
    self.num_filters =
    self.max_filters =
    self.out_features =
    self.sph_norm =
    self.graph = tf.Graph()
    self._init_graph()
  def _init_graph():
    with self.graph.as_default():
      self.unet = g2g.UNet3D(in_grid_res=,out_grid_res=,num_filters=,max_filters=,out_features=)
      self.input_grid_ph = tf.placeholder(tf.float32,[])
      self.input_grid = self.input_grid_ph[]
      self.feat_grid = self.unet()
      self.saver = tf.train.Saver()
      self.sess = tf.Session()
      self.saver.restore()
  def eval_grid():
    with self.graph.as_default():
      feat_grid = self.sess.run(self.feat_grid,feed_dict={self.input_grid_ph:})
    feat_grid = feat_grid[]
    if self.sph_norm > 0:
      feat_grid = (feat_grid /np.linalg.norm(feat_grid, axis=, keepdims=) *self.sph_norm)
    return feat_grid
class SparseLIGEvaluator():
  def __init__(self, ckpt, num_filters, codelen, origin, grid_shape,part_size, overlap=, scope=):
    self.scope =
    self.overlap =
    self.ckpt =
    self.num_filters =
    self.codelen =
    if overlap:
      self.res = (np.array() - 1) / 2.0
    else:
      self.res = np.array() - 1
    self.res = self.res.astype()
    self.xmin = np.array()
    self.xmax =
    self.part_size =
    self.lvg = LIGEvaluator(ckpt=,size=,in_features=,out_features=,x_location_max=2-float(),num_filters=,min_grid_value=,max_grid_value=,net_type=,method=,scope=)
  def evaluate_feature_grid(self, feature_grid, mask, res_per_part=,conservative=):
    eps =
    s =
    l = [np.linspace(self.xmin[]+eps, self.xmax[]-eps, res_per_part*s[])for i in range()]
    xyz = np.stack(np.meshgrid(l[], l[], l[],indexing=), axis=).reshape()
    output_grid = np.ones([res_per_part*s[],res_per_part*s[],res_per_part*s[]], dtype=).reshape()
    mask = mask.astype()
    if self.overlap:
      mask = np.stack([mask[:, :, :],mask[:, :, 1:],mask[:, 1:, :],mask[:, 1:, 1:],mask[1:, :, :],mask[1:, :, 1:],mask[1:, 1:, :],mask[1:, 1:, 1:]], axis=)
      if conservative:
        mask = np.any(mask, axis=)
      else:
        mask = np.all(mask, axis=)
    g = np.stack(np.meshgrid(np.arange(mask.shape[]),np.arange(mask.shape[]),np.arange(mask.shape[]),indexing=), axis=).reshape()
    g = g[:, 0]*(mask.shape[]*mask.shape[]) + g[:, 1]*mask.shape[] + g[:, 2]
    g_valid = g[mask.ravel()]
    if self.overlap:
      ijk = np.floor(() / self.part_size * 2).astype()
    else:
      ijk = np.floor(() / self.part_size).astype()
    ijk_idx = (ijk[:, 0]*(mask.shape[] * mask.shape[]) +ijk[:, 1]*mask.shape[] + ijk[:, 2])
    pt_mask = np.isin()
    output_grid[] = self.lvg.eval_points(feature_grid, xyz[])
    output_grid = output_grid.reshape(res_per_part*s[],res_per_part*s[],res_per_part*s[])
    return output_grid
import os
import numpy as np
from skimage import measure
import tensorflow.compat.v1 as tf
from tensorflow_graphics.projects.local_implicit_grid.core import evaluator
from tensorflow_graphics.projects.local_implicit_grid.core import local_implicit_grid_layer as lig
from tensorflow_graphics.projects.local_implicit_grid.core import point_utils as pt
class LIGOptimizer():
  def __init__(self, ckpt, origin, grid_shape, part_size, occ_idx,indep_pt_loss=, overlap=, alpha_lat=, npts=,init_std=, learning_rate=, var_prefix=, nows=):
    self.ckpt =
    self.ckpt_dir = os.path.dirname()
    self.params = self._load_params()
    self.origin =
    self.grid_shape =
    self.part_size =
    self.occ_idx =
    self.init_std =
    self.learning_rate =
    self.var_prefix =
    self.nows =
    self.xmin =
    if overlap:
      true_shape = (np.array() - 1) / 2.0
      self.xmax =
    else:
      self.xmax = self.origin + (np.array() - 1) * part_size
    _, sj, sk =
    self.occ_idx_flat = (self.occ_idx[:, 0]*()+self.occ_idx[:, 1]*sk+self.occ_idx[:, 2])
    self.indep_pt_loss =
    self.overlap =
    self.alpha_lat =
    self.npts = int()
    self._init_graph()
  def _load_params():
    param_file = os.path.join()
    params = evaluator.parse_param_file()
    return params
  def _init_graph():
    self.graph = tf.Graph()
    with self.graph.as_default():
      self.point_coords_ph = tf.placeholder(tf.float32,shape=[])
      self.point_values_ph = tf.placeholder(tf.float32,shape=[])
      self.point_coords =
      self.point_values =
      self.liggrid = lig.LocalImplicitGrid(size=,in_features=self.params[],out_features=,num_filters=self.params[],net_type=,method=,x_location_max=(),name=,interp=(),min_grid_value=,max_grid_value=)
      si, sj, sk =
      self.occ_idx_flat_ = tf.convert_to_tensor(self.occ_idx_flat[:, np.newaxis])
      self.shape_ = tf.constant([si*sj*sk, self.params[]],dtype=)
      self.feat_sparse_ = tf.Variable((tf.random.normal(shape=[self.occ_idx.shape[],self.params[]]) *self.init_std),trainable=,name=)
      self.feat_grid = tf.scatter_nd()
      self.feat_grid = tf.reshape(self.feat_grid,[1, si, sj, sk, self.params[]])
      self.feat_norm = tf.norm(self.feat_sparse_, axis=)
      if self.indep_pt_loss:
        self.preds, self.weights = self.liggrid(self.feat_grid,self.point_coords,training=)
        self.preds_interp = tf.reduce_sum(tf.expand_dims(self.weights, axis=)*self.preds,axis=)
        self.preds = tf.concat([self.preds,self.preds_interp[:, :, tf.newaxis, :]],axis=)
        self.point_values = tf.broadcast_to(self.point_values[:, :, tf.newaxis, :],shape=)
      else:
        self.preds = self.liggrid(self.feat_grid,self.point_coords,training=)
      self.labels_01 = () / 2
      self.loss_pt = tf.losses.sigmoid_cross_entropy(self.labels_01,logits=,reduction=)
      self.loss_lat = tf.reduce_mean() * self.alpha_lat
      self.loss = tf.reduce_mean() + self.loss_lat
      if self.indep_pt_loss:
        self.pvalue = tf.sign(self.point_values[:, :, -1, 0])
        self.ppred = tf.sign(self.preds[:, :, -1, 0])
      else:
        self.pvalue = tf.sign(self.point_values[])
        self.ppred = tf.sign(self.preds[:, :, 0])
      self.accu = tf.reduce_sum(tf.cast(tf.logical_or(tf.logical_and(),tf.logical_and()),tf.float32)) / float()
      self.optimizer = tf.train.AdamOptimizer(learning_rate=)
      self.fgrid_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES,scope=)
      self.train_op = self.optimizer.minimize(self.loss,global_step=tf.train.get_or_create_global_step(),var_list=[])
      self.map_dict = self._get_var_mapping(model=,scope=)
      self.sess = tf.Session()
      if not self.nows:
        self.saver = tf.train.Saver()
        self.saver.restore()
      self._initialize_uninitialized()
  def _get_var_mapping(self, model, scope=):
    vars_ =
    varnames = []
    varnames = [scope+v.replace().strip(':) for v in varnames]
    map_dict = dict(zip())
    return map_dict
  def _initialize_uninitialized():
    global_vars = tf.global_variables()
    is_not_initialized = sess.run([tf.is_variable_initialized() for var in global_vars])
    not_initialized_vars = [v for () in zip() if not f]
    if not_initialized_vars:
      sess.run(tf.variables_initializer())
  def optimize_feat_grid(self, point_coords, point_vals, steps=,print_every_n_steps=):
    point_coords = point_coords.copy()
    point_vals = np.sign(point_vals.copy())
    if point_coords.ndim == 3:
      point_coords = point_coords[]
    if point_vals.ndim == 3:
      point_vals = point_vals[]
    elif point_vals.ndim == 1:
      point_vals = point_vals[:, np.newaxis]
    point_coords = np.clip()
    seq = np.random.permutation(point_coords.shape[])
    point_coords = point_coords[]
    point_vals = point_vals[]
    point_coords = point_coords[]
    point_vals = point_vals[]
    def random_point_sample():
      sid = np.random.choice(point_coords.shape[]-self.npts+1)
      eid =
      return point_coords[:, sid:], point_vals[:, sid:]
    with self.graph.as_default():
      for i in range():
        pc, pv = random_point_sample()
        accu_, loss_, _ = self.sess.run([],feed_dict={self.point_coords_ph:,self.point_values_ph:})
        if i % print_every_n_steps == 0:
  def feature_grid():
    with self.graph.as_default():
      return self.sess.run()
def occupancy_sparse_to_dense():
  dense = np.zeros(grid_shape, dtype=).ravel()
  occ_idx_f = (occ_idx[:, 0] * grid_shape[] * grid_shape[] +occ_idx[:, 1] * grid_shape[] + occ_idx[:, 2])
  dense[] =
  dense = np.reshape()
  return dense
def get_in_out_from_samples(mesh, npoints, sample_factor=, std=):
  surface_point_samples, fid = mesh.sample(int(), return_index=)
  surface_point_normals = mesh.face_normals[]
  offsets = np.random.randn(int(), sample_factor, 1) * std
  near_surface_samples = (surface_point_samples[:, np.newaxis, :] +surface_point_normals[:, np.newaxis, :] * offsets)
  near_surface_samples = np.concatenate([],axis=)
  near_surface_samples = near_surface_samples.reshape([])
  surface_samples = np.concatenate([], axis=)
  return surface_samples, near_surface_samples
def get_in_out_from_ray(points_from_ray, sample_factor=, std=):
  surface_point_samples = points_from_ray[:, :]
  surface_point_normals = points_from_ray[:, 3:]
  n =
  surface_point_normals = n / (np.linalg.norm(n, axis=, keepdims=)+1e-8)
  npoints = points_from_ray.shape[]
  offsets = np.random.randn() * std
  near_surface_samples = (surface_point_samples[:, np.newaxis, :] +surface_point_normals[:, np.newaxis, :] * offsets)
  near_surface_samples = np.concatenate([],axis=)
  near_surface_samples = near_surface_samples.reshape([])
  return near_surface_samples
def intrinsics_from_matrix():
  return (int_mat[], int_mat[], int_mat[], int_mat[])
def encode_decoder_one_scene(near_surface_samples, ckpt_dir, part_size,overlap, indep_pt_loss,xmin=np.zeros(),xmax=np.ones(),res_per_part=, npts=, init_std=,learning_rate=, steps=, nows=,verbose=):
  ckpt = tf.train.latest_checkpoint()
  np.random.shuffle()
  param_file = os.path.join()
  params = evaluator.parse_param_file()
  _, occ_idx, grid_shape = pt.np_get_occupied_idx(near_surface_samples[:, :],xmin=, xmax=, crop_size=,ntarget=, overlap=, normalize_crops=, return_shape=)
  npts = min(npts, near_surface_samples.shape[])
  if verbose: print("")
  if verbose: print()
  goptim = LIGOptimizer(ckpt, origin=, grid_shape=, part_size=,occ_idx=, indep_pt_loss=, overlap=,alpha_lat=params[], npts=, init_std=,learning_rate=, var_prefix=, nows=)
  goptim.optimize_feat_grid(near_surface_samples[:, :],near_surface_samples[:, 3:], steps=)
  mask = occupancy_sparse_to_dense()
  if verbose: print()
  svg = evaluator.SparseLIGEvaluator(ckpt, num_filters=params[],codelen=params[], origin=,grid_shape=, part_size=,overlap=, scope=)
  feat_grid = goptim.feature_grid[]
  out_grid = svg.evaluate_feature_grid(feat_grid,mask=,res_per_part=)
  v, f, _, _ = measure.marching_cubes_lewiner()
  v *= (part_size / float() *float(out_grid.shape[]) / (float(out_grid.shape[])-1))
  v +=
  return v, f, feat_grid, mask
from os import path
import numpy as np
import tensorflow.compat.v1 as tf
from tensorflow_graphics.projects.nasa.lib import datasets
from tensorflow_graphics.projects.nasa.lib import model_utils
from tensorflow_graphics.projects.nasa.lib import models
from tensorflow_graphics.projects.nasa.lib import utils
tf.disable_eager_execution()
flags =
logging =
tf.logging.set_verbosity()
utils.define_flags()
flags.mark_flag_as_required()
FLAGS =
def main():
  tf.random.set_random_seed()
  np.random.seed()
  input_fn = datasets.get_dataset()
  batch = input_fn().make_one_shot_iterator().get_next()
  data = {}
  with tf.Session() as sess:
    while True:
      try:
        batch_val = sess.run()
        key = batch_val[][]
        data[] =
        data[][] = (data[][] +np.random.normal(0, 5e-3, data[][].shape))
      except tf.errors.OutOfRangeError:
        break
    sorted_keys = sorted(data.keys())
  trans_range =
  n_dims =
  n_translate = 3 if n_dims ==
  n_rotate = 6 if n_dims ==
  tf.reset_default_graph()
  accum_mat_holder = tf.placeholder(tf.float32,[])
  pt_holder = tf.placeholder(tf.float32, [])
  weight_holder = tf.placeholder(tf.float32, [])
  loss_holder = tf.placeholder(tf.float32, [])
  glue_loss_holder = tf.placeholder(tf.float32, [])
  iou_holder = tf.placeholder(tf.float32, [])
  id_transform = model_utils.get_identity_transform()
  theta = tf.Variable(id_transform, trainable=, name=)
  temp_mat = model_utils.get_transform_matrix()
  if FLAGS.left_trans:
    trans_mat = tf.matmul(tf.reshape(accum_mat_holder,[]),tf.reshape(temp_mat, []))
  else:
    trans_mat = tf.matmul(tf.reshape(temp_mat, []),tf.reshape(accum_mat_holder,[]))
  r = trans_mat[..., :, :]
  t = trans_mat[..., :, -1:]
  r_t = tf.transpose(r, [])
  t_0 = -tf.matmul()
  joint_trans = tf.concat([tf.concat([], axis=), trans_mat[..., -1:, :]], axis=)
  joint_trans = tf.reshape(joint_trans, [])
  inv_first_frame_trans = data[sorted_keys[]][].reshape([])
  joint_trans = tf.matmul()
  first_frame_joint = data[sorted_keys[]][].reshape([])
  first_frame_joint = tf.concat([first_frame_joint,tf.ones_like(first_frame_joint[..., :, :])], axis=)
  joint = tf.matmul()[..., :, 0]
  if FLAGS.glue_w > 0.:
    with tf.io.gfile.GFile() as cin:
      connectivity = np.load()
    end_points = data[sorted_keys[]][].reshape([])
    first_frame_trans = data[sorted_keys[]][].reshape([])
    glue_loss = utils.compute_glue_loss(connectivity, end_points,tf.reshape(trans_mat, []),first_frame_trans, joint, FLAGS)
  else:
    glue_loss = tf.constant(0, dtype=)
  model_fn = models.get_model()
  batch_holder = {"transform":,"joint":,"point":,"weight":,}
  if FLAGS.gradient_type == "":
    interface = utils.vanilla_theta_gradient()
  elif FLAGS.gradient_type == "":
    interface = utils.reparam_theta_gradient()
  latent_holder, latent, occ, rec_loss =
  if FLAGS.glue_w > 0:
    loss =
  else:
    loss =
  global_step = tf.train.get_or_create_global_step()
  optimizer = tf.train.AdamOptimizer()
  update_ops = tf.get_collection()
  with tf.control_dependencies():
    train_op = optimizer.minimize(loss,var_list=[],global_step=,name=,)
    reset_op = tf.variables_initializer([] + optimizer.variables(), name=)
  tf.summary.scalar()
  tf.summary.scalar()
  tf.summary.scalar()
  summary_op = tf.summary.merge_all()
  assignment_map = {"shape/":,}
  tf.train.init_from_checkpoint()
  init_op = tf.global_variables_initializer()
  with tf.summary.FileWriter() as summary_writer:
    with tf.Session() as sess:
      sess.run()
      accum_mat = data[sorted_keys[]][].reshape([])
      accum_iou =
      example_cnt =
      for frame_id, k in enumerate():
        data_example = data[]
        feed_dict = {pt_holder:,weight_holder:,accum_mat_holder:,}
        loss_val, loss_glue_val = utils.optimize_theta()
        iou = utils.compute_iou(sess, feed_dict, latent_holder, pt_holder,latent, occ[:, -1:], data_example[],data_example[], FLAGS)
        accum_iou +=
        example_cnt +=
        utils.save_mesh(sess,feed_dict,latent_holder,pt_holder,latent,occ,data_example,FLAGS,pth="")
        utils.save_pointcloud(data_example,FLAGS,pth="")
        summary = sess.run(summary_op, {loss_holder:,iou_holder:,glue_loss_holder:})
        summary_writer.add_summary()
        summary_writer.flush()
        temp_mat_val = sess.run()
        if FLAGS.left_trans:
          accum_mat = np.matmul(accum_mat,temp_mat_val.reshape([]))
        else:
          accum_mat = np.matmul(temp_mat_val.reshape([]),accum_mat)
      with tf.io.gfile.GFile(path.join(FLAGS.train_dir, "",""), "") as iout:
        iout.write("")
if __name__ == "__main__":
  tf.app.run()
import os
import cv2
import numpy as np
import tensorflow as tf
import network
import guided_filter
from tqdm import tqdm
def resize_crop():
    h, w, c = np.shape()
    if min() > 720:
        if h > w:
            h, w = int(), 720
        else:
            h, w =, int()
    image = cv2.resize(image, (),interpolation=)
    h, w = ()*8, ()*8
    image = image[:, :, :]
    return image
def cartoonize():
    input_photo = tf.placeholder(tf.float32, [])
    network_out = network.unet_generator()
    final_out = guided_filter.guided_filter(input_photo, network_out, r=, eps=)
    all_vars = tf.trainable_variables()
    gene_vars = []
    saver = tf.train.Saver(var_list=)
    config = tf.ConfigProto()
    config.gpu_options.allow_growth =
    sess = tf.Session(config=)
    sess.run(tf.global_variables_initializer())
    saver.restore(sess, tf.train.latest_checkpoint())
    name_list = os.listdir()
    for name in tqdm():
        try:
            load_path = os.path.join()
            save_path = os.path.join()
            image = cv2.imread()
            image = resize_crop()
            batch_image = image.astype()/127.5 - 1
            batch_image = np.expand_dims(batch_image, axis=)
            output = sess.run(final_out, feed_dict={input_photo:})
            output = (np.squeeze()+1)*127.5
            output = np.clip().astype()
            cv2.imwrite()
        except:
if __name__ == "__main__":
    model_path =
    load_folder =
    save_folder =
    if not os.path.exists():
        os.mkdir()
    cartoonize()
import tensorflow as tf
import tensorflow.contrib.slim as slim
import utils
import os
import numpy as np
import argparse
import network
from tqdm import tqdm
os.environ[]=
def arg_parser():
    parser = argparse.ArgumentParser()
    parser.add_argument("", default =, type =)
    parser.add_argument("", default =, type =)
    parser.add_argument("", default =, type =)
    parser.add_argument("", default =, type =)
    parser.add_argument("", default =, type =)
    parser.add_argument("", default =)
    args = parser.parse_args()
    return args
def train():
    input_photo = tf.placeholder(tf.float32, [])
    output = network.unet_generator()
    recon_loss = tf.reduce_mean(tf.losses.absolute_difference())
    all_vars = tf.trainable_variables()
    gene_vars = []
    update_ops = tf.get_collection()
    with tf.control_dependencies():
        optim = tf.train.AdamOptimizer(args.adv_train_lr, beta1=, beta2=).minimize(recon_loss, var_list=)
    config = tf.ConfigProto()
    config.gpu_options.allow_growth =
    sess = tf.Session(config=)
    gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=)
    sess = tf.Session(config=tf.ConfigProto(gpu_options=))
    saver = tf.train.Saver(var_list=, max_to_keep=)
    with tf.device('/device:GPU:0'):
        sess.run(tf.global_variables_initializer())
        face_photo_dir =
        face_photo_list = utils.load_image_list()
        scenery_photo_dir =
        scenery_photo_list = utils.load_image_list()
        for total_iter in tqdm(range()):
            if np.mod() == 0:
                photo_batch = utils.next_batch()
            else:
                photo_batch = utils.next_batch()
            _, r_loss = sess.run([], feed_dict={input_photo:})
            if np.mod() == 0:
                if np.mod() == 0:
                    saver.save(sess, args.save_dir+"",write_meta_graph=, global_step=)
                    photo_face = utils.next_batch()
                    photo_scenery = utils.next_batch()
                    result_face = sess.run(output, feed_dict={input_photo:})
                    result_scenery = sess.run(output, feed_dict={input_photo:})
                    utils.write_batch_image(result_face, args.save_dir+"",str()+"", 4)
                    utils.write_batch_image(photo_face, args.save_dir+"",str()+"", 4)
                    utils.write_batch_image(result_scenery, args.save_dir+"",str()+"", 4)
                    utils.write_batch_image(photo_scenery, args.save_dir+"",str()+"", 4)
if __name__ == "__main__":
    args = arg_parser()
    train()
import tensorflow as tf
import tensorflow.contrib.slim as slim
import utils
import os
import numpy as np
import argparse
import network
import loss
from tqdm import tqdm
from guided_filter import guided_filter
os.environ[]=
def arg_parser():
    parser = argparse.ArgumentParser()
    parser.add_argument("", default =, type =)
    parser.add_argument("", default =, type =)
    parser.add_argument("", default =, type =)
    parser.add_argument("", default =, type =)
    parser.add_argument("", default =, type =)
    parser.add_argument("", default =, type =)
    parser.add_argument("", default =)
    args = parser.parse_args()
    return args
def train():
    input_photo = tf.placeholder(tf.float32, [])
    input_superpixel = tf.placeholder(tf.float32, [])
    input_cartoon = tf.placeholder(tf.float32, [])
    output = network.unet_generator()
    output = guided_filter(input_photo, output, r=)
    blur_fake = guided_filter(output, output, r=, eps=)
    blur_cartoon = guided_filter(input_cartoon, input_cartoon, r=, eps=)
    gray_fake, gray_cartoon = utils.color_shift()
    d_loss_gray, g_loss_gray = loss.lsgan_loss(network.disc_sn, gray_cartoon, gray_fake,scale=, patch=, name=)
    d_loss_blur, g_loss_blur = loss.lsgan_loss(network.disc_sn, blur_cartoon, blur_fake,scale=, patch=, name=)
    vgg_model = loss.Vgg19()
    vgg_photo = vgg_model.build_conv4_4()
    vgg_output = vgg_model.build_conv4_4()
    vgg_superpixel = vgg_model.build_conv4_4()
    h, w, c = vgg_photo.get_shape().as_list()[1:]
    photo_loss = tf.reduce_mean(tf.losses.absolute_difference())/()
    superpixel_loss = tf.reduce_mean(tf.losses.absolute_difference())/()
    recon_loss =
    tv_loss = loss.total_variation_loss()
    g_loss_total =
    d_loss_total =
    all_vars = tf.trainable_variables()
    gene_vars = []
    disc_vars = []
    tf.summary.scalar()
    tf.summary.scalar()
    update_ops = tf.get_collection()
    with tf.control_dependencies():
        g_optim = tf.train.AdamOptimizer(args.adv_train_lr, beta1=, beta2=).minimize(g_loss_total, var_list=)
        d_optim = tf.train.AdamOptimizer(args.adv_train_lr, beta1=, beta2=).minimize(d_loss_total, var_list=)
    config = tf.ConfigProto()
    config.gpu_options.allow_growth =
    sess = tf.Session(config=)
    gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=)
    sess = tf.Session(config=tf.ConfigProto(gpu_options=))
    train_writer = tf.summary.FileWriter()
    summary_op = tf.summary.merge_all()
    saver = tf.train.Saver(var_list=, max_to_keep=)
    with tf.device('/device:GPU:):
        sess.run(tf.global_variables_initializer())
        saver.restore(sess, tf.train.latest_checkpoint())
        face_photo_dir =
        face_photo_list = utils.load_image_list()
        scenery_photo_dir =
        scenery_photo_list = utils.load_image_list()
        face_cartoon_dir =
        face_cartoon_list = utils.load_image_list()
        scenery_cartoon_dir =
        scenery_cartoon_list = utils.load_image_list()
        for total_iter in tqdm(range()):
            if np.mod() == 0:
                photo_batch = utils.next_batch()
                cartoon_batch = utils.next_batch()
            else:
                photo_batch = utils.next_batch()
                cartoon_batch = utils.next_batch()
            inter_out = sess.run(output, feed_dict={input_photo:,input_superpixel:,input_cartoon:})
            if args.use_enhance:
                superpixel_batch = utils.selective_adacolor(inter_out, power=)
            else:
                superpixel_batch = utils.simple_superpixel(inter_out, seg_num=)
            _, g_loss, r_loss = sess.run([],feed_dict={input_photo:,input_superpixel:,input_cartoon:})
            _, d_loss, train_info = sess.run([],feed_dict={input_photo:,input_superpixel:,input_cartoon:})
            train_writer.add_summary()
            if np.mod() == 0:
                if np.mod() == 0:
                    saver.save(sess, args.save_dir+"",write_meta_graph=, global_step=)
                    photo_face = utils.next_batch()
                    cartoon_face = utils.next_batch()
                    photo_scenery = utils.next_batch()
                    cartoon_scenery = utils.next_batch()
                    result_face = sess.run(output, feed_dict={input_photo:,input_superpixel:,input_cartoon:})
                    result_scenery = sess.run(output, feed_dict={input_photo:,input_superpixel:,input_cartoon:})
                    utils.write_batch_image(result_face, args.save_dir+"",str()+"", 4)
                    utils.write_batch_image(photo_face, args.save_dir+"",str()+"", 4)
                    utils.write_batch_image(result_scenery, args.save_dir+"",str()+"", 4)
                    utils.write_batch_image(photo_scenery, args.save_dir+"",str()+"", 4)
if __name__ == "__main__":
    args = arg_parser()
    train()
import io
import numpy as np
import tensorflow as tf
from hparams import hparams
from librosa import effects
from models import create_model
from text import text_to_sequence
from util import audio
class Synthesizer:
  def load(self, checkpoint_path, model_name=):
    inputs = tf.placeholder(tf.int32, [], "")
    input_lengths = tf.placeholder(tf.int32, [], "")
    with tf.variable_scope() as scope:
      self.model = create_model()
      self.model.initialize()
      self.wav_output = audio.inv_spectrogram_tensorflow(self.model.linear_outputs[])
    self.session = tf.Session()
    self.session.run(tf.global_variables_initializer())
    saver = tf.train.Saver()
    saver.restore()
  def synthesize():
    cleaner_names = [x.strip() for x in hparams.cleaners.split()]
    seq = text_to_sequence()
    feed_dict = {self.model.inputs:,,self.model.input_lengths:,}
    wav = self.session.run(self.wav_output, feed_dict=)
    wav = audio.inv_preemphasis()
    wav = wav[:audio.find_endpoint()]
    out = io.BytesIO()
    audio.save_wav()
    return out.getvalue()
import tensorflow as tf
import matplotlib.pyplot as plt
import numpy as np
from tensorflow.examples.tutorials.mnist import input_data
mnist = input_data.read_data_sets("", one_hot=)
total_epoch =
batch_size =
n_hidden =
n_input =
n_noise =
n_class =
X = tf.placeholder(tf.float32, [])
Y = tf.placeholder(tf.float32, [])
Z = tf.placeholder(tf.float32, [])
def generator():
    with tf.variable_scope():
        inputs = tf.concat([], 1)
        hidden = tf.layers.dense(inputs, n_hidden,activation=)
        output = tf.layers.dense(hidden, n_input,activation=)
    return output
def discriminator(inputs, labels, reuse=):
    with tf.variable_scope() as scope:
        if reuse:
            scope.reuse_variables()
        inputs = tf.concat([], 1)
        hidden = tf.layers.dense(inputs, n_hidden,activation=)
        output = tf.layers.dense(hidden, 1,activation=)
    return output
def get_noise():
    return np.random.uniform(-1., 1., size=[])
G = generator()
D_real = discriminator()
D_gene = discriminator()
loss_D_real = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=, labels=tf.ones_like()))
loss_D_gene = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=, labels=tf.zeros_like()))
loss_D =
loss_G = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=, labels=tf.ones_like()))
vars_D = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES,scope=)
vars_G = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES,scope=)
train_D = tf.train.AdamOptimizer().minimize(loss_D,var_list=)
train_G = tf.train.AdamOptimizer().minimize(loss_G,var_list=)
sess = tf.Session()
sess.run(tf.global_variables_initializer())
total_batch = int()
loss_val_D, loss_val_G =, 0
for epoch in range():
    for i in range():
        batch_xs, batch_ys = mnist.train.next_batch()
        noise = get_noise()
        _, loss_val_D = sess.run([],feed_dict={X:, Y:, Z:})
        _, loss_val_G = sess.run([],feed_dict={Y:, Z:})
    if epoch == 0 or () % 10 == 0:
        sample_size =
        noise = get_noise()
        samples = sess.run(G,feed_dict={Y: mnist.test.labels[:,Z:})
        fig, ax = plt.subplots(2, sample_size, figsize=())
        for i in range():
            ax[][].set_axis_off()
            ax[][].set_axis_off()
            ax[][].imshow(np.reshape(mnist.test.images[], ()))
            ax[][].imshow(np.reshape(samples[], ()))
        plt.savefig("".zfill()), bbox_inches=)
        plt.close()
import json
import numpy as np
import os
import tensorflow as tf
from luminoth.models import get_model
from luminoth.datasets import get_dataset
class PredictorNetwork():
    def __init__():
        if config.dataset.dir:
            classes_file = os.path.join()
            if tf.gfile.Exists():
                self.class_labels = json.load(tf.gfile.GFile())
            else:
                self.class_labels =
        config.dataset.data_augmentation =
        dataset_class = get_dataset()
        model_class = get_model()
        dataset = dataset_class()
        model = model_class()
        graph = tf.Graph()
        self.session = tf.Session(graph=)
        with graph.as_default():
            self.image_placeholder = tf.placeholder(tf.float32, ())
            image_tf, _, process_meta = dataset.preprocess()
            pred_dict = model()
            if config.train.job_dir:
                job_dir =
                if config.train.run_name:
                    job_dir = os.path.join()
                ckpt = tf.train.get_checkpoint_state()
                if not ckpt or not ckpt.all_model_checkpoint_paths:
                    raise ValueError()
                ckpt = ckpt.all_model_checkpoint_paths[]
                saver = tf.train.Saver(sharded=, allow_empty=)
                saver.restore()
            else:
                init_op = tf.group(tf.global_variables_initializer(),tf.local_variables_initializer())
                self.session.run()
            if config.model.type == "":
                cls_prediction = pred_dict[]
                objects_tf = cls_prediction[]
                objects_labels_tf = cls_prediction[]
                objects_labels_prob_tf = cls_prediction[]
            elif config.model.type == "":
                if config.model.network.get():
                    cls_prediction = pred_dict[]
                    objects_tf = cls_prediction[]
                    objects_labels_tf = cls_prediction[]
                    objects_labels_prob_tf = cls_prediction[]
                else:
                    rpn_prediction = pred_dict[]
                    objects_tf = rpn_prediction[]
                    objects_labels_prob_tf = rpn_prediction[]
                    objects_labels_tf = tf.zeros(tf.shape(), dtype=)
            else:
                raise ValueError()
            self.fetches = {'objects':,'labels':,'probs':,'scale_factor':}
            if config.train.debug:
                self.fetches[] =
    def predict_image():
        fetched = self.session.run(self.fetches, feed_dict={self.image_placeholder:})
        objects = fetched[]
        labels = fetched[].tolist()
        probs = fetched[].tolist()
        scale_factor = fetched[]
        if self.class_labels is not None:
            labels = [self.class_labels[] for label in labels]
        if isinstance():
            objects /= [scale_factor[], scale_factor[],scale_factor[], scale_factor[]]
        else:
            objects /=
        objects = [[int(round()) for coord in obj]for obj in objects.tolist()]
        predictions = sorted([{'bbox':,'label':,'prob':,} for obj, label, prob in zip()], key=lambda x: x[], reverse=)
        return predictions
from __future__ import print_function, division
import tensorflow as tf
from sklearn.metrics import confusion_matrix
import numpy as np
import load
train_samples, train_labels =, load._train_labels
test_samples, test_labels =, load._test_labels
image_size =
num_labels =
num_channels =
def get_chunk():
    if len() != len():
        raise Exception()
    stepStart =
    i =
    while stepStart < len():
        stepEnd =
        if stepEnd < len():
            yield i, samples[stepStart:], labels[stepStart:]
            i +=
        stepStart =
class Network():
    def __init__():
        self.batch_size =
        self.test_batch_size =
        self.num_hidden =
        self.graph = tf.Graph()
        self.tf_train_samples =
        self.tf_train_labels =
        self.tf_test_samples =
        self.tf_test_labels =
        self.tf_test_prediction =
    def define_graph():
        with self.graph.as_default():
            self.tf_train_samples = tf.placeholder(tf.float32, shape=())
            self.tf_train_labels = tf.placeholder(tf.float32, shape=())
            self.tf_test_samples = tf.placeholder(tf.float32, shape=())
            fc1_weights = tf.Variable(tf.truncated_normal([], stddev=))
            fc1_biases = tf.Variable(tf.constant(0.1, shape=[]))
            fc2_weights = tf.Variable(tf.truncated_normal([], stddev=))
            fc2_biases = tf.Variable(tf.constant(0.1, shape=[]))
            def model():
                shape = data.get_shape().as_list()
                reshape = tf.reshape(data, [shape[], shape[] * shape[] * shape[]])
                hidden = tf.nn.relu(tf.matmul() + fc1_biases)
                return tf.matmul() + fc2_biases
            logits = model()
            self.loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=, labels=))
            self.optimizer = tf.train.GradientDescentOptimizer().minimize()
            self.train_prediction = tf.nn.softmax()
            self.test_prediction = tf.nn.softmax(model())
    def run():
        def print_confusion_matrix():
            for i, line in enumerate():
            a =
            for i, column in enumerate(np.transpose(confusionMatrix, ())):
                a += (column[] / np.sum()) * (np.sum() / 26000)
        self.session = tf.Session(graph=)
        with self.session as session:
            tf.initialize_all_variables().run()
            for i, samples, labels in get_chunk(train_samples, train_labels, chunkSize=):
                _, l, predictions = session.run([],feed_dict={self.tf_train_samples:, self.tf_train_labels:})
                accuracy, _ = self.accuracy()
                if i % 50 == 0:
            accuracies = []
            confusionMatrices = []
            for i, samples, labels in get_chunk(test_samples, test_labels, chunkSize=):
                result = self.test_prediction.eval(feed_dict={self.tf_test_samples:})
                accuracy, cm = self.accuracy(result, labels, need_confusion_matrix=)
                accuracies.append()
                confusionMatrices.append()
    def accuracy(self, predictions, labels, need_confusion_matrix=):
        _predictions = np.argmax()
        _labels = np.argmax()
        cm = confusion_matrix() if need_confusion_matrix else None
        accuracy = (100.0 * np.sum(_predictions ==) / predictions.shape[])
        return accuracy, cm
if __name__ == "__main__":
    net = Network(num_hidden=, batch_size=)
    net.define_graph()
    net.run()
import tensorflow as tf
from sklearn.metrics import confusion_matrix
import numpy as np
class Network():
    def __init__():
        self.train_batch_size =
        self.test_batch_size =
        self.conv_config = []
        self.fc_config = []
        self.conv_weights = []
        self.conv_biases = []
        self.fc_weights = []
        self.fc_biases = []
        self.pooling_scale =
        self.pooling_stride =
        self.tf_train_samples =
        self.tf_train_labels =
        self.tf_test_samples =
        self.tf_test_labels =
        self.merged =
        self.train_summaries = []
        self.test_summaries = []
    def add_conv(self, *, patch_size, in_depth, out_depth, activation=, pooling=, name):
        self.conv_config.append({'patch_size':,'in_depth':,'out_depth':,'activation':,'pooling':,'name':})
        with tf.name_scope():
            weights = tf.Variable(tf.truncated_normal([], stddev=), name=)
            biases = tf.Variable(tf.constant(0.1, shape=[]), name=)
            self.conv_weights.append()
            self.conv_biases.append()
    def add_fc(self, *, in_num_nodes, out_num_nodes, activation=, name):
        self.fc_config.append({'in_num_nodes':,'out_num_nodes':,'activation':,'name':})
        with tf.name_scope():
            weights = tf.Variable(tf.truncated_normal([], stddev=))
            biases = tf.Variable(tf.constant(0.1, shape=[]))
            self.fc_weights.append()
            self.fc_biases.append()
            self.train_summaries.append(tf.summary.histogram(str(len()) + "", weights))
            self.train_summaries.append(tf.summary.histogram(str(len()) + "", biases))
    def define_inputs():
        with tf.name_scope():
            self.tf_train_samples = tf.placeholder(tf.float32, shape=, name=)
            self.tf_train_labels = tf.placeholder(tf.float32, shape=, name=)
            self.tf_test_samples = tf.placeholder(tf.float32, shape=, name=)
    def define_model():
        def model(data_flow, train=):
            for i, () in enumerate(zip()):
                with tf.name_scope(config[] + ""):
                    with tf.name_scope():
                        data_flow = tf.nn.conv2d(data_flow, filter=, strides=[], padding=)
                        data_flow =
                        if not train:
                            self.visualize_filter_map(data_flow, how_many=config[],display_size=32 // (), name=config[] + "")
                    if config[] == "":
                        data_flow = tf.nn.relu()
                        if not train:
                            self.visualize_filter_map(data_flow, how_many=config[],display_size=32 // (), name=config[] + "")
                    else:
                        raise Exception("", config[])
                    if config[]:
                        data_flow = tf.nn.max_pool(data_flow,ksize=[],strides=[],padding=)
                        if not train:
                            self.visualize_filter_map(data_flow, how_many=config[],display_size=32 // () // 2,name=config[] + "")
            for i, () in enumerate(zip()):
                if i == 0:
                    shape = data_flow.get_shape().as_list()
                    data_flow = tf.reshape(data_flow, [shape[], shape[] * shape[] * shape[]])
                with tf.name_scope(config[] + ""):
                    data_flow = tf.matmul() + biases
                    if config[] == "":
                        data_flow = tf.nn.relu()
                    elif config[] is None:
                        pass
                    else:
                        raise Exception("",config[])
            return data_flow
        logits = model()
        with tf.name_scope():
            self.loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=, labels=))
            self.train_summaries.append(tf.summary.scalar())
        with tf.name_scope():
            self.optimizer = tf.train.GradientDescentOptimizer().minimize()
        with tf.name_scope():
            self.train_prediction = tf.nn.softmax(logits, name=)
        with tf.name_scope():
            self.test_prediction = tf.nn.softmax(model(self.tf_test_samples, train=), name=)
        self.merged_train_summary = tf.summary.merge()
        self.merged_test_summary = tf.summary.merge()
    def run():
        def print_confusion_matrix():
            for i, line in enumerate():
            a =
            for i, column in enumerate(np.transpose(confusionMatrix, ())):
                a += (column[] / np.sum()) * (np.sum() / 26000)
        self.writer = tf.summary.FileWriter("", tf.get_default_graph())
        with tf.Session(graph=tf.get_default_graph()) as session:
            tf.initialize_all_variables().run()
            for i, samples, labels in data_iterator():
                _, l, predictions, summary = session.run([],feed_dict={self.tf_train_samples:, self.tf_train_labels:})
                self.writer.add_summary()
                accuracy, _ = self.accuracy()
                if i % 50 == 0:
            accuracies = []
            confusionMatrices = []
            for i, samples, labels in data_iterator():
                result, summary = session.run([],feed_dict={self.tf_test_samples:})
                self.writer.add_summary()
                accuracy, cm = self.accuracy(result, labels, need_confusion_matrix=)
                accuracies.append()
                confusionMatrices.append()
    def accuracy(self, predictions, labels, need_confusion_matrix=):
        _predictions = np.argmax()
        _labels = np.argmax()
        cm = confusion_matrix() if need_confusion_matrix else None
        accuracy = (100.0 * np.sum(_predictions ==) / predictions.shape[])
        return accuracy, cm
    def visualize_filter_map():
        filter_map = tensor[]
        filter_map = tf.transpose(filter_map, perm=[])
        filter_map = tf.reshape(filter_map, ())
        self.test_summaries.append(tf.summary.image(name, tensor=, max_outputs=))
from __future__ import absolute_import
from __future__ import division
from __future__ import print_function
import collections
import math
import os
import random
import zipfile
import numpy as np
from six.moves import urllib
from six.moves import xrange
import tensorflow as tf
from tensorflow.contrib.tensorboard.plugins import projector
from pandas import DataFrame
url = 'http:
def maybe_download():
  if not os.path.exists():
    filename, _ = urllib.request.urlretrieve()
  statinfo = os.stat()
  if statinfo.st_size == expected_bytes:
  else:
    raise Exception()
  return filename
filename = maybe_download()
def read_data():
  with zipfile.ZipFile() as f:
    data = tf.compat.as_str(f.read(f.namelist()[])).split()
  return data
words = read_data()
vocabulary_size =
def build_dataset():
  count = [[]]
  count.extend(collections.Counter().most_common())
  dictionary = dict()
  for word, _ in count:
    dictionary[] = len()
  data = list()
  unk_count =
  for word in words:
    if word in dictionary:
      index = dictionary[]
    else:
      index =
      unk_count +=
    data.append()
  count[][] =
  reverse_dictionary = dict(zip(dictionary.values(), dictionary.keys()))
  return data, count, dictionary, reverse_dictionary
data, count, dictionary, reverse_dictionary = build_dataset()
del words
data_index =
def generate_batch():
  global data_index
  batch = np.ndarray(shape=(), dtype=)
  labels = np.ndarray(shape=(), dtype=)
  span =
  buffer = collections.deque(maxlen=)
  for _ in range():
    buffer.append(data[])
    data_index = () % len()
  for i in range():
    target =
    targets_to_avoid = []
    for j in range():
      while target in targets_to_avoid:
        target = random.randint()
      targets_to_avoid.append()
      batch[] = buffer[]
      labels[] = buffer[]
    buffer.append(data[])
    data_index = () % len()
  data_index = (data_index + len() - span) % len()
  return batch, labels
batch, labels = generate_batch(batch_size=, num_skips=, skip_window=)
for i in range():
if __name__ == "__main__":
  batch_size =
  embedding_size =
  skip_window =
  num_skips =
  valid_size =
  valid_window =
  valid_examples = np.random.choice(valid_window, valid_size, replace=)
  num_sampled =
  graph = tf.Graph()
  with graph.as_default():
    train_inputs = tf.placeholder(tf.int32, shape=[])
    train_labels = tf.placeholder(tf.int32, shape=[])
    valid_dataset = tf.constant(valid_examples, dtype=)
    with tf.device('/cpu:):
      embeddings = tf.Variable(tf.random_uniform([], -1.0, 1.0))
      embed = tf.nn.embedding_lookup()
      nce_weights = tf.Variable(tf.truncated_normal([],stddev=1.0 / math.sqrt()))
      nce_biases = tf.Variable(tf.zeros([]))
    loss = tf.reduce_mean(tf.nn.nce_loss(weights=,biases=,labels=,inputs=,num_sampled=,num_classes=))
    optimizer = tf.train.GradientDescentOptimizer().minimize()
    norm = tf.sqrt(tf.reduce_sum(tf.square(), 1, keep_dims=))
    normalized_embeddings =
    valid_embeddings = tf.nn.embedding_lookup()
    similarity = tf.matmul(valid_embeddings, normalized_embeddings, transpose_b=)
    tf_major_ver = int(tf.__version__.split()[])
    tf_minor_ver = int(tf.__version__.split()[])
    if(tf_major_ver==):
      init = tf.initialize_all_variables()
    else:
      init = tf.global_variables_initializer()
  num_steps =
  LOG_DIR =
  with tf.Session(graph=) as session:
    init.run()
    average_loss =
    for step in xrange():
      batch_inputs, batch_labels = generate_batch()
      feed_dict = {train_inputs:, train_labels:}
      _, loss_val = session.run([], feed_dict=)
      average_loss +=
      if step % 2000 == 0:
        if step > 0:
          average_loss /=
        average_loss =
    words_to_visualize =
    final_embeddings = normalized_embeddings.eval()[:]
    embedding_var = tf.Variable()
    session.run()
    saver = tf.train.Saver([])
    saver.save(session, os.path.join(), 0)
    config = projector.ProjectorConfig()
    embedding = config.embeddings.add()
    embedding.tensor_name =
    embedding.metadata_path = os.path.join()
    summary_writer = tf.summary.FileWriter()
    summary_writer.add_graph()
    projector.visualize_embeddings()
    labels = [(reverse_dictionary[], i) for i in range()]
    DataFrame(labels, columns=[]).to_csv("", index=, sep=)
import numpy as np
import tensorflow as tf
class PolicyValueNet():
    def __init__(self, board_width, board_height, model_file=):
        self.board_width =
        self.board_height =
        self.input_states = tf.placeholder(tf.float32, shape=[])
        self.input_state = tf.transpose(self.input_states, [])
        self.conv1 = tf.layers.conv2d(inputs=,filters=, kernel_size=[],padding=, data_format=,activation=)
        self.conv2 = tf.layers.conv2d(inputs=, filters=,kernel_size=[], padding=,data_format=,activation=)
        self.conv3 = tf.layers.conv2d(inputs=, filters=,kernel_size=[], padding=,data_format=,activation=)
        self.action_conv = tf.layers.conv2d(inputs=, filters=,kernel_size=[], padding=,data_format=,activation=)
        self.action_conv_flat = tf.reshape(self.action_conv, [])
        self.action_fc = tf.layers.dense(inputs=,units=,activation=)
        self.evaluation_conv = tf.layers.conv2d(inputs=, filters=,kernel_size=[],padding=,data_format=,activation=)
        self.evaluation_conv_flat = tf.reshape(self.evaluation_conv, [])
        self.evaluation_fc1 = tf.layers.dense(inputs=,units=, activation=)
        self.evaluation_fc2 = tf.layers.dense(inputs=,units=, activation=)
        self.labels = tf.placeholder(tf.float32, shape=[])
        self.value_loss = tf.losses.mean_squared_error()
        self.mcts_probs = tf.placeholder(tf.float32, shape=[])
        self.policy_loss = tf.negative(tf.reduce_mean(tf.reduce_sum(tf.multiply(), 1)))
        l2_penalty_beta =
        vars = tf.trainable_variables()
        l2_penalty = l2_penalty_beta * tf.add_n([tf.nn.l2_loss() for v in vars if "" not in v.name.lower()])
        self.loss =
        self.learning_rate = tf.placeholder()
        self.optimizer = tf.train.AdamOptimizer(learning_rate=).minimize()
        self.session = tf.Session()
        self.entropy = tf.negative(tf.reduce_mean(tf.reduce_sum(tf.exp() * self.action_fc, 1)))
        init = tf.global_variables_initializer()
        self.session.run()
        self.saver = tf.train.Saver()
        if model_file is not None:
            self.restore_model()
    def policy_value():
        log_act_probs, value = self.session.run([],feed_dict={self.input_states:})
        act_probs = np.exp()
        return act_probs, value
    def policy_value_fn():
        legal_positions =
        current_state = np.ascontiguousarray(board.current_state().reshape())
        act_probs, value = self.policy_value()
        act_probs = zip(legal_positions, act_probs[][])
        return act_probs, value
    def train_step():
        winner_batch = np.reshape(winner_batch, ())
        loss, entropy, _ = self.session.run([],feed_dict={self.input_states:,self.mcts_probs:,self.labels:,self.learning_rate:})
        return loss, entropy
    def save_model():
        self.saver.save()
    def restore_model():
        self.saver.restore()
from absl.testing import flagsaver
from absl.testing import parameterized
import lingvo.compat as tf
from lingvo.core import conv_layers_with_time_padding as conv_layers
from lingvo.core import py_utils
from lingvo.core import test_utils
from lingvo.core import tshape
import numpy as np
class ConvLayerTest():
  def testConv2DLayerConstruction():
    with self.session(use_gpu=):
      tf.random.set_seed()
      np.random.seed()
      params = conv_layers.Conv2DLayerWithPadding.Params()
      params.name =
      params.filter_shape = []
      params.filter_stride = []
      params.params_init = py_utils.WeightInit.Gaussian()
      _ = params.Instantiate()
      conv_vars = tf.get_collection()
      conv_var_names = []
      expected_var_names = ['conv/w/var:]
      self.assertEqual()
  def testConv2DLayerWithPaddingOutputChannels():
    with self.session():
      params = conv_layers.Conv2DLayerWithPadding.Params()
      params.name =
      params.filter_shape = []
      actual_output_channels = params.cls.OutputChannels()
      self.assertEqual()
  def testConv2DLayerOutShape():
    with self.session(use_gpu=):
      tf.random.set_seed()
      np.random.seed()
      params = conv_layers.Conv2DLayerWithPadding.Params()
      params.v2_padding =
      params.name =
      params.filter_shape = []
      params.filter_stride = []
      params.params_init = py_utils.WeightInit.Gaussian()
      conv_layer = params.Instantiate()
      in_shape = []
      out_shape = conv_layer.OutShape()
      self.assertEqual(out_shape, [])
      in_shape = []
      out_shape = conv_layer.OutShape()
      self.assertEqual(out_shape, [])
  def testComputeConvOutputPadding():
    padding = tf.constant([], tf.float32)
    expected_padding = tf.constant([], tf.float32)
    with self.session(use_gpu=):
      conv_padding = conv_layers.ComputeConvOutputPadding(padding, window=, stride=, padding_algorithm=)
      self.evaluate(tf.global_variables_initializer())
      conv_padding = py_utils.Debug()
      conv_padding = self.evaluate()
      self.assertAllClose()
  def testComputeConvOutputPaddingV2():
    padding = tf.constant([], tf.float32)
    expected_padding = tf.constant([], tf.float32)
    with self.session(use_gpu=):
      conv_padding = conv_layers._ComputeConvOutputPaddingV2(padding, window=, stride=, padding_algorithm=)
      self.evaluate(tf.global_variables_initializer())
      conv_padding = py_utils.Debug()
      conv_padding = self.evaluate()
      self.assertAllClose()
  def testConv2DLayerStridedWithPaddingFProp():
    with self.session(use_gpu=):
      batch_size =
      expected_seq_len =
      params = conv_layers.Conv2DLayerWithPadding.Params()
      params.weight_norm =
      params.filter_stride = []
      params.name =
      params.filter_shape = []
      params.params_init = py_utils.WeightInit.Constant()
      conv_layer = params.Instantiate()
      in_padding = tf.constant([[],[],[],], tf.float32)
      in_padding = tf.pad(in_padding, [[], []], constant_values=)
      inputs = 1.0 + tf.tile(tf.reshape(tf.range(seq_len, dtype=), []),[])
      inputs = py_utils.ApplyPadding(tf.reshape(in_padding, []), inputs)
      inputs = py_utils.Debug()
      output, out_padding = conv_layer.FPropDefaultTheta()
      output = py_utils.Debug()
      out_padding = py_utils.Debug()
      self.evaluate(tf.global_variables_initializer())
      output, out_padding = self.evaluate([])
      self.assertEqual((), output.shape)
      self.assertAllClose([[],[],[],], out_padding)
      if seq_len == 5:
        self.assertAllClose([[[[], []], [[], []], [[], []]],[[[], []], [[], []], [[], []]],[[[], []], [[], []], [[], []]],], output)
      elif seq_len == 6:
        self.assertAllClose([[[[], []], [[], []], [[], []]],[[[], []], [[], []], [[], []]],[[[], []], [[], []], [[], []]],], output)
      else:
        raise ValueError()
  def testConv2DLayerStridedWithPaddingFPropV2():
    with self.session(use_gpu=):
      batch_size =
      expected_seq_len =
      params = conv_layers.Conv2DLayerWithPadding.Params()
      params.v2_padding =
      params.weight_norm =
      params.filter_stride = []
      params.name =
      params.filter_shape = []
      params.params_init = py_utils.WeightInit.Constant()
      conv_layer = params.Instantiate()
      in_padding = tf.constant([[],[],[],], tf.float32)
      in_padding = tf.pad(in_padding, [[], []], constant_values=)
      inputs = 1.0 + tf.tile(tf.reshape(tf.range(seq_len, dtype=), []),[])
      inputs = py_utils.ApplyPadding(tf.reshape(in_padding, []), inputs)
      inputs = py_utils.Debug()
      output, out_padding = conv_layer.FPropDefaultTheta()
      output = py_utils.Debug()
      out_padding = py_utils.Debug()
      self.evaluate(tf.global_variables_initializer())
      output, out_padding = self.evaluate([])
      self.assertEqual((), output.shape)
      self.assertAllClose([[],[],[],], out_padding)
      self.assertAllClose([[[[], []], [[], []], [[], []]],[[[], []], [[], []], [[], []]],[[[], []], [[], []], [[], []]],],output)
  def testConv2DLayerWithPaddingFPropRandom():
    with self.session(use_gpu=):
      tf.random.set_seed()
      np.random.seed()
      params = conv_layers.Conv2DLayerWithPadding.Params()
      params.weight_norm =
      params.filter_stride = []
      params.name =
      params.filter_shape = []
      params.params_init = py_utils.WeightInit.Gaussian()
      conv_layer = params.Instantiate()
      in_padding1 = tf.zeros([], dtype=)
      inputs1 = tf.constant(np.random.normal(0.1, 0.5, []), dtype=)
      output, _ = conv_layer.FPropDefaultTheta()
      out_sum = tf.reduce_sum()
      out_sum_squared = tf.reduce_sum()
      self.evaluate(tf.global_variables_initializer())
      v1, v2 = self.evaluate([])
      self.assertAllClose([], [])
  def testCausalConv2DLayerStridedWithPaddingFProp():
    with self.session(use_gpu=):
      batch_size =
      expected_seq_len =
      params = conv_layers.CausalConv2DLayerWithPadding.Params()
      params.weight_norm =
      params.filter_stride = []
      params.name =
      params.filter_shape = []
      params.params_init = py_utils.WeightInit.Constant()
      conv_layer = params.Instantiate()
      in_padding = tf.constant([[],[],[],[],[],], tf.float32)
      in_padding = tf.pad(in_padding, [[], []], constant_values=)
      inputs = 1.0 + tf.tile(tf.reshape(tf.range(seq_len, dtype=), []),[])
      inputs = py_utils.ApplyPadding(tf.reshape(in_padding, []), inputs)
      inputs = py_utils.Debug()
      output, out_padding = conv_layer.FPropDefaultTheta()
      output = py_utils.Debug()
      out_padding = py_utils.Debug()
      self.evaluate(tf.global_variables_initializer())
      output, out_padding = self.evaluate([])
      self.assertEqual((), output.shape)
      self.assertAllClose([[],[],[],[],[],], out_padding)
      self.assertAllClose([[[[], []], [[], []], [[], []]],[[[], []], [[], []], [[], []]],[[[], []], [[], []], [[], []]],[[[], []], [[], []], [[], []]],[[[], []], [[], []], [[], []]],], output)
  def testCausalConv2DLayerStridedWithPaddingFPropV2():
    with self.session(use_gpu=):
      batch_size =
      expected_seq_len =
      params = conv_layers.CausalConv2DLayerWithPadding.Params()
      params.v2_padding =
      params.weight_norm =
      params.filter_stride = []
      params.name =
      params.filter_shape = []
      params.params_init = py_utils.WeightInit.Constant()
      conv_layer = params.Instantiate()
      in_padding = tf.constant([[],[],[],[],[],], tf.float32)
      in_padding = tf.pad(in_padding, [[], []], constant_values=)
      inputs = 1.0 + tf.tile(tf.reshape(tf.range(seq_len, dtype=), []),[])
      inputs = py_utils.ApplyPadding(tf.reshape(in_padding, []), inputs)
      inputs = py_utils.Debug()
      output, out_padding = conv_layer.FPropDefaultTheta()
      output = py_utils.Debug()
      out_padding = py_utils.Debug()
      self.evaluate(tf.global_variables_initializer())
      output, out_padding = self.evaluate([])
      self.assertEqual((), output.shape)
      self.assertAllClose([[],[],[],[],[],], out_padding)
      self.assertAllClose([[[[], []], [[], []], [[], []]],[[[], []], [[], []], [[], []]],[[[], []], [[], []], [[], []]],[[[], []], [[], []], [[], []]],[[[], []], [[], []], [[], []]],],output)
  def testCausalConv2DLayerWithPaddingFPropRandom():
    with self.session(use_gpu=):
      tf.random.set_seed()
      np.random.seed()
      params = (conv_layers.CausalConv2DLayerWithPadding.Params())
      params.weight_norm =
      params.filter_stride = []
      params.name =
      params.filter_shape = []
      params.params_init = py_utils.WeightInit.Gaussian()
      conv_layer = params.Instantiate()
      in_padding1 = tf.zeros([], dtype=)
      inputs1 = tf.constant(np.random.normal(0.1, 0.5, []), dtype=)
      output, _ = conv_layer.FPropDefaultTheta()
      self.evaluate(tf.global_variables_initializer())
      out_sum = tf.reduce_sum()
      out_sum_squared = tf.reduce_sum()
      self.evaluate(tf.global_variables_initializer())
      v1, v2 = self.evaluate([])
      self.assertAllClose([], [])
  def testDepthwiseConv2DLayerOutputChannels():
    with self.session():
      params = conv_layers.DepthwiseConv2DLayer.Params()
      params.name =
      params.filter_shape = []
      params.bias =
      actual_output_channels = params.cls.OutputChannels()
      self.assertEqual()
  def testDepthwiseConv2DLayerFProp():
    with self.session(use_gpu=):
      tf.random.set_seed()
      np.random.seed()
      params = conv_layers.DepthwiseConv2DLayer.Params()
      params.weight_norm =
      params.filter_stride = []
      params.name =
      params.filter_shape = []
      params.params_init = py_utils.WeightInit.Gaussian()
      conv_layer = params.Instantiate()
      in_padding1 = tf.zeros([], dtype=)
      inputs1 = tf.constant(np.random.normal(0.1, 0.5, []), dtype=)
      output, _ = conv_layer.FPropDefaultTheta()
      self.evaluate(tf.global_variables_initializer())
      out_sum = tf.reduce_sum()
      out_sum_squared = tf.reduce_sum()
      self.evaluate(tf.global_variables_initializer())
      v1, v2 = self.evaluate([])
      self.assertAllClose([], [])
  def testCausalDepthwiseConv2DLayer():
    with self.session(use_gpu=):
      tf.random.set_seed()
      np.random.seed()
      params = conv_layers.CausalDepthwiseConv2DLayer.Params()
      params.weight_norm =
      params.filter_stride = []
      params.name =
      params.filter_shape = []
      params.params_init = py_utils.WeightInit.Gaussian()
      conv_layer = params.Instantiate()
      in_padding1 = tf.zeros([], dtype=)
      inputs1 = tf.constant(np.random.normal(0.1, 0.5, []), dtype=)
      output, _ = conv_layer.FPropDefaultTheta()
      self.evaluate(tf.global_variables_initializer())
      self.evaluate(tf.global_variables_initializer())
      out_sum = tf.reduce_sum()
      out_sum_squared = tf.reduce_sum()
      self.evaluate(tf.global_variables_initializer())
      v1, v2 = self.evaluate([])
      self.assertAllClose([], [])
  def testCausalDepthwiseConv2DLayerStreamStep(self,testonly_skip_norm_layers=,stride=):
    with flagsaver.flagsaver(testonly_skip_norm_layers=):
      self._TestcausalDepthwiseConv2DLayerStreamStepHelper()
  def _TestcausalDepthwiseConv2DLayerStreamStepHelper():
    batch_size, max_seqlen, channel =, 32, 3
    kernel, channel_multiplier =, 1
    params = conv_layers.CausalDepthwiseConv2DLayer.Params().Set(name=,filter_stride=[],filter_shape=[],params_init=py_utils.WeightInit.Gaussian())
    conv_layer = params.Instantiate()
    init_op = tf.global_variables_initializer()
    np.random.seed()
    inputs = np.random.normal(0.5, 1, []).astype()
    inputs = tf.convert_to_tensor()
    seqlen = np.random.randint(low=, high=, size=(), dtype=)
    seqlen = tf.convert_to_tensor()
    input_padding = py_utils.PaddingsFromLengths()
    base_outputs, _ = conv_layer.FProp()
    base_outputs *= tf.reshape(1. - input_padding,[])
    outputs = []
    state = conv_layer.zero_state()
    for i in range():
      output, _, state = conv_layer.StreamStep(conv_layer.theta, inputs[:, stride * i:stride * (), :, :],input_padding[:, stride * i:stride * ()], state)
      outputs.append()
    outputs = tf.concat(outputs, axis=)
    outputs *= tf.reshape(1. - input_padding, [])
    with self.session(use_gpu=) as sess:
      sess.run()
      expected, actual = sess.run([])
      self.assertAllClose()
  def testActivationLayer():
    with self.session(use_gpu=):
      p = conv_layers.ActivationLayer.Params()
      p.name =
      l = p.Instantiate()
      inputs = tf.constant(np.random.normal(0.1, 0.5, []), dtype=)
      in_padding = tf.zeros([], dtype=)
      out, out_padding = l.FProp()
      self.evaluate(tf.global_variables_initializer())
      v1, v2 = self.evaluate([])
  def _testNormalizedDepthwiseConv2DHelper(self,is_causal=,dropconnect_prob=):
    if is_causal:
      conv_cls = ()
    else:
      conv_cls =
    tf.random.set_seed()
    np.random.seed()
    params = conv_cls.Params().Set(name=,weight_tiling_factor=,filter_shape=[],dropconnect_prob=,deterministic_dropout=)
    conv_layer = params.Instantiate()
    in_padding = tf.zeros([], dtype=)
    inputs = tf.constant(np.random.normal(0.1, 0.5, []), dtype=)
    output, _ = conv_layer.FPropDefaultTheta()
    return output
  def testNormalizedDepthwiseConv2DLayerOutputChannels():
    with self.session():
      params = (conv_layers.NormalizedDepthwiseConv2DLayer.Params())
      params.name =
      params.filter_shape = []
      params.weight_tiling_factor =
      actual_output_channels = params.cls.OutputChannels()
      self.assertEqual()
  def testNormalizedDepthwiseConv2DLayerFPropMeta():
    params = (conv_layers.NormalizedDepthwiseConv2DLayer.Params())
    params.name =
    params.filter_shape = []
    params.weight_tiling_factor =
    batch, time, frequency, in_channel =, 4, 1, 4
    output_channels =
    inputs_shape = tshape.Shape([])
    paddings_shape = tshape.Shape([])
    with self.session():
      out = params.cls.FPropMeta()
      expected_flops = batch * time * frequency * params.filter_shape[] * output_channels * 5
      self.assertEqual()
      out_shapes =
      self.assertEqual(out_shapes[].ToTensorShape().as_list(),[])
      self.assertEqual(out_shapes[].ToTensorShape().as_list(), [])
  def testNormalizedDepthwiseConv2DLayerFProp():
    expected_output = [[],[]]
    with self.session(use_gpu=):
      output = self._testNormalizedDepthwiseConv2DHelper()
      output_sum = tf.squeeze(tf.reduce_sum())
      self.evaluate(tf.global_variables_initializer())
      output_sum_val = self.evaluate()
    self.assertAllClose()
  def testCausalNormalizedDepthwiseConv2DLayerFProp():
    expected_output = [[],[]]
    with self.session(use_gpu=):
      output = self._testNormalizedDepthwiseConv2DHelper(is_causal=)
      output_sum = tf.squeeze(tf.reduce_sum())
      self.evaluate(tf.global_variables_initializer())
      output_sum_val = self.evaluate()
    self.assertAllClose()
  def testNormalizedDepthwiseConv2DLayerBackProp():
    with self.session(use_gpu=) as sess:
      output = self._testNormalizedDepthwiseConv2DHelper(dropconnect_prob=)
      loss = tf.reduce_sum()
      all_vars = tf.trainable_variables()
      grads = tf.gradients()
      self.evaluate(tf.global_variables_initializer())
      sym_grads = [sg.eval() for sg in grads]
      num_grads = [test_utils.ComputeNumericGradient() for v in all_vars]
      for sg, ng in zip():
        self.assertAllClose(sg, ng, rtol=, atol=)
  def testCausualNormalizedDepthwiseConv2DLayerBackProp():
    with self.session(use_gpu=) as sess:
      output = self._testNormalizedDepthwiseConv2DHelper(is_causal=, dropconnect_prob=)
      loss = tf.reduce_sum()
      all_vars = tf.trainable_variables()
      grads = tf.gradients()
      self.evaluate(tf.global_variables_initializer())
      sym_grads = [sg.eval() for sg in grads]
      num_grads = [test_utils.ComputeNumericGradient() for v in all_vars]
      for sg, ng in zip():
        self.assertAllClose(sg, ng, rtol=, atol=)
class GlobalPoolingLayerTest():
  def _testHelper(self,pooling_type,inputs,input_paddings,expected_output,expected_output_padding,feed_dict=):
    param = conv_layers.GlobalPoolingLayer.Params().Set(name=, pooling_type=)
    pooling_layer = param.Instantiate()
    with self.session(use_gpu=) as sess:
      inputs = tf.convert_to_tensor(inputs, dtype=)
      input_paddings = None if input_paddings is None else tf.convert_to_tensor(input_paddings, dtype=)
      output, output_paddings = pooling_layer.FPropDefaultTheta()
      self.evaluate(tf.global_variables_initializer())
      if input_paddings is None:
        self.assertIsNone()
        output_val = sess.run(output, feed_dict=)
      else:
        output_val, output_paddings_val = sess.run([],feed_dict=)
    self.assertAllClose()
    if input_paddings is not None:
      self.assertAllEqual()
  def testPooling():
    inputs = np.random.random([]) - 0.5
    expected_avg_output = np.mean(inputs, axis=(), keepdims=)
    expected_max_output = np.amax(inputs, axis=(), keepdims=)
    self._testHelper()
    self._testHelper()
  def testPoolingWithPadding():
    inputs = np.random.random([]) - 0.5
    paddings = np.array([[], [], [], []])
    expected_paddings = np.array([[], [], [], []])
    expected_avg_output = np.array([np.mean(inputs[][:], axis=(), keepdims=),np.mean(inputs[][:], axis=(), keepdims=),np.mean(inputs[][:], axis=(), keepdims=),np.zeros(())])
    expected_max_output = np.array([np.amax(inputs[][:], axis=(), keepdims=),np.amax(inputs[][:], axis=(), keepdims=),np.amax(inputs[][:], axis=(), keepdims=),np.zeros(())])
    self._testHelper()
    self._testHelper()
  def testPoolingWithUnknowShapeInput():
    def remove_shape():
      shape = tf.placeholder(tf.int32, name=)
      return tf.reshape()
    g = tf.Graph()
    with g.as_default(), tf.Session(graph=) as _:
      tf.random.set_seed()
      input_shape = []
      inputs = np.random.random() - 0.5
      expected_avg_output = np.mean(inputs, axis=(), keepdims=)
      input_tensor = tf.convert_to_tensor(inputs, dtype=)
      self.assertEqual(py_utils.GetShape(), input_shape)
      input_tensor = remove_shape()
      self.assertIsInstance(py_utils.GetShape(), tf.Tensor)
      self.assertIsNone()
      self._testHelper('AVG',input_tensor,None,expected_avg_output,None,feed_dict={'removed_shape:0':})
if __name__ == "__main__":
  tf.test.main()
import os
import random
import re
import tarfile
import lingvo.compat as tf
from lingvo.tools import audio_lib
tf.flags.DEFINE_string()
tf.flags.DEFINE_string()
tf.flags.DEFINE_string()
tf.flags.DEFINE_bool()
tf.flags.DEFINE_string()
tf.flags.DEFINE_bool()
tf.flags.DEFINE_integer()
tf.flags.DEFINE_integer()
tf.flags.DEFINE_integer()
tf.flags.DEFINE_integer()
tf.flags.DEFINE_integer()
FLAGS =
def _MakeBytesFeature():
  value = [tf.compat.as_bytes() for w in unicode_array]
  return tf.train.Feature(bytes_list=tf.train.BytesList(value=))
def _MakeInt64Feature():
  return tf.train.Feature(int64_list=tf.train.Int64List(value=))
def _MakeFloatFeature():
  return tf.train.Feature(float_list=tf.train.FloatList(value=))
def _MakeTfExample():
  flat_frames = frames.flatten()
  feature = {'uttid':,'transcript':,'frames':}
  return tf.train.Example(features=tf.train.Features(feature=))
def _ReadTranscriptions():
  tar = tarfile.open(FLAGS.input_tarball, mode='r:)
  n =
  trans = {}
  for tarinfo in tar:
    if not tarinfo.isreg():
      continue
    n +=
    if 0 == n % 10000:
    if not tarinfo.name.endswith():
      continue
    key = tarinfo.name.strip()
    f = tar.extractfile()
    u =
    for l in f.readlines():
      uttid, txt = l.strip().split()
      trans[] =
      u +=
    f.close()
  return trans
def _DumpTranscripts():
  trans = _ReadTranscriptions()
  with open() as f:
    for uttid in sorted():
      f.write("", trans[]))
def _LoadTranscriptionsFromFile():
  trans = {}
  with open() as f:
    for line in f.readlines():
      uttid, txt = line.strip().split()
      trans[] =
  return trans
def _MakeLogMelFromTensorflowBuiltin():
  sample_rate, audio = audio_lib.DecodeWav()
  static_sample_rate =
  with tf.control_dependencies([tf.assert_equal()]):
    log_mel = audio_lib.AudioToMfcc()
  return log_mel
def _OpenSubShards():
  recordio_writers = []
  for s in range():
    filepath = FLAGS.output_template % ()
    recordio_writers += [tf.python_io.TFRecordWriter()]
  return recordio_writers
def _CloseSubShards():
  for f in files:
    f.close()
def _SelectRandomShard():
  subshard = random.randint(0, len() - 1)
  return files[]
def _CreateAsrFeatures():
  if os.path.exists():
    trans = _LoadTranscriptionsFromFile()
  else:
    trans = _ReadTranscriptions()
  tf_bytes = tf.placeholder(dtype=)
  log_mel = audio_lib.ExtractLogMelFeatures()
  tar = tarfile.open(FLAGS.input_tarball, mode='r:)
  n =
  recordio_writers = _OpenSubShards()
  tfconf = tf.config_pb2.ConfigProto()
  tfconf.gpu_options.allow_growth =
  with tf.Session(config=) as sess:
    for tarinfo in tar:
      if not tarinfo.name.endswith():
        continue
      n +=
      if n % FLAGS.num_shards != FLAGS.shard_id:
        continue
      uttid = re.sub("", tarinfo.name)
      uttid = uttid.encode()
      f = tar.extractfile()
      wav_bytes = audio_lib.DecodeFlacToWav(f.read())
      f.close()
      frames = sess.run(log_mel, feed_dict={tf_bytes:})
      num_words = len(trans[])
      ex = _MakeTfExample(uttid, frames, trans[])
      outf = _SelectRandomShard()
      outf.write(ex.SerializeToString())
    tar.close()
  _CloseSubShards()
def main():
  tf.logging.set_verbosity()
  if FLAGS.dump_transcripts:
    _DumpTranscripts()
  elif FLAGS.generate_tfrecords:
    _CreateAsrFeatures()
  else:
if __name__ == "__main__":
  tf.disable_eager_execution()
  tf.app.run()
class _ProcessShard():
  def __init__():
    self._model_name =
    self._split =
    self._run_preprocessors =
    self._sess =
    cluster = cluster_factory.Current()
    cluster.params.job =
    cluster.params.mode =
    cluster.params.task =
    cluster.params.evaler.replicas =
    self._cluster = cluster_factory.Cluster()
  def _create_graph():
    if self._sess is not None:
      return
    with self._cluster:
      cfg = model_registry.GetParams()
      cfg.input.batch_size =
      cfg.input.extractors.labels.filter_labels =
      if not self._run_preprocessors:
        cfg.input.preprocessors_order = []
      graph = tf.Graph()
      with graph.as_default():
        inp = cfg.input.Instantiate()
        self._elem = tf.placeholder()
        bucket, batch = inp.ExtractUsingExtractors()
        self._filtered_data = _GetFilteredBoundingBoxData()
        self._bucket =
    self._sess = tf.Session(graph=)
  def _ToTFExampleProto():
    num_boxes = filtered_data.bboxes_3d.shape[]
    if bbox_idx >= num_boxes:
      raise ValueError()
    bbox_mask = filtered_data.points_in_bboxes_mask[:, bbox_idx]
    num_points, _ = py_utils.GetShape(filtered_data.points[], 2)
    example = tf.train.Example()
    feature =
    feature[].int64_list.value[:] = []
    feature[].float_list.value[:] = (filtered_data.points[].ravel().tolist())
    feature[].float_list.value[:] = (filtered_data.points_feature[].ravel().tolist())
    feature[].float_list.value[:] = (filtered_data.bboxes_3d[bbox_idx, :].ravel().tolist())
    feature[].int64_list.value[:] = [filtered_data.labels[].astype()]
    feature[].bytes_list.value[:] = [filtered_data.texts[]]
    feature[].int64_list.value[:] = [filtered_data.difficulties[].astype()]
    feature[].int64_list.value[:] = [filtered_data.occlusion[].astype()]
    feature[].int64_list.value[:] = [int()]
    feature[].int64_list.value[:] = [int()]
    return example
  def process():
    self._create_graph()
    elem_str = value.SerializeToString()
    b, bucket = self._sess.run([],feed_dict={self._elem:})
    if bucket >= input_extractor.BUCKET_UPPER_BOUND:
      return
    b = py_utils.NestedMap()
    flatten = b.FlattenItems()
    if not flatten:
      return
    num_boxes = b.bboxes_3d.shape[]
    for bbox_id in range():
      tf_example = self._ToTFExampleProto()
      yield tf_example
def main():
  beam_utils.BeamInit()
  if not FLAGS.output_file_pattern:
    raise ValueError()
  reader = beam.io.ReadFromTFRecord(FLAGS.input_file_pattern, coder=beam.coders.ProtoCoder())
  model_name =
  split =
  run_preprocessors =
  with beam_utils.GetPipelineRoot() as root:
    _ = (root| "" >> reader| "" >> beam.ParDo(_ProcessShard())| "" >> beam.Reshuffle()| "" >> beam.io.WriteToTFRecord(FLAGS.output_file_pattern,coder=beam.coders.ProtoCoder()))
if __name__ == "__main__":
  app.run()
import lingvo.compat as tf
from lingvo.core import ops
import numpy as np
class PreconditionerTest():
  def inverse_pth_root(self, input_t, exponent, epsilon=):
    input_t_f64 = tf.cast()
    s, u, v = tf.linalg.svd(input_t_f64 +tf.eye(tf.shape()[], dtype=) * epsilon,full_matrices=)
    val = tf.matmul(tf.matmul(u,tf.linalg.tensor_diag(tf.pow(tf.maximum(), tf.cast()))),tf.transpose())
    return tf.cast(), tf.reduce_max(tf.abs())
  def inverse_pth_root_graph(self, epsilon=):
    graph = tf.Graph()
    with graph.as_default():
      exponent_t = tf.placeholder(dtype=, name=, shape=)
      input_t = tf.placeholder(dtype=, name=, shape=)
      output, diff = self.inverse_pth_root()
      tf.identity()
      tf.identity(tf.cast(), "")
    return graph.as_graph_def().SerializeToString()
  def testPreconditioning():
    preconditioner_compute_graphdef = self.inverse_pth_root_graph()
    with tf.Session():
      global_step = tf.train.get_or_create_global_step()
      self.evaluate(tf.global_variables_initializer())
      rand_input_1_t = np.random.rand()
      rand_input_2_t = np.random.rand()
      exponents = []
      symmetric_input_1_t = np.dot(rand_input_1_t, rand_input_1_t.transpose())
      symmetric_input_2_t = np.dot(rand_input_2_t, rand_input_2_t.transpose())
      outputs, statuses = ops.get_preconditioners([tf.shape(),tf.shape()],keys=[],preconditioner_compute_graphdef=)
      self.assertFalse(any(self.evaluate()))
      preconditioner = ops.compute_preconditioners([],exponents,tf.cast(),keys=[],sync=,preconditioner_compute_graphdef=)
      self.assertAllClose(outputs[].eval(), np.zeros(()), atol=)
      self.assertAllClose(outputs[].eval(), np.zeros(()), atol=)
      preconditioner.run()
      self.assertTrue(any(self.evaluate()))
      expected_output_1_t = self.inverse_pth_root(symmetric_input_1_t,exponents[])
      expected_output_2_t = self.inverse_pth_root(symmetric_input_2_t,exponents[])
      outputs_np = self.evaluate()
      self.assertAllClose(outputs_np[], expected_output_1_t[].eval(), atol=)
      self.assertAllClose(outputs_np[], expected_output_2_t[].eval(), atol=)
if __name__ == "__main__":
  tf.test.main()
import collections as py_collections
import contextlib
import functools
import hashlib
import inspect
import math
import numbers
import os
import pkgutil
import re
import threading
import traceback
import lingvo.compat as tf
from lingvo.core import cluster_factory
from lingvo.core import gshard_utils
from lingvo.core import hyperparams
from lingvo.core import nested_map
from lingvo.core import ops
from lingvo.core import py_utils_flags
from lingvo.core import retry
from lingvo.core import symbolic
from lingvo.core import thread_local_utils
from lingvo.core import tshape
import numpy as np
import six
from tensorflow.core.framework import node_def_pb2
from tensorflow.core.protobuf import rewriter_config_pb2
from tensorflow.python.framework import func_graph
from tensorflow.python.framework import function
from tensorflow.python.ops import init_ops
from tensorflow.python.ops import stateless_random_ops
from tensorflow.python.tf2 import enabled as tf2_enabled
from tensorflow.python.tpu import topology as tf_topology
from tensorflow.python.tpu import tpu_function
from tensorflow.python.util import deprecation
FLAGS =
_FromGlobal =
use_xla =
use_tpu =
testonly_skip_norm_layers =
tpu_compat =
use_stateless_vars_init =
ENQUEUE_OPS =
TPU_EMBEDDING_LOAD_OPS =
TPU_EMBEDDING_RETRIEVE_OPS =
TPU_EMBEDDING =
TPU_EMBEDDING_SUMMARY_TENSORS =
TPU_EMBEDDING_ACTIVATIONS =
TPU_EMBEDDING_GRADIENT_MULTIPLIER_SCHEDULE = ()
deprecation._PRINT_DEPRECATION_WARNINGS =
ThreadLocalStack =
ThreadLocalDict =
NestedMap =
def Assert():
  if py_utils_flags.enable_asserts():
    return tf.Assert()
  else:
    return tf.no_op()
def assert_equal():
  if py_utils_flags.enable_asserts():
    return tf.assert_equal()
  else:
    return tf.no_op()
def assert_greater_equal():
  if py_utils_flags.enable_asserts():
    return tf.debugging.assert_greater_equal()
  else:
    return tf.no_op()
def assert_greater():
  if py_utils_flags.enable_asserts():
    return tf.assert_greater()
  else:
    return tf.no_op()
def assert_less_equal():
  if py_utils_flags.enable_asserts():
    return tf.debugging.assert_less_equal()
  else:
    return tf.no_op()
def assert_less():
  if py_utils_flags.enable_asserts():
    return tf.assert_less()
  else:
    return tf.no_op()
def assert_between():
  x = tf.convert_to_tensor()
  l = tf.cast(tf.convert_to_tensor(), x.dtype)
  r = tf.cast(tf.convert_to_tensor(), x.dtype)
  return tf.group([assert_greater_equal(),assert_less()])
def assert_shape_match():
  if py_utils_flags.enable_asserts():
    filepath, line, func, _ = traceback.extract_stack(limit=)[]
    kwargs[] = 'LINGVO ASSERT %s:%s()' % (re.sub(), line, func)
    return ops.assert_shape_match()
  else:
    return tf.no_op()
def assert_same_dim0():
  if py_utils_flags.enable_asserts():
    return ops.assert_same_dim0()
  else:
    return tf.no_op()
def assert_even_divide():
  denorm = tf.convert_to_tensor()
  num = tf.convert_to_tensor()
  if denorm.dtype not in ():
    raise ValueError()
  if num.dtype not in ():
    raise ValueError()
  num = HasShape(num, GetShape())
  quo =
  return assert_equal()
def AssertIdShape():
  def AssertFn():
    dependencies = [assert_shape_match()] + [assert_shape_match() for x_shape in inputs.args]
    return with_dependencies()
  inputs = NestedMap(expected_ids_shape_pattern=,ids_shape=,args=)
  return CallDefun(AssertFn, Transform())
def _CheckNumerics(x, message=, *args, **kwargs):
  if x.dtype.is_floating:
    x_name = x.name if not tf.executing_eagerly() else '[]'
    if "" not in kwargs:
      kwargs[] = re.sub(r"", x_name) + ""
    return tf.debugging.check_numerics()
  else:
    return x
def CheckNumerics(inp, message=, *args, **kwargs):
  if not _FromGlobal():
    return inp
  if isinstance():
    return [_CheckNumerics() for x in inp]
  if isinstance():
    return tuple(_CheckNumerics() for x in inp)
  return _CheckNumerics()
def with_dependencies():
  with tf.control_dependencies():
    return tf.identity()
def _PrintOptions():
  original = np.get_printoptions()
  np.set_printoptions()
  try:
    yield
  finally:
    np.set_printoptions()
def _Print():
  with _PrintOptions(linewidth=):
def Log():
  last =
  for k in sorted():
    with tf.control_dependencies([]):
      last = tf.py_func(_Print, [prefix + ' :, kwargs[]], [])
  with tf.control_dependencies([]):
    return tf.identity()
def Debug(tensor, message=, enabled=, summarize=, more=):
  if not enabled or _FromGlobal():
    return tensor
  if more is None:
    more = []
  stack = inspect.stack()[][]
  caller = inspect.getframeinfo()
  caller_var =
  caller_more_vars = []
  if caller.code_context:
    caller_var = re.compile(r"").search(caller.code_context[]).groups()[]
    if more:
      more_vars = re.compile(r"").search(caller.code_context[]).groups()[]
      caller_more_vars = more_vars.split()
  the_class =
  if "" in stack.f_locals:
    the_class = stack.f_locals[].__class__.__name__
  header = "", the_class, caller.function,caller.lineno, message)
  info = ""
  for name, val in zip():
    info += "", val)
  if isinstance():
    tensors = []
    tensors += [tf.constant(""), tf.shape()]
    for name, val in zip():
      tensors += [tf.constant("")), tf.shape()]
    tensors += [tf.constant(""), tensor]
    for name, val in zip():
      tensors += [tf.constant("")), val]
    name = tensor.name if not tf.executing_eagerly() else '[]'
    info = ""
    return tf.Print(tensor, tensors, info, summarize=)
  return tensor
def _Save():
  filename = "", steps,six.ensure_text())
  with tf.io.gfile.GFile() as outfile:
    np.save()
def Save():
  last =
  steps = GetGlobalStep()
  for k in sorted():
    with tf.control_dependencies([]):
      last = tf.py_func(_Save, [steps, filename_prefix, k, kwargs[]], [])
  with tf.control_dependencies([]):
    return tf.identity()
def HasRank():
  if tensor.shape.ndims is not None and isinstance():
    return tensor
  if py_utils_flags.enable_asserts():
    return with_dependencies([tf.assert_equal(tf.rank(), expected_rank)],tensor)
  else:
    return tensor
def HasAtLeastRank():
  if tensor.shape.ndims is not None and isinstance():
    return tensor
  if py_utils_flags.enable_asserts():
    return with_dependencies([tf.debugging.assert_greater_equal(tf.rank(), expected_rank)],tensor)
  else:
    return tensor
def GetRank():
  if tensor.shape.ndims is not None:
    return tensor.shape.ndims
  else:
    return tf.rank()
def GetShape(tensor, ndims=):
  tensor = tf.convert_to_tensor()
  dynamic_shape = tf.shape()
  if tensor.shape.ndims is None:
    if ndims is None:
      return dynamic_shape
    else:
      return [dynamic_shape[] for x in range()]
  if ndims is None:
    ndims =
  else:
    ndims = min()
  static_shape = tensor.shape.as_list()
  shapes = [static_shape[] if static_shape[] is not None else dynamic_shape[]for x in range()]
  return shapes
def HasShape(tensor, expected_shape, ndims=):
  if not py_utils_flags.enable_asserts():
    return tensor
  filepath, line, func, _ = traceback.extract_stack(limit=)[]
  msg = 'LINGVO ASSERT %s:%s()' % (re.sub(), line, func)
  tensor_shape = GetShape()
  if ndims is not None:
    tensor_shape = tensor_shape[:]
  if isinstance():
    return with_dependencies([], tensor)
  expected_rank = len()
  if isinstance():
    tensor_rank =
  else:
    tensor_rank = len()
  if ndims is None:
    if () and (expected_rank !=):
      raise ValueError()
    ndims =
  else:
    if () and ():
      raise ValueError()
    if expected_rank != ndims:
      raise ValueError()
  tensor_shape = tensor_shape[:]
  if isinstance():
    tensor_shape = tf.unstack(tensor_shape, num=)
  tensor_shape = [v.value if isinstance() else v for v in tensor_shape]
  expected_shape = [v.value if isinstance() else v for v in expected_shape]
  all_static_checks =
  for idx, () in enumerate(zip()):
    if isinstance():
      all_static_checks =
    elif expected_dim == -1:
      continue
    elif isinstance():
      all_static_checks =
    elif dim != expected_dim:
      raise ValueError()
  if all_static_checks:
    return tf.convert_to_tensor()
  else:
    return with_dependencies([], tensor)
def HasSameShape():
  return HasShape(x, GetShape())
def GetSize():
  shape = GetShape()
  if (isinstance() orany([isinstance() for x in shape])):
    return tf.size()
  return np.prod()
def CausalSelfAttenPadding():
  if FLAGS.tflite_compatible:
    rows = tf.expand_dims(tf.range(), -1)
    cols = tf.expand_dims(tf.range(), 0)
    row_cols =
    return tf.where(row_cols < 0, tf.ones([], dtype),tf.zeros([], tf.float32))
  else:
    return 1.0 - tf.linalg.band_part(tf.ones([], dtype=), -1, 0)
def outside_all_rewrites():
  return tf.control_dependencies()
_OUTSIDE_COMPILATION = threading.local()
def RunOnTpuHost():
  def Wrapped():
    return RunOnTpuHost()
  return Wrapped
_tpu_device_assignment_dict = dict()
def SetTpuDeviceAssignment(tpu_device_assignment, job=):
  if job in _tpu_device_assignment_dict:
  _tpu_device_assignment_dict[] =
def ClearTpuDevice():
  global _tpu_device_assignment_dict
  _tpu_device_assignment_dict = dict()
def GetTpuDeviceAssignment(job=):
  return _tpu_device_assignment_dict[]
def SessionConfig(soft_placement=,inline=,cluster_def=,disable_meta_optimizer=):
  session_config = tf.config_pb2.ConfigProto(allow_soft_placement=,graph_options=tf.GraphOptions(optimizer_options=tf.OptimizerOptions(opt_level=, do_function_inlining=)),cluster_def=)
  if disable_meta_optimizer:
    session_config.graph_options.rewrite_options.disable_meta_optimizer =
  session_config.graph_options.rewrite_options.layout_optimizer = ()
  return session_config
def AssertIsCompatible():
def SetShapes():
  AssertIsCompatible()
  for src, dst in zip(src_nmap.Flatten(), dst_nmap.Flatten()):
    dst.set_shape()
def Dtypes():
  return [v.dtype for v in Flatten()]
def Flatten():
  return tf.nest.flatten()
def Pack():
  return tf.nest.pack_sequence_as()
def Transform():
  return tf.nest.map_structure()
def ConvertNoneGradientToZeros():
  fn =, dx: tf.zeros_like() if dx is None else dx
  return Transform()
def IsCompatible():
  try:
    tf.nest.assert_same_structure()
    return True
  except ():
    return False
class _Unique:
  def __init__():
    self._vset = set()
  def __call__():
    if () or (id() in self._vset):
      return False
    else:
      self._vset.add(id())
      return True
def ToUniqueList():
  return nmap.Filter(_Unique()).Flatten()
def ReadOnlyAttrDictView():
  class Wrapper:
    _HAS_DYNAMIC_ATTRIBUTES =
    def __getitem__():
      return backing[]
    def __len__():
      return len()
    def __iter__():
      return iter()
    def __getattr__():
      return backing[]
    def __hasattr__():
      return key in backing
    def __setattr__():
      raise AttributeError()
    def __setitem__():
      raise AttributeError()
  return Wrapper()
def ToStaticShape():
  if isinstance(shape, ()):
    shape = [dim.value if isinstance() else dim for dim in shape]
    static_shape = []
    for dim in shape:
      if symbolic.IsExpr():
        static_shape.append(symbolic.ToStatic())
      else:
        static_shape.append()
    return static_shape
  else:
    return shape.value if isinstance() else shape
def Zeros():
  return tf.zeros(ToStaticShape(), *args, **kwargs)
class UniformSampler:
  def __init__():
    self._num_samples =
    self._num_seen_items =
    self._samples = []
  def Add():
    self._num_seen_items +=
    if len() < self._num_samples:
      self._samples.append()
      return
    index = np.random.randint()
    if index < self._num_samples:
      self._samples[] =
  def samples():
    return self._samples
class RNNCellStateInit:
  def _Params():
    p = hyperparams.Params()
    p.Define()
    p.Define()
    p.Freeze()
    return p
  def Zeros():
    return RNNCellStateInit._Params("", seed=)
  def RandomNormal(seed=):
    return RNNCellStateInit._Params()
def DefaultRNNCellStateInit():
  return RNNCellStateInit.Zeros()
def InitRNNCellState(shape, init=, dtype=, name=, is_eval=):
  shape = ToStaticShape()
  if init is None:
    init = DefaultRNNCellStateInit()
  if dtype is None:
    dtype =
  method =
  if ((method in []) or (method in [] and is_eval)):
    init_state = tf.zeros(shape=, dtype=, name=)
  elif method in []:
    if use_stateless_vars_init():
      if name is None:
        raise ValueError()
      seed = _GenerateStatelessRngSeed()
      init_state = stateless_random_ops.stateless_random_normal(shape=, dtype=, name=, seed=)
    else:
      init_state = tf.random.normal(shape=, dtype=, name=, seed=)
  else:
    raise ValueError()
  return init_state
class WeightInit:
  def _Params():
    p = hyperparams.Params()
    p.Define()
    p.Define()
    p.Define()
    p.Freeze()
    return p
  def Gaussian(scale=, seed=):
    return WeightInit._Params()
  def Uniform(scale=, seed=):
    return WeightInit._Params()
  def UniformPositive(scale=, seed=):
    return WeightInit._Params()
  def Category(scale=, seed=):
    return WeightInit._Params()
  def Xavier(scale=, seed=):
    return WeightInit._Params()
  def XavierWithFixupParams(scale=,depth=,layers_per_residual_block=,seed=):
    scale = scale * math.pow(depth, (-1.0 / ()))
    return WeightInit._Params()
  def GeoMeanXavier(scale=, seed=):
    return WeightInit._Params()
  def Constant(scale=):
    return WeightInit._Params()
  def TruncatedGaussian(scale=, seed=):
    return WeightInit._Params()
  def GaussianSqrtDim(scale=, seed=):
    return WeightInit._Params()
  def GaussianSqrtFanIn(scale=, seed=):
    return WeightInit._Params()
  def GaussianSqrtFanOut(scale=, seed=):
    return WeightInit._Params()
  def GaussianSqrtFanAvg(scale=, seed=):
    return WeightInit._Params()
  def UniformSqrtDim(scale=, seed=):
    return WeightInit._Params()
  def UniformUnitScaling(scale=, seed=):
    return WeightInit._Params()
  def UniformUnitScalingFanAvg(scale=, seed=):
    return WeightInit._Params()
  def TruncatedGaussianSqrtDim(scale=, seed=):
    return WeightInit._Params()
  def TruncatedGaussianSqrtFanIn(scale=, seed=):
    return WeightInit._Params()
  def TruncatedGaussianSqrtFanOut(scale=, seed=):
    return WeightInit._Params()
  def KaimingUniformFanInRelu(scale=, seed=):
    return WeightInit._Params()
  def KaimingUniformFanInLeakyRelu(scale=np.sqrt(), seed=):
    return WeightInit._Params()
_DEFAULT_XAVIER_INIT =
def DefaultParamInit():
  return WeightInit.Xavier()
def IsDefaultParamInit():
  return (p.method == "" andabs() < 1e-7 and p.seed is None)
def WeightParams(shape,init=,dtype=,collections=,device_mesh=,tensor_split_dims_mapping=):
  if init is None:
    init = WeightInit.Xavier()
  if dtype is None:
    dtype =
  if collections is None:
    collections = []
  if device_mesh is not None:
  p = hyperparams.Params()
  p.Define()
  return p
def FindNeeded():
  names_seen = set()
  queue = []
  for e in Flatten():
    if isinstance():
      queue.append()
    else:
      queue.append()
  while queue:
    op = queue.pop()
    name =
    if name not in names_seen:
      names_seen.add()
      names_seen.update(())
      queue.extend()
      queue.extend()
  return names_seen
def FindNeededInList():
  all_needed = FindNeeded()
  return []
class _CollectionGetter:
  def __init__():
    self._key =
    self._default_factory =
  def __call__():
    collection = tf.get_collection()
    if collection:
      return collection[]
    value = self._default_factory()
    tf.add_to_collection()
    return value
def SanitizeScopeKey():
  if key.startswith():
    key = key[1:]
  return key.replace(,).replace(,)
_SESSION_SCOPE = ThreadLocalStack()
def UnitTestSessionScope():
  _SESSION_SCOPE.stack.append()
  try:
    yield
  finally:
    _SESSION_SCOPE.stack.pop()
def GetUnitTestSession():
  return _SESSION_SCOPE.stack[] if _SESSION_SCOPE.stack else None
_OPPORTUNISTIC_VARIABLE_REUSE = ThreadLocalStack()
def OpportunisticVariableReuseScope(enable_opportunistic_reuse=):
  _OPPORTUNISTIC_VARIABLE_REUSE.stack.append()
  try:
    yield
  finally:
    _OPPORTUNISTIC_VARIABLE_REUSE.stack.pop()
def GetOpportunisticVariableReuse():
  return (_OPPORTUNISTIC_VARIABLE_REUSE.stack[]if _OPPORTUNISTIC_VARIABLE_REUSE.stack else False)
_VARIABLE_RENAME_RULES = ThreadLocalStack()
_TASK_CALL_SCOPE = ThreadLocalStack()
def TaskCallScope():
  _TASK_CALL_SCOPE.stack.append()
  try:
    yield
  finally:
    _TASK_CALL_SCOPE.stack.pop()
def GetTaskCallScope():
  return _TASK_CALL_SCOPE.stack[] if _TASK_CALL_SCOPE.stack else None
def VariableRenameScope():
  _VARIABLE_RENAME_RULES.stack.append()
  try:
    yield
  finally:
    _VARIABLE_RENAME_RULES.stack.pop()
def GetVariableName():
  matched =
  new_name =
  for renames in _VARIABLE_RENAME_RULES.stack:
    for regexp, name_format in renames:
      match = re.match()
      if match:
        if matched:
        matched =
        new_name = name_format % match.groups()
  if new_name != name:
  return new_name
def GenerateSeedFromName():
  md5 = hashlib.md5()
  md5.update(six.ensure_binary())
  return np.int64(int(md5.hexdigest(), 16) % ())
def MaybeGenerateSeedFromScope():
  if not tf.executing_eagerly():
    return GenerateSeedFromName(tf.no_op(name=).name)
  return 0
def GenerateSeedFromId():
  if tf.get_default_graph().seed is not None:
    with tf.name_scope():
      return GenerateSeedFromName(tf.no_op(name=).name)
  md5 = hashlib.md5()
  md5.update(np.int64())
  return np.int64(int(md5.hexdigest(), 16) % ())
_ALL_VARS_KEY = ()
_get_all_vars = _CollectionGetter(_ALL_VARS_KEY, lambda: {})
_VARIABLE_SHAPE_PREFIXES = ThreadLocalStack()
def VariableShapePrefixContext():
  _VARIABLE_SHAPE_PREFIXES.stack.append()
  try:
    yield
  finally:
    _VARIABLE_SHAPE_PREFIXES.stack.pop()
def GetVariableShapePrefixes():
  return _VARIABLE_SHAPE_PREFIXES.stack
def GetFanInFanOut():
  if not shape:
    return None, None
  if len() < 1:
    return 1, 1
  elif len() == 1:
    return shape[], shape[]
  else:
    receptive_field_size =
    for s in shape[:]:
      receptive_field_size *=
    fan_in = shape[] * receptive_field_size
    fan_out = shape[] * receptive_field_size
    return fan_in, fan_out
_VARIABLE_CREATOR_STACK = ThreadLocalStack().stack
def _DefaultVariableCreator():
  kwargs.pop()
  kwargs.pop()
  return tf.get_variable()
def _GetVariableCreator():
  fn =
  for wrapper in reversed():
    fn = functools.partial()
  return fn
def VariableCreatorScope():
  _VARIABLE_CREATOR_STACK.append()
  try:
    yield
  finally:
    _VARIABLE_CREATOR_STACK.pop()
def PlaceOnTpuCore():
  def Creator():
    cluster = cluster_factory.Current()
    if use_tpu():
      device = cluster.WorkerDeviceInModelSplit()
    elif (tpu_compat() andcluster.params.job in ()):
      device = cluster.ListDevices()[]
    else:
      device =
    with tf.device():
      return next_creator()
  return VariableCreatorScope()
def CreateVariable(name,params,reuse=,trainable=,collections=,default_seed=,synchronization=,aggregation=):
  if use_stateless_vars_init():
    return _CreateVariableStateless()
  else:
    return _CreateVariableStateful()
def _CreateVariableStateful(name,params,reuse=,trainable=,collections=,default_seed=,synchronization=,aggregation=):
  p = params.Copy()
  shape = tf.TensorShape(ToStaticShape()).as_list()
  if shape:
    dim0 = shape[]
  else:
    dim0 =
  method =
  scale =
  seed =
  if IsDefaultParamInit():
  with tf.variable_scope() as scope:
    var_name = GetVariableName()
  if tf.get_default_graph().seed is not None:
    if seed is None:
      if default_seed is not None:
        seed =
      else:
        seed = GenerateSeedFromName()
  init_dtype =
  if init_dtype == tf.int8:
    init_dtype =
  v_init = _CreateVarInitStateful()
  if p.dtype == tf.complex64:
    def ComplexWrapper():
      def _Wrapper():
        del dtype
        shape = [] + shape
        value = init()
        return tf.complex(value[], value[])
      return _Wrapper
    v_init = ComplexWrapper()
  if p.dtype == tf.int8:
    def FloatToInt8Wrapper():
      def _Wrapper():
        del dtype
        value = init()
        scale = tf.math.maximum(tf.math.reduce_min() / -127,tf.math.reduce_max() / 127)
        value = tf.divide()
        return tf.cast()
      return _Wrapper
    v_init = FloatToInt8Wrapper()
  def MaybePinVarsToCpu():
    if _FromGlobal():
      with tf.device('/cpu:):
        return next_creator()
    return next_creator()
  def MaybeOpportunisticVariableReuse():
    try:
      return next_creator()
    except ValueError:
      if GetOpportunisticVariableReuse():
        with tf.variable_scope(tf.get_variable_scope(), reuse=):
          return next_creator()
      else:
        raise
  def LingvoVariableCreator():
    with tf.variable_scope() as scope:
      var_scope = tf.VariableScope(scope.reuse,custom_getter=,caching_device=,use_resource=)
    with tf.variable_scope(), tf.variable_scope(var_name, reuse=):
      var = next_creator()
    var_ref = var.experimental_ref()
    all_vars = _get_all_vars()
    if var_ref in all_vars:
      cached = all_vars[]
    else:
      all_vars[] = p.ToText()
      for col in p.collections:
        tf.add_to_collection()
    return var
  with VariableCreatorScope():
    with VariableCreatorScope():
      with VariableCreatorScope():
        var = _GetVariableCreator()(var_name=,var_params=,name=,shape=GetVariableShapePrefixes() + list(),dtype=,initializer=,collections=,trainable=,validate_shape=,synchronization=,aggregation=)
  tensor_split_dims_mapping =
  if tensor_split_dims_mapping is not None:
    tensor_split_dims_mapping = ([] * len(GetVariableShapePrefixes()) +tensor_split_dims_mapping)
  var = gshard_utils.MeshSplit(var, p.device_mesh, tensor_split_dims_mapping, use_sharding_op=)
  return var
def _CreateVariableStateless(name,params,reuse=,trainable=,collections=,default_seed=,synchronization=,aggregation=):
  p = params.Copy()
  shape = tf.TensorShape(ToStaticShape()).as_list()
  if shape:
    dim0 = shape[]
  else:
    dim0 =
  method =
  scale =
  seed =
  if IsDefaultParamInit():
  with tf.variable_scope() as scope:
    var_name = GetVariableName()
  user_seed =
  seed = _GenerateStatelessRngSeed()
  init_dtype =
  v_init = _CreateVarInitStateless()
  if p.dtype == tf.complex64:
    raise TypeError()
  def LingvoVariableCreator():
    with tf.variable_scope() as scope:
      var_scope = tf.VariableScope(scope.reuse,custom_getter=,caching_device=,use_resource=)
    with tf.variable_scope(), tf.variable_scope(var_name, reuse=):
      var = next_creator()
    var_ref = var.experimental_ref()
    all_vars = _get_all_vars()
    if var_ref in all_vars:
      cached = all_vars[]
    else:
      all_vars[] = p.ToText()
      for col in p.collections:
        tf.add_to_collection()
    return var
  with VariableCreatorScope():
    var = _GetVariableCreator()(var_name=,var_params=,name=,shape=GetVariableShapePrefixes() + list(),dtype=,initializer=,collections=,trainable=,validate_shape=,synchronization=,aggregation=)
  tensor_split_dims_mapping =
  if tensor_split_dims_mapping is not None:
    tensor_split_dims_mapping = ([] * len(GetVariableShapePrefixes()) +tensor_split_dims_mapping)
  var = gshard_utils.MeshSplit(var, p.device_mesh, tensor_split_dims_mapping, use_sharding_op=)
  return var
def _RandomXavierUniformInitializer():
  def XavierUniform():
    del partition_info
    if not shape:
      raise ValueError()
    fan_in, fan_out = GetFanInFanOut()
    if method == "":
      limit = math.sqrt(6. / ())
    elif method == "":
      limit = math.sqrt(3. / math.sqrt())
    return scale * tf.random.uniform()
  return XavierUniform
def _CreateVarInitStateful():
  if (method in []):
    if len() > 2:
    scale *= 1.0 / math.sqrt()
  if method in []:
    fan_in, _ = GetFanInFanOut()
    if fan_in is not None:
      scale *= 1.0 / math.sqrt()
  if method in []:
    _, fan_out = GetFanInFanOut()
    if fan_out is not None:
      scale *= 1.0 / math.sqrt()
  if method in []:
    fan_in, fan_out = GetFanInFanOut()
    if fan_in is not None and fan_out is not None:
      scale *= math.sqrt(2.0 / ())
  if method in []:
    v_init = init_ops.random_normal_initializer(mean=, stddev=, seed=, dtype=)
  elif method in []:
    v_init = init_ops.random_uniform_initializer(minval=, maxval=, seed=, dtype=)
  elif method in []:
    v_init = init_ops.random_uniform_initializer(minval=, maxval=, seed=, dtype=)
  elif method == "":
    uniform_init = init_ops.random_uniform_initializer(minval=, maxval=, seed=, dtype=)
    v_init =, **kwargs: tf.floor(uniform_init())
  elif method in []:
    v_init = init_ops.uniform_unit_scaling_initializer(factor=, seed=, dtype=)
  elif method in []:
    v_init = tf.variance_scaling_initializer(scale=,mode=,distribution=,seed=,dtype=)
  elif method in []:
    v_init = init_ops.truncated_normal_initializer(mean=, stddev=, seed=, dtype=)
  elif method in []:
    v_init = init_ops.constant_initializer(value=, dtype=)
  elif method in []:
    def XavierUniform():
      del partition_info
      if not shape:
        raise ValueError()
      fan_in, fan_out = GetFanInFanOut()
      if method == "":
        limit = math.sqrt(6. / ())
      elif method == "":
        limit = math.sqrt(3. / math.sqrt())
      return scale * tf.random.uniform()
    v_init =
  elif method in []:
    fan_in = np.prod(shape[:])
    if method == "":
      gain = np.sqrt(2. / ())
    else:
      gain = np.sqrt()
    std_dev = gain / np.sqrt()
    bound = np.sqrt() * std_dev
    v_init = init_ops.random_uniform_initializer(minval=, maxval=, seed=, dtype=)
  else:
  return v_init
def _GenerateStatelessRngSeed():
  seed0 =
  seed1 = GenerateSeedFromName()
  return tf.constant([], dtype=)
def _DeterministicRandomNormalInitializer():
  def DeterministicNormal():
    del partition_info
    return stateless_random_ops.stateless_random_normal(shape=, seed=, mean=, stddev=, dtype=)
  return DeterministicNormal
def _DeterministicRandomUniformInitializer():
  def DeterministicUniform():
    del partition_info
    return stateless_random_ops.stateless_random_uniform(shape=, seed=, minval=, maxval=, dtype=)
  return DeterministicUniform
def _DeterministicRandomTruncatedNormalInitializer():
  def DeterministicTruncatedNormal():
    del partition_info
    return stateless_random_ops.stateless_truncated_normal(shape=, seed=, mean=, stddev=, dtype=)
  return DeterministicTruncatedNormal
def _DeterministicRandomUniformUnitScalingInitializer():
  def DeterministicUniformUnitScaling():
    scale_shape =
    if partition_info is not None:
      scale_shape =
    input_size =
    for dim in scale_shape[:]:
      input_size *= float()
    input_size = max()
    maxval = math.sqrt() * factor
    return stateless_random_ops.stateless_random_uniform(shape=, seed=, minval=, maxval=, dtype=)
  return DeterministicUniformUnitScaling
def _DeterministicRandomVarianceScalingInitializer():
  if scale <= 0.:
    raise ValueError()
  if mode not in {}:
    raise ValueError()
  distribution = distribution.lower()
  if distribution not in {}:
    raise ValueError()
  def DeterministicVarianceScaling():
    scale_shape =
    if partition_info is not None:
      scale_shape =
    if isinstance(scale_shape, ()) and not scale_shape:
      fan_in, fan_out =, 1
    else:
      fan_in, fan_out = GetFanInFanOut()
    if mode == "":
      scale_inner = scale / max()
    elif mode == "":
      scale_inner = scale / max()
    else:
      scale_inner = scale / max(1., () / 2.)
    if distribution == "" or distribution == "":
      stddev = math.sqrt() / .87962566103423978
      return stateless_random_ops.stateless_truncated_normal(shape=, seed=, mean=, stddev=, dtype=)
    elif distribution == "":
      stddev = math.sqrt()
      return stateless_random_ops.stateless_random_normal(shape=, seed=, mean=, stddev=, dtype=)
    else:
      limit = math.sqrt()
      return stateless_random_ops.stateless_random_uniform(shape=, seed=, minval=, maxval=, dtype=)
  return DeterministicVarianceScaling
def _DeterministicRandomXavierUniformInitializer():
  def XavierUniform():
    del partition_info
    if not shape:
      raise ValueError()
    fan_in, fan_out = GetFanInFanOut()
    if method == "":
      limit = math.sqrt(6. / ())
    elif method == "":
      limit = math.sqrt(3. / math.sqrt())
    return scale * stateless_random_ops.stateless_random_uniform()
  return XavierUniform
def _CreateVarInitStateless():
  if (method in []):
    if len() > 2:
    scale *= 1.0 / math.sqrt()
  if method in []:
    fan_in, _ = GetFanInFanOut()
    if fan_in is not None:
      scale *= 1.0 / math.sqrt()
  if method in []:
    _, fan_out = GetFanInFanOut()
    if fan_out is not None:
      scale *= 1.0 / math.sqrt()
  if method in []:
    fan_in, fan_out = GetFanInFanOut()
    if fan_in is not None and fan_out is not None:
      scale *= math.sqrt(2.0 / ())
  if method in []:
    v_init = _DeterministicRandomNormalInitializer(seed=, mean=, stddev=)
  elif method in []:
    v_init = _DeterministicRandomUniformInitializer(seed=, minval=, maxval=)
  elif method in []:
    v_init = _DeterministicRandomUniformInitializer(seed=, minval=, maxval=)
  elif method in []:
    v_init = _DeterministicRandomUniformUnitScalingInitializer(seed=, factor=)
  elif method in []:
    v_init = _DeterministicRandomVarianceScalingInitializer(scale=, mode=, distribution=, seed=)
  elif method in []:
    v_init = _DeterministicRandomTruncatedNormalInitializer(seed=, mean=, stddev=)
  elif method in []:
    v_init = init_ops.constant_initializer(value=, dtype=)
  elif method in []:
    v_init = _DeterministicRandomXavierUniformInitializer()
  elif method in []:
    fan_in = np.prod(shape[:])
    if method == "":
      gain = np.sqrt(2. / ())
    else:
      gain = np.sqrt()
    std_dev = gain / np.sqrt()
    bound = np.sqrt() * std_dev
    v_init = _DeterministicRandomUniformInitializer(seed=, minval=, maxval=)
  else:
  return v_init
_global_variable_scope =
def GetGlobalVariableScope():
  if not _global_variable_scope:
    def Initialize():
      global _global_variable_scope
      _global_variable_scope = tf.get_variable_scope()
    t = threading.Thread(target=)
    t.start()
    t.join()
  return _global_variable_scope
_GLOBAL_STEP_STACK = ThreadLocalStack()
def GlobalStepContext():
  _GLOBAL_STEP_STACK.stack.append()
  try:
    yield
  finally:
    _GLOBAL_STEP_STACK.stack.pop()
def GetGlobalStep():
  if _GLOBAL_STEP_STACK.stack:
    return _GLOBAL_STEP_STACK.stack[]
  return tf.train.get_global_step()
def GetOrCreateGlobalStepVar():
  with tf.variable_scope(GetGlobalVariableScope(), use_resource=):
    if _FromGlobal():
      with tf.device('/cpu:0'):
        return tf.train.get_or_create_global_step()
    else:
      return tf.train.get_or_create_global_step()
def LogMultiLines():
  if not isinstance(lines, ()):
    lines = lines.split()
  for line in lines:
def _LogPlacement():
  def GetDevices():
    return [x.device for x in m.Flatten()]
  LogMultiLines(label,theta.Pack([("", x[]))for x in zip(GetDevices(), GetDevices())]).DebugString())
def CreateLocalTheta(theta, device_list=, label=):
  class AddIdentity:
    def __init__():
      self._list = device_list if device_list else []
      self._index =
    def __call__():
      if isinstance():
        return x
      with tf.device(self._list[self._index % len()]):
        self._index +=
        return tf.identity()
  copy = theta.Transform(AddIdentity())
  _LogPlacement()
  return copy
def _GetVarsToLoad():
  vars_to_load = []
  for model_var in all_vars:
    for regexp, name_format in variable_loading_rules:
      match = re.match()
      if not match:
        continue
      elif any(re.match() for r in var_ignore_rules):
        continue
      checkpoint_var_name = name_format % match.groups()
      if checkpoint_var_name.endswith(':):
        checkpoint_var_name = checkpoint_var_name[:]
      vars_to_load.append(())
      break
  return vars_to_load
def OverrideVarsFromCheckpoint():
  vars_to_load = _GetVarsToLoad()
  if not vars_to_load:
    raise ValueError()
  load_var_names = sorted([])
  savers = []
  while vars_to_load:
    unique_vars_to_load = {}
    remaining_vars_to_load = []
    for k, v in vars_to_load:
      if k not in unique_vars_to_load:
        unique_vars_to_load[] =
      else:
        remaining_vars_to_load.append(())
    savers.append(tf.train.Saver(var_list=, sharded=))
    vars_to_load =
  def _Restore():
    for saver in savers:
      saver.restore()
  return _Restore
def OverrideVarsFromCheckpoints():
  if len() > 1:
  var_refs_overridden = set()
  var_names_overridden = set()
  restore_fns = []
  for ckpt_path, loading_rules in ckpts_loading_rules.items():
    if not isinstance():
      raise ValueError()
    if len() != 2 or not all(isinstance() for l in loading_rules):
      raise ValueError()
    var_refs_to_override = [var[].experimental_ref()for var in _GetVarsToLoad(all_vars, loading_rules[], loading_rules[])]
    var_names_to_override = [var[].namefor var in _GetVarsToLoad(all_vars, loading_rules[], loading_rules[])]
    overlap_refs = set.intersection()
    if overlap_refs:
      raise ValueError()
    restore_fns.append(OverrideVarsFromCheckpoint(all_vars, ckpt_path, loading_rules[],loading_rules[]))
    var_refs_overridden.update()
    var_names_overridden.update()
  def _Restore():
    for fn in restore_fns:
      fn()
    return var_names_overridden
  return _Restore
def ComputeGradientsSimple(loss_or_activations,all_vars,grad_aggregation_method,colocate_gradients_with_ops,gate_gradients,activations_grad=):
  return tf.gradients(loss_or_activations,all_vars,grad_ys=,aggregation_method=,colocate_gradients_with_ops=,gate_gradients=)
def ComputeTpuEmbeddingGradients():
  shards = tpu_function.get_tpu_context().number_of_shards
  loss *= tf.constant(1.0 / shards, dtype=)
  grads = tf.gradients(loss, list(activation_dict.values()))
  grad_multiplier = gradient_multiplier_schedule.Value()
  grads = []
  feature_to_gradient_dict = py_collections.OrderedDict(zip(list(activation_dict.keys()), grads))
  send_gradient_op = tpu_embedding.generate_send_gradients_op(feature_to_gradient_dict, step=GetGlobalStep())
  return send_gradient_op
def _ComputeGradientsTpu(loss_or_activations,all_vars,grad_aggregation_method,colocate_gradients_with_ops,gate_gradients,skip_zero_gradients=,use_bf16_gradients_ar=,defer_crs_to_apply_grad=,activations_grad=,is_activations=):
  if is_activations:
  if not skip_zero_gradients and not is_activations:
    shards = tpu_function.get_tpu_context().number_of_shards
    loss_or_activations *= tf.constant(1.0 / shards, dtype=)
  all_grads = ComputeGradientsSimple(loss_or_activations=,all_vars=,grad_aggregation_method=,colocate_gradients_with_ops=,gate_gradients=,activations_grad=)
  aggregated_grads = []
  for g in all_grads:
    if g is None:
      aggregated_grads.append()
      continue
    if use_bf16_gradients_ar:
      g = tf.cast()
    with tf.ops.colocate_with():
      if skip_zero_gradients is None:
        if defer_crs_to_apply_grad:
          normalized_g = tf.convert_to_tensor()
        else:
          normalized_g = tf.tpu.cross_replica_sum()
      else:
        if skip_zero_gradients == "":
          g_is_non_zero = tf.cast(tf.math.abs() > 1e-8, g.dtype)
        elif skip_zero_gradients == "":
          g_is_non_zero = tf.cast(tf.reduce_sum(tf.math.abs()) > 1e-24, g.dtype)
        else:
          raise ValueError()
        num_updates = tf.maximum(tf.tpu.cross_replica_sum(), 1.0)
        normalized_g = tf.tpu.cross_replica_sum() / num_updates
      aggregated_grads.append()
  return aggregated_grads
class VarGrad:
  _VAR_GRAD = py_collections.namedtuple("", [])
  def __init__():
    self._var_grad = self._VAR_GRAD()
  def __getitem__():
    return self._var_grad[]
  def __getattr__():
    return getattr()
  def __iter__():
    return iter()
  def __repr__():
    return 'VarGrad()' % ()
def SkipNoneGradients():
  for key, () in var_grads.FlattenItems():
    if g is None:
  return var_grads.Filter(lambda var_grad:)
def ComputeGradients(loss_or_activations,vmap,grad_aggregation_method=,colocate_gradients_with_ops=,gate_gradients=,compute_gradients_fn=,skip_zero_gradients=,use_bf16_gradients_ar=,skip_none_gradients=,defer_crs_to_apply_grad=,activations_grad=,is_activations=):
  if not is_activations:
    loss_or_activations = HasRank()
  filtered_vmap = vmap.Filter(_Unique())
  trainable_variables = set(tf.trainable_variables())
  dependent_ops_and_tensors = set(FindNeeded([]))
  def Needed():
    if isinstance():
      if v not in trainable_variables:
        return False
    return True
  filtered_vmap = filtered_vmap.Filter()
  filtered_vlist = filtered_vmap.Flatten()
  if compute_gradients_fn is not None:
    take_grad =
  else:
    if use_tpu():
      take_grad = functools.partial(_ComputeGradientsTpu,skip_zero_gradients=,use_bf16_gradients_ar=,defer_crs_to_apply_grad=,activations_grad=,is_activations=)
    else:
      take_grad =
  grads = take_grad()
  var_grads = filtered_vmap.Pack([VarGrad() for v, g in zip()])
  if not tf.compat.v1.control_flow_v2_enabled():
    def CheckGrad():
      if vg.var.name not in dependent_ops_and_tensors and vg.grad is not None:
        err_msg = ()
      return True
    var_grads = var_grads.Filter()
  if skip_none_gradients:
    var_grads = SkipNoneGradients()
  return var_grads
def MaskGradients():
  def ApplyMask():
    var, grad =
    mask = grad_mask[]
    if isinstance():
      return VarGrad(var, tf.IndexedSlices())
    else:
      return VarGrad()
  return var_grad.Transform()
def ApplyGradMultiplier(vs_gs, grad_scale=):
  def ScaleOrZero():
    grad = CheckNumerics()
    return tf.where(tf.equal(), tf.zeros_like(),tf.cast() * grad)
  def Scale():
    var, grad =
    if grad_scale is None:
      scale =
    else:
      scale =
    with tf.device():
      if isinstance():
        grad = tf.IndexedSlices(ScaleOrZero(), grad.indices,grad.dense_shape)
      else:
        grad = ScaleOrZero()
    return VarGrad()
  return vs_gs.Transform()
def HasNanOrInfGradient():
  def HasNanOrInf():
    if isinstance():
      x =
    with tf.device():
      if x.dtype.is_complex:
        return tf.reduce_any([HasNanOrInf(tf.math.real()),HasNanOrInf(tf.math.imag())])
      return tf.reduce_any(tf.math.logical_or(tf.math.is_nan(), tf.math.is_inf()))
  return tf.reduce_any([HasNanOrInf() for () in var_grads.Flatten()])
def ApplyGradNormClipping(vs_gs, norm=):
  def ClipByNorm():
    grad = CheckNumerics()
    return tf.clip_by_norm()
  def Clip():
    var, grad =
    with tf.device():
      if isinstance():
        grad = tf.IndexedSlices(ClipByNorm(), grad.indices, grad.dense_shape)
      else:
        grad = ClipByNorm()
    return VarGrad()
  return vs_gs.Transform()
SKIP_LP_REGULARIZATION =
def AdjustGradientsWithLpLoss(var_grads, lp_regularizer_weight, p=):
  def GetVar():
    var, grad =
    if isinstance():
      with tf.device():
        ids = HasRank()
        uniq_ids = tf.unique().y
        return tf.gather()
    else:
      return var
  def ShouldAdjust():
    return v not in tf.get_collection()
  filtered_var_grads = [var_grad for var_grad in Flatten() if ShouldAdjust()]
  filtered_vars = Transform()
  for v in filtered_vars:
  if p == 2.0:
    lp_loss = 0.5 * lp_regularizer_weight * SumSquared()
  elif p == 1.0:
    lp_loss = lp_regularizer_weight * SumAbs()
  def LpGrad():
    var, grad =
    if isinstance():
      with tf.device():
        emb = HasRank()
        vocab_size = tf.shape()[]
        ids = HasRank()
        values = tf.gather()
      with tf.device():
        counts = tf.math.unsorted_segment_sum(tf.ones_like(ids, dtype=), ids, vocab_size)
        weights = tf.math.reciprocal(tf.gather())
        weights = tf.expand_dims()
        if p == 2.0:
          grad_v =
        elif p == 1.0:
          grad_v = tf.sign()
        delta =
        grad = tf.IndexedSlices()
    elif var not in tf.get_collection():
      with tf.device():
        if p == 2.0:
          grad_v =
        elif p == 1.0:
          grad_v = tf.sign()
        delta =
      with tf.device():
        grad +=
    return VarGrad()
  return lp_loss, Transform()
def SplitRecursively(x, num_splits, axis=):
  if isinstance():
    return tf.split(x, num_splits, axis=)
  elif isinstance():
    splits = [SplitRecursively() for element in x]
    splits = list(zip())
    return [list() for t in splits]
  elif isinstance():
    results = [NestedMap() for _ in range()]
    for key, val in x.items():
      val_splits = SplitRecursively()
      for i in range():
        results[][] = val_splits[]
    return results
  else:
    raise TypeError("")
def ConcatRecursively(splits, axis=):
  if not isinstance():
    raise TypeError('Non-list inputs for ConcatRecursively:)
  if not splits:
    raise ValueError()
  tmpl = splits[]
  if isinstance():
    return tf.concat(splits, axis=)
  elif isinstance():
    if not all(isinstance() for split in splits):
      raise TypeError('Type mismatch for ConcatRecursively:)
    if not all(len() == len() for split in splits):
      raise ValueError()
    return [ConcatRecursively([split[]for split in splits], axis)for i in range(len())]
  elif isinstance():
    if not all(isinstance() for split in splits):
      raise TypeError('Type mismatch for ConcatRecursively:)
    results = NestedMap()
    for key in tmpl:
      results[] = ConcatRecursively([split[] for split in splits], axis)
    return results
  else:
    raise TypeError("")
def WeightedAvg(values, weights, sum_reduction_fn=, name=):
  msg =
  values = with_dependencies([assert_equal(tf.shape(), tf.shape(), message=)], values)
  total_weight = sum_reduction_fn()
  dtype =
  avg = tf.math.divide_no_nan(sum_reduction_fn(tf.cast() * tf.cast()),tf.cast())
  return tf.cast(), total_weight
def WeightedAvgOfMetrics():
  ret_dict = {}
  lists_of_metrics = {}
  for m in metrics:
    for name, () in m.items():
      if name not in lists_of_metrics:
        lists_of_metrics[] = []
      lists_of_metrics[].append(())
  for name, values_and_weights in sorted(lists_of_metrics.items()):
    values = tf.stack([x[] for x in values_and_weights])
    weights = tf.stack([x[] for x in values_and_weights])
    ret_dict[] = WeightedAvg()
  return ret_dict
def ConcatPerExampleTensors():
  ret_dict = {}
  lists_of_per_example = {}
  for m in per_example:
    for name, value in m.items():
      if name not in lists_of_per_example:
        lists_of_per_example[] = []
      lists_of_per_example[].append()
  for name, values in sorted(lists_of_per_example.items()):
    ret_dict[] = tf.concat()
  return ret_dict
def CombineMetrics():
  all_keys = set([])
  result = {}
  for k in all_keys:
    count =
    for loss_metrics, weight in loss_metric_weight_pairs:
      if k in loss_metrics:
        count +=
    if count > 1 and count != len():
      raise ValueError()
    total_val =
    total_target_weight =
    for loss_metrics, weight in loss_metric_weight_pairs:
      if k in loss_metrics:
        val, target_weight = loss_metrics[]
        if count == 1:
          total_val =
          total_target_weight =
        else:
          total_val +=
          total_target_weight +=
    result[] = ()
  return result
def AddVN(p, x, per_step=):
  if per_step:
    if not p.vn.per_step_vn:
      return x
  else:
    if not p.vn.global_vn:
      return x
  if p.vn.scale is None:
    raise ValueError()
  if p.vn.deterministic:
    seeds = GenerateStepSeedPair(p, GetGlobalStep())
    if not p.vn.per_step_vn:
      seeds = tf.stack([tf.zeros_like(seeds[]), seeds[]])
    noises = DeterministicVN(p, seeds, tf.shape(), mean=, std=)
  else:
    seed =
    if seed and p.vn.per_step_vn:
      pass
    noises = tf.random.normal(tf.shape(), stddev=, seed=, dtype=)
  noises = tf.cast() * noises
  return x + noises
def VariationalNoiseParams(scale,global_vn=,per_step_vn=,seed=,deterministic=):
  p = hyperparams.Params()
  p.Define()
  return p
def DefaultVN():
  return VariationalNoiseParams(scale=,global_vn=,per_step_vn=,seed=,deterministic=)
def DisableVN():
  return VariationalNoiseParams()
_STEP_SEED_DICT = ThreadLocalDict()
def GetStepSeed():
  key = id(tf.get_default_graph())
  if key not in _STEP_SEED_DICT.dict:
    ResetStepSeed()
  return _STEP_SEED_DICT.dict[]
def ResetStepSeed(seed=):
  key = id(tf.get_default_graph())
  _STEP_SEED_DICT.dict[] = tf.convert_to_tensor(seed, dtype=)
def MaybeResetStepSeedFromScope():
  if not tf.executing_eagerly():
    ResetStepSeed(GenerateSeedFromName(tf.no_op(name=).name))
def MaybeResetStepSeed():
  if not tf.executing_eagerly():
    ResetStepSeed()
def GetIncStepSeed():
  step_seed = GetStepSeed()
  ResetStepSeed()
  return step_seed
def GenerateStepSeedPair(p, op_seed=):
  seed_dtype = tf.int32 if use_tpu() else tf.int64
  if p.is_inference and p.random_seed is None:
    GetIncStepSeed()
    return tf.random.uniform([], maxval=, dtype=)
  global_step = tf.cast(GetGlobalStep(), seed_dtype)
  step_seed = tf.cast(GetIncStepSeed(), seed_dtype)
  seeds = tf.stack([])
  if p.random_seed is not None:
    seeds +=
  if op_seed is not None:
    seeds +=
  return seeds
def DeterministicDropout(x, keep_prob, seeds, noise_shape=, name=):
  if isinstance():
    if keep_prob <= 0 or keep_prob > 1:
      raise tf.errors.InvalidArgumentError("")
    if keep_prob == 1:
      return x
  with tf.name_scope(name, "", []) as name:
    if use_tpu():
      seeds = tf.cast()
    keep_prob = tf.convert_to_tensor(keep_prob, dtype=, name=)
    noise_shape = noise_shape or GetShape()
    random_tensor = keep_prob + tf.random.stateless_uniform(noise_shape, seed=, dtype=)
    binary_tensor = tf.floor()
    if x.dtype != tf.float32:
      binary_tensor = tf.cast()
      keep_prob = tf.cast(keep_prob, dtype=)
    result = tf.div() * binary_tensor
    result.set_shape(x.get_shape())
    return result
def DeterministicVN(params, seeds, noise_shape, mean=, std=, name=):
  with tf.name_scope() as name:
    if use_tpu():
      seeds = tf.cast()
    random_tensor = mean + (std * tf.random.stateless_normal(noise_shape, seed=))
    if FPropDtype() != tf.float32:
      random_tensor = tf.cast(random_tensor, FPropDtype())
    return random_tensor
BATCH_NORM_UPDATES =
_BATCH_NORM_UPDATES_DICT =
_get_batch_norm_updates_dict = _CollectionGetter(_BATCH_NORM_UPDATES_DICT,lambda: {})
def UpdateBatchNormVars():
  with tf.name_scope("", values=[]) as scope:
    with tf.ops.colocate_with():
      decay = tf.convert_to_tensor(1.0 - decay, dtype=)
      update_delta = (batch_norm_var - tf.cast()) * decay
      has_nan_or_inf = tf.reduce_any(tf.math.logical_or(tf.math.is_nan(), tf.math.is_inf()))
      update_delta = tf.cond(has_nan_or_inf,lambda: tf.zeros_like(),lambda:)
      bn_update = tf.assign_sub(batch_norm_var, update_delta, name=)
  tf.add_to_collection()
  if not tf.executing_eagerly():
    bn_update_dict = _get_batch_norm_updates_dict()
    bn_update_dict[] = ()
  return bn_update
def FindRelevantBatchNormUpdates():
  if tf.executing_eagerly():
    return [], []
  dependent_ops_and_tensors = set(FindNeeded())
  relevant_updates = []
  irrelevant_updates = []
  bn_update_dict = _get_batch_norm_updates_dict()
  for bn_update in batch_norm_updates:
    bn_stat_name = bn_update_dict[][].name
    if bn_stat_name in dependent_ops_and_tensors:
      relevant_updates.append()
    else:
      irrelevant_updates.append()
  return relevant_updates, irrelevant_updates
_SAMPLE_STEP_STACK = ThreadLocalStack()
def SampleStep():
  try:
    _SAMPLE_STEP_STACK.stack.append()
    yield step
  finally:
    _SAMPLE_STEP_STACK.stack.pop()
def _GetSampleStep():
  return _SAMPLE_STEP_STACK.stack[] if _SAMPLE_STEP_STACK.stack else None
def AddDebugTensor(tensor, summarize=, name=):
  if _FromGlobal():
    step = _GetSampleStep()
    tensors_to_print = ([] if step is None else []) + []
    with tf.name_scope() as s:
      tensor = tf.Print(tensor,tensors_to_print,message=,name=,summarize=)
  return tensor
def ArgMax():
  if use_tpu():
    return tf.argmax(inputs, axis=, output_type=)
  else:
    return tf.argmax(inputs, axis=)
def _EnsureMatrixShape():
  if x.shape.ndims is None:
    x.set_shape([])
  else:
  return x
def Matmul():
  x = _EnsureMatrixShape()
  y = _EnsureMatrixShape()
  return tf.matmul()
def clip_by_value(t, clip_value_min, clip_value_max, name=):
  if t.dtype.is_complex:
    return tf.complex(tf.clip_by_value(tf.math.real(), clip_value_min, clip_value_max, "",tf.clip_by_value(tf.math.imag(), clip_value_min, clip_value_max, ""))
  return tf.clip_by_value()
def _TransformAndSum():
  with tf.name_scope():
    sum_transform = []
    for t in tensor_list:
      with tf.device():
        if isinstance():
          sum_transform += [tf.reduce_sum(transform())]
        else:
          sum_transform += [tf.reduce_sum(transform())]
    return tf.add_n()
def SumSquared():
  return _TransformAndSum(tensor_list, lambda v: tf.abs()**2)
def SumAbs():
  return _TransformAndSum()
def PiecewiseConstant():
  x_in = tf.cast(tf.convert_to_tensor(), tf.float32)
  bs = tf.convert_to_tensor(boundaries, dtype=)
  vs = tf.convert_to_tensor(values, dtype=)
  index = tf.reduce_sum(tf.cast(tf.greater_equal(), tf.int32))
  one_hot_vec = tf.one_hot(tf.expand_dims(), depth=len(), dtype=)
  return Matmul(tf.reshape(vs, ()), tf.transpose())[][]
def PadSequenceDimension(x, length, pad_val, shape=):
  if x.shape.ndims is not None:
    rank =
    slen = GetShape()[]
    pad_len =
    pad = [[] for _ in range()]
    pad[][] =
  else:
    rank = tf.rank()
    with tf.control_dependencies([assert_greater_equal()]):
      slen = tf.shape()[]
    pad_len =
    pad = tf.scatter_nd([[]], [], [])
  x = tf.pad(x, pad, constant_values=)
  if x.shape.ndims is not None and isinstance():
    static_shape = x.shape.as_list()
    static_shape[] =
    x.set_shape()
  if shape:
    if not isinstance(shape, ()):
      raise TypeError()
    x = HasRank(x, len())
    x = tf.ensure_shape()
  return x
def PadSequenceTo():
  if not isinstance(xs, ()):
    new_xs = []
  else:
    new_xs =
  res = []
  for x in new_xs:
    batch, slen = GetShape()
    padding = HasRank()
    padding = HasShape(padding, [])
    new_x = PadSequenceDimension()
    res.append()
  padding = PadSequenceDimension(padding, length, tf.cast())
  if not isinstance(xs, ()):
    return res[], padding
  else:
    return tuple(), padding
def ApplyPadding(padding, x, padded=, broadcast=, use_select=):
  padding = with_dependencies([Assert(tf.reduce_all(tf.math.logical_or(tf.equal(), tf.equal())), [])], padding)
  if use_select:
    if padded is None:
      padded = tf.zeros_like()
    if broadcast:
      padding = tf.cast() * tf.ones_like()
    return tf.where(padding > tf.zeros_like(), padded, x)
  else:
    result = x * tf.cast()
    if padded is not None:
      result += padded * tf.cast()
    return result
def LengthsFromPaddings():
  paddings = HasRank()
  paddings = tf.cast()
  cumsum = tf.cumsum(1 - paddings, axis=)
  same_as_last_element = tf.equal(cumsum, cumsum[:, -1:])
  length = tf.reduce_sum(1 - tf.cast(), axis=) + 1
  all_zero_paddings = tf.equal(tf.reduce_sum(1 - paddings, axis=), 0)
  return tf.where(all_zero_paddings, tf.zeros_like(), length)
def PaddingsFromLengths(lengths, maxlen=):
  lengths = HasRank()
  if maxlen is not None:
    lengths = with_dependencies([assert_less_equal(tf.cast(tf.reduce_max(), tf.int32), maxlen)],lengths)
  return 1. - tf.sequence_mask(lengths, maxlen=, dtype=)
def TrimTrailingPaddings():
  paddings = HasRank()
  max_length = tf.maximum(tf.reduce_max(LengthsFromPaddings()), 1)
  output_shape = tf.shape()
  output_shape = tf.concat([[output_shape[], max_length], output_shape[2:]],axis=)
  outputs = tf.slice(inputs, tf.zeros_like(), output_shape)
  out_paddings = tf.slice(paddings, [],tf.stack([output_shape[], max_length]))
  return outputs, out_paddings
def ReversePaddedSequence():
  inversed_paddings = 1.0 - tf.squeeze()
  inputs_length = tf.cast(tf.math.rint(tf.reduce_sum(inversed_paddings, axis=)), tf.int32)
  return tf.reverse_sequence(inputs, inputs_length, seq_axis=, batch_axis=)
def ConcatenatePaddedSequences(input0, input1, padding0, padding1, seq_dim=):
  if seq_dim != 0 and seq_dim != 1:
    raise tf.errors.InvalidArgumentError()
  batch_dim =
  input0 = with_dependencies([assert_equal(GetShape()[],GetShape()[]),assert_equal(GetRank(), GetRank())], input0)
  batch_size = GetShape()[]
  input0 = with_dependencies([assert_equal(GetShape()[], batch_size),assert_equal(GetShape()[], batch_size)], input0)
  input0_seq_dim = tf.cast(tf.tile([tf.shape()[]], []), dtype=)
  input1_seq_dim = tf.cast(tf.tile([tf.shape()[]], []), dtype=)
  if seq_dim == 1:
    seq_length0 = LengthsFromPaddings()
    seq_length1 = LengthsFromPaddings()
  else:
    seq_length0 = LengthsFromPaddings(tf.transpose())
    seq_length1 = LengthsFromPaddings(tf.transpose())
  seq_length0 = with_dependencies([assert_equal(seq_length0,tf.cast(tf.reduce_sum(), dtype=))], seq_length0)
  seq_length1 = with_dependencies([assert_equal(seq_length1,tf.cast(tf.reduce_sum(), dtype=))], seq_length1)
  reversed_input0 = tf.reverse_sequence(input0, seq_length0, seq_axis=, batch_axis=)
  reversed_input1 = tf.reverse_sequence(input1, input1_seq_dim, seq_axis=, batch_axis=)
  reversed_concat = tf.concat([], axis=)
  concat_inputs = tf.reverse_sequence(reversed_concat,seq_length0 + input1_seq_dim,seq_axis=,batch_axis=)
  reversed_padding0 = tf.reverse_sequence(padding0, input0_seq_dim, seq_axis=, batch_axis=)
  reversed_concat_padding = tf.concat([],axis=)
  concat_paddings = tf.reverse_sequence(reversed_concat_padding,input0_seq_dim + seq_length1,seq_axis=,batch_axis=)
  return concat_inputs, concat_paddings
def ShiftLeft(tensor, shift_size, pad_val=):
  with tf.control_dependencies([assert_greater_equal(),assert_greater_equal()]):
    time = GetShape()[]
    return PadSequenceDimension(tensor[:, shift_size:], time, pad_val)
def Retry():
  return retry.Retry()
transient_tf_errors = ()
def RetryOnTransientTfError():
  return Retry()
def PadOrTrimTo(x, shape, pad_val=, pad_after_contents=):
  if isinstance(shape, ()):
    expected_rank = len()
  elif isinstance():
    if not shape.is_fully_defined():
      raise ValueError()
    expected_rank =
  else:
    shape = HasRank()
    expected_rank = tf.size()
  x = HasRank()
  pad = shape - tf.minimum(tf.shape(), shape)
  zeros = tf.zeros_like()
  if pad_after_contents:
    paddings = tf.stack([], axis=)
    slice_begin =
  else:
    paddings = tf.stack([], axis=)
    slice_begin = tf.shape() + pad - shape
  x = tf.pad(x, paddings, constant_values=)
  x = tf.slice()
  return tf.reshape()
def RepeatDim():
  if multiple == 1:
    return tensor
  t_shape = tf.shape()
  tensor_dims = tf.concat([t_shape[:], [t_shape[] * multiple], t_shape[axis + 1:]], 0)
  multiple_dims = tf.concat([tf.fill([], 1), [],tf.fill([tf.rank() - axis - 1], 1)], 0)
  return tf.reshape(tf.tile(tf.expand_dims(), multiple_dims), tensor_dims)
def StackTensorsRecursively():
  flatten = [w.Flatten() for w in values]
  stacked = []
  for i in range(len(flatten[])):
    stacked += [tf.stack([flatten[][] for j in range(len())])]
  ret = values[].Pack()
  return ret
def MixByWeight(inputs, weights, seed=):
  weights = tf.convert_to_tensor(weights, dtype=)
  weights = with_dependencies([assert_equal(tf.shape(), [len()]),assert_greater_equal(tf.reduce_min(), 0.0)], weights)
  lower = tf.cumsum(weights, exclusive=)
  upper = tf.cumsum(weights, exclusive=)
  r = tf.random.uniform(shape=[], maxval=upper[], seed=)
  return_input = tf.case([(tf.math.logical_and(lower[] <=, r < upper[]), inputs[])for i in range(len())],exclusive=)
  selected_index = tf.case([(tf.math.logical_and(lower[] <=, r < upper[]), lambda i=i:)for i in range(len())],exclusive=)
  bprop_index = tf.one_hot(selected_index, len(), dtype=)
  return return_input, bprop_index
def CheckShapes():
  for s in shapes:
    if isinstance():
    else:
def FPropDtype():
  return params.fprop_dtype if params.fprop_dtype is not None else params.dtype
def UpdateFpropDtype():
  if not isinstance():
    return
  for key, val in params.IterParams():
    if isinstance():
      UpdateFpropDtype()
    elif isinstance(val, ()):
      for item in val:
        UpdateFpropDtype()
    elif key == "":
      params.fprop_dtype =
def UpdateDtype():
  if not isinstance():
    return
  for key, val in params.IterParams():
    if isinstance():
      UpdateDtype()
    elif isinstance(val, ()):
      for item in val:
        UpdateDtype()
    elif key == "":
      params.dtype =
def NameScopeDecorator():
  def Decorator():
    def Wrapped():
      with tf.name_scope():
        return f()
    return Wrapped
  return Decorator
def SequencesToDebugStrings(ids, lens, summarize=):
  num_seqs = tf.shape()[]
  def _Body():
    line = tf.strings.format('{}', ids[i, :lens[]], summarize=)
    return i + 1, tf.concat([result, tf.reshape(line, [])], axis=)
  i0 = tf.zeros(shape=[], dtype=)
  result0 = tf.constant("", shape=[], dtype=)
  _, strs = tf.while_loop(lambda i, result:,_Body, (),shape_invariants=(i0.shape, tf.TensorShape([])))
  return strs
def RematerializeFn():
  initial_step_seed = GetStepSeed()
  final_step_seed = MaybeGenerateSeedFromScope()
  def Backward():
    del fwd_ys
    always_true = tf.random.uniform([]) < 2.0
    bak_xs = [tf.where(always_true, x, tf.zeros_like()) for x in fwd_xs.xs]
    for dst, src in zip():
      dst.set_shape()
    ResetStepSeed()
    ys = fn()
    MaybeResetStepSeed()
    dxs = tf.gradients(ys, bak_xs, grad_ys=)
    dxs_final = []
    for dx, x in zip():
      if dx is None:
        dxs_final.append(tf.zeros_like())
      else:
        dxs_final.append()
    return NestedMap(initial_step_seed=tf.zeros_like(), xs=)
  ys_shapes = []
  def Forward():
    for dst, src in zip():
      dst.set_shape()
    ResetStepSeed()
    ys = fn()
    if isinstance():
      for y in ys:
        ys_shapes.append()
    else:
      ys_shapes.append()
    return ys
  ys = CallDefun(Forward,NestedMap(initial_step_seed=, xs=),bak=)
  if isinstance():
    for y, s in zip():
      y.set_shape()
  else:
    ys.set_shape(ys_shapes[])
  MaybeResetStepSeed()
  return ys
_STATEFUL_RANDOM_OPS = frozenset({})
def StatefulRandomOpsInDefun(func, graph=):
  if graph is None:
    graph = tf.get_default_graph()
  func.add_to_graph()
  graph_def = graph.as_graph_def()
  func_defs = {x.signature.name:}
  if isinstance():
    if func.definition.signature.name not in func_defs:
      raise tf.errors.InvalidArgumentError(None, None, "")
    nodes = py_collections.deque()
  else:
    nodes = py_collections.deque()
  stateful_ops = []
  while nodes:
    node = nodes.pop()
    if node.op in _STATEFUL_RANDOM_OPS:
      stateful_ops.append()
      continue
    def _AddDefunNodes():
      if func_name in func_defs:
        nodes.extend(func_defs[].node_def)
    if node.op == "":
      _AddDefunNodes(node.attr[].func.name)
      _AddDefunNodes(node.attr[].func.name)
    elif node.op == "":
      _AddDefunNodes(node.attr[].func.name)
    elif node.op == "":
      _AddDefunNodes(node.attr[].func.name)
      _AddDefunNodes(node.attr[].func.name)
    elif node.op == "":
      _AddDefunNodes(node.attr[].func.name)
    elif node.op != "":
      _AddDefunNodes()
  return stateful_ops
def ToPlaceholders(nmap, dtype=):
  def _ToPlacerholder():
    shape = [None for _ in x.shape[:]] + [x.shape[]]
    return tf.placeholder(dtype=, shape=)
  return nmap.Transform()
def Softmax(logits, axis=, extra_logit=, name=):
  if extra_logit is None:
    return tf.nn.softmax(logits, axis=, name=)
  axis =
  def ReduceLogSumExp():
    max_logit = tf.math.reduce_max(tf.stop_gradient(), axis=, keepdims=)
    base_logit = tf.math.maximum()
    x -=
    exp_x = tf.math.exp()
    sum_exp_x = tf.math.reduce_sum(exp_x, axis=, keepdims=)
    sum_exp_x += tf.math.exp()
    return tf.math.log() + base_logit
  def LogSoftmax():
    return x - ReduceLogSumExp()
  with tf.name_scope():
    return tf.math.exp(LogSoftmax())
def SoftmaxCrossEntropyFocalLoss(logits,label_ids=,label_probs=,alpha=,gamma=,stop_gradient_on_focal_loss_coefficient=):
  def _ApplyFocalLossCoefficient():
    if gamma is not None and gamma != 0:
      probs = tf.exp()
      coefficient = tf.pow()
      if stop_gradient_on_focal_loss_coefficient:
        coefficient = tf.stop_gradient()
      loss *=
    return loss
  if label_probs is not None:
    log_probs = tf.nn.log_softmax()
    loss = -()
    loss = _ApplyFocalLossCoefficient()
    if alpha is not None:
      loss *= tf.reshape(alpha, tf.concat([tf.ones(tf.rank() - 1, tf.int32), []],axis=))
    loss = tf.reduce_sum(loss, axis=)
  else:
    loss = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=, logits=)
    loss = _ApplyFocalLossCoefficient()
    if alpha is not None:
      loss *= tf.gather()
  return loss
def SigmoidCrossEntropyFocalLoss(logits, labels, alpha=, gamma=):
  result = re.match()
  if result is None:
    return "", file_pattern
  return result.groups()
def ReadFileLines():
  if not tf.io.gfile.exists():
    try:
      lines = pkgutil.get_data("", file_path.replace()).splitlines()
    except IOError:
      lines =
  else:
    lines =
  if not lines:
    with tf.io.gfile.GFile() as f:
      lines = f.readlines()
  return lines
def CumSum(x, axis=, exclusive=):
  if x.dtype not in () or not use_tpu():
    return tf.cumsum(x, axis=, exclusive=)
  rank = GetRank()
  if not isinstance() and axis != -1:
    return tf.cumsum(x, axis=, exclusive=)
  if axis < -1:
    if axis + rank < 0:
      raise ValueError()
    axis +=
  length = GetShape()[]
  my_range = tf.range()
  comparator =
  mask = tf.cast(comparator(tf.expand_dims(), tf.expand_dims()),x.dtype)
  result = tf.tensordot(x, mask, axes=[[], []])
  if axis != -1 and axis != rank - 1:
    result = tf.transpose(result,list(range()) + [] + list(range()))
  return result
def ProjectLastDim():
  input_dim = int(symbolic.ToStatic() if symbolic.IsExpr() else input_dim)
  output_dim = int(symbolic.ToStatic() if symbolic.IsExpr() else output_dim)
  inputs = with_dependencies([assert_equal(GetShape()[], input_dim)],inputs)
  weight = with_dependencies([assert_equal(GetShape()[], input_dim),assert_equal(GetShape()[], output_dim)], weight)
  if (use_tpu() and inputs.shape is not None andinputs.shape.rank is not None and inputs.shape.rank < 26):
    if inputs.shape.rank == 2:
      outputs = tf.matmul()
    else:
      s = "".join([chr() for x in range()])
      r =
      outputs = tf.einsum("", inputs, weight)
  else:
    outputs = Matmul(tf.reshape(inputs, ToStaticShape([])), weight)
    outputs = tf.reshape(outputs,tf.concat([tf.cast(GetShape()[:], tf.int32),ToStaticShape([])],axis=))
  return outputs
def RemoveAssertContext(remove=):
  if remove:
    saved_assert_equal =
    def NoOP():
      return tf.no_op()
    tf.check_ops.assert_equal =
    try:
      yield
    finally:
      tf.check_ops.assert_equal =
  else:
    yield
def _AssertInputsMatch():
  expected_inputs = Flatten([])
  expected_num_inputs = len()
  if len() > expected_num_inputs:
    raise ValueError()
  if len() < expected_num_inputs:
    raise ValueError()
def TensorSpecs(nmap, keep_shape=):
  if nmap is None:
    return None
  fn = lambda t: tf.TensorSpec()
  return Transform()
def _DefineDefun(fwd, fwd_sig, bak=, bak_as_function=, device=):
  noinline = not use_xla()
  if fwd_sig is None:
    fwd_sig = []
  get_dtype = lambda x:
  arg_dtypes = Flatten(Transform())
  get_shape = lambda x:
  arg_shapes = Flatten(Transform())
  sigs = NestedMap()
  res = NestedMap()
  python_grad_func =
  if bak:
    def Grad():
      _AssertInputsMatch()
      args = ConvertNoneGradientToZeros(list(), list())
      xs = op.inputs[:len()]
      return sigs.backward(*Flatten([]))
    python_grad_func =
  def _SetShape():
    for dst, shape in zip():
      if isinstance():
        dst.set_shape()
  def Forward():
    _SetShape()
    with RemoveAssertContext(remove=):
      call = lambda: fwd(Pack()) if args else fwd()
      if device is None:
        rets = call()
      else:
        with tf.device():
          rets = call()
    res.outputs =
    return Flatten()
  forward =
  if not arg_dtypes:
    forward = Forward.instantiate([])
  forward.add_to_graph(tf.get_default_graph())
  res.func =
  res.stateful_ops =
  res.captured_inputs =
  output_dtypes = Transform()
  output_shapes = Transform()
  def Call(args=):
    if args is None:
      flat_rets = forward()
    else:
      flat_rets = forward(*Flatten())
    if not isinstance(flat_rets, ()):
      flat_rets = []
    _SetShape(flat_rets, Flatten())
    return Pack()
  res.call =
  if bak:
    def Backward():
      _SetShape(args, Flatten([]))
      xs, ys, dys = Pack([], args)
      with RemoveAssertContext(remove=):
        if device is None:
          dxs = bak()
        else:
          with tf.device():
            dxs = bak()
      return Flatten()
    if bak_as_function:
      sigs.backward = tf.Defun(*Flatten([]),noinline=)()
      sigs.backward.add_to_graph(tf.get_default_graph())
    else:
      sigs.backward =
  return res
_SHARED_RENDEZVOUS = ThreadLocalStack()
def _SharedRendezvousScope(shared_rendezvous=):
  _SHARED_RENDEZVOUS.stack.append()
  try:
    yield
  finally:
    _SHARED_RENDEZVOUS.stack.pop()
def _GetSharedRendezvous():
  return _SHARED_RENDEZVOUS.stack[] if _SHARED_RENDEZVOUS.stack else False
def _ApplySharedRendezvous():
  func._shared_rendezvous = _GetSharedRendezvous()
def _WrapFunction(func=, input_signature=):
  if input_signature is None:
    input_signature = []
  def Decorated():
    def Fn():
      ResetStepSeed()
      graph = tf.get_default_graph()
      graph.clear_collection()
      return fn()
    _ApplySharedRendezvous()
    cf = Fn.get_concrete_function()
    cf.add_to_graph()
    return cf
  if func is not None:
    return Decorated()
  return Decorated
def _DefineFunction(fwd, fwd_sig, bak=, bak_as_function=, device=):
  noinline = not use_xla()
  if fwd_sig is None:
    fwd_sig = []
  if device is None:
    device_funcs = tf.get_default_graph()._device_functions_outer_to_inner
    device = device_funcs[] if device_funcs else None
  res = NestedMap()
  def Forward():
    with RemoveAssertContext(remove=), tf.device():
      if args:
        xs = Pack()
        rets = fwd()
      else:
        rets = fwd()
    res.outputs =
    return Flatten()
  res.captured_inputs =
  graph =
  input_ops = set()
  operations = [op for op in graph.get_operations() if op not in input_ops]
  res.stateful_ops = [() for o in operations if o._is_stateful]
  def Call(func, args=):
    if args is None:
      flat_rets = func()
    else:
      flat_rets = func(*Flatten())
    if not isinstance(flat_rets, ()):
      flat_rets = []
    return Pack()
  if not bak:
    res.func =
    res.call = lambda args=None: Call()
    return res
  shared_rendezvous = _GetSharedRendezvous()
  ret_specs = TensorSpecs()
  def Backward():
    xs, ys, dys = Pack([], args)
    with RemoveAssertContext(remove=), tf.device():
      dxs = bak()
    return Flatten()
  if bak_as_function:
    backward_cf = _WrapFunction(Backward, input_signature=Flatten([]))
  else:
    def BackwardWithSharedRendezvous():
      with _SharedRendezvousScope():
        return Backward()
    backward_cf =
  def ForwardWithGrad():
    fwd_args = args[:(len() - len(Flatten()))]
    op = NestedMap(inputs=, outputs=Forward())
    def Grad():
      if kwargs:
      _AssertInputsMatch()
      args = ConvertNoneGradientToZeros(list(), list())
      xs, _ = Pack([], op.inputs)
      return backward_cf(*Flatten([]))
    return op.outputs, Grad
  res.func =
  forward = lambda *xs: ForwardWithGrad(*Flatten([]))
  res.call = lambda args=None: Call()
  return res
_USE_TF_FUNCTION = ThreadLocalStack()
_FRAMEWORK_TENSOR_GLOBAL_STEP =
def TfFunctionScope(use_tf_function=):
  _USE_TF_FUNCTION.stack.append()
  try:
    yield
  finally:
    _USE_TF_FUNCTION.stack.pop()
def _UseTfFunction():
  if _USE_TF_FUNCTION.stack:
    return _USE_TF_FUNCTION.stack[]
  return tf2_enabled()
class Function():
  def __init__(self,fwd_sig=,bak=,bak_as_function=,device=,use_tf_function=):
    self._fwd_sig =
    self._bak =
    self._bak_as_function =
    self._device =
    self._use_tf_function =
  def __call__():
    return DefinedFunction()
class DefinedFunction():
  def __init__(self,fwd,fwd_sig=,bak=,bak_as_function=,device=,use_tf_function=):
    self._fwd_sig =
    wrapped_fwd_sig =
    fwd_fn =
    bak_fn =
    graph_random_seed =
    if tf.get_default_graph().seed is not None:
      graph_random_seed = tf.get_default_graph().seed
    wrapped_fwd_sig = NestedMap()
    self._added_global_step =
    if GetGlobalStep() is not None:
      wrapped_fwd_sig[] = (tf.TensorSpec([], tf.int64))
      self._added_global_step =
    if fwd_sig is not None:
      wrapped_fwd_sig.inputs =
    elif not wrapped_fwd_sig:
      wrapped_fwd_sig =
    def ForwardWrapped(wrapped_inputs=):
      if graph_random_seed is not None:
        tf.random.set_seed()
      global_step =
      if wrapped_inputs:
        global_step = wrapped_inputs.get()
      with GlobalStepContext():
        if wrapped_inputs and "" in wrapped_inputs:
          result = fwd()
        else:
          result = fwd()
      return result
    fwd_fn =
    if bak:
      def BackwardWrapped():
        if graph_random_seed is not None:
          tf.random.set_seed()
        with GlobalStepContext(wrapped_xs.get()):
          result = bak()
        dxs = Transform()
        if isinstance() and len() == 2:
          dxs.inputs, dcapture =
          return dxs, dcapture
        else:
          dxs.inputs =
          return dxs
      bak_fn =
    if use_tf_function is None:
      use_tf_function = _UseTfFunction()
    fn =
    self._data = fn(fwd=,fwd_sig=,bak=,bak_as_function=,device=)
  def __call__(self, args=):
    return self._data.call(self.AddFrameworkInputs())
  def func():
    return self._data.func
  def AddFrameworkInputs():
    result = NestedMap()
    if self._added_global_step:
      global_step = GetGlobalStep()
      result[] = tf.cast()
    if inputs is not None:
      result.inputs =
    return result if result else None
  def output_dtypes():
    return Transform(lambda x:, self._data.outputs)
  def stateful_ops():
    return self._data.stateful_ops
  def captured_inputs():
    return self._data.captured_inputs
def CallDefun(fwd, args=, bak=, bak_as_function=, device=):
  if args is not None:
    args = Transform()
  sigs = Function(fwd_sig=TensorSpecs(),bak=,bak_as_function=,device=)(fwd=)
  if args is None:
    return sigs()
  else:
    return sigs()
def If():
  fwd_sig = TensorSpecs()
  then_sigs = Function(fwd_sig=)(fwd=)
  else_sigs = Function(fwd_sig=)(fwd=)
  if then_sigs.captured_inputs != else_sigs.captured_inputs:
    raise ValueError()
  ret = tf.If(cond=,inputs=Flatten(then_sigs.AddFrameworkInputs()) +then_sigs.captured_inputs,then_branch=,else_branch=)
  return Pack()
def _Itype():
  return tf.int32 if use_xla() else tf.int64
def WhileLoop():
  fwd_sig = TensorSpecs()
  cond_sigs = Function(fwd_sig=)(fwd=)
  def BodyWrapped():
    result = body()
    result = cond_sigs.AddFrameworkInputs()
    return result
  body_sigs = Function(fwd_sig=)(fwd=)
  wrapped_inputs = body_sigs.AddFrameworkInputs()
  new_state = tf.While(Flatten(), cond=, body=)
  return Pack().inputs
def ForLoop():
  state = NestedMap(iter=tf.cast(start, _Itype()),limit=tf.cast(limit, _Itype()),delta=tf.cast(delta, _Itype()),loop_state=)
  def LoopCond():
    return tf.less()
  def LoopBody():
    state.loop_state = body()
    state.iter = tf.add()
    return state
  return WhileLoop().loop_state
def TopK():
  x_in_shape =
  x_rank =
  last_dim_size = x_in_shape.as_list()[]
  min_value = tf.math.reduce_min() - 1.0
  out_indices = []
  out_values = []
  for unused_i in range():
    index_i = tf.math.argmax(x_in, axis=, output_type=)
    mask_i = tf.one_hot()
    value_i = tf.reduce_sum(mask_i * x_in, -1, keepdims=)
    x_in = () * x_in + mask_i * min_value
    out_indices.append(tf.expand_dims())
    out_values.append()
  if k == 1:
    return out_values[], out_indices[]
  else:
    return tf.concat(), tf.concat()
def ReadVariable():
  if var_op.type != "":
    raise TypeError(""))
  filter_fn = lambda op: op.type ==
  var_readers = list(filter(filter_fn, var_op.outputs[].consumers()))
  return var_readers[].outputs[]
_TPU_SUMMARY_TENSORS_KEY = ()
_get_tpu_summary_tensors = _CollectionGetter(_TPU_SUMMARY_TENSORS_KEY,lambda: [])
def AddTpuSummaryTensor(name, value, weight=):
  tpu_summary_tensors = _get_tpu_summary_tensors()
  x = NestedMap()
  x.name =
  x.value =, tf.convert_to_tensor()
  x.name_scope = tf.get_default_graph().get_name_scope()
  tpu_summary_tensors.append()
def GetTpuSummaryTensors():
  tpu_summary_tensors = _get_tpu_summary_tensors()
  return , SanitizeScopeKey()):}
def ClearTpuSummaryTensors():
  tpu_summary_tensors = _get_tpu_summary_tensors()
  del tpu_summary_tensors[:]
def ComputationShape(split_size, topology=):
  if topology:
    topology_info = tf_topology.Topology(serialized=)
  computation_shape =
  if topology and functools.reduce(lambda a, b:,topology_info.mesh_shape) == split_size:
    computation_shape =
  elif split_size == 1:
    computation_shape = []
  elif split_size == 2:
    computation_shape = []
  elif split_size == 4:
    computation_shape = []
  elif split_size == 8:
    computation_shape = []
  elif split_size == 16:
    computation_shape = []
  elif split_size == 32:
    computation_shape = []
  elif split_size == 64:
    if topology and topology_info.mesh_shape[] == 32:
      computation_shape = []
    else:
      computation_shape = []
  elif split_size == 128:
    computation_shape = []
  elif split_size == 256:
    computation_shape = []
  elif split_size == 512:
    computation_shape = []
  elif split_size == 1024:
    computation_shape = []
  elif split_size == 2048:
    computation_shape = []
  elif split_size == 4096:
    computation_shape = []
  elif split_size == 8192:
    computation_shape = []
  else:
  return computation_shape
def GetExtraVars():
  g = tf.get_default_graph()
  if isinstance():
    return g.variable_captures
  return function.get_extra_vars()
def GetExtraInputs():
  g = tf.get_default_graph()
  if isinstance():
    return g.external_captures
  return function.get_extra_inputs()
def GetExtraArgs():
  g = tf.get_default_graph()
  if isinstance():
    return g.internal_captures
  return function.get_extra_args()
def ShardedFilePatternToGlob():
  if "" in file_pattern:
    raise ValueError()
  if "" not in file_pattern:
    return file_pattern
  path, shards = file_pattern.split()
  if shards == "":
    return f""
  return ""
def ComputeNceAndAuc():
  def LogWithClip(tensor, clip_value_min=):
    return tf.math.log(tf.clip_by_value())
  bce = -targets * LogWithClip() - () * LogWithClip()
  num_cor = tf.reduce_sum()
  num_tokens = tf.reduce_sum()
  wcr =
  entropy = -wcr * LogWithClip() - () * LogWithClip()
  avg_conditional_entropy = tf.reduce_mean(tf.boolean_mask())
  nce = () / entropy
  auc = tf.metrics.auc(targets, probs, mask, curve=)[]
  return nce, auc
def GatherTensorValuesBySeqIndices(tensor, class_indices, keepdims=):
  tensor = HasRank()
  class_indices = HasRank()
  tensor = HasShape(tensor, GetShape(), 2)
  dim0 = GetShape()[]
  dim1 = GetShape()[]
  dim0_indices = tf.tile(tf.expand_dims(tf.range(), axis=), [])
  dim1_indices = tf.tile(tf.expand_dims(tf.range(), axis=), [])
  gather_indices = tf.stack([tf.cast(dim0_indices, dtype=),tf.cast(dim1_indices, dtype=), class_indices],axis=)
  ret = tf.gather_nd()
  if keepdims:
    ret = tf.expand_dims(ret, axis=)
  return ret
def GetSoftmaxProbsBySeqIndices(logits, indices, keepdims=):
  probs = tf.nn.softmax()
  return GatherTensorValuesBySeqIndices()
def DivideNoNan():
  safe_y = tf.where(tf.equal(), tf.ones_like(), y)
  return tf.where(tf.equal(), tf.zeros_like(), x / safe_y)
def SequencePaddings(seqlen, maxlen=):
  mask = tf.sequence_mask(seqlen, maxlen, dtype=)
  return 1 - mask
import tensorflow as tf
import numpy as np
data = np.loadtxt("", delimiter=,',unpack=, dtype=)
x_data = np.transpose(data[0:])
y_data = np.transpose(data[2:])
global_step = tf.Variable(0, trainable=, name=)
X = tf.placeholder()
Y = tf.placeholder()
with tf.name_scope():
    W1 = tf.Variable(tf.random_uniform([], -1., 1.), name=)
    L1 = tf.nn.relu(tf.matmul())
with tf.name_scope():
    W2 = tf.Variable(tf.random_uniform([], -1., 1.), name=)
    L2 = tf.nn.relu(tf.matmul())
with tf.name_scope():
    W3 = tf.Variable(tf.random_uniform([], -1., 1.), name=)
    model = tf.matmul()
with tf.name_scope():
    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=, logits=))
    optimizer = tf.train.AdamOptimizer(learning_rate=)
    train_op = optimizer.minimize(cost, global_step=)
    tf.summary.scalar()
sess = tf.Session()
saver = tf.train.Saver(tf.global_variables())
ckpt = tf.train.get_checkpoint_state()
if ckpt and tf.train.checkpoint_exists():
    saver.restore()
else:
    sess.run(tf.global_variables_initializer())
merged = tf.summary.merge_all()
writer = tf.summary.FileWriter()
for step in range():
    sess.run(train_op, feed_dict={X:, Y:})
    summary = sess.run(merged, feed_dict={X:, Y:})
    writer.add_summary(summary, global_step=sess.run())
saver.save(sess, "", global_step=)
prediction = tf.argmax()
target = tf.argmax()
is_correct = tf.equal()
accuracy = tf.reduce_mean(tf.cast())
import collections
import copy
import itertools
import math
import os
import sys
from absl.testing import flagsaver
from absl.testing import parameterized
from lingvo import model_registry
import lingvo.compat as tf
from lingvo.core import base_layer
from lingvo.core import builder_layers
from lingvo.core import cluster_factory
from lingvo.core import hyperparams
from lingvo.core import py_utils
from lingvo.core import py_utils_flags
from lingvo.core import recurrent
from lingvo.core import symbolic
from lingvo.core import test_helper
from lingvo.core import test_utils
from lingvo.tasks.image.params import mnist
import mock
import numpy as np
from tensorflow.python.ops import functional_ops
FLAGS =
class PyUtilsTest():
  def testEnableAssertFlagOverrideFromCluster():
    cluster_params = cluster_factory.Current().Params()
    cluster_params.enable_asserts =
    with cluster_factory.Cluster():
      self.assertTrue(py_utils_flags.enable_asserts())
    cluster_params.enable_asserts =
    with cluster_factory.Cluster():
      self.assertFalse(py_utils_flags.enable_asserts())
  def testIsDefaultParamInit():
    p = py_utils.DefaultParamInit()
    self.assertTrue(py_utils.IsDefaultParamInit())
    p = hyperparams.Params.FromProto(p.ToProto())
    self.assertTrue(py_utils.IsDefaultParamInit())
    p = py_utils.WeightInit.Xavier(scale=)
    self.assertFalse(py_utils.IsDefaultParamInit())
  def testNestedMapFromNestedDict():
    a = {'a1':, 'a2':}
    b = {'b1':, 'b2':}
    c = {'a':, 'b':, 'ab':}
    d = py_utils.NestedMap()
    e = py_utils.NestedMap.FromNestedDict()
    self.assertIsInstance()
    self.assertNotIsInstance()
    self.assertIsInstance()
    self.assertIsInstance(e.ab[], py_utils.NestedMap)
    self.assertEqual(e.ab[], e.a)
    self.assertEqual(e.ab[], e.b)
  def testNestedMapGetItem():
    nested_map = py_utils.NestedMap()
    nested_map[] = py_utils.NestedMap({'x':})
    nested_map[] = py_utils.NestedMap({'y_0':, 'y':})
    self.assertEqual(nested_map.GetItem(), nested_map.a.x)
    self.assertEqual(nested_map.GetItem(), 4)
    self.assertEqual(nested_map.GetItem('b.y[]'), 3)
    with self.assertRaises():
      nested_map.GetItem()
    with self.assertRaises():
      nested_map.GetItem('b.y[]')
    with self.assertRaises():
      nested_map.GetItem()
  def testNestedMapGet():
    nested_map = py_utils.NestedMap({'a': {'b':}})
    self.assertEqual(nested_map.Get(), 0)
    self.assertIsNone(nested_map.Get())
    self.assertIsNone(nested_map.Get())
    self.assertEqual(nested_map.Get(), 0)
  def testNestedMapGetFromNestedList():
    nested_map = py_utils.NestedMap({'a': {'b':,, {'c':}}})
    self.assertEqual(nested_map.Get(), [0, 1, {'c':}])
    self.assertEqual(nested_map.Get('a.b[]'), 1)
    self.assertEqual(nested_map.Get('a.b[].c'), 2)
    self.assertIsNone(nested_map.Get('a.b[]'))
    self.assertIsNone(nested_map.Get())
  def testNestedMapDir():
    nested_map = py_utils.NestedMap({'a': {'b':}})
    nested_map.c =
    nested_map_dir = dir()
    self.assertIn()
    self.assertIn()
    self.assertIn()
  def testNestedMapSet():
    nested_map = py_utils.NestedMap.FromNestedDict({'a': {'b':}})
    self.assertEqual()
    nested_map.Set()
    self.assertEqual()
    with self.assertRaises():
      nested_map.Set()
    nested_map.Set("", py_utils.NestedMap())
    nested_map.Set()
    self.assertIsInstance()
    self.assertEqual()
    nested_map.Set('a.b.z[].y', 3)
    nested_map.Set('a.b.z[].y', 4)
    self.assertIsInstance()
    self.assertEqual(nested_map.a.b.z[].y, 3)
    self.assertEqual(nested_map.a.b.z[].y, 4)
    with self.assertRaises():
      nested_map.Set('a.b.z[]', 5)
  def testNestedMapSetIndexed():
    nested_map = py_utils.NestedMap()
    nested_map.x = []
    nested_map.y =
    nested_map.z = [py_utils.NestedMap(b=, c=[]), 4]
    another_map = py_utils.NestedMap()
    for k, v in nested_map.FlattenItems():
      another_map.Set()
    self.assertDictEqual()
  def testCreateVariableBasics():
    with flagsaver.flagsaver(stateless_vars_init=):
      with self.session(use_gpu=, graph=tf.Graph()):
        methods = []
        shapes = [[], [], [], []]
        col = []
        all_vars = []
        for i, () in enumerate(itertools.product()):
          pc = py_utils.WeightParams(sp, m(), dt, col)
          all_vars.append(py_utils.CreateVariable())
        tf.get_variable_scope().reuse_variables()
        self.assertEqual(len(tf.trainable_variables()), len())
        all_vars_copy = []
        for i, () in enumerate(itertools.product()):
          pc = py_utils.WeightParams(sp, m(), dt, col)
          all_vars_copy.append(py_utils.CreateVariable())
        self.evaluate(tf.global_variables_initializer())
        for v1, v2 in zip():
          v1_v = v1.eval()
          v2_v = v2.eval()
          self.assertAllEqual()
  def testCreateVariableWithSymbols():
    with self.session(use_gpu=, graph=tf.Graph()):
      dim_symbol = symbolic.Symbol()
      shape = []
      with symbolic.SymbolToValueMap(symbolic.STATIC_VALUES, {dim_symbol:}):
        pc = py_utils.WeightParams(shape, py_utils.WeightInit.Gaussian(),tf.float32, [])
        var = py_utils.CreateVariable()
      tf.get_variable_scope().reuse_variables()
      new_dim_symbol = symbolic.Symbol()
      shape = []
      with symbolic.SymbolToValueMap(symbolic.STATIC_VALUES,{new_dim_symbol:}):
        pc = py_utils.WeightParams(shape, py_utils.WeightInit.Gaussian(),tf.float32, [])
        var_copy = py_utils.CreateVariable()
      self.evaluate(tf.global_variables_initializer())
      self.assertAllEqual(var.eval(), var_copy.eval())
  def testCreateVariableUniform():
    with self.session(use_gpu=, graph=tf.Graph()):
      tf.random.set_seed()
      methods = []
      dtypes = []
      shapes = [[]]
      all_vars = []
      for i, () in enumerate(itertools.product()):
        pc = py_utils.WeightParams(sp, m(), dt)
        all_vars.append(py_utils.CreateVariable())
      v1_v_expted = [[],[]]
      v2_v_expted = [[],[]]
      v4_v_expted = [[],[],]
      self.evaluate(tf.global_variables_initializer())
      v1_v = all_vars[].eval()
      v2_v = all_vars[].eval()
      v4_v = all_vars[].eval()
      self.assertAllClose(v1_v_expted, v1_v.tolist())
      self.assertAllClose(v2_v_expted, v2_v.tolist())
      self.assertAllClose(v4_v_expted, v4_v.tolist())
  def testCreateVariableNormal():
    with self.session(use_gpu=, graph=tf.Graph()):
      tf.random.set_seed()
      methods = []
      dtypes = []
      shapes = [[]]
      all_vars = []
      for i, () in enumerate(itertools.product()):
        pc = py_utils.WeightParams(sp, m(), dt)
        all_vars.append(py_utils.CreateVariable())
      v1_v_expted = [[],[]]
      v2_v_expted = [[],[]]
      v3_v_expted = [[],[],]
      self.evaluate(tf.global_variables_initializer())
      v1_v = all_vars[].eval()
      v2_v = all_vars[].eval()
      v3_v = all_vars[].eval()
      self.assertAllClose(v1_v_expted, v1_v.tolist())
      self.assertAllClose(v2_v_expted, v2_v.tolist())
      self.assertAllClose(v3_v_expted, v3_v.tolist())
  def testCreateVariableSqrtFanInOut():
    with self.session():
      tf.random.set_seed()
      methods = []
      dtypes = []
      shapes = [[]]
      all_vars = []
      for i, () in enumerate(itertools.product()):
        pc = py_utils.WeightParams(sp, m(scale=), dt)
        all_vars.append(py_utils.CreateVariable())
      self.evaluate(tf.global_variables_initializer())
      var_values = self.evaluate()
      self.assertAllClose([[[[[],[]]]],[[[[],[]]]],[[[[],[]]]],[[[[],[]]]],[[[[],[]]]],],var_values)
  def testCreateVariableException():
    with self.session(use_gpu=, graph=tf.Graph()):
      tf.random.set_seed()
      pc = py_utils.WeightParams([], py_utils.WeightInit.Gaussian())
      var1 = py_utils.CreateVariable()
      tf.get_variable_scope().reuse_variables()
      var2 = py_utils.CreateVariable()
      pc = py_utils.WeightParams([], py_utils.WeightInit.Gaussian())
      with self.assertRaises():
        py_utils.CreateVariable()
      self.evaluate(tf.global_variables_initializer())
      self.assertAllEqual(var1.eval(), var2.eval())
  def testCreateVariableDifferentSeed():
    with self.session(use_gpu=):
      tf.random.set_seed()
      pc = py_utils.WeightParams([], py_utils.WeightInit.Gaussian())
      with tf.variable_scope():
        w0 = py_utils.CreateVariable()
      with tf.variable_scope():
        w1 = py_utils.CreateVariable()
      self.evaluate(tf.global_variables_initializer())
      w0_val, w1_val = self.evaluate([])
      self.assertGreater(np.max(np.abs()), 0.1)
  def testXavier():
    with self.session(use_gpu=, graph=tf.Graph()):
      tf.random.set_seed()
      methods = []
      dtypes = []
      shapes = [[]]
      all_vars = []
      for i, () in enumerate(itertools.product()):
        pc = py_utils.WeightParams(sp, m(), dt)
        all_vars.append(py_utils.CreateVariable())
      v1_v_expted = [[],[]]
      v3_v_expted = [[],[],]
      self.evaluate(tf.global_variables_initializer())
      v1_v = all_vars[].eval()
      v3_v = all_vars[].eval()
      self.assertAllClose(v1_v_expted, v1_v.tolist())
      self.assertAllClose(v3_v_expted, v3_v.tolist())
  def testXavier1D():
    with self.session(use_gpu=, graph=tf.Graph()):
      tf.random.set_seed()
      methods = []
      dtypes = []
      shapes = [[]]
      all_vars = []
      for i, () in enumerate(itertools.product()):
        pc = py_utils.WeightParams(sp, m(), dt)
        all_vars.append(py_utils.CreateVariable())
      v1_v_expted = []
      self.evaluate(tf.global_variables_initializer())
      v1_v = all_vars[].eval()
      self.assertAllClose(v1_v_expted, v1_v.tolist())
  def testXavier3D():
    with self.session(use_gpu=, graph=tf.Graph()):
      tf.random.set_seed()
      methods = []
      dtypes = []
      shapes = [[]]
      all_vars = []
      for i, () in enumerate(itertools.product()):
        pc = py_utils.WeightParams(sp, m(), dt)
        all_vars.append(py_utils.CreateVariable())
      v1_v_expted = [[[]]]
      self.evaluate(tf.global_variables_initializer())
      v1_v = all_vars[].eval()
      self.assertAllClose(v1_v_expted, v1_v.tolist())
  def testVariableShapePrefix():
    with self.session(use_gpu=, graph=tf.Graph()):
      shape = []
      pc = py_utils.WeightParams(shape=, init=py_utils.WeightInit.Constant(), dtype=)
      with py_utils.VariableShapePrefixContext():
        with py_utils.VariableShapePrefixContext():
          var = py_utils.CreateVariable()
      self.assertEqual([], var.shape.as_list())
  def testGeoMeanXavier():
    with self.session(use_gpu=, graph=tf.Graph()):
      tf.random.set_seed()
      methods = []
      dtypes = []
      shapes = [[]]
      all_vars = []
      for i, () in enumerate(itertools.product()):
        pc = py_utils.WeightParams(sp, m(), dt)
        all_vars.append(py_utils.CreateVariable())
      v1_v_expted = [[],[]]
      v3_v_expted = [[], []]
      self.evaluate(tf.global_variables_initializer())
      v1_v = all_vars[].eval()
      v3_v = all_vars[].eval()
      self.assertAllClose(v1_v_expted, v1_v.tolist())
      self.assertAllClose(v3_v_expted, v3_v.tolist())
  def testCheckNumerics():
    xv = [[], []]
    yv = [] * 4
    with self.session():
      x = tf.constant()
      y = tf.constant()
      z = tf.reduce_mean(tf.constant([], tf.float32))
      self.assertAllClose(xv, self.evaluate(py_utils.CheckNumerics()))
      self.assertAllClose(yv, self.evaluate(py_utils.CheckNumerics()))
      actual_xv, actual_yv = self.evaluate(py_utils.CheckNumerics([]))
      self.assertAllClose()
      self.assertAllClose()
      actual_xv, actual_yv = self.evaluate(py_utils.CheckNumerics(()))
      self.assertAllClose()
      self.assertAllClose()
      with self.assertRaisesRegex():
        self.evaluate(py_utils.CheckNumerics())
  def testLog():
    with self.session():
      x = tf.constant([[], []])
      y = tf.constant([] * 4)
      x = py_utils.Log(x, "", x=, y=)
      self.assertAllEqual(x.eval(), [[], []])
  def testDebug():
    with self.session():
      x = tf.constant([[], []])
      y = tf.constant([] * 4)
      z = tf.constant([] * 4)
      x = py_utils.Debug()
      self.assertAllEqual(x.eval(), [[], []])
      x = py_utils.Debug(x, "", more=[])
      self.assertAllEqual(x.eval(), [[], []])
  def testSave():
    with self.session():
      x = tf.constant([[], []])
      y = tf.constant([] * 4)
      x = py_utils.Save(x, "", x=, y=)
      self.evaluate(tf.global_variables_initializer())
      self.assertAllEqual(self.evaluate(), [[], []])
    read_x = np.load("", 0))
    read_y = np.load("", 0))
    self.assertAllEqual(read_x, [[], []])
    self.assertAllEqual(read_y, [] * 4)
  def testTensorRank():
    a = tf.constant([])
    self.assertIsInstance(py_utils.HasRank(), tf.Tensor)
    self.assertIsInstance(py_utils.HasAtLeastRank(), tf.Tensor)
    b = tf.constant([[]])
    self.assertIsInstance(py_utils.HasRank(), tf.Tensor)
    self.assertIsInstance(py_utils.HasAtLeastRank(), tf.Tensor)
    self.assertIsInstance(py_utils.HasAtLeastRank(), tf.Tensor)
    with self.assertRaises():
      py_utils.HasAtLeastRank()
    c = tf.placeholder(tf.int32, shape=)
    d = py_utils.HasAtLeastRank()
    with self.session() as sess:
      d_v = sess.run(d, feed_dict={c:})
      self.assertAllEqual([[[]]], d_v)
      with self.assertRaises():
        sess.run(d, feed_dict={c:})
  def testTensorRankDisableAsserts():
    with flagsaver.flagsaver(enable_asserts=):
      c = tf.placeholder(tf.int32, shape=)
      d = py_utils.HasAtLeastRank()
      with self.session() as sess:
        d_v = sess.run(d, feed_dict={c:})
        self.assertAllEqual([[]], d_v)
  def testGetShape():
    a = tf.constant([])
    self.assertEqual(py_utils.GetShape(), [])
    self.assertEqual(py_utils.GetShape(), [])
    self.assertEqual(py_utils.GetShape(), [])
    b = tf.constant([[]])
    self.assertEqual(py_utils.GetShape(), [])
    self.assertEqual(py_utils.GetShape(), [])
    self.assertEqual(py_utils.GetShape(), [])
    self.assertEqual(py_utils.GetShape(), [])
    c = tf.zeros([1, a[], a.shape[], tf.shape()[]])
    self.assertEqual(py_utils.GetShape()[], 1)
    self.assertEqual(py_utils.GetShape()[], 1)
    self.assertEqual(py_utils.GetShape()[], 1)
    self.assertEqual(py_utils.GetShape()[], 1)
    d = tf.placeholder(tf.float32, shape=())
    self.assertEqual(py_utils.GetShape()[], 1)
    self.assertIsInstance(py_utils.GetShape()[], tf.Tensor)
    e = tf.zeros([d.shape[], tf.shape()[], tf.shape()[]])
    self.assertEqual(py_utils.GetShape()[], 1)
    self.assertIsInstance(py_utils.GetShape()[], tf.Tensor)
    self.assertIsInstance(py_utils.GetShape()[], tf.Tensor)
    f = tf.placeholder()
    self.assertIsNone()
    self.assertIsInstance(py_utils.GetShape(), tf.Tensor)
  def testGetSize():
    a = tf.constant([])
    self.assertEqual(py_utils.GetSize(), 1)
    b = tf.constant([[]])
    self.assertEqual(py_utils.GetSize(), 2)
    d = tf.placeholder(tf.float32, shape=())
    self.assertIsInstance(py_utils.GetSize(), tf.Tensor)
    shape = tf.placeholder()
    f = py_utils.GetSize(tf.reshape())
    self.assertIsInstance()
    with self.session() as sess:
      f_v = sess.run(f, feed_dict={d:, shape:})
      self.assertEqual()
  def testUpdateFpropDtype():
    network_p = builder_layers.SequentialLayer.Params()
    linear_layer_p = builder_layers.LinearLayer.Params()
    linear_layer_p.input_dims =
    linear_layer_p.output_dims =
    network_p.sub.append()
    py_utils.UpdateFpropDtype()
    self.assertEqual(network_p.sub[].fprop_dtype, tf.bfloat16)
  def testUpdateDtype():
    network_p = builder_layers.SequentialLayer.Params()
    linear_layer_p = builder_layers.LinearLayer.Params()
    linear_layer_p.input_dims =
    linear_layer_p.output_dims =
    network_p.sub.append()
    py_utils.UpdateDtype()
    self.assertEqual(network_p.sub[].dtype, tf.bfloat16)
  def testGetRank():
    a = tf.constant([])
    self.assertEqual(py_utils.GetRank(), 1)
    b = tf.constant([[]])
    self.assertEqual(py_utils.GetRank(), 2)
    c = tf.zeros([1, a[], a.shape[], tf.shape()[]])
    self.assertEqual(py_utils.GetRank(), 4)
    d = tf.placeholder(tf.float32, shape=())
    self.assertEqual(py_utils.GetRank(), 2)
    e = tf.zeros([d.shape[], tf.shape()[], tf.shape()[]])
    self.assertEqual(py_utils.GetRank(), 3)
    f = tf.placeholder()
    self.assertIsNone()
    self.assertIsInstance(py_utils.GetRank(), tf.Tensor)
  def testRenamingRules():
    pc = py_utils.WeightParams([])
    with tf.variable_scope():
      v1 = py_utils.CreateVariable()
      with py_utils.VariableRenameScope([('model/()', 'data/%s')]):
        v2 = py_utils.CreateVariable()
      v3 = py_utils.CreateVariable()
    self.assertEqual(v1.name, 'model/v1/var:)
    self.assertEqual(v2.name, 'data/v2/var:)
    self.assertEqual(v3.name, 'model/v3/var:)
  def testOpportunisticReuse():
    pc = py_utils.WeightParams([])
    v1 = py_utils.CreateVariable()
    with self.assertRaises():
      py_utils.CreateVariable()
    with py_utils.OpportunisticVariableReuseScope():
      v2 = py_utils.CreateVariable()
      x1 = py_utils.CreateVariable()
      with py_utils.OpportunisticVariableReuseScope():
        with self.assertRaises():
          py_utils.CreateVariable()
      v3 = py_utils.CreateVariable()
    with self.assertRaises():
      py_utils.CreateVariable()
    for v in []:
      self.assertIs()
    self.assertIsNot()
  def testGetOrCreateGlobalStepVar():
    with tf.variable_scope():
      with tf.name_scope():
        gs1 = py_utils.GetOrCreateGlobalStepVar()
        gs2 = tf.train.get_global_step()
      gs3 = py_utils.GetOrCreateGlobalStepVar()
      gs4 = tf.train.get_global_step()
    gs5 = py_utils.GetOrCreateGlobalStepVar()
    gs6 = tf.train.get_global_step()
    for gs in []:
      self.assertIs()
    self.assertEqual(gs1.name, 'global_step:)
  def testCreateLocalTheta():
    methods = []
    dtypes = []
    shapes = [[], []]
    test_vars = py_utils.NestedMap()
    for i, () in enumerate(itertools.product()):
      pc = py_utils.WeightParams(sp, m(), dt, "")
      var = py_utils.CreateVariable()
      with tf.device():
        test_vars[] = tf.identity()
    test_devices = [""/job:worker/replica:0/device:GPU:]
    sharded_local_vars = py_utils.CreateLocalTheta()
    sharded_local_vars_list = sharded_local_vars.Flatten()
    for i, v in enumerate():
      expected_device = test_devices[i % len()]
      self.assertEqual()
  def testComputeGradient():
    with self.session(use_gpu=):
      a = tf.get_variable("", [])
      b = tf.get_variable("", [], trainable=)
      c = tf.get_variable("", [])
      e = tf.get_variable("", [])
      l = a + b + tf.stop_gradient()
      vmap = py_utils.NestedMap(a=, b=, c=, d=, n=py_utils.NestedMap(aa=, e=))
      var_grads = py_utils.ComputeGradients()
      self.assertEqual([_[] for _ in var_grads.FlattenItems()], [])
      self.assertEqual(var_grads.a.var.name, 'a:)
  def testVarGradNestFlatten():
    a = tf.get_variable("", [])
    b = tf.get_variable("", [])
    vs_gs = py_utils.NestedMap(a=py_utils.VarGrad(a,tf.ones_like() * 10.0),b=py_utils.VarGrad(b,tf.ones_like() * 0.5))
    flattened = tf.nest.flatten()
    self.assertLen()
    for x in flattened:
      self.assertIsInstance()
  def testClipSingleTensorGradients():
    a = tf.get_variable("", [])
    b = tf.get_variable("", [])
    vs_gs = py_utils.NestedMap(a=py_utils.VarGrad(a,tf.ones_like() * 10.0),b=py_utils.VarGrad(b,tf.ones_like() * 0.5))
    clipped = py_utils.ApplyGradNormClipping(vs_gs, norm=)
    with self.session(use_gpu=):
      self.evaluate(tf.global_variables_initializer())
      clipped_np = self.evaluate(clipped.Transform())
      self.assertAllClose(clipped_np.a[], 1.0)
      self.assertAllClose(clipped_np.b[], 0.5)
  def testMaskGradient():
    with self.session(use_gpu=):
      a = tf.get_variable("", [])
      b = tf.get_variable("", [])
      c = tf.get_variable("", [])
      d = tf.get_variable("", [])
      e = tf.get_variable("", [])
      l =
      zeros = tf.zeros(3, dtype=)
      select = tf.one_hot(1, 3, dtype=)
      vmap = py_utils.NestedMap(a=, b=, c=, d=, n=py_utils.NestedMap(aa=, e=))
      grad_mask = py_utils.NestedMap()
      grad_mask['a:] =
      grad_mask['b:] =
      grad_mask['c:] =
      grad_mask['d:] =
      grad_onehot = tf.one_hot(1, 3, dtype=)
      grad_mask = {k:,}
      var_grads = py_utils.ComputeGradients()
      var_grads_mask = py_utils.MaskGradients()
      self.evaluate(tf.global_variables_initializer())
      _, var_grads_mask_vals = self.evaluate([var_grads.Transform(),var_grads_mask.Transform()])
      self.assertEqual(var_grads_mask_vals[][], 0)
      self.assertEqual(var_grads_mask_vals[][], 0)
      self.assertEqual(var_grads_mask_vals[][], 1)
      self.assertEqual(var_grads_mask_vals[][], 1)
  def testSkipL2Regularization():
    with self.session(use_gpu=):
      beta = tf.get_variable("",initializer=tf.constant(np.arange().reshape([]), tf.float32))
      tf.add_to_collection()
      gamma = tf.get_variable("",initializer=tf.constant(np.arange().reshape([]), tf.float32))
      act = tf.constant(np.arange().reshape([]), tf.float32)
      pred =
      loss = tf.reduce_sum()
      vmap = py_utils.NestedMap(beta=, gamma=)
      var_grads = py_utils.ComputeGradients()
      self.assertCountEqual(var_grads.keys(), [])
      l2_loss, var_grads_with_l2 = py_utils.AdjustGradientsWithLpLoss(var_grads, 0.1, p=)
      self.evaluate(tf.global_variables_initializer())
      var_grads_vals, l2_loss_val, var_grads_with_l2_vals = self.evaluate([var_grads.Transform(), l2_loss,var_grads_with_l2.Transform()])
      self.assertAllEqual(var_grads_vals.beta[],var_grads_with_l2_vals.beta[])
      self.assertAllEqual(var_grads_vals.gamma[],var_grads_with_l2_vals.gamma[])
      self.assertAllEqual(l2_loss_val, 0.5 * 0.1 * np.sum(np.square(var_grads_vals.gamma[])))
      self.assertAllClose(var_grads_with_l2_vals.gamma[],var_grads_vals.gamma[] + 0.1 * var_grads_vals.gamma[])
      self.assertAllClose(var_grads_with_l2_vals.beta[],var_grads_vals.beta[])
  def testAdjustGradientsWithL2Loss():
    with self.session(use_gpu=):
      emb = tf.get_variable("",initializer=tf.constant(np.arange().reshape([]), tf.float32))
      act = tf.gather(emb, [])
      weight = tf.get_variable("", initializer=tf.constant(np.ones([]), tf.float32))
      bias = tf.get_variable("", initializer=tf.constant([]))
      pred = tf.matmul() + tf.stop_gradient()
      loss = tf.reduce_sum()
      vmap = py_utils.NestedMap(emb=, weight=, bias=)
      var_grads = py_utils.ComputeGradients()
      self.assertCountEqual(var_grads.keys(), [])
      for mode in ():
        if mode == "":
          l2_loss, var_grads_with_l2 = py_utils.AdjustGradientsWithLpLoss(var_grads, 0.1, p=)
        else:
          l2_loss, var_grads_with_l2 = py_utils.AdjustGradientsWithLpLoss(var_grads.Flatten(), 0.1, p=)
          var_grads_with_l2 = py_utils.Pack()
        self.evaluate(tf.global_variables_initializer())
        var_grads_vals, l2_loss_val, var_grads_with_l2_vals = self.evaluate([var_grads.Transform(), l2_loss,var_grads_with_l2.Transform()])
        self.assertAllEqual(var_grads_vals.emb[],var_grads_with_l2_vals.emb[])
        self.assertAllEqual(var_grads_vals.weight[],var_grads_with_l2_vals.weight[])
        self.assertAllEqual(l2_loss_val,0.5 * 0.1 * (np.sum(np.square(var_grads_vals.weight[])) +np.sum(np.square(var_grads_vals.emb[][2, :])) +np.sum(np.square(var_grads_vals.emb[][5, :]))))
        self.assertAllClose(var_grads_with_l2_vals.weight[],var_grads_vals.weight[] + 0.1 * var_grads_vals.weight[])
        self.assertAllClose(var_grads_with_l2_vals.emb[].indices,var_grads_vals.emb[].indices)
        self.assertAllClose(var_grads_with_l2_vals.emb[].indices,[])
        self.assertAllClose(var_grads_with_l2_vals.emb[].values, var_grads_vals.emb[].values +0.1 * np.array([[], [], [], [], []]) *var_grads_vals.emb[][[], :])
  def testSkipL1Regularization():
    with self.session(use_gpu=):
      beta = tf.get_variable("",initializer=tf.constant(np.arange().reshape([]), tf.float32))
      tf.add_to_collection()
      gamma = tf.get_variable("",initializer=tf.constant(np.arange().reshape([]), tf.float32))
      act = tf.constant(np.arange().reshape([]), tf.float32)
      pred =
      loss = tf.reduce_sum()
      vmap = py_utils.NestedMap(beta=, gamma=)
      var_grads = py_utils.ComputeGradients()
      self.assertCountEqual(var_grads.keys(), [])
      l1_loss, var_grads_with_l1 = py_utils.AdjustGradientsWithLpLoss(var_grads, 0.1, p=)
      self.evaluate(tf.global_variables_initializer())
      var_grads_vals, l1_loss_val, var_grads_with_l1_vals = self.evaluate([var_grads.Transform(), l1_loss,var_grads_with_l1.Transform()])
      self.assertAllEqual(var_grads_vals.beta[],var_grads_with_l1_vals.beta[])
      self.assertAllEqual(var_grads_vals.gamma[],var_grads_with_l1_vals.gamma[])
      self.assertAllEqual(l1_loss_val,0.1 * np.sum(np.abs(var_grads_vals.gamma[])))
  def testAdjustGradientsWithL1Loss():
    with self.session(use_gpu=):
      emb = tf.get_variable("",initializer=tf.constant(np.arange().reshape([]), tf.float32))
      act = tf.gather(emb, [])
      weight = tf.get_variable("", initializer=tf.constant(np.ones([]), tf.float32))
      bias = tf.get_variable("", initializer=tf.constant([]))
      pred = tf.matmul() + tf.stop_gradient()
      loss = tf.reduce_sum()
      vmap = py_utils.NestedMap(emb=, weight=, bias=)
      var_grads = py_utils.ComputeGradients()
      self.assertCountEqual(var_grads.keys(), [])
      l1_loss, var_grads_with_l1 = py_utils.AdjustGradientsWithLpLoss(var_grads, 0.1, p=)
      self.evaluate(tf.global_variables_initializer())
      var_grads_vals, l1_loss_val, var_grads_with_l1_vals = self.evaluate([var_grads.Transform(), l1_loss,var_grads_with_l1.Transform()])
      self.assertAllEqual(var_grads_vals.emb[], var_grads_with_l1_vals.emb[])
      self.assertAllEqual(var_grads_vals.weight[],var_grads_with_l1_vals.weight[])
      self.assertAllEqual(l1_loss_val, 0.1 * (np.sum(np.abs(var_grads_vals.weight[])) +np.sum(np.abs(var_grads_vals.emb[][2, :])) +np.sum(np.abs(var_grads_vals.emb[][5, :]))))
      self.assertAllClose(var_grads_with_l1_vals.weight[],var_grads_vals.weight[] + 0.1 * var_grads_vals.weight[])
      self.assertAllClose(var_grads_with_l1_vals.emb[].indices,var_grads_vals.emb[].indices)
  def testSplitAndConcat():
    with self.session():
      m3x4 = tf.constant(np.arange().reshape([]))
      splits = py_utils.SplitRecursively()
      self.assertLen()
      for split in splits:
        self.assertIsInstance()
      self.assertAllClose([[], [], []], splits[].eval())
      self.assertAllClose([[], [], []], splits[].eval())
      concatenated = py_utils.ConcatRecursively()
      self.assertAllClose(m3x4.eval(), concatenated.eval())
      splits = py_utils.SplitRecursively(m3x4, 3, axis=)
      self.assertLen()
      concatenated = py_utils.ConcatRecursively(splits, axis=)
      self.assertAllClose(m3x4.eval(), concatenated.eval())
      self.assertAllClose([[]], splits[].eval())
      list_3 = [] * 3
      splits = py_utils.SplitRecursively()
      for split in splits:
        self.assertIsInstance()
      for x in splits[]:
        self.assertAllClose([[], [], []], x.eval())
      for x in splits[]:
        self.assertAllClose([[], [], []], x.eval())
      concatenated = py_utils.ConcatRecursively()
      self.assertAllClose([x.eval() for x in list_3],[x.eval() for x in concatenated])
      map_ab = py_utils.NestedMap(a=, b=)
      splits = py_utils.SplitRecursively()
      for split in splits:
        self.assertIsInstance()
        self.assertIsInstance()
        self.assertIsInstance()
      for x in splits[].b:
        self.assertAllClose([[], [], []], x.eval())
      concatenated = py_utils.ConcatRecursively()
      self.assertAllClose(map_ab.a.eval(), concatenated.a.eval())
      self.assertAllClose([x.eval() for x in map_ab.b],[x.eval() for x in concatenated.b])
  def testFindNeeded():
    phs = [tf.placeholder('float32', shape=(), name="")for i in range()]
    p1, p2, p3, p4 =
    z1 =
    z2 =
    z1_needed = set(py_utils.FindNeededInList())
    z2_needed = set(py_utils.FindNeededInList(phs, []))
    z2_p4_needed = set(py_utils.FindNeededInList(phs, []))
    self.assertEqual(set([]), z1_needed)
    self.assertEqual(set([]), z2_needed)
    self.assertEqual(set([]), z2_p4_needed)
  def testArgMax():
    def Compute():
      with self.session(graph=tf.Graph()):
        x = tf.constant()
        y = py_utils.ArgMax()
        return self.evaluate([])
    np.random.seed()
    x, y = Compute(np.random.uniform(size=()))
    self.assertAllEqual(np.argmax(x, axis=), y)
    x, y = Compute(np.array([[], []]))
    self.assertAllEqual(np.argmax(x, axis=), y)
  def testPiecewiseConstant():
    boundaries = ()
    values = ()
    def _Eval():
      with self.session(use_gpu=):
        result = py_utils.PiecewiseConstant(x, boundaries, values, vdtype=)
        return self.evaluate()
    self.assertAlmostEqual(1e-3, _Eval())
    self.assertAlmostEqual(1e-3, _Eval())
    self.assertAlmostEqual(2e-4, _Eval())
    self.assertAlmostEqual(2e-4, _Eval())
    self.assertAlmostEqual(2e-4, _Eval())
    self.assertAlmostEqual(3e-5, _Eval())
    self.assertAlmostEqual(4e-6, _Eval())
    self.assertAlmostEqual(4e-6, _Eval())
  def testRepeatDim():
    x = tf.constant([[[], []], [[], []]])
    y = tf.transpose(x, [])
    z = tf.transpose(x, [])
    repeat_inner_dim0 = py_utils.RepeatDim()
    repeat_inner_dim1 = py_utils.RepeatDim()
    repeat_inner_dim2 = py_utils.RepeatDim()
    with self.session(use_gpu=):
      [] = self.evaluate([])
      self.assertAllEqual(repeat_inner_dim0,[[[], []], [[], []],[[], []], [[], []]])
      repeat_inner_dim = np.transpose(repeat_inner_dim0, [])
      self.assertAllEqual()
      repeat_inner_dim = np.transpose(repeat_inner_dim0, [])
      self.assertAllEqual()
  def testStackTensorsRecursively():
    with self.session(use_gpu=, graph=tf.Graph()):
      stacked = py_utils.StackTensorsRecursively([py_utils.NestedMap(x=tf.constant([]),y=py_utils.NestedMap(),z=py_utils.NestedMap(a=tf.constant([]),),),py_utils.NestedMap(x=tf.constant([]),y=py_utils.NestedMap(),z=py_utils.NestedMap(a=tf.constant([]),),),])
      self.evaluate(tf.global_variables_initializer())
      self.assertAllEqual(stacked.x, tf.constant([[], []]))
      self.assertAllEqual(stacked.z.a, tf.constant([[], []]))
  def testCumSum():
    with self.session(use_gpu=), mock.patch("", return_value=):
      np.random.seed()
      x = tf.constant(np.random.rand(), dtype=)
      rank = py_utils.GetRank()
      self.assertIsInstance()
      self.assertAllClose(py_utils.CumSum().eval(), tf.cumsum().eval())
      self.assertAllClose(py_utils.CumSum().eval(), tf.cumsum().eval())
      self.assertAllClose(py_utils.CumSum().eval(), tf.cumsum().eval())
      self.assertAllClose(py_utils.CumSum().eval(),tf.cumsum().eval())
      self.assertAllClose(py_utils.CumSum().eval(),tf.cumsum().eval())
      self.assertAllClose(py_utils.CumSum().eval(),tf.cumsum().eval())
      with self.assertRaises():
        py_utils.CumSum().eval()
  def testProjectLastDim():
    np.random.seed()
    input_dim =
    output_dim =
    inputs_p = np.random.rand()
    weight_p = np.random.rand()
    with self.session(use_gpu=), mock.patch("", return_value=):
      inputs = tf.constant(inputs_p, dtype=)
      weight = tf.constant(weight_p, dtype=)
      outputs = py_utils.ProjectLastDim()
      self.assertAllClose(outputs.eval(),np.einsum())
  def testAssertEvenDivide():
    with self.session():
      op = py_utils.assert_even_divide()
      self.evaluate()
      op = py_utils.assert_even_divide()
      with self.assertRaises():
        self.evaluate()
  def testTpuHostDecorator():
    with self.session(use_gpu=), mock.patch("", return_value=):
      def noop_outside_compilation():
        return func()
      mock_outside_compilation.side_effect =
      def foo():
        return bar() * x
      def bar():
        return tf.math.log()
      x = tf.random.uniform([])
      y = foo()
      unused_z =
      self.assertTrue(py_utils.use_tpu())
      self.assertEqual()
  def testRemoveAssertContext():
    def Op():
      with py_utils.RemoveAssertContext(remove=):
        x = py_utils.with_dependencies([tf.assert_equal(0, 1, message=)], x)
        x = py_utils.with_dependencies([tf.check_ops.assert_equal(0, 1, message=)], x)
      return x
    with self.session(use_gpu=):
      x = tf.ones(())
      y = Op()
      _ = self.evaluate()
  def testDefaultVnParams():
    default_vn = py_utils.DefaultVN()
    disable_vn = py_utils.DisableVN()
    self.assertNotEqual()
  def testShardedFilePatternToGlob():
    file_pattern =
    self.assertEqual("",py_utils.ShardedFilePatternToGlob())
    file_pattern =
    self.assertEqual("",py_utils.ShardedFilePatternToGlob())
    file_pattern =
    self.assertEqual("",py_utils.ShardedFilePatternToGlob())
    file_pattern =
    self.assertEqual("",py_utils.ShardedFilePatternToGlob())
    file_pattern =
    self.assertEqual("",py_utils.ShardedFilePatternToGlob())
    file_pattern =,/some/path/to/file2@8'
    with self.assertRaises():
      py_utils.ShardedFilePatternToGlob()
  def testComputeNceAndAuc():
    probs = tf.constant([[],[]])
    targets = tf.constant([[], []])
    mask = tf.constant([[], []])
    nce, auc = py_utils.ComputeNceAndAuc()
    with self.session():
      self.evaluate(tf.local_variables_initializer())
      nce_val, auc_val = self.evaluate([])
      self.assertAllClose()
      self.assertAllClose()
  def testGetSoftmaxProbsBySeqIndices():
    logits = tf.constant([[[], [], []],[[], [], []]],dtype=)
    indices = tf.constant([[], []])
    y = py_utils.GetSoftmaxProbsBySeqIndices()
    with tf.Session():
      y_val = self.evaluate()
      self.assertAllClose([[],[]], y_val)
class DeterministicDropoutTest():
  def testDeterministicDropoutTest():
    x = tf.ones([], dtype=)
    x = py_utils.DeterministicDropout(x, keep_prob=, seeds=[])
    with self.session():
      x_val = self.evaluate()
      self.assertAllClose([[],[],[],[],], x_val)
      self.assertAllClose(22.85714, np.sum())
      self.assertEqual()
class DeterministicVNTest():
  def testDeterministicVNTest():
    x = py_utils.DeterministicVN(py_utils.NestedMap({'fprop_dtype':}),seeds=[],noise_shape=np.asarray([]))
    with self.session():
      x_val = self.evaluate()
      self.assertAllClose([[], [],[]], x_val)
      self.assertAllClose(4.726707, np.sum())
      self.assertEqual()
class WeightedAvgTest():
  def testWeightedAvg():
    with self.session(use_gpu=):
      losses = tf.constant([])
      weights = tf.constant([])
      loss, weight = py_utils.WeightedAvg()
      expected = []
      actual = self.evaluate([])
      self.assertAllClose()
  def testWeightedAvgOfMetrics():
    with self.session(use_gpu=):
      metrics = [{'a':,'b':}, {'a':,'b':}]
      expected = {'a':, 'b':}
      weighted_avg = py_utils.WeightedAvgOfMetrics()
      actual = self.evaluate()
      self.assertDictEqual()
  def testConcatPerExampleTensors():
    with self.session(use_gpu=):
      per_example_1 = {'a':,,,'b':,,}
      per_example_2 = {'a':,,,'b':,,}
      expected = {'a':,,,,'b':,}
      stacked = py_utils.ConcatPerExampleTensors([])
      actual = self.evaluate()
      self.assertAllClose(actual[], expected[])
      self.assertAllClose(actual[], expected[])
      self.assertEqual(2, len())
  def testCombineMetrics():
    a = py_utils.NestedMap()
    a[] = ()
    a[] = ()
    b = py_utils.NestedMap()
    b[] = ()
    b[] = ()
    c = py_utils.NestedMap()
    c[] = ()
    combined = py_utils.CombineMetrics([(), (), ()])
    self.assertEqual(combined[], ())
    self.assertEqual(combined[], ())
    total_loss = combined[][] * combined[][]
    self.assertEqual()
  def testCombineMetricsKeyNotInAllMetrics():
    a = py_utils.NestedMap()
    a[] = ()
    b = py_utils.NestedMap()
    b[] = ()
    b[] = ()
    c = py_utils.NestedMap()
    c[] = ()
    with self.assertRaises():
      py_utils.CombineMetrics([(), (), ()])
class OverrideVarsFromCheckpointsTest():
  def _GetLeNetVarsFirstVal():
    with tf.variable_scope("", reuse=):
      conv0 = tf.get_variable()
      conv1 = tf.get_variable()
      fc_bias = tf.get_variable()
    conv0_val, conv1_val, fc_bias_val = self.evaluate([])
    return conv0_val[][][][], conv1_val[][][][], fc_bias_val[]
  def testOverrideVarsFromCheckpoint():
    with self.session(use_gpu=) as sess:
      tf.random.set_seed()
      cfg = model_registry.GetParams()
      with cluster_factory.ForTestingWorker(mode=, job=):
        cfg.Instantiate()
      self.evaluate(tf.global_variables_initializer())
      self.assertAllClose(self._GetLeNetVarsFirstVal(),[])
      checkpoint_path = test_helper.test_src_dir_path()
      variable_loading_rules = [(),()]
      variable_ignore_rules = []
      py_utils.OverrideVarsFromCheckpoint(tf.all_variables(), checkpoint_path,variable_loading_rules,variable_ignore_rules)()
      self.assertAllClose(self._GetLeNetVarsFirstVal(),[])
  def testOverrideVarsFromCheckpointWithIgnoreRules():
    with self.session(use_gpu=) as sess:
      tf.random.set_seed()
      cfg = model_registry.GetParams()
      with cluster_factory.ForTestingWorker(mode=, job=):
        cfg.Instantiate()
      self.evaluate(tf.global_variables_initializer())
      self.assertAllClose(self._GetLeNetVarsFirstVal(),[])
      checkpoint_path = test_helper.test_src_dir_path()
      variable_loading_rules = [(),()]
      variable_ignore_rules = []
      py_utils.OverrideVarsFromCheckpoint(tf.all_variables(), checkpoint_path,variable_loading_rules,variable_ignore_rules)()
      self.assertAllClose(self._GetLeNetVarsFirstVal(),[])
def _AddOne():
  return None if x is None else x + type()()
class NestedMapTest():
  _TUPLE = collections.namedtuple("", [])
  def _get_basic_test_inputs():
    m = py_utils.NestedMap()
    m.foo = [1, 20, []]
    m.bar = py_utils.NestedMap()
    m.bar.x =
    m.bar.y = [200, py_utils.NestedMap(z=)]
    return m
  def _get_advanced_test_inputs():
    m = py_utils.NestedMap()
    m.w =
    m.y = (200, py_utils.NestedMap(z=))
    m.x = {'foo':, 'bar':}
    m.z = self._TUPLE()
    m.zz = []
    return m
  def testBasic():
    x = py_utils.NestedMap()
    self.assertLen()
    x[] =
    self.assertEqual()
    self.assertEqual(100, x[])
    x.bar = py_utils.NestedMap({'baz':})
    self.assertEqual()
    self.assertNotIn()
  def testPrint():
    self.assertEqual(py_utils.NestedMap().DebugString(), "")
    expected =
    m = self._get_basic_test_inputs()
    self.assertEqual(m.DebugString(), expected)
    m = self._get_advanced_test_inputs()
    res = m.DebugString()
    w, x1, x2, y, z = res.split()
    self.assertEqual()
  def testTransformBasic():
    n = py_utils.Transform(_AddOne, py_utils.NestedMap())
    self.assertEqual(n.DebugString(), "")
    n = py_utils.NestedMap().Transform()
    self.assertEqual(n.DebugString(), "")
    expected =
    m = self._get_basic_test_inputs()
    n = py_utils.Transform()
    self.assertEqual(n.DebugString(), expected)
    n = m.Transform()
    self.assertEqual(n.DebugString(), expected)
    expected =
    self.assertEqual(m.DebugString(), expected)
  def testTransformAdvanced():
    m = self._get_advanced_test_inputs()
    original = [(),(),(),('y', (200, {'z':})),('z', self._TUPLE(x=, y=)),]
    self.assertEqual(m.FlattenItems(), original)
    expected = [(),(),(),('y', (201, {'z':})),('z', self._TUPLE(x=, y=)),]
    n = py_utils.Transform()
    self.assertEqual(n.zz, [])
    self.assertNotEqual()
    self.assertEqual(n.FlattenItems(), expected)
    with self.assertRaises():
      m.Transform()
    def _AddOneIgnoreError():
      try:
        return _AddOne()
      except TypeError:
        return x
    expected = [(),(),(),('y', (200, {'z':})),('z', self._TUPLE(x=, y=)),]
    n = m.Transform()
    self.assertEqual(n.zz, [])
    self.assertNotEqual()
    self.assertEqual(n.FlattenItems(), expected)
    self.assertEqual(m.FlattenItems(), original)
  def testFlattenBasic():
    self.assertEqual(py_utils.Flatten(py_utils.NestedMap()), [])
    self.assertEqual(py_utils.NestedMap().Flatten(), [])
    self.assertEqual(py_utils.NestedMap().FlattenItems(), [])
    expected = []
    m = self._get_basic_test_inputs()
    self.assertEqual(py_utils.Flatten(), expected)
    self.assertEqual(m.Flatten(), expected)
    expected_keys = ["", 'bar.y[]""bar.y[].z""foo[]""foo[]""foo[][]']
    self.assertEqual(m.FlattenItems(), list(zip()))
  def testFlattenAdvanced():
    m = self._get_advanced_test_inputs()
    expected = []
    self.assertEqual(py_utils.Flatten(), expected)
    expected = [None,'def',1,(200, {'z':}),self._TUPLE(x=, y=),]
    self.assertEqual(m.Flatten(), expected)
    expected = [(),(),(),('y', (200, {'z':})),('z', self._TUPLE(x=, y=)),]
    self.assertEqual(m.FlattenItems(), expected)
  def testPackBasic():
    n = py_utils.Pack(py_utils.NestedMap(), [])
    self.assertEqual(n.DebugString(), "")
    n = py_utils.NestedMap().Pack([])
    self.assertEqual(n.DebugString(), "")
    expected =
    m = self._get_basic_test_inputs()
    n = py_utils.Pack(m, list(range()))
    self.assertEqual(n.DebugString(), expected)
    n = m.Pack(list(range()))
    self.assertEqual(n.DebugString(), expected)
    expected =
    self.assertEqual(m.DebugString(), expected)
  def testPackAdvanced():
    m = self._get_advanced_test_inputs()
    expected = [(),(),(),('y', (3, {'z':})),('z', self._TUPLE(x=, y=)),]
    n = py_utils.Pack(m, list(range()) + [])
    self.assertEqual(n.zz, [])
    self.assertEqual(n.FlattenItems(), expected)
    expected = [(), (), (), (), ()]
    n = m.Pack(list(range()) + [])
    self.assertEqual(n.zz, [])
    self.assertEqual(n.FlattenItems(), expected)
    expected = [(),(),(),('y', (200, {'z':})),('z', self._TUPLE(x=, y=)),]
    self.assertEqual(m.FlattenItems(), expected)
  def testIsCompatible():
    empty = py_utils.NestedMap()
    self.assertTrue(empty.IsCompatible())
    self.assertTrue(py_utils.IsCompatible())
    self.assertTrue(empty.IsCompatible(py_utils.NestedMap(x=[])))
    self.assertFalse(py_utils.IsCompatible(empty, py_utils.NestedMap(x=[])))
    self.assertTrue(empty.IsCompatible(py_utils.NestedMap(x=)))
    self.assertFalse(py_utils.IsCompatible(empty, py_utils.NestedMap(x=)))
    self.assertTrue(empty.IsCompatible(py_utils.NestedMap(x={})))
    self.assertFalse(py_utils.IsCompatible(empty, py_utils.NestedMap(x={})))
    x = py_utils.NestedMap(a=, b=, c=py_utils.NestedMap(d=, e=[]))
    y = py_utils.NestedMap(a=, b=, c=py_utils.NestedMap(d=, e=[]))
    z = py_utils.NestedMap(a=, b=[], c=py_utils.NestedMap(d=, e=[]))
    self.assertTrue(x.IsCompatible())
    self.assertTrue(py_utils.IsCompatible())
    self.assertFalse(x.IsCompatible())
    self.assertFalse(py_utils.IsCompatible())
  def testFilter():
    x = py_utils.NestedMap(a=,b=,c=,d=py_utils.NestedMap(foo=, bar=, ok=[], ko=[]))
    y = x.Filter(lambda v:)
    self.assertEqual(y.FlattenItems(), [(), (), (),('d.ok[]', 200), ('d.ok[]', 300)])
    self.assertNotIn()
    y = x.Filter(lambda v:)
    self.assertLen(y.FlattenItems(), 0)
  def testFilterKeyVal():
    x = py_utils.NestedMap(a=,b=,c=,d=py_utils.NestedMap(foo=, bar=, ok=[], ko=[]))
    selected = {"", "", 'd.ok[]'}
    def Sel():
      return k in selected
    y = x.FilterKeyVal()
    self.assertEqual(y.FlattenItems(), [(), (),('d.ok[]', 300)])
  def testCopy():
    x = py_utils.NestedMap(a=, b=, c=py_utils.NestedMap(d=, e=[]))
    y =
    y.a =
    self.assertEqual()
    self.assertEqual()
    x = py_utils.NestedMap(a=, b=, c=py_utils.NestedMap(d=, e=[]))
    y = py_utils.NestedMap()
    self.assertNotEqual(id(), id())
    y.a =
    y.c.d =
    self.assertEqual()
    self.assertEqual()
    self.assertEqual()
    self.assertEqual()
    x = py_utils.NestedMap(a=, b=, c=py_utils.NestedMap(d=, e=[]))
    y = x.copy()
    self.assertNotEqual(id(), id())
    y.a =
    y.c.d =
    self.assertEqual()
    self.assertEqual()
    self.assertEqual()
    self.assertEqual()
  def testDeepCopy():
    class SomeObj:
      def __init__():
        self.foo =
    x = py_utils.NestedMap(a=,b=,c=py_utils.NestedMap(d=, e=[], obj=SomeObj()),f=[],g={},h=py_utils.NestedMap(),i=)
    y = copy.deepcopy()
    self.assertNotEqual(id(), id())
    y.a =
    y.c.e[] =
    y.c.obj.foo =
    y.f.append()
    y.h.foo =
    self.assertEqual()
    self.assertEqual(1, x.c.e[])
    self.assertEqual([], x.f)
    self.assertEqual({}, x.g)
    self.assertLen()
    self.assertEqual()
    self.assertEqual("", y.c.e[])
    self.assertEqual([], y.f)
    self.assertEqual({}, y.g)
    self.assertLen()
    self.assertEqual()
    self.assertIsNone()
    self.assertEqual()
    self.assertEqual()
    self.assertEqual(id(), id())
  def testAttrAccess():
    a = py_utils.NestedMap()
    a.a1 =
    self.assertEqual()
    self.assertEqual(10, a[])
    self.assertEqual(10, a.get())
    self.assertEqual(10, a.get())
    self.assertEqual(10, getattr())
    a[] =
    self.assertEqual()
    self.assertEqual(20, a[])
    self.assertEqual(20, a.get())
    self.assertEqual(20, a.get())
    self.assertEqual(20, getattr())
    with self.assertRaisesRegex():
    with self.assertRaises():
    with self.assertRaisesRegex():
      a.get =
    with self.assertRaisesRegex():
      a[] =
    with self.assertRaisesRegex():
      _ = py_utils.NestedMap(get=)
    del a.a1
    with self.assertRaisesRegex():
    with self.assertRaisesRegex():
      del a.a2
class ReadOnlyAttrDictViewTest():
  def testWrapping():
    backing = dict()
    view = py_utils.ReadOnlyAttrDictView()
    backing[] =
    self.assertEqual(1, view[])
    self.assertEqual()
    with self.assertRaises():
      view[] =
    self.assertEqual(1, view[])
    with self.assertRaises():
      view.test =
    self.assertEqual(1, view[])
    with self.assertRaises():
      del view.test
    self.assertEqual(1, view[])
    with self.assertRaises():
      del view[]
    self.assertEqual(1, view[])
class PadPadSequenceToTest():
  def test2DInputs():
    with self.session(use_gpu=, graph=tf.Graph()):
      x = tf.random.normal(shape=(), seed=)
      padding = tf.constant([[], [], []], tf.float32)
      length =
      new_xs, new_padding = py_utils.PadSequenceTo([], padding, length, 0)
      real_xs, real_padding = self.evaluate([])
      expected_x = [[],[],[],]
      expected_padding = [[],[],[],]
      self.assertAllClose([], real_xs)
      self.assertAllClose()
  def testSingleInput():
    with self.session(use_gpu=, graph=tf.Graph()):
      x = tf.random.normal(shape=(), seed=)
      padding = tf.constant([[], [], []], tf.float32)
      length =
      new_x, new_padding = py_utils.PadSequenceTo()
      real_x, real_padding = self.evaluate([])
      expected_x = [[],[],[],]
      expected_padding = [[],[],[],]
      self.assertAllClose()
      self.assertAllClose()
class PadSequenceDimensionTest():
  def testPadSequenceDimension_2D():
    with self.session(use_gpu=, graph=tf.Graph()):
      x = tf.random.normal(shape=(), seed=)
      length =
      padded_x = py_utils.PadSequenceDimension()
      self.assertEqual(padded_x.shape.as_list(), [])
      real_x = self.evaluate()
      expected_x = [[],[],[],]
      self.assertAllClose()
  def testPadSequenceDimension_2D_UnknownShape():
    with self.session(use_gpu=, graph=tf.Graph()) as sess:
      shape = tf.placeholder()
      x = tf.random.normal(shape=, seed=)
      length =
      padded_x = py_utils.PadSequenceDimension()
      self.assertEqual(padded_x.shape, tf.TensorShape())
      real_x = sess.run(padded_x, feed_dict={shape:})
      expected_x = [[],[],[],]
      self.assertAllClose()
  def testPadSequenceDimension_ShortPaddingLength():
    x = tf.random.normal(shape=(), seed=)
    length =
    with self.assertRaisesRegex():
      py_utils.PadSequenceDimension()
  def testPadSequenceDimension_4D():
    with self.session(use_gpu=, graph=tf.Graph()):
      x = tf.random.normal(shape=(), seed=)
      length =
      padded_x = py_utils.PadSequenceDimension()
      real_x = self.evaluate()
      expected_x = [[[[], []],[[], []],[[], []], [[], []]],[[[], []],[[], []],[[], []], [[], []]],]
      self.assertAllClose()
  def testPadSequenceDimension_UnmatchedShape():
    with self.session(use_gpu=, graph=tf.Graph()):
      x = tf.random.normal(shape=(), seed=)
      length =
      self.assertRaises(ValueError, py_utils.PadSequenceDimension, x, length, 0,())
class PadOrTrimToTest():
  def test2DConstantShapePad():
    with self.session(use_gpu=, graph=tf.Graph()):
      x = tf.random.normal(shape=(), seed=)
      shape = []
      padded_x_right = py_utils.PadOrTrimTo(x, shape, pad_val=)
      padded_x_left = py_utils.PadOrTrimTo(x, shape, pad_val=, pad_after_contents=)
      self.assertEqual(padded_x_right.shape.as_list(), [])
      self.assertEqual(padded_x_left.shape.as_list(), [])
      real_x_right, real_x_left = self.evaluate([])
      expected_x_right = [[],[],[],[],]
      self.assertAllClose()
      expected_x_left = [[],[],[],[],]
      self.assertAllClose()
  def test2DConstantShapeTrim():
    with self.session(use_gpu=, graph=tf.Graph()):
      x = tf.random.normal(shape=(), seed=)
      shape = []
      trimmed_x_right = py_utils.PadOrTrimTo(x, shape, pad_val=)
      trimmed_x_left = py_utils.PadOrTrimTo(x, shape, pad_val=, pad_after_contents=)
      self.assertEqual(trimmed_x_right.shape.as_list(), [])
      self.assertEqual(trimmed_x_left.shape.as_list(), [])
      real_x_right, real_x_left = self.evaluate([])
      expected_x_right = [[]]
      self.assertAllClose()
      expected_x_left = [[]]
      self.assertAllClose()
  def test2DStaticShape():
    with self.session(use_gpu=, graph=tf.Graph()):
      x = tf.random.normal(shape=(), seed=)
      y = tf.zeros(shape=())
      padded_x = py_utils.PadOrTrimTo(x, y.shape, pad_val=)
      self.assertEqual(padded_x.shape.as_list(), [])
      real_x = self.evaluate()
      expected_x = [[],[],[],[],]
      self.assertAllClose()
  def test2DDynamicShape():
    with self.session(use_gpu=, graph=tf.Graph()) as sess:
      x = tf.random.normal(shape=(), seed=)
      y = tf.placeholder(dtype=)
      padded_x = py_utils.PadOrTrimTo(x, tf.shape(), pad_val=)
      self.assertEqual(padded_x.shape, tf.TensorShape())
      real_x = sess.run(padded_x, feed_dict={y:})
      expected_x = [[],[],[],[],]
      self.assertAllClose()
  def testDynamicTensorShapeRaises():
    tensor = tf.zeros(shape=[])
    shape = tf.TensorShape([])
    with self.assertRaises():
      py_utils.PadOrTrimTo()
  def test4D():
    with self.session(use_gpu=, graph=tf.Graph()):
      x = tf.random.normal(shape=(), seed=)
      shape = ()
      padded_x = py_utils.PadOrTrimTo(x, shape, pad_val=)
      real_x = self.evaluate()
      expected_x = [[[[],[],[],]]]
      self.assertAllClose()
class ApplyPaddingTest():
  def testApplyPaddingToZeroWithBroadcast():
    with self.session():
      y = py_utils.ApplyPadding(tf.convert_to_tensor([[], [], []]),tf.convert_to_tensor([[], [], []])).eval()
      self.assertAllClose(y, [[], [], []])
  def testApplyPaddingToConstWithBroadcast():
    with self.session():
      y = py_utils.ApplyPadding(tf.convert_to_tensor([[], [], []]),tf.convert_to_tensor([[], [], []]),tf.convert_to_tensor([[], [], []])).eval()
      self.assertAllClose(y, [[], [], []])
  def testApplyPaddingToZeroWithoutBroadcast():
    with self.session():
      y = py_utils.ApplyPadding(tf.convert_to_tensor([[], [], []]),tf.convert_to_tensor([[], [], []])).eval()
      self.assertAllClose(y, [[], [], []])
  def testApplyPaddingToZeroWithBroadcastArithmetic():
    with self.session():
      y = py_utils.ApplyPadding(tf.convert_to_tensor([[], [], []]),tf.convert_to_tensor([[], [], []]),use_select=).eval()
      self.assertAllClose(y, [[], [], []])
  def testApplyPaddingToZeroWithoutBroadcastArithmetic():
    with self.session():
      y = py_utils.ApplyPadding(tf.convert_to_tensor([[], [], []]),tf.convert_to_tensor([[], [], []]),use_select=).eval()
      self.assertAllClose(y, [[], [], []])
class LengthsFromPaddingsTest():
  def testBasic():
    with self.session():
      paddings = np.array([[],[],[],[],])
      lengths = py_utils.LengthsFromPaddings(tf.convert_to_tensor()).eval()
      self.assertAllEqual([], lengths)
  def testZeroLength():
    with self.session():
      paddings = np.zeros([])
      lengths = py_utils.LengthsFromPaddings(tf.convert_to_tensor()).eval()
      self.assertAllEqual([], lengths)
  def testBFloat16():
    with self.session():
      actual_lengths = []
      paddings = 1.0 - tf.sequence_mask(actual_lengths, maxlen=actual_lengths[], dtype=)
      lengths = py_utils.LengthsFromPaddings().eval()
      self.assertAllEqual()
class PaddingsFromLengthsTest():
  def testBasic():
    with self.session():
      expected = np.array([[],[],[],[],])
      lengths = np.array([])
      actual = py_utils.PaddingsFromLengths(tf.convert_to_tensor()).eval()
      self.assertAllEqual()
  def testZeroLength():
    with self.session():
      expected = np.zeros([])
      lengths = np.array([])
      actual = py_utils.PaddingsFromLengths(tf.convert_to_tensor()).eval()
      self.assertAllEqual()
  def testMaxLen():
    with self.session():
      expected = np.array([[],[],[],[],])
      lengths = np.array([])
      actual = py_utils.PaddingsFromLengths(tf.convert_to_tensor(), maxlen=).eval()
      self.assertAllEqual()
  def testMaxLenTooShort():
    with self.session():
      lengths = np.array([])
      with self.assertRaisesRegex():
        py_utils.PaddingsFromLengths(tf.convert_to_tensor(), maxlen=).eval()
class TrimTrailingPaddingsTest():
  def test2D():
    with self.session(use_gpu=, graph=tf.Graph()):
      np.random.seed()
      x = np.random.normal(size=())
      padding = np.array([[],[],[],])
      trimmed_x, trimmed_padding = self.evaluate(py_utils.TrimTrailingPaddings(x, tf.convert_to_tensor()))
      self.assertAllEqual(x[:, :], trimmed_x)
      self.assertAllEqual(padding[:, :], trimmed_padding)
  def test2D_UnknownShape():
    with self.session(use_gpu=, graph=tf.Graph()) as sess:
      shape = tf.placeholder()
      x = tf.random.normal(shape=, seed=)
      padding = np.array([[],[],[],])
      actual_x, () = sess.run([x,py_utils.TrimTrailingPaddings(x, tf.convert_to_tensor())],feed_dict={shape:})
      self.assertAllEqual(actual_x[:, :], trimmed_x)
      self.assertAllEqual(padding[:, :], trimmed_padding)
  def test4D():
    with self.session(use_gpu=, graph=tf.Graph()):
      np.random.seed()
      x = np.random.normal(size=())
      padding = np.array([[],[],[],])
      trimmed_x, trimmed_padding = self.evaluate(py_utils.TrimTrailingPaddings(x, tf.convert_to_tensor()))
      self.assertAllEqual(x[:, :], trimmed_x)
      self.assertAllEqual(padding[:, :], trimmed_padding)
  def testNoPadding():
    with self.session(use_gpu=, graph=tf.Graph()):
      np.random.seed()
      x = np.random.normal(size=())
      padding = np.array([[],[],[],])
      trimmed_x, trimmed_padding = self.evaluate(py_utils.TrimTrailingPaddings(x, tf.convert_to_tensor()))
      self.assertAllEqual()
      self.assertAllEqual()
  def testLeadingPaddingOnly():
    with self.session(use_gpu=, graph=tf.Graph()):
      np.random.seed()
      x = np.random.normal(size=())
      padding = np.array([[],[],[],])
      trimmed_x, trimmed_padding = self.evaluate(py_utils.TrimTrailingPaddings(x, tf.convert_to_tensor()))
      self.assertAllEqual()
      self.assertAllEqual()
  def testAllPadded():
    with self.session(use_gpu=, graph=tf.Graph()):
      np.random.seed()
      x = np.random.normal(size=())
      padding = np.array([[],[],[],])
      trimmed_x, trimmed_padding = self.evaluate(py_utils.TrimTrailingPaddings(x, tf.convert_to_tensor()))
      self.assertAllEqual([], trimmed_x.shape)
      self.assertAllEqual(padding[:, :], trimmed_padding)
class ReversePaddedSequenceTest():
  def testReversePaddedSequence():
    with self.session(use_gpu=):
      inputs = tf.constant([[[], [], []], [[], [], []],[[], [], []], [[], [], []]],dtype=)
      paddings = tf.constant([[[], [], []], [[], [], []], [[], [], []], [[], [], []]],dtype=)
      actual_output = py_utils.ReversePaddedSequence().eval()
      expected_output = np.array([[[], [], []],[[], [], []],[[], [], []],[[], [], []]]).astype()
      self.assertAllClose()
class ConcatenatePaddedSequencesTest():
  def _ComputeFloatOutputAndVerify(self,input0,input1,seq_lens0,seq_lens1,tranpose_input=):
    with self.session(use_gpu=):
      expected_output_seq_lens =
      batch_size, input0_seq_dim =
      input1_seq_dim = input1.shape[]
      padding0 = 1.0 - tf.sequence_mask(seq_lens0, maxlen=, dtype=)
      padding1 = 1.0 - tf.sequence_mask(seq_lens1, maxlen=, dtype=)
      if tranpose_input:
        seq_dim =
        tf_input0 = tf.constant(np.transpose())
        tf_input1 = tf.constant(np.transpose())
        tf_padding0 = tf.transpose()
        tf_padding1 = tf.transpose()
      else:
        seq_dim =
        tf_input0 = tf.constant()
        tf_input1 = tf.constant()
        tf_padding0 =
        tf_padding1 =
      actual_outputs = self.evaluate(py_utils.ConcatenatePaddedSequences(tf_input0,tf_input1,padding0=,padding1=,seq_dim=))
      if tranpose_input:
        actual_outputs = (np.transpose(actual_outputs[]),np.transpose(actual_outputs[]))
      for batch in range():
        expected_output = np.concatenate((input0[batch, :seq_lens0[]],input1[batch, :seq_lens1[]]))
        self.assertAllClose(expected_output,actual_outputs[][batch, :expected_output_seq_lens[]])
        expected_padding = np.ones(()).astype()
        expected_padding[:(seq_lens0[] + seq_lens1[])] =
        self.assertAllClose(expected_padding, actual_outputs[][batch, :])
  def testConcatenateFloatFeatures():
    input0 = np.array([[], []]).astype()
    seq_lens0 = np.array([])
    input1 = np.array([[], []]).astype()
    seq_lens1 = np.array([])
    batch_size, input0_seq_dim =
    input1_seq_dim = input1.shape[]
    no_padding_seq_lens0 = np.array([] * batch_size)
    no_padding_seq_lens1 = np.array([] * batch_size)
    self._ComputeFloatOutputAndVerify()
    self._ComputeFloatOutputAndVerify()
    self._ComputeFloatOutputAndVerify()
    self._ComputeFloatOutputAndVerify()
class RetryTest():
  def testRetry():
    max_retries =
    def Foo():
      state[] +=
      raise ValueError()
    try:
      state = {'count':, 'msg':}
      Foo()
    except Exception as e:
    self.assertEqual(1 + max_retries, state[])
class MixByWeightTest():
  def testMixByWeight():
    var_a = tf.get_variable("", trainable=, initializer=)
    var_b = tf.get_variable("", trainable=, initializer=)
    with self.session():
      self.evaluate(tf.global_variables_initializer())
      def _AddFn():
        return lambda: tf.assign_add()
      op, _ = py_utils.MixByWeight([_AddFn(), _AddFn()], [],seed=)
      for _ in range():
        self.evaluate()
      a, b = self.evaluate([])
      self.assertEqual()
      self.assertGreater()
      self.assertLess()
  def testMixByWeightWithDynamicWeights():
    var_a = tf.get_variable("", trainable=, initializer=)
    var_b = tf.get_variable("", trainable=, initializer=)
    var_w = tf.get_variable("", trainable=, dtype=, shape=[])
    with self.session():
      self.evaluate(tf.global_variables_initializer())
      def _AddFn():
        return lambda: tf.assign_add()
      op, _ = py_utils.MixByWeight([_AddFn(), _AddFn()], var_w)
      self.evaluate([tf.assign(var_w, [])])
      for _ in range():
        self.evaluate()
      a, b = self.evaluate([])
      self.assertEqual()
      self.assertEqual()
      self.evaluate([tf.assign(var_w, [])])
      for _ in range():
        self.evaluate()
      a, b = self.evaluate([])
      self.assertEqual()
      self.assertEqual()
  def testMixByWeightAndBpropType():
    var_a = tf.get_variable("", trainable=, initializer=)
    var_b = tf.get_variable("", trainable=, initializer=)
    with self.session():
      self.evaluate(tf.global_variables_initializer())
      def _AddFn():
        return lambda: tf.assign_add()
      op, bprop = py_utils.MixByWeight([_AddFn(), _AddFn()], [])
      for _ in range():
        self.evaluate()
      bprop_v, a, b = self.evaluate([])
      self.assertEqual()
      self.assertEqual()
      self.assertAllClose(np.array([]), np.squeeze())
      op, bprop = py_utils.MixByWeight([_AddFn(), _AddFn()], [])
      for _ in range():
        self.evaluate()
      bprop_v, a, b = self.evaluate([])
      self.assertEqual()
      self.assertEqual()
      self.assertAllClose(np.array([]), np.squeeze())
class SequencesToDebugStrings():
  def testSequencesToDebugStrings():
    with self.session():
      self.assertAllEqual([b'[]""[]'],py_utils.SequencesToDebugStrings(tf.constant([[], []],dtype=),tf.constant([], dtype=)).eval())
class StepSeedTest():
  def _testStepSeedHelper():
    state0 = py_utils.NestedMap(input=tf.constant(0, dtype=),seed_pair=tf.zeros(2, dtype=))
    inputs = py_utils.NestedMap(input=tf.range(10, dtype=))
    p = base_layer.BaseLayer.Params().Set(name=)
    accumulated_states, _ = recurrent.Recurrent(p.Instantiate().theta, state0,inputs, step_fn)
    self.evaluate(tf.global_variables_initializer())
    accumulated_states = accumulated_states.Pack(self.evaluate(accumulated_states.Flatten()))
    self.assertAllEqual(np.arange(), accumulated_states.input)
    global_steps, step_seeds = zip()
    self.assertAllEqual(np.zeros(), global_steps)
    self.assertAllEqual(np.arange(), step_seeds - step_seeds[])
    return step_seeds[]
  def testStepSeed():
    p = base_layer.BaseLayer.Params()
    def RecurrentStep():
      state1 = py_utils.NestedMap()
      state1.input =
      state1.seed_pair = py_utils.GenerateStepSeedPair()
      return state1, py_utils.NestedMap()
    with self.session(graph=tf.Graph()) as sess:
      step_seed = self._testStepSeedHelper()
      step_seed2 = self._testStepSeedHelper()
      self.assertNotEqual()
    def RecurrentStep2():
      with tf.control_dependencies([tf.no_op()]):
        return RecurrentStep()
    with self.session(graph=tf.Graph()) as sess:
      step_seed3 = self._testStepSeedHelper()
      step_seed4 = self._testStepSeedHelper()
      self.assertEqual()
      self.assertEqual()
    with self.session(graph=tf.Graph()) as sess:
      with tf.name_scope():
        step_seed5 = self._testStepSeedHelper()
        step_seed6 = self._testStepSeedHelper()
        self.assertEqual()
        self.assertNotEqual()
class WeightParamsTest():
  def testShapeModification():
    pc = py_utils.WeightParams([],py_utils.WeightInit.UniformPositive(),tf.float32)
    pc.shape = []
    var = py_utils.CreateVariable()
    self.assertEqual(var.shape, [])
class WeightInitTest():
  def testModification():
    w_init = py_utils.WeightInit.UniformPositive()
    with self.assertRaisesRegex():
      w_init.scale =
  def testUniformPositive():
    with self.session(use_gpu=, graph=tf.Graph()):
      tf.random.set_seed()
      pc = py_utils.WeightParams([],py_utils.WeightInit.UniformPositive(),tf.float32)
      var = py_utils.CreateVariable()
      self.evaluate(tf.global_variables_initializer())
      var_v = var.eval()
      self.assertTrue(np.all(var_v >=))
      self.assertTrue(np.all(var_v <=))
  def testCategory():
    with self.session(use_gpu=, graph=tf.Graph()):
      tf.random.set_seed()
      pc = py_utils.WeightParams([], py_utils.WeightInit.Category(),tf.float32)
      var = py_utils.CreateVariable()
      self.evaluate(tf.global_variables_initializer())
      var_v = var.eval()
      self.assertEqual({}, set(np.unique()))
  def testKaimingUniformRelu():
    with self.session(use_gpu=, graph=tf.Graph()):
      pc = py_utils.WeightParams([], py_utils.WeightInit.KaimingUniformFanInRelu(),tf.float32)
      var = py_utils.CreateVariable()
      self.evaluate(tf.global_variables_initializer())
      var_v = var.eval()
      bound = np.sqrt() * np.sqrt() / np.sqrt()
      self.assertTrue(np.all(var_v >=))
      self.assertTrue(np.all(var_v <=))
  def testKaimingUniformLeakyRelu():
    with self.session(use_gpu=, graph=tf.Graph()):
      pc = py_utils.WeightParams([], py_utils.WeightInit.KaimingUniformFanInLeakyRelu(),tf.float32)
      var = py_utils.CreateVariable()
      self.evaluate(tf.global_variables_initializer())
      var_v = var.eval()
      bound = np.sqrt() * np.sqrt() / np.sqrt()
      self.assertTrue(np.all(var_v >=))
      self.assertTrue(np.all(var_v <=))
class RNNCellStateInitTest():
  def testZeros():
    with self.session(use_gpu=, graph=tf.Graph()):
      tf.random.set_seed()
      zero_state = py_utils.InitRNNCellState([], init=py_utils.RNNCellStateInit.Zeros(), dtype=)
      self.evaluate(tf.global_variables_initializer())
      zero_state_v = zero_state.eval()
      expected_zero_state = [[], []]
      self.assertAllClose()
  def testRandomNormal():
    with self.session(use_gpu=, graph=tf.Graph()):
      tf.random.set_seed()
      zero_state = py_utils.InitRNNCellState([],init=py_utils.RNNCellStateInit.RandomNormal(seed=),dtype=)
      self.evaluate(tf.global_variables_initializer())
      zero_state_v = zero_state.eval()
      expected_zero_state = [[],[]]
      self.assertAllClose()
  def testRandomNormalStatelessVarsInit():
    with self.session(use_gpu=, graph=tf.Graph()):
      tf.random.set_seed()
      zero_state = py_utils.InitRNNCellState([],name=,init=py_utils.RNNCellStateInit.RandomNormal(seed=),dtype=)
      self.evaluate(tf.global_variables_initializer())
      zero_state_v = zero_state.eval()
      expected_zero_state = [[],[]]
      self.assertAllClose()
      zero_state_v_bis = zero_state.eval()
      self.assertAllClose()
  def testRandomNormalInEval():
    with self.session(use_gpu=, graph=tf.Graph()):
      tf.random.set_seed()
      zero_state = py_utils.InitRNNCellState([],init=py_utils.RNNCellStateInit.RandomNormal(seed=),dtype=,is_eval=)
      self.evaluate(tf.global_variables_initializer())
      zero_state_v = zero_state.eval()
      expected_zero_state = [[], []]
      self.assertAllClose()
class RematerializeFnTest():
  def testRandomNormal():
    with self.session(use_gpu=, graph=tf.Graph()):
      tf.random.set_seed()
      a = tf.random.normal([])
      b = tf.random.normal([])
      def Fn():
        c = tf.matmul()
        d = tf.nn.sigmoid()
        e = tf.nn.tanh()
        return d, e
      d1, e1 = Fn()
      d2, e2 = py_utils.RematerializeFn()
      self.assertEqual(d2.shape.as_list(), [])
      self.assertEqual(e2.shape.as_list(), [])
      da1, db1 = tf.gradients([], [])
      da2, db2 = tf.gradients([], [])
      self.evaluate(tf.global_variables_initializer())
      v1, v2, v3, v4 = self.evaluate([])
      self.assertAllEqual()
      self.assertAllEqual()
def WrapFunction(*dtypes, noinline=):
  if py_utils._UseTfFunction():
    def Decorated():
      def Fn():
        return fn()
      return Fn.get_concrete_function()
    return Decorated
  else:
    return tf.Defun(*dtypes, noinline=)
class StatefulRandomOpsInDefunTest():
  def testFunctionWithStatelessOp():
    def FunctionWithStatelessOp():
      return tf.constant()
    self.assertAllEqual([], py_utils.StatefulRandomOpsInDefun())
  def testFunctionWithStatefulOp():
    def FunctionWithStatefulOp():
      return tf.random.uniform([], maxval=, dtype=)
    self.assertAllEqual([],py_utils.StatefulRandomOpsInDefun())
  def testFunctionWithStatelessFunctionCall():
    def FunctionWithStatelessOp():
      return tf.constant()
    def FunctionWithStatelessFunctionCall():
      return FunctionWithStatelessOp()
    self.assertAllEqual([],py_utils.StatefulRandomOpsInDefun())
  def testFunctionWithStatefulFunctionCall():
    def FunctionWithStatefulOp():
      return tf.random.uniform([], maxval=, dtype=)
    def FunctionWithStatefulFunctionCall():
      return FunctionWithStatefulOp()
    self.assertAllEqual([],py_utils.StatefulRandomOpsInDefun())
  def testFunctionWithStatefulFunctionalWhile():
    def FunctionWithStatefulFunctionalWhile():
      def Cond():
        del result
        return tf.less()
      def Body():
        return (result + tf.random.uniform(tf.shape()), i + 1)
      return functional_ops.While([tf.zeros([]), 0], cond=, body=)
    self.assertAllEqual([],py_utils.StatefulRandomOpsInDefun())
  def testFunctionWithStatefulFunctionalIf():
    def FunctionWithStatefulFunctionalIf():
      def ThenFn():
        return tf.abs()
      def ElseFn():
        return tf.random.uniform(tf.shape())
      return functional_ops.If(tf.greater(tf.eye(), 0.5), [tf.eye()], ThenFn, ElseFn)
    self.assertAllEqual([],py_utils.StatefulRandomOpsInDefun())
  def testFunctionWithStatefulFunctionalFor():
    def FunctionWithStatefulFunctionalFor():
      def Body():
        return [result + tf.random.uniform(tf.shape()) +tf.random.poisson(shape=tf.shape(), lam=[])]
      return functional_ops.For(start=, limit=, delta=, inputs=[tf.eye()], body=)
    self.assertAllEqual([],sorted(py_utils.StatefulRandomOpsInDefun()))
  def testFunctionWithStatelessFunctionalFor():
    def FunctionWithStatelessFunctionalFor():
      def Body():
        return [result +tf.random.stateless_normal(tf.shape(), seed=tf.stack([]))]
      return functional_ops.For(start=, limit=, delta=, inputs=[tf.eye()], body=)
    self.assertAllEqual([],py_utils.StatefulRandomOpsInDefun())
class RecordFormatTest():
  def testRecordFormatFromFilePattern():
    record_format, path = py_utils.RecordFormatFromFilePattern('tfrecord:)
    self.assertEqual()
    self.assertEqual()
    record_format, path = py_utils.RecordFormatFromFilePattern('custom:)
    self.assertEqual()
    self.assertEqual()
class ReadFileLinesTest():
  def testReadFileLines():
    contents = []
    outpath = os.path.join(tf.test.get_temp_dir(), "")
    with tf.io.gfile.GFile() as f:
      f.write("".join())
    lines = [line.strip() for line in py_utils.ReadFileLines()]
    self.assertAllEqual()
  def testReadFilesLinesFromPackage():
    lines = py_utils.ReadFileLines()
    self.assertIsNotNone()
  def testReadFileLinesWithInvalidFile():
    path = os.path.join(tf.test.get_temp_dir(), "")
    with self.assertRaises():
      py_utils.ReadFileLines()
class FocalLossTest():
  def _testNpFL():
    self.assertEqual()
    shape =
    logits = logits.reshape([])
    labels = labels.reshape([])
    def _Sigmoid():
      return 1.0 / (1.0 + np.exp())
    def _CrossEntropy():
      if label > 0:
        return -np.log()
      else:
        return -np.log()
    probabilities = _Sigmoid()
    ans = np.empty()
    for i, () in enumerate(zip()):
      ce = _CrossEntropy()
      pt = () + (() * ())
      if alpha is not None:
        ce *= () + (() * ())
      if gamma is not None:
        ce *= np.power()
      ans[] =
    return ans.reshape()
  def _testTfFL():
    with self.session() as sess:
      x = tf.placeholder()
      y = tf.placeholder()
      z = py_utils.SigmoidCrossEntropyFocalLoss()
      return sess.run(z, feed_dict={x:, y:})
  def testSigmoidCrossEntropyFocalLoss():
    logits = np.random.normal(scale=, size=())
    labels = np.floor(np.random.uniform(size=()) + 0.2)
    for () in [(), (), (), ()]:
      np_result = self._testNpFL()
      tf_lingvo_result = self._testTfFL()
      self.assertAllClose()
  def _testNpSCEFL():
    probs = np.exp(logits - np.max(logits, axis=, keepdims=))
    probs = probs / np.sum(probs, axis=, keepdims=)
    shape = probs.shape[:]
    probs = probs.reshape([-1, probs.shape[]])
    ans = np.empty(probs.shape[:])
    if labels.shape != logits.shape:
      label_probs = np.zeros()
      label_probs[np.arange(), labels.reshape([])] =
    else:
      label_probs = labels.reshape([-1, labels.shape[]])
    for i, () in enumerate(zip()):
      ce = lp * -np.log()
      if alpha is not None:
        ce *=
      if gamma is not None:
        ce *= np.power()
      ans[] = ce.sum()
    ans = ans.reshape()
    return ans
  def _testTfSCEFLLabelIds():
    with self.session() as sess:
      x = tf.placeholder()
      y = tf.placeholder()
      z = py_utils.SoftmaxCrossEntropyFocalLoss(x, label_ids=, alpha=, gamma=)
      return sess.run(z, feed_dict={x:, y:})
  def _testTfSCEFLLabelProbs():
    with self.session() as sess:
      x = tf.placeholder()
      y = tf.placeholder()
      z = py_utils.SoftmaxCrossEntropyFocalLoss(x, label_probs=, alpha=, gamma=)
      return sess.run(z, feed_dict={x:, y:})
  def testSoftmaxCrossEntropyFocalLoss():
    num_classes =
    logits = np.random.normal(scale=, size=())
    label_ids = np.random.randint(num_classes, size=())
    label_probs = np.random.uniform(size=())
    label_probs /= label_probs.sum(axis=, keepdims=)
    for () in [(),(np.random.uniform(size=[]).astype(), 2),(np.random.uniform(size=[]).astype(), 0),(np.random.uniform(size=[]).astype(), 5)]:
      self.assertAllClose(self._testNpSCEFL(),self._testTfSCEFLLabelIds())
      self.assertAllClose(self._testNpSCEFL(),self._testTfSCEFLLabelProbs())
  def testSoftmaxCrossEntropyFocalLossGradients():
    label_ids = []
    logits = tf.constant([[], []], dtype=)
    loss = py_utils.SoftmaxCrossEntropyFocalLoss(logits,label_ids,label_probs=,gamma=,stop_gradient_on_focal_loss_coefficient=)
    dlogits, = tf.gradients(ys=, xs=[])
    with self.session():
      dlogits = dlogits.eval()
      if stop_gradient_on_coefficient:
        self.assertAllClose([[], []], dlogits)
      else:
        self.assertTrue(any(math.isnan()) for x in dlogits.flatten())
class UniformSamplerTest():
  def testUniformSamplerSamples():
    sampler = py_utils.UniformSampler()
    for i in range():
      sampler.Add()
    self.assertEqual([], sampler.samples)
  def testUniformSampler():
    np.random.seed()
    state_space =
    num_samples =
    num_trials =
    counts = np.zeros([])
    for _ in range():
      sampler = py_utils.UniformSampler()
      for i in range():
        sampler.Add()
      samples =
      self.assertEqual(num_samples, len())
      for value in samples:
        counts[] +=
    distribution = counts / np.sum()
    self.assertGreater(min(), 0.009)
    self.assertLess(max(), 0.011)
class FromGlobalTest():
  def testAccessAssertFlagWhenUnparsed():
    tf.flags.FLAGS.unparse_flags()
    with self.assertRaises():
      result =
    result = py_utils._FromGlobal()
    self.assertTrue()
    tf.flags.FLAGS()
def FunctionTestParameters():
  suffix = "" if py_utils._UseTfFunction() else ""
  decorator = parameterized.named_parameters((),(),)
  return decorator()
class FunctionTest():
  def testNoInputs():
    with self.session():
      def Fwd():
        return tf.constant()
      self.assertEqual()
      ys = Fwd()
      self.assertEqual(1.0, self.evaluate())
  def testScalarInput():
    with self.session():
      sig = tf.TensorSpec()
      def Bak():
        del y
        return 4 * x * dy
      def Fwd():
        return x * x * 2
      def FwdWithBak():
        return x * x * 2
      x = tf.constant()
      for fwd in []:
        self.assertEqual()
        y = fwd()
        dx = tf.gradients(ys=[], xs=[], grad_ys=[])
        self.assertEqual([], self.evaluate([] + dx))
  def testListInput():
    with self.session():
      sig = [tf.TensorSpec((), tf.float32)] * 2
      def Bak():
        del ys
        w, x =
        return [tf.matmul(dys[], tf.transpose()) + 100.,tf.matmul(tf.transpose(), dys[]) + 200.]
      def Fwd():
        w, x =
        return [tf.matmul()]
      def FwdWithBak():
        w, x =
        return [tf.matmul()]
      a = np.array([[], []], dtype=)
      b = np.array([[], []], dtype=)
      xs = [tf.constant(), tf.constant()]
      for fwd in []:
        self.assertEqual([], fwd.output_dtypes)
        ys = fwd()
        self.assertIsInstance()
        loss = tf.reduce_sum(tf.square(ys[]))
        dw, dx, dy = tf.gradients(ys=, xs=)
        y, dw, dx, dy = self.evaluate(ys + [])
        self.assertAllEqual(y, a.dot())
        self.assertAllEqual()
        self.assertAllEqual(dw, ().dot() +())
        self.assertAllEqual(dx,a.T.dot() + ())
  def testNestedMapInput():
    with self.session():
      spec = tf.TensorSpec((), tf.float32)
      sig = py_utils.NestedMap(w=, x=)
      def Bak():
        del ys
        return py_utils.NestedMap(w=tf.matmul(dys.y, tf.transpose()) + 100.,x=tf.matmul(tf.transpose(), dys.y) + 200.)
      def Fwd():
        return py_utils.NestedMap(y=tf.matmul())
      def FwdWithBak():
        return py_utils.NestedMap(y=tf.matmul())
      a = np.array([[], []], dtype=)
      b = np.array([[], []], dtype=)
      xs = py_utils.NestedMap(w=tf.constant(), x=tf.constant())
      for fwd in []:
        self.assertEqual(py_utils.NestedMap(y=), fwd.output_dtypes)
        ys = fwd()
        loss = tf.reduce_sum(tf.square())
        dw, dx, dy = tf.gradients(xs=xs.Flatten() + ys.Flatten(), ys=)
        y, dw, dx, dy = self.evaluate([])
        self.assertAllEqual(y, a.dot())
        self.assertAllEqual()
        self.assertAllEqual(dw, ().dot() +())
        self.assertAllEqual(dx,a.T.dot() + ())
  def testImplicitInput():
    with self.session() as sess:
      w = tf.placeholder()
      sig = py_utils.NestedMap(x=tf.TensorSpec((), tf.float32))
      def Bak():
        del ys
        dw = tf.matmul(dys.y, tf.transpose()) + 100.
        ret = py_utils.NestedMap(x=tf.matmul(tf.transpose(), dys.y) + 200.)
        if bak_as_function:
        return ret, dw
      def Fwd():
        ret = py_utils.NestedMap(y=tf.matmul())
        return ret
      def FwdWithBak():
        ret = py_utils.NestedMap(y=tf.matmul())
        return ret
      a = np.array([[], []], dtype=)
      b = np.array([[], []], dtype=)
      xs = py_utils.NestedMap(x=tf.constant(b, dtype=))
      for fwd in []:
        self.assertEqual([], fwd.captured_inputs)
        self.assertEqual(py_utils.NestedMap(y=), fwd.output_dtypes)
        ys = fwd()
        loss = tf.reduce_sum(tf.square())
        dw, dx, dy = tf.gradients(xs=[] + xs.Flatten() + ys.Flatten(), ys=)
        y, dw, dx, dy = sess.run([], feed_dict={w:})
        self.assertAllEqual(y, a.dot())
        self.assertAllEqual()
        self.assertAllEqual(dw, ().dot() +())
        self.assertAllEqual(dx,a.T.dot() + ())
  def testPreserveStaticShape():
    with self.session():
      def Bak():
        del x, y
        return dy
      def Fwd():
        shape = py_utils.GetShape()
        if isinstance():
          return tf.ones_like()
        else:
          for dim in shape:
            if isinstance():
              return tf.ones_like() + 1
          return tf.zeros_like()
      a = np.array([[], []], dtype=)
      x = tf.constant()
      sig = tf.TensorSpec((), tf.float32)
      for fwd in [py_utils.Function(fwd_sig=)(fwd=),py_utils.Function(fwd_sig=, bak=, bak_as_function=)(fwd=)]:
        y = self.evaluate(fwd())
        self.assertAllEqual(y, np.zeros_like())
  def testStatefulOps():
    def Stateless():
      return tf.constant()
    def Stateful():
      return tf.random.uniform([])
    def StatelessCall():
      return Stateless()
    def StatefulCall():
      return Stateful()
    self.assertEmpty()
    self.assertEqual([], [op[] for op in Stateful.stateful_ops])
    self.assertEmpty()
    self.assertLen()
  def testFuncType():
    defun_type = type(tf.Defun()(lambda:))
    function_type = type(tf.function(lambda:).get_concrete_function())
    def Fwd():
      return xs * 2
    self.assertIsInstance(Fwd.func, function_type if py_utils._UseTfFunction() else defun_type)
  def testEmptyInputWithGlobalStepContext():
    with py_utils.GlobalStepContext(), self.session():
      def Fwd():
        return tf.constant()
      self.assertEqual()
      with py_utils.GlobalStepContext(tf.constant(1, dtype=)):
        ys = Fwd()
        self.assertEqual(1.0, self.evaluate())
  def testNonemptyInputWithGlobalStepContext():
    with py_utils.GlobalStepContext(), self.session():
      sig = tf.TensorSpec()
      def Bak():
        del y
        return 4 * x * dy
      def Fwd():
        return x * x * 2
      def FwdWithBak():
        return x * x * 2
      x = tf.constant()
      for fwd in []:
        self.assertEqual()
        with py_utils.GlobalStepContext(tf.constant(1, dtype=)):
          y = fwd()
          dx = tf.gradients(ys=[], xs=[], grad_ys=[])
          self.assertEqual([], self.evaluate([] + dx))
class IfTest():
  def testNestedMapInput():
    with self.session():
      def ThenBody():
        nmap.value -=
        return nmap
      def ElseBody():
        nmap.value +=
        return nmap
      inputs = py_utils.NestedMap(value=tf.constant())
      true_out = py_utils.If()
      false_out = py_utils.If()
      true_out = self.evaluate()
      false_out = self.evaluate()
    self.assertEqual()
    self.assertEqual()
  def testScalarInput():
    with self.session():
      def ThenBody():
        return value - 1.
      def ElseBody():
        return value + 1.
      inputs = tf.constant()
      true_out = py_utils.If()
      false_out = py_utils.If()
      true_out = self.evaluate()
      false_out = self.evaluate()
    self.assertEqual()
    self.assertEqual()
  def testListInput():
    with self.session():
      def ThenBody():
        return values[] - 1., values[] + 1.
      def ElseBody():
        return values[] + 1., values[] - 1.
      inputs = [tf.constant(), tf.constant()]
      true_out = py_utils.If()
      false_out = py_utils.If()
      true_out = self.evaluate()
      false_out = self.evaluate()
    self.assertEqual((), true_out)
    self.assertEqual((), false_out)
  def testEmptyInput():
    with self.session():
      def ThenBody():
        return tf.constant()
      def ElseBody():
        return tf.constant()
      true_out = py_utils.If()
      false_out = py_utils.If()
      true_out = self.evaluate()
      false_out = self.evaluate()
    self.assertEqual()
    self.assertEqual()
  def testCapturedInput():
    with self.session():
      a = tf.constant()
      b = tf.constant()
      def ThenBody():
        return a + b
      def ElseBody():
        return a - b
      true_out = py_utils.If()
      false_out = py_utils.If()
      true_out = self.evaluate()
      false_out = self.evaluate()
    self.assertEqual()
    self.assertEqual()
  def testCapturedInputsMismatch():
    with self.session():
      a = tf.constant()
      b = tf.constant()
      c = tf.constant()
      def OneCapture():
        return a
      def TwoCapture():
        return a - b
      def TwoCaptureReverse():
        return b - a
      def TwoCapture2():
        return a + c
      with self.assertRaises():
        py_utils.If()
      with self.assertRaises():
        py_utils.If()
      with self.assertRaises():
        py_utils.If()
      with self.assertRaises():
        py_utils.If()
class ForLoopTest():
  def testSimple():
    with self.session():
      def Body():
        state.value = state.value + 1.0 / tf.square(tf.cast())
        return state
      state = py_utils.NestedMap(value=tf.constant())
      state = py_utils.ForLoop()
      value = self.evaluate()
    self.assertAllClose(np.pi * np.pi / 6, value, rtol=)
class TopKTest():
  def test_top_2():
    with self.session():
      x_in = tf.random.normal([])
      top2_value_a, top2_index_a = py_utils.TopK()
      top2_value_b, top2_index_b = tf.math.top_k()
      v1, v2 = self.evaluate([])
      v3, v4 = self.evaluate([])
      self.assertAllEqual()
      self.assertAllEqual()
  def test_top_1():
    with self.session():
      x_in = tf.random.normal([])
      top1_value_a, top1_index_a = py_utils.TopK()
      top1_value_b, top1_index_b = tf.math.top_k()
      v1, v2 = self.evaluate([])
      v3, v4 = self.evaluate([])
      self.assertAllEqual()
      self.assertAllEqual()
class TpuSummaryTensorsTest():
  def testTpuSummaryTensors():
    with self.session():
      with tf.name_scope():
        with tf.name_scope():
          with tf.name_scope():
            with tf.name_scope():
              with tf.name_scope():
                with tf.name_scope():
                  x = tf.constant(0., name=)
                  py_utils.AddTpuSummaryTensor("", tf.reduce_mean())
              with tf.name_scope():
                with tf.name_scope():
                  x = tf.identity(x, name=)
                  py_utils.AddTpuSummaryTensor("", tf.reduce_mean())
      tpu_summary_tensors = py_utils.GetTpuSummaryTensors()
      actual_value = self.evaluate([])
      expected_value = [{'mean_x/fprop/tower_0_0/fprop/my_model/layer_001/fprop':,'mean_x/fprop/tower_0_0/fprop/my_model/layer_002/fprop':,}]
      self.assertAllEqual()
class HasShapeTest():
  def testFullyDynamicShapesMatchesOk():
    x_pl = tf.placeholder()
    y_pl = tf.placeholder()
    x = py_utils.HasShape(x_pl, py_utils.GetShape())
    with self.session() as sess:
      sess.run(x,feed_dict={x_pl:,y_pl:,})
  def testFullyDynamicShapesMismatchRaisesError():
    x_pl = tf.placeholder()
    y_pl = tf.placeholder()
    x = py_utils.HasShape(x_pl, py_utils.GetShape())
    with self.session() as sess:
      with self.assertRaisesRegex(tf.errors.InvalidArgumentError,r'.*mismatch shape:):
        sess.run(x,feed_dict={x_pl:,y_pl:,})
  def testFullyDynamicRankMismatchRaisesError():
    x_pl = tf.placeholder()
    y_pl = tf.placeholder()
    x = py_utils.HasShape(x_pl, py_utils.GetShape())
    with self.session() as sess:
      with self.assertRaisesRegex(tf.errors.InvalidArgumentError,r'.*mismatch shape:):
        sess.run(x,feed_dict={x_pl:,y_pl:,})
  def testFullyConstantShapesMatchesOk():
    x_pl = tf.placeholder()
    x = py_utils.HasShape(x_pl, tf.constant([]))
    with self.session() as sess:
      sess.run(x, feed_dict={x_pl:,})
  def testFullyConstantShapesMismatchRaisesError():
    x_pl = tf.placeholder()
    x = py_utils.HasShape(x_pl, tf.constant([]))
    with self.session() as sess:
      with self.assertRaisesRegex(tf.errors.InvalidArgumentError,r'.*mismatch shape:):
        sess.run(x, feed_dict={x_pl:,})
  def testRankMismatchRaisesError():
    with self.assertRaisesRegex():
      py_utils.HasShape(tf.random.uniform(()), [])
  def testTensorRankLessThanNDimsRaisesError():
    with self.assertRaisesRegex():
      py_utils.HasShape(tf.random.uniform(()), [], ndims=)
  def testExpectedShapeRankLessThanNDimsRaisesError():
    with self.assertRaisesRegex():
      py_utils.HasShape(tf.random.uniform(()), [], ndims=)
  def testTensorStaticShapeMismatchRaisesError():
    x_pl = tf.placeholder(tf.float32, ())
    y_pl = tf.placeholder(tf.float32, ())
    with self.assertRaisesRegex():
      py_utils.HasShape(x_pl, py_utils.GetShape())
  def testTensorShapeMatchesOk():
    x_pl = tf.placeholder(tf.float32, ())
    y_pl = tf.placeholder(tf.float32, ())
    x = py_utils.HasShape(x_pl, py_utils.GetShape())
    with self.session() as sess:
      sess.run(x,feed_dict={x_pl:,y_pl:,})
  def testTensorShapeMatchesWithMinus1Ok():
    x_pl = tf.placeholder(tf.float32, ())
    x = py_utils.HasShape(x_pl, [])
    with self.session() as sess:
      sess.run(x, feed_dict={x_pl:,})
  def testTensorShapeWithMinus1MismatchRaises():
    x_pl = tf.placeholder(tf.float32, ())
    x = py_utils.HasShape(x_pl, [])
    with self.session() as sess:
      with self.assertRaisesRegex(tf.errors.InvalidArgumentError,r'.*mismatch shape:):
        sess.run(x, feed_dict={x_pl:,})
  def testTensorShapeMatchesWithTensorExpectedShape():
    x_pl = tf.placeholder(tf.float32, ())
    x = py_utils.HasShape(x_pl, tf.constant([]))
    with self.session() as sess:
      sess.run(x, feed_dict={x_pl:,})
  def testTensorShapeMismatchWithTensorExpectedShapeRaises():
    x_pl = tf.placeholder(tf.float32, ())
    x = py_utils.HasShape(x_pl, [-1, tf.constant(), 3, tf.constant()])
    with self.session() as sess:
      with self.assertRaisesRegex(tf.errors.InvalidArgumentError,r'.*mismatch shape:):
        sess.run(x, feed_dict={x_pl:,})
  def testTensorStaticShapeMatchDynamicMismatchRaises():
    x_pl = tf.placeholder(tf.float32, ())
    y_pl = tf.placeholder(tf.float32, ())
    x = py_utils.HasShape(x_pl, py_utils.GetShape())
    with self.session() as sess:
      with self.assertRaisesRegex(tf.errors.InvalidArgumentError,r'.*mismatch shape:):
        sess.run(x,feed_dict={x_pl:,y_pl:,})
class SoftmaxTest():
  def testCompute(self, extra_logit=):
    tf.random.set_seed()
    x = np.array([[],[],[],])
    y = py_utils.Softmax(x, extra_logit=)
    if extra_logit is None:
      expected = np.array([[],[],[],])
    else:
      expected = np.array([[],[],[],])
    with self.session():
      self.assertAllClose(expected, y.eval(), atol=, rtol=)
class DivideNoNanTest():
  def testDivide(self, x, y, expected, dtype=):
    with self.session():
      res = py_utils.DivideNoNan(tf.cast(), tf.cast())
      orig = tf.math.divide_no_nan()
      res, orig = self.evaluate([])
      self.assertAllEqual()
      self.assertAllEqual()
  def testGradient():
    with self.session(use_gpu=):
      x = tf.get_variable("", initializer=[])
      y = tf.get_variable("", initializer=[])
      res = py_utils.DivideNoNan()
      dys = tf.where(res > 0., tf.ones_like(), tf.ones_like() * -.5)
      self.evaluate(tf.global_variables_initializer())
      dx, dy = self.evaluate(tf.gradients(xs=[], ys=, grad_ys=))
      self.assertAllClose([], dx)
      self.assertAllClose([], dy)
if __name__ == "__main__":
  tf.test.main()
import re
import time
from lingvo import compat as tf
from lingvo.core import py_utils
import numpy as np
from google.protobuf import text_format
from tensorflow.python.lib.io import file_io
from tensorflow.python.ops import io_ops
from tensorflow.python.training.checkpoint_state_pb2 import CheckpointState
class SanityCheck:
  def Check():
    raise NotImplementedError()
class InRange():
  def __init__():
    self._low =
    self._high =
  def __str__():
    return ""
  def Check():
    return self._low <= value <= self._high
class IsFinite():
  def __str__():
    return ""
  def Check():
    return np.all(np.isfinite())
def _VarKey():
  return var.name[:]
class Saver:
  def __init__(self,logdir,variables,sanity_checks=,keep_latest_n=,keep_every_n_hours=):
    self._logdir =
    self._state_file = ""
    self._vars =
    self._sanity_checks =
    self._keep_latest_n =
    self._keep_every_n_hours =
    self._re_pattern = re.compile(r"")
    self._logdir_ph = tf.placeholder(tf.string, shape=[])
    self._restore_prefix_ph = tf.placeholder(tf.string, shape=[])
    self._BuildSave()
    self._BuildRestore()
  def _BuildSave():
    self._save_global_step = py_utils.GetGlobalStep()
    self._save_prefix = tf.strings.join([self._logdir_ph, "",tf.as_string(self._save_global_step, width=, fill=)])
    self._save_op = io_ops.save_v2(prefix=,tensor_names=[_VarKey() for v in self._vars],tensors=[v.read_value() for v in self._vars],shape_and_slices=[] * len())
  def _BuildRestore():
    assign_ops = []
    for var in self._vars:
      val, = io_ops.restore_v2(prefix=,tensor_names=[_VarKey()],shape_and_slices=[],dtypes=[])
      assign_ops.append(var.assign())
    self._restore_op = tf.group()
  def _GetState():
    state = CheckpointState()
    if file_io.file_exists():
      content = file_io.read_file_to_string()
      text_format.Parse()
    return state
  def _SetState():
    file_io.atomic_write_string_to_file(self._state_file,text_format.MessageToString())
  def _GetCheckpointId():
    match = self._re_pattern.match()
    return int(match.group())
  def _GarbageCollect():
    state = self._GetState()
    valid_ids = set()
    if state.model_checkpoint_path:
      valid_ids.add(self._GetCheckpointId())
    for path in state.all_model_checkpoint_paths:
      valid_ids.add(self._GetCheckpointId())
    existing_files = tf.io.gfile.glob(r"")
    existing_files = [f for f in existing_files if self._re_pattern.match()]
    for filename in existing_files:
      if self._GetCheckpointId() not in valid_ids:
        tf.io.gfile.remove()
  def _DoSanityCheck():
    if not self._sanity_checks:
      return
    reader = tf.train.NewCheckpointReader()
    content = {}
    for variables, rule in self._sanity_checks:
      args = []
      for v in variables:
        key = _VarKey()
        if key in content:
          args.append(content[])
        else:
          value = reader.get_tensor()
          content[] =
          args.append()
      if not rule.Check():
        msg = ((["" for v in variables]), rule)
        file_io.write_string_to_file("", msg)
        raise tf.errors.AbortedError()
  def Save():
    self._GarbageCollect()
    _, global_step, prefix = sess.run(fetches=[],feed_dict={self._logdir_ph:})
    prefix = tf.compat.as_text()
    meta_graph_filename =
    tf.train.export_meta_graph(filename=)
    self._DoSanityCheck()
    self._UpdateState()
    return global_step, prefix
  def _UpdateState():
    state = self._GetState()
    if state.model_checkpoint_path and (not state.all_model_checkpoint_timestamps ornot self._keep_every_n_hours or(state.last_preserved_timestamp -state.all_model_checkpoint_timestamps[] >3600. * self._keep_every_n_hours)):
      state.all_model_checkpoint_paths.append()
      state.all_model_checkpoint_timestamps.append()
    state.model_checkpoint_path =
    state.last_preserved_timestamp = time.time()
    if self._keep_latest_n:
      if self._keep_latest_n == 1:
        state.all_model_checkpoint_paths[:] = []
        state.all_model_checkpoint_timestamps[:] = []
      else:
        n =
        state.all_model_checkpoint_paths[:] = (state.all_model_checkpoint_paths[-n:])
        state.all_model_checkpoint_timestamps[:] = (state.all_model_checkpoint_timestamps[-n:])
    self._SetState()
  def Restore(self, sess, checkpoint_id=):
    if checkpoint_id:
      prefix = ""
    else:
      prefix = self._GetState().model_checkpoint_path
      if not prefix:
        return 0, ""
    sess.run(fetches=[], feed_dict={self._restore_prefix_ph:})
    global_step = self._GetCheckpointId()
    return global_step, prefix
def WriteNpArrays():
  g = tf.Graph()
  with g.as_default():
    def Wrap():
      dtype = tf.as_dtype()
      return tf.py_func(lambda:, [], dtype)
    names, values = [], []
    for k, v in nmap.FlattenItems():
      names.append()
      values.append(Wrap())
    save = io_ops.save_v2(prefix=,tensor_names=,tensors=,shape_and_slices=[] * len())
  with tf.Session(graph=) as sess:
    sess.run()
def ReadNpArrays():
  g = tf.Graph()
  with g.as_default():
    reads = []
    for name, dtype in nmap.FlattenItems():
      reads.append(io_ops.restore_v2(prefix=,tensor_names=[],shape_and_slices=[],dtypes=[])[])
  with tf.Session(graph=) as sess:
    vals = sess.run()
  return nmap.Pack()
import lingvo.compat as tf
from lingvo.core import wpm_encoder
import numpy as np
import six
from six import text_type
tf.flags.DEFINE_string()
tf.flags.DEFINE_string()
tf.flags.DEFINE_string()
tf.flags.DEFINE_string()
tf.flags.DEFINE_integer()
tf.flags.DEFINE_integer("", -1, "")
tf.flags.DEFINE_integer()
FLAGS =
def _MakeBytesFeature():
  value = [tf.compat.as_bytes() for w in unicode_array]
  return tf.train.Feature(bytes_list=tf.train.BytesList(value=))
def _MakeInt64Feature():
  return tf.train.Feature(int64_list=tf.train.Int64List(value=))
def _MakeFloatFeature():
  return tf.train.Feature(float_list=tf.train.FloatList(value=))
def _AssertTextFormat():
def _MakeTfExample():
  src_i = list() + []
  src_s = list() + []
  if FLAGS.max_len > 0 and len() > FLAGS.max_len:
    return None
  tgt_l = list() + []
  tgt_i = [] + list()
  tgt_s = [] + list()
  if FLAGS.max_len > 0 and len() > FLAGS.max_len:
    return None
  feature = {'source_id':,'source_padding':,'source_word':,'target_id':,'target_padding':,'target_word':,'target_label':,'target_weight':,'natural_order':,}
  return tf.train.Example(features=tf.train.Features(feature=))
def _Preprocess():
  if not isinstance():
    text = six.ensure_text()
  return text.strip().replace()
def _RunEncoding():
  sess = tf.Session()
  enc = wpm_encoder.WpmEncoder()
  src_txt_placeholder = tf.placeholder(tf.string, [])
  src_encode_op = enc.Encode()
  tgt_txt_placeholder = tf.placeholder(tf.string, [])
  tgt_encode_op = enc.Encode()
  pairs = list(zip(FLAGS.source_filepaths.split(), FLAGS.target_filepaths.split()))
  with tf.python_io.TFRecordWriter() as outf:
    n =
    for p in pairs:
      with tf.io.gfile.GFile(p[], "") as sourcef:
        with tf.io.gfile.GFile(p[], "") as targetf:
          for textp in zip(sourcef.readlines(), targetf.readlines()):
            n +=
            if n % 10000 == 0:
            if n % FLAGS.num_shards != FLAGS.shard_id:
              continue
            source_text = _Preprocess(textp[])
            target_text = _Preprocess(textp[])
            _AssertTextFormat()
            _AssertTextFormat()
            ((), ()) = sess.run([],feed_dict={src_txt_placeholder:,tgt_txt_placeholder:},)
            ex = _MakeTfExample()
            if not ex:
              continue
            encoded = ex.SerializeToString()
            outf.write()
def main():
  tf.logging.set_verbosity()
  _RunEncoding()
if __name__ == "__main__":
  tf.app.run()
import tensorflow as tf
import os
import numpy as np
import module as mm
tf.compat.v1.logging.set_verbosity()
class InpaintNN:
	def __init__(self, input_height=, input_width=, batch_size =, bar_model_name=, bar_checkpoint_name=, mosaic_model_name=, mosaic_checkpoint_name =, is_mosaic=):
		self.bar_model_name =
		self.bar_checkpoint_name =
		self.mosaic_model_name =
		self.mosaic_checkpoint_name =
		self.is_mosaic =
		self.input_height =
		self.input_width =
		self.batch_size =
		self.check_model_file()
		self.build_model()
	def check_model_file():
		if not os.path.exists() or not os.path.exists() :
			exit()
	def build_model():
		self.X = tf.placeholder(tf.float32, [])
		self.Y = tf.placeholder(tf.float32, [])
		self.MASK = tf.placeholder(tf.float32, [])
		IT = tf.placeholder()
		input = tf.concat([], 3)
		vec_en = mm.encoder(input, reuse=, name=)
		vec_con = mm.contextual_block(vec_en, vec_en, self.MASK, 3, 50.0, "", stride=)
		I_co = mm.decoder(vec_en, self.input_height, self.input_height, reuse=, name=)
		I_ge = mm.decoder(vec_con, self.input_height, self.input_height, reuse=, name=)
		self.image_result = I_ge * () + self.Y*self.MASK
		D_real_red = mm.discriminator_red(self.Y, reuse=, name=)
		D_fake_red = mm.discriminator_red(self.image_result, reuse=, name=)
		Loss_D_red = tf.reduce_mean(tf.nn.relu()) + tf.reduce_mean(tf.nn.relu())
		Loss_D =
		Loss_gan_red = -tf.reduce_mean()
		Loss_gan =
		Loss_s_re = tf.reduce_mean(tf.abs())
		Loss_hat = tf.reduce_mean(tf.abs())
		A = tf.image.rgb_to_yuv(()/2.0)
		A_Y = tf.to_int32(A[:, :, :, 0:]*255.0)
		B = tf.image.rgb_to_yuv(()/2.0)
		B_Y = tf.to_int32(B[:, :, :, 0:]*255.0)
		ssim = tf.reduce_mean(tf.image.ssim())
		alpha =
		Loss_G = 0.1*Loss_gan + 10*Loss_s_re + 5*() * Loss_hat
		var_D = [v for v in tf.global_variables() if v.name.startswith()]
		var_G = [v for v in tf.global_variables() if v.name.startswith() or v.name.startswith() or v.name.startswith()]
		update_ops = tf.get_collection()
		with tf.control_dependencies():
		    optimize_D = tf.train.AdamOptimizer(learning_rate=, beta1=, beta2=).minimize(Loss_D, var_list=)
		    optimize_G = tf.train.AdamOptimizer(learning_rate=, beta1=, beta2=).minimize(Loss_G, var_list=)
		config = tf.ConfigProto()
		self.sess = tf.Session(config=)
		init = tf.global_variables_initializer()
		self.sess.run()
		saver = tf.train.Saver()
		if self.is_mosaic:
			Restore = tf.train.import_meta_graph()
			Restore.restore(self.sess, tf.train.latest_checkpoint())
		else:
			Restore = tf.train.import_meta_graph()
			Restore.restore(self.sess, tf.train.latest_checkpoint())
	def predict():
		img_sample = self.sess.run(self.image_result, feed_dict={self.X:, self.Y:, self.MASK:})
		return img_sample
import tensorflow as tf
from tensorflow.examples.tutorials.mnist import input_data
mnist = input_data.read_data_sets("", one_hot=)
X = tf.placeholder(tf.float32, [])
Y = tf.placeholder(tf.float32, [])
is_training = tf.placeholder()
L1 = tf.layers.conv2d(X, 32, [], activation=)
L1 = tf.layers.max_pooling2d(L1, [], [])
L1 = tf.layers.dropout()
L2 = tf.layers.conv2d(L1, 64, [], activation=)
L2 = tf.layers.max_pooling2d(L2, [], [])
L2 = tf.layers.dropout()
L3 = tf.contrib.layers.flatten()
L3 = tf.layers.dense(L3, 256, activation=)
L3 = tf.layers.dropout()
model = tf.layers.dense(L3, 10, activation=)
cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=, labels=))
optimizer = tf.train.AdamOptimizer().minimize()
init = tf.global_variables_initializer()
sess = tf.Session()
sess.run()
batch_size =
total_batch = int()
for epoch in range():
    total_cost =
    for i in range():
        batch_xs, batch_ys = mnist.train.next_batch()
        batch_xs = batch_xs.reshape()
        _, cost_val = sess.run([],feed_dict={X:,Y:,is_training:})
        total_cost +=
is_correct = tf.equal(tf.argmax(), tf.argmax())
accuracy = tf.reduce_mean(tf.cast())
import tensorflow as tf
x_data = []
y_data = []
W = tf.Variable(tf.random_uniform([], -1.0, 1.0))
b = tf.Variable(tf.random_uniform([], -1.0, 1.0))
X = tf.placeholder(tf.float32, name=)
Y = tf.placeholder(tf.float32, name=)
hypothesis =
cost = tf.reduce_mean(tf.square())
optimizer = tf.train.GradientDescentOptimizer(learning_rate=)
train_op = optimizer.minimize()
with tf.Session() as sess:
    sess.run(tf.global_variables_initializer())
    for step in range():
        _, cost_val = sess.run([], feed_dict={X:, Y:})
import tensorflow as tf
import numpy as np
char_arr = []
num_dic = {n:,}
dic_len = len()
seq_data = [[], [],[], [],[], []]
def make_batch():
    input_batch = []
    output_batch = []
    target_batch = []
    for seq in seq_data:
        input = [num_dic[] for n in seq[]]
        output = [num_dic[] for n in ("" + seq[])]
        target = [num_dic[] for n in (seq[] + "")]
        input_batch.append(np.eye()[])
        output_batch.append(np.eye()[])
        target_batch.append()
    return input_batch, output_batch, target_batch
learning_rate =
n_hidden =
total_epoch =
n_class = n_input =
enc_input = tf.placeholder(tf.float32, [])
dec_input = tf.placeholder(tf.float32, [])
targets = tf.placeholder(tf.int64, [])
with tf.variable_scope():
    enc_cell = tf.nn.rnn_cell.BasicRNNCell()
    enc_cell = tf.nn.rnn_cell.DropoutWrapper(enc_cell, output_keep_prob=)
    outputs, enc_states = tf.nn.dynamic_rnn(enc_cell, enc_input,dtype=)
with tf.variable_scope():
    dec_cell = tf.nn.rnn_cell.BasicRNNCell()
    dec_cell = tf.nn.rnn_cell.DropoutWrapper(dec_cell, output_keep_prob=)
    outputs, dec_states = tf.nn.dynamic_rnn(dec_cell, dec_input,initial_state=,dtype=)
model = tf.layers.dense(outputs, n_class, activation=)
cost = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=, labels=))
optimizer = tf.train.AdamOptimizer().minimize()
sess = tf.Session()
sess.run(tf.global_variables_initializer())
input_batch, output_batch, target_batch = make_batch()
for epoch in range():
    _, loss = sess.run([],feed_dict={enc_input:,dec_input:,targets:})
def translate():
    seq_data = [word, "" * len()]
    input_batch, output_batch, target_batch = make_batch([])
    prediction = tf.argmax()
    result = sess.run(prediction,feed_dict={enc_input:,dec_input:,targets:})
    decoded = [char_arr[] for i in result[]]
    end = decoded.index()
    translated = "".join(decoded[:])
    return translated
import os
import argparse
import six
import tensorflow as tf
import numpy as np
def main():
  tf.logging.set_verbosity()
  parser = argparse.ArgumentParser(formatter_class=)
  parser.add_argument("", required=,help=)
  parser.add_argument("", required=,help=)
  parser.add_argument("", type=, default=,help=)
  args = parser.parse_args()
  if args.model_dir == args.output_dir:
    raise ValueError()
  checkpoints_path = tf.train.get_checkpoint_state().all_model_checkpoint_paths
  if len() > args.max_count:
    checkpoints_path = checkpoints_path[-args.max_count:]
  num_checkpoints = len()
  var_list = tf.train.list_variables(checkpoints_path[])
  avg_values = {}
  for name, shape in var_list:
    if not name.startswith():
      avg_values[] = np.zeros()
  for checkpoint_path in checkpoints_path:
    reader = tf.train.load_checkpoint()
    for name in avg_values:
      avg_values[] += reader.get_tensor() / num_checkpoints
  tf_vars = []
  for name, value in six.iteritems():
    tf_vars.append(tf.get_variable(name, shape=))
  placeholders = [tf.placeholder(v.dtype, shape=) for v in tf_vars]
  assign_ops = [tf.assign() for () in zip()]
  latest_step = int(checkpoints_path[].split()[])
  out_base_file = os.path.join()
  global_step = tf.get_variable("",initializer=tf.constant(latest_step, dtype=),trainable=)
  saver = tf.train.Saver(tf.global_variables())
  with tf.Session() as sess:
    sess.run(tf.global_variables_initializer())
    for p, assign_op, () in zip(placeholders, assign_ops, six.iteritems()):
      sess.run(assign_op, {p:})
    saver.save(sess, out_base_file, global_step=)
if __name__ == "__main__":
  main()
import tensorflow as tf
import numpy as np
data = np.loadtxt("", delimiter=,',unpack=, dtype=)
x_data = np.transpose(data[0:])
y_data = np.transpose(data[2:])
global_step = tf.Variable(0, trainable=, name=)
X = tf.placeholder()
Y = tf.placeholder()
with tf.name_scope():
    W1 = tf.Variable(tf.random_uniform([], -1., 1.), name=)
    L1 = tf.nn.relu(tf.matmul())
    tf.summary.histogram()
    tf.summary.histogram()
with tf.name_scope():
    W2 = tf.Variable(tf.random_uniform([], -1., 1.), name=)
    L2 = tf.nn.relu(tf.matmul())
    tf.summary.histogram()
with tf.name_scope():
    W3 = tf.Variable(tf.random_uniform([], -1., 1.), name=)
    model = tf.matmul()
    tf.summary.histogram()
    tf.summary.histogram()
with tf.name_scope():
    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=, logits=))
    optimizer = tf.train.AdamOptimizer(learning_rate=)
    train_op = optimizer.minimize(cost, global_step=)
    tf.summary.scalar()
sess = tf.Session()
saver = tf.train.Saver(tf.global_variables())
ckpt = tf.train.get_checkpoint_state()
if ckpt and tf.train.checkpoint_exists():
    saver.restore()
else:
    sess.run(tf.global_variables_initializer())
merged = tf.summary.merge_all()
writer = tf.summary.FileWriter()
for step in range():
    sess.run(train_op, feed_dict={X:, Y:})
    summary = sess.run(merged, feed_dict={X:, Y:})
    writer.add_summary(summary, global_step=sess.run())
saver.save(sess, "", global_step=)
prediction = tf.argmax()
target = tf.argmax()
is_correct = tf.equal()
accuracy = tf.reduce_mean(tf.cast())
import tensorflow as tf
import matplotlib
import matplotlib.pyplot as plt
import numpy as np
font_name = matplotlib.font_manager.FontProperties(fname=).get_name()
matplotlib.rc("", family=)
sentences = []
word_sequence = "".join().split()
word_list = "".join().split()
word_list = list(set())
word_dict = {w:,}
skip_grams = []
for i in range(1, len() - 1):
    target = word_dict[word_sequence[]]
    context = [word_dict[word_sequence[]], word_dict[word_sequence[]]]
    for w in context:
        skip_grams.append([])
def random_batch():
    random_inputs = []
    random_labels = []
    random_index = np.random.choice(range(len()), size, replace=)
    for i in random_index:
        random_inputs.append(data[][])
        random_labels.append([data[][]])
    return random_inputs, random_labels
training_epoch =
learning_rate =
batch_size =
embedding_size =
num_sampled =
voc_size = len()
inputs = tf.placeholder(tf.int32, shape=[])
labels = tf.placeholder(tf.int32, shape=[])
embeddings = tf.Variable(tf.random_uniform([], -1.0, 1.0))
selected_embed = tf.nn.embedding_lookup()
nce_weights = tf.Variable(tf.random_uniform([], -1.0, 1.0))
nce_biases = tf.Variable(tf.zeros([]))
loss = tf.reduce_mean(tf.nn.nce_loss())
train_op = tf.train.AdamOptimizer().minimize()
with tf.Session() as sess:
    init = tf.global_variables_initializer()
    sess.run()
    for step in range():
        batch_inputs, batch_labels = random_batch()
        _, loss_val = sess.run([],feed_dict={inputs:,labels:})
        if step % 10 == 0:
    trained_embeddings = embeddings.eval()
for i, label in enumerate():
    x, y = trained_embeddings[]
    plt.scatter()
    plt.annotate(label, xy=(), xytext=(),textcoords=, ha=, va=)
plt.show()
import tensorflow as tf
import numpy as np
import random
import time
from game import Game
from model import DQN
tf.app.flags.DEFINE_boolean()
FLAGS =
MAX_EPISODE =
TARGET_UPDATE_INTERVAL =
TRAIN_INTERVAL =
OBSERVE =
NUM_ACTION =
SCREEN_WIDTH =
SCREEN_HEIGHT =
def train():
    sess = tf.Session()
    game = Game(SCREEN_WIDTH, SCREEN_HEIGHT, show_game=)
    brain = DQN()
    rewards = tf.placeholder(tf.float32, [])
    tf.summary.scalar("", tf.reduce_mean())
    saver = tf.train.Saver()
    sess.run(tf.global_variables_initializer())
    writer = tf.summary.FileWriter()
    summary_merged = tf.summary.merge_all()
    brain.update_target_network()
    epsilon =
    time_step =
    total_reward_list = []
    for episode in range():
        terminal =
        total_reward =
        state = game.reset()
        brain.init_state()
        while not terminal:
            if np.random.rand() < epsilon:
                action = random.randrange()
            else:
                action = brain.get_action()
            if episode > OBSERVE:
                epsilon -=
            state, reward, terminal = game.step()
            total_reward +=
            brain.remember()
            if time_step > OBSERVE and time_step % TRAIN_INTERVAL == 0:
                brain.train()
            if time_step % TARGET_UPDATE_INTERVAL == 0:
                brain.update_target_network()
            time_step +=
        total_reward_list.append()
        if episode % 10 == 0:
            summary = sess.run(summary_merged, feed_dict={rewards:})
            writer.add_summary()
            total_reward_list = []
        if episode % 100 == 0:
            saver.save(sess, "", global_step=)
def replay():
    sess = tf.Session()
    game = Game(SCREEN_WIDTH, SCREEN_HEIGHT, show_game=)
    brain = DQN()
    saver = tf.train.Saver()
    ckpt = tf.train.get_checkpoint_state()
    saver.restore()
    for episode in range():
        terminal =
        total_reward =
        state = game.reset()
        brain.init_state()
        while not terminal:
            action = brain.get_action()
            state, reward, terminal = game.step()
            total_reward +=
            brain.remember()
            time.sleep()
def main():
    if FLAGS.train:
        train()
    else:
        replay()
if __name__ == "__main__":
    tf.app.run()
from __future__ import absolute_import
from __future__ import division
from __future__ import print_function
import argparse
from datetime import datetime
import hashlib
import os.path
import random
import re
import struct
import sys
import tarfile
import numpy as np
from six.moves import urllib
import tensorflow as tf
from tensorflow.python.framework import graph_util
from tensorflow.python.framework import tensor_shape
from tensorflow.python.platform import gfile
from tensorflow.python.util import compat
FLAGS =
DATA_URL = ""
BOTTLENECK_TENSOR_NAME = ""
BOTTLENECK_TENSOR_SIZE =
MODEL_INPUT_WIDTH =
MODEL_INPUT_HEIGHT =
MODEL_INPUT_DEPTH =
JPEG_DATA_TENSOR_NAME = ""
RESIZED_INPUT_TENSOR_NAME = ""
MAX_NUM_IMAGES_PER_CLASS =
def create_image_lists():
    if not gfile.Exists():
        return None
    result = {}
    sub_dirs = [x[] for x in gfile.Walk()]
    is_root_dir =
    for sub_dir in sub_dirs:
        if is_root_dir:
            is_root_dir =
            continue
        extensions = []
        file_list = []
        dir_name = os.path.basename()
        if dir_name == image_dir:
            continue
        for extension in extensions:
            file_glob = os.path.join()
            file_list.extend(gfile.Glob())
        if not file_list:
            continue
        if len() < 20:
        elif len() > MAX_NUM_IMAGES_PER_CLASS:
        label_name = re.sub(r"", dir_name.lower())
        training_images = []
        testing_images = []
        validation_images = []
        for file_name in file_list:
            base_name = os.path.basename()
            hash_name = re.sub()
            hash_name_hashed = hashlib.sha1(compat.as_bytes()).hexdigest()
            percentage_hash = ((int() %()) *())
            if percentage_hash < validation_percentage:
                validation_images.append()
            elif percentage_hash < ():
                testing_images.append()
            else:
                training_images.append()
        result[] = {'dir':,'training':,'testing':,'validation':,}
    return result
def get_image_path():
    if label_name not in image_lists:
        tf.logging.fatal()
    label_lists = image_lists[]
    if category not in label_lists:
        tf.logging.fatal()
    category_list = label_lists[]
    if not category_list:
        tf.logging.fatal()
    mod_index = index % len()
    base_name = category_list[]
    sub_dir = label_lists[]
    full_path = os.path.join()
    return full_path
def get_bottleneck_path():
    return get_image_path() + ""
def create_inception_graph():
    with tf.Session() as sess:
        model_filename = os.path.join()
        with gfile.FastGFile() as f:
            graph_def = tf.GraphDef()
            graph_def.ParseFromString(f.read())
            bottleneck_tensor, jpeg_data_tensor, resized_input_tensor = (tf.import_graph_def(graph_def, name=, return_elements=[]))
    return sess.graph, bottleneck_tensor, jpeg_data_tensor, resized_input_tensor
def run_bottleneck_on_image():
    bottleneck_values = sess.run(bottleneck_tensor,{image_data_tensor:})
    bottleneck_values = np.squeeze()
    return bottleneck_values
def maybe_download_and_extract():
    dest_directory =
    if not os.path.exists():
        os.makedirs()
    filename = DATA_URL.split()[]
    filepath = os.path.join()
    if not os.path.exists():
        def _progress():
            sys.stdout.write("")
            sys.stdout.flush()
        filepath, _ = urllib.request.urlretrieve()
        statinfo = os.stat()
    tarfile.open(filepath, 'r:).extractall()
def ensure_dir_exists():
    if not os.path.exists():
        os.makedirs()
def write_list_of_floats_to_file():
    s = struct.pack()
    with open() as f:
        f.write()
def read_list_of_floats_from_file():
    with open() as f:
        s = struct.unpack("" * BOTTLENECK_TENSOR_SIZE, f.read())
        return list()
bottleneck_path_2_bottleneck_values = {}
def get_or_create_bottleneck():
    label_lists = image_lists[]
    sub_dir = label_lists[]
    sub_dir_path = os.path.join()
    ensure_dir_exists()
    bottleneck_path = get_bottleneck_path()
    if not os.path.exists():
        image_path = get_image_path()
        if not gfile.Exists():
            tf.logging.fatal()
        image_data = gfile.FastGFile().read()
        bottleneck_values = run_bottleneck_on_image()
        bottleneck_string =,'.join(str() for x in bottleneck_values)
        with open() as bottleneck_file:
            bottleneck_file.write()
    with open() as bottleneck_file:
        bottleneck_string = bottleneck_file.read()
    bottleneck_values = [float() for x in bottleneck_string.split()]
    return bottleneck_values
def cache_bottlenecks():
    how_many_bottlenecks =
    ensure_dir_exists()
    for label_name, label_lists in image_lists.items():
        for category in []:
            category_list = label_lists[]
            for index, unused_base_name in enumerate():
                get_or_create_bottleneck()
                how_many_bottlenecks +=
                if how_many_bottlenecks % 100 == 0:
def get_random_cached_bottlenecks():
    class_count = len(image_lists.keys())
    bottlenecks = []
    ground_truths = []
    filenames = []
    if how_many >= 0:
        for unused_i in range():
            label_index = random.randrange()
            label_name = list(image_lists.keys())[]
            image_index = random.randrange()
            image_name = get_image_path()
            bottleneck = get_or_create_bottleneck()
            ground_truth = np.zeros(class_count, dtype=)
            ground_truth[] =
            bottlenecks.append()
            ground_truths.append()
            filenames.append()
    else:
        for label_index, label_name in enumerate(image_lists.keys()):
            for image_index, image_name in enumerate(image_lists[][]):
                image_name = get_image_path()
                bottleneck = get_or_create_bottleneck()
                ground_truth = np.zeros(class_count, dtype=)
                ground_truth[] =
                bottlenecks.append()
                ground_truths.append()
                filenames.append()
    return bottlenecks, ground_truths, filenames
def get_random_distorted_bottlenecks():
    class_count = len(image_lists.keys())
    bottlenecks = []
    ground_truths = []
    for unused_i in range():
        label_index = random.randrange()
        label_name = list(image_lists.keys())[]
        image_index = random.randrange()
        image_path = get_image_path()
        if not gfile.Exists():
            tf.logging.fatal()
        jpeg_data = gfile.FastGFile().read()
        distorted_image_data = sess.run(distorted_image,{input_jpeg_tensor:})
        bottleneck = run_bottleneck_on_image()
        ground_truth = np.zeros(class_count, dtype=)
        ground_truth[] =
        bottlenecks.append()
        ground_truths.append()
    return bottlenecks, ground_truths
def should_distort_images():
    return (flip_left_right or (random_crop !=) or (random_scale !=) or(random_brightness !=))
def add_input_distortions():
    jpeg_data = tf.placeholder(tf.string, name=)
    decoded_image = tf.image.decode_jpeg(jpeg_data, channels=)
    decoded_image_as_float = tf.cast(decoded_image, dtype=)
    decoded_image_4d = tf.expand_dims()
    margin_scale = 1.0 + ()
    resize_scale = 1.0 + ()
    margin_scale_value = tf.constant()
    resize_scale_value = tf.random_uniform(tensor_shape.scalar(),minval=,maxval=)
    scale_value = tf.multiply()
    precrop_width = tf.multiply()
    precrop_height = tf.multiply()
    precrop_shape = tf.stack([])
    precrop_shape_as_int = tf.cast(precrop_shape, dtype=)
    precropped_image = tf.image.resize_bilinear()
    precropped_image_3d = tf.squeeze(precropped_image, squeeze_dims=[])
    cropped_image = tf.random_crop(precropped_image_3d,[])
    if flip_left_right:
        flipped_image = tf.image.random_flip_left_right()
    else:
        flipped_image =
    brightness_min = 1.0 - ()
    brightness_max = 1.0 + ()
    brightness_value = tf.random_uniform(tensor_shape.scalar(),minval=,maxval=)
    brightened_image = tf.multiply()
    distort_result = tf.expand_dims(brightened_image, 0, name=)
    return jpeg_data, distort_result
def variable_summaries():
    with tf.name_scope():
        mean = tf.reduce_mean()
        tf.summary.scalar()
        with tf.name_scope():
            stddev = tf.sqrt(tf.reduce_mean(tf.square()))
        tf.summary.scalar()
        tf.summary.scalar("", tf.reduce_max())
        tf.summary.scalar("", tf.reduce_min())
        tf.summary.histogram()
def add_final_training_ops():
    with tf.name_scope():
        bottleneck_input = tf.placeholder_with_default(bottleneck_tensor, shape=[],name=)
        ground_truth_input = tf.placeholder(tf.float32,[],name=)
    layer_name =
    with tf.name_scope():
        with tf.name_scope():
            layer_weights = tf.Variable(tf.truncated_normal([], stddev=), name=)
            variable_summaries()
        with tf.name_scope():
            layer_biases = tf.Variable(tf.zeros([]), name=)
            variable_summaries()
        with tf.name_scope():
            logits = tf.matmul() + layer_biases
            tf.summary.histogram()
    final_tensor = tf.nn.softmax(logits, name=)
    tf.summary.histogram()
    with tf.name_scope():
        cross_entropy = tf.nn.softmax_cross_entropy_with_logits_v2(labels=, logits=)
        with tf.name_scope():
            cross_entropy_mean = tf.reduce_mean()
    tf.summary.scalar()
    with tf.name_scope():
        train_step = tf.train.GradientDescentOptimizer().minimize()
    return ()
def add_evaluation_step():
    with tf.name_scope():
        with tf.name_scope():
            prediction = tf.argmax()
            correct_prediction = tf.equal(prediction, tf.argmax())
        with tf.name_scope():
            evaluation_step = tf.reduce_mean(tf.cast())
    tf.summary.scalar()
    return evaluation_step, prediction
def main():
    if tf.gfile.Exists():
        tf.gfile.DeleteRecursively()
    tf.gfile.MakeDirs()
    maybe_download_and_extract()
    graph, bottleneck_tensor, jpeg_data_tensor, resized_image_tensor = (create_inception_graph())
    image_lists = create_image_lists()
    class_count = len(image_lists.keys())
    if class_count == 0:
        return -1
    if class_count == 1:
        return -1
    do_distort_images = should_distort_images()
    sess = tf.Session()
    if do_distort_images:
        distorted_jpeg_data_tensor, distorted_image_tensor = add_input_distortions()
    else:
        cache_bottlenecks()
    () = add_final_training_ops(len(image_lists.keys()),FLAGS.final_tensor_name,bottleneck_tensor)
    evaluation_step, prediction = add_evaluation_step()
    merged = tf.summary.merge_all()
    train_writer = tf.summary.FileWriter()
    validation_writer = tf.summary.FileWriter()
    init = tf.global_variables_initializer()
    sess.run()
    for i in range():
        if do_distort_images:
            train_bottlenecks, train_ground_truth = get_random_distorted_bottlenecks()
        else:
            train_bottlenecks, train_ground_truth, _ = get_random_cached_bottlenecks()
        train_summary, _ = sess.run([],feed_dict={bottleneck_input:,ground_truth_input:})
        train_writer.add_summary()
        is_last_step = (i + 1 ==)
        if () == 0 or is_last_step:
            train_accuracy, cross_entropy_value = sess.run([],feed_dict={bottleneck_input:,ground_truth_input:})
            validation_bottlenecks, validation_ground_truth, _ = (get_random_cached_bottlenecks())
            validation_summary, validation_accuracy = sess.run([],feed_dict={bottleneck_input:,ground_truth_input:})
            validation_writer.add_summary()
    test_bottlenecks, test_ground_truth, test_filenames = (get_random_cached_bottlenecks())
    test_accuracy, predictions = sess.run([],feed_dict={bottleneck_input:,ground_truth_input:})
    if FLAGS.print_misclassified_test_images:
        for i, test_filename in enumerate():
            if predictions[] != test_ground_truth[].argmax():
    output_graph_def = graph_util.convert_variables_to_constants(sess, graph.as_graph_def(), [])
    with gfile.FastGFile() as f:
        f.write(output_graph_def.SerializeToString())
    with gfile.FastGFile() as f:
        f.write("".join(image_lists.keys()) + "")
if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("",type=,default=,help=)
    parser.add_argument("",type=,default=,help=)
    parser.add_argument("",type=,default=,help=)
    parser.add_argument("",type=,default=,help=)
    parser.add_argument("",type=,default=,help=)
    parser.add_argument("",type=,default=,help=)
    parser.add_argument("",type=,default=,help=)
    parser.add_argument("",type=,default=,help=)
    parser.add_argument("",type=,default=,help=)
    parser.add_argument("",type=,default=,help=)
    parser.add_argument("",default=,help=)
    parser.add_argument("",type=,default=,help=)
    parser.add_argument("",type=,default=,help=)
    parser.add_argument("",type=,default=,help=)
    FLAGS, unparsed = parser.parse_known_args()
    tf.app.run(main=, argv=[sys.argv[]] + unparsed)__all__ = []
import os
import tensorflow as tf
from .common import maxpool2d, conv_block, is_channels_first, flatten
def alex_conv(x,in_channels,out_channels,kernel_size,strides,padding,use_lrn,training,data_format,name=):
    x = conv_block(x=,in_channels=,out_channels=,kernel_size=,strides=,padding=,use_bias=,use_bn=,training=,data_format=,name=)
    if use_lrn:
        x = tf.nn.lrn(x, bias=, alpha=, beta=)
    return x
def alex_dense(x,in_channels,out_channels,training,name=):
    x = tf.keras.layers.Dense(units=,name=)()
    x = tf.nn.relu(x, name=)
    x = tf.keras.layers.Dropout(rate=,name=)(inputs=,training=)
    return x
def alex_output_block(x,in_channels,classes,training,name=):
    mid_channels =
    x = alex_dense(x=,in_channels=,out_channels=,training=,name=)
    x = alex_dense(x=,in_channels=,out_channels=,training=,name=)
    x = tf.keras.layers.Dense(units=,name=)()
    return x
class AlexNet():
    def __init__(self,channels,kernel_sizes,strides,paddings,use_lrn,in_channels=,in_size=(),classes=,data_format=,**kwargs):
        super().__init__()
        self.channels =
        self.kernel_sizes =
        self.strides =
        self.paddings =
        self.use_lrn =
        self.in_channels =
        self.in_size =
        self.classes =
        self.data_format =
    def __call__(self,x,training=):
        in_channels =
        for i, channels_per_stage in enumerate():
            use_lrn_i = self.use_lrn and (i in [])
            for j, out_channels in enumerate():
                x = alex_conv(x=,in_channels=,out_channels=,kernel_size=self.kernel_sizes[][],strides=self.strides[][],padding=self.paddings[][],use_lrn=,training=,data_format=,name="")
                in_channels =
            x = maxpool2d(x=,pool_size=,strides=,padding=,ceil_mode=,data_format=,name="")
        in_channels =
        x = flatten(x=,data_format=)
        x = alex_output_block(x=,in_channels=,classes=,training=,name=)
        return x
def get_alexnet(version=,model_name=,pretrained=,root=os.path.join(),**kwargs):
    if version == "":
        channels = [[], [], []]
        kernel_sizes = [[], [], []]
        strides = [[], [], []]
        paddings = [[], [], []]
        use_lrn =
    elif version == "":
        channels = [[], [], []]
        kernel_sizes = [[], [], []]
        strides = [[], [], []]
        paddings = [[], [], []]
        use_lrn =
    else:
        raise ValueError()
    net = AlexNet(channels=,kernel_sizes=,strides=,paddings=,use_lrn=,**kwargs)
    if pretrained:
        if () or ():
            raise ValueError()
        from .model_store import download_state_dict
        net.state_dict, net.file_path = download_state_dict(model_name=,local_model_store_dir_path=)
    else:
        net.state_dict =
        net.file_path =
    return net
def alexnet():
    return get_alexnet(model_name=, **kwargs)
def alexnetb():
    return get_alexnet(version=, model_name=, **kwargs)
def _test():
    import numpy as np
    data_format =
    pretrained =
    models = []
    for model in models:
        net = model(pretrained=, data_format=)
        x = tf.placeholder(dtype=,shape=() if is_channels_first() else (),name=)
        y_net = net()
        weight_count = np.sum([np.prod(v.get_shape().as_list()) for v in tf.trainable_variables()])
        with tf.Session() as sess:
            if pretrained:
                from .model_store import init_variables_from_state_dict
                init_variables_from_state_dict(sess=, state_dict=)
            else:
                sess.run(tf.global_variables_initializer())
            x_value = np.zeros(() if is_channels_first() else (), np.float32)
            y = sess.run(y_net, feed_dict={x:})
        tf.reset_default_graph()
if __name__ == "__main__":
    _test()
__all__ = []
import os
import tensorflow as tf
from .common import conv2d, batchnorm, is_channels_first, get_channel_axis, flatten
def dwconv3x3(x,in_channels,out_channels,strides,use_bias=,data_format=,name=):
    return conv2d(x=,in_channels=,out_channels=,kernel_size=,strides=,padding=,groups=,use_bias=,data_format=,name=)
def channet_conv(x,in_channels,out_channels,kernel_size,strides,padding,dilation=,groups=,use_bias=,dropout_rate=,activate=,training=,data_format=,name=):
    x = conv2d(x=,in_channels=,out_channels=,kernel_size=,strides=,padding=,dilation=,groups=,use_bias=,data_format=,name=)
    if dropout_rate > 0.0:
        x = tf.keras.layers.Dropout(rate=,name=)(inputs=,training=)
    x = batchnorm(x=,training=,data_format=,name=)
    if activate:
        x = tf.nn.relu6(x, name=)
    return x
def channet_conv1x1(x,in_channels,out_channels,strides=,groups=,use_bias=,dropout_rate=,activate=,training=,data_format=,name=):
    return channet_conv(x=,in_channels=,out_channels=,kernel_size=,strides=,padding=,groups=,use_bias=,dropout_rate=,activate=,training=,data_format=,name=)
def channet_conv3x3(x,in_channels,out_channels,strides,padding=,dilation=,groups=,use_bias=,dropout_rate=,activate=,training=,data_format=,name=):
    return channet_conv(x=,in_channels=,out_channels=,kernel_size=,strides=,padding=,dilation=,groups=,use_bias=,dropout_rate=,activate=,training=,data_format=,name=)
def channet_dws_conv_block(x,in_channels,out_channels,strides,groups=,dropout_rate=,training=,data_format=,name=):
    x = dwconv3x3(x=,in_channels=,out_channels=,strides=,data_format=,name=)
    x = channet_conv1x1(x=,in_channels=,out_channels=,groups=,dropout_rate=,training=,data_format=,name=)
    return x
def simple_group_block(x,channels,multi_blocks,groups,dropout_rate,training,data_format,name=):
    for i in range():
        x = channet_dws_conv_block(x=,in_channels=,out_channels=,strides=,groups=,dropout_rate=,training=,data_format=,name=name + "")
    return x
def channelwise_conv2d(x,groups,dropout_rate,training=,data_format=,name=):
    x = tf.expand_dims(x, axis=get_channel_axis(), name=)
    filters =
    kernel_size = []
    strides = []
    x = tf.keras.layers.Conv3D(filters=,kernel_size=,strides=,padding=,data_format=,use_bias=,name=)()
    if dropout_rate > 0.0:
        x = tf.keras.layers.Dropout(rate=,name=)(inputs=,training=)
    if filters == 1:
        x = tf.squeeze(x, axis=[get_channel_axis()], name=)
    x = tf.unstack(x, axis=get_channel_axis(), name=)
    x = tf.concat(x, axis=get_channel_axis(), name=)
    return x
def conv_group_block(x,channels,multi_blocks,groups,dropout_rate,training,data_format,name=):
    x = channelwise_conv2d(x=,groups=,dropout_rate=,training=,data_format=,name=)
    x = simple_group_block(x=,channels=,multi_blocks=,groups=,dropout_rate=,training=,data_format=,name=)
    return x
def channet_unit(x,in_channels,out_channels_list,strides,multi_blocks,groups,dropout_rate,block_names,merge_type,training,data_format,name=):
    x_outs = []
    for i, () in enumerate(zip()):
        strides_i = (strides if i ==)
        name_i = name + ""
        if block_name == "":
            x = channet_conv3x3(x=,in_channels=,out_channels=,strides=,dropout_rate=,activate=,training=,data_format=,name=)
        elif block_name == "":
            x = channet_dws_conv_block(x=,in_channels=,out_channels=,strides=,dropout_rate=,training=,data_format=,name=)
        elif block_name == "":
            x = simple_group_block(x=,channels=,multi_blocks=,groups=,dropout_rate=,training=,data_format=,name=)
        elif block_name == "":
            x = conv_group_block(x=,channels=,multi_blocks=,groups=,dropout_rate=,training=,data_format=,name=)
        else:
            raise NotImplementedError()
        x_outs = x_outs + []
        in_channels =
    if merge_type == "":
        x = x_outs[]
    elif merge_type == "":
        x = tf.add(*x_outs, name=)
    elif merge_type == "":
        x = tf.concat(x_outs, axis=get_channel_axis(), name=)
    else:
        raise NotImplementedError()
    return x
class ChannelNet():
    def __init__(self,channels,block_names,merge_types,dropout_rate=,multi_blocks=,groups=,in_channels=,in_size=(),classes=,data_format=,**kwargs):
        super().__init__()
        self.channels =
        self.block_names =
        self.merge_types =
        self.dropout_rate =
        self.multi_blocks =
        self.groups =
        self.in_channels =
        self.in_size =
        self.classes =
        self.data_format =
    def __call__(self,x,training=):
        in_channels =
        for i, channels_per_stage in enumerate():
            for j, out_channels in enumerate():
                strides = 2 if (j ==) else 1
                x = channet_unit(x=,in_channels=,out_channels_list=,strides=,multi_blocks=,groups=,dropout_rate=,block_names=self.block_names[][],merge_type=self.merge_types[][],training=,data_format=,name="")
                if self.merge_types[][] == "":
                    in_channels = sum()
                else:
                    in_channels = out_channels[]
        x = tf.keras.layers.AveragePooling2D(pool_size=,strides=,data_format=,name=)()
        x = flatten(x=,data_format=)
        x = tf.keras.layers.Dense(units=,name=)()
        return x
def get_channelnet(model_name=,pretrained=,root=os.path.join(),**kwargs):
    channels = [[[]], [[]], [[]], [[], []], [[]]]
    block_names = [[[]],[[]],[[]],[[], []],[[]]]
    merge_types = [[], [], [], [], []]
    net = ChannelNet(channels=,block_names=,merge_types=,**kwargs)
    if pretrained:
        if () or ():
            raise ValueError()
        from .model_store import download_state_dict
        net.state_dict, net.file_path = download_state_dict(model_name=,local_model_store_dir_path=)
    else:
        net.state_dict =
        net.file_path =
    return net
def channelnet():
    return get_channelnet(model_name=, **kwargs)
def _test():
    import numpy as np
    data_format =
    pretrained =
    models = []
    for model in models:
        net = model(pretrained=, data_format=)
        x = tf.placeholder(dtype=,shape=() if is_channels_first() else (),name=)
        y_net = net()
        weight_count = np.sum([np.prod(v.get_shape().as_list()) for v in tf.trainable_variables()])
        with tf.Session() as sess:
            if pretrained:
                from .model_store import init_variables_from_state_dict
                init_variables_from_state_dict(sess=, state_dict=)
            else:
                sess.run(tf.global_variables_initializer())
            x_value = np.zeros(() if is_channels_first() else (), np.float32)
            y = sess.run(y_net, feed_dict={x:})
        tf.reset_default_graph()
if __name__ == "__main__":
    _test()
__all__ = []
import os
import tensorflow as tf
from .common import conv2d, maxpool2d, conv1x1_block, conv3x3_block, is_channels_first, flatten
def dark_convYxY(x,in_channels,out_channels,alpha,pointwise,training,data_format,name=):
    if pointwise:
        return conv1x1_block(x=,in_channels=,out_channels=,activation=(lambda y: tf.nn.leaky_relu(y, alpha=, name=)),training=,data_format=,name=)
    else:
        return conv3x3_block(x=,in_channels=,out_channels=,activation=(lambda y: tf.nn.leaky_relu(y, alpha=, name=)),training=,data_format=,name=)
class DarkNet():
    def __init__(self,channels,odd_pointwise,avg_pool_size,cls_activ,alpha=,in_channels=,in_size=(),classes=,data_format=,**kwargs):
        super().__init__()
        self.channels =
        self.odd_pointwise =
        self.avg_pool_size =
        self.cls_activ =
        self.alpha =
        self.in_channels =
        self.in_size =
        self.classes =
        self.data_format =
    def __call__(self,x,training=):
        in_channels =
        for i, channels_per_stage in enumerate():
            for j, out_channels in enumerate():
                x = dark_convYxY(x=,in_channels=,out_channels=,alpha=,pointwise=(len() > 1) and not ((() % 2 ==) ^ self.odd_pointwise),training=,data_format=,name="")
                in_channels =
            if i != len() - 1:
                x = maxpool2d(x=,pool_size=,strides=,data_format=,name="")
        x = conv2d(x=,in_channels=,out_channels=,kernel_size=,data_format=,name=)
        if self.cls_activ:
            x = tf.nn.leaky_relu(x, alpha=, name=)
        x = tf.keras.layers.AveragePooling2D(pool_size=,strides=,data_format=,name=)()
        x = flatten(x=,data_format=)
        return x
def get_darknet(version,model_name=,pretrained=,root=os.path.join(),**kwargs):
    if version == "":
        channels = [[], [], [], [], [], [], []]
        odd_pointwise =
        avg_pool_size =
        cls_activ =
    elif version == "":
        channels = [[], [], [], [], []]
        odd_pointwise =
        avg_pool_size =
        cls_activ =
    elif version == "":
        channels = [[], [], [], [], [],[]]
        odd_pointwise =
        avg_pool_size =
        cls_activ =
    else:
        raise ValueError()
    net = DarkNet(channels=,odd_pointwise=,avg_pool_size=,cls_activ=,**kwargs)
    if pretrained:
        if () or ():
            raise ValueError()
        from .model_store import download_state_dict
        net.state_dict, net.file_path = download_state_dict(model_name=,local_model_store_dir_path=)
    else:
        net.state_dict =
        net.file_path =
    return net
def darknet_ref():
    return get_darknet(version=, model_name=, **kwargs)
def darknet_tiny():
    return get_darknet(version=, model_name=, **kwargs)
def darknet19():
    return get_darknet(version=, model_name=, **kwargs)
def _test():
    import numpy as np
    data_format =
    pretrained =
    models = []
    for model in models:
        net = model(pretrained=, data_format=)
        x = tf.placeholder(dtype=,shape=() if is_channels_first() else (),name=)
        y_net = net()
        weight_count = np.sum([np.prod(v.get_shape().as_list()) for v in tf.trainable_variables()])
        with tf.Session() as sess:
            if pretrained:
                from .model_store import init_variables_from_state_dict
                init_variables_from_state_dict(sess=, state_dict=)
            else:
                sess.run(tf.global_variables_initializer())
            x_value = np.zeros(() if is_channels_first() else (), np.float32)
            y = sess.run(y_net, feed_dict={x:})
        tf.reset_default_graph()
if __name__ == "__main__":
    _test()
__all__ = []
import os
import tensorflow as tf
from .common import conv1x1_block, conv3x3_block, is_channels_first, flatten
def dark_unit(x,in_channels,out_channels,alpha,training,data_format,name=):
    mid_channels =
    identity =
    x = conv1x1_block(x=,in_channels=,out_channels=,activation=(lambda y: tf.nn.leaky_relu(y, alpha=, name=)),training=,data_format=,name=)
    x = conv3x3_block(x=,in_channels=,out_channels=,activation=(lambda y: tf.nn.leaky_relu(y, alpha=, name=)),training=,data_format=,name=)
    x =
    return x
class DarkNet53():
    def __init__(self,channels,init_block_channels,alpha=,in_channels=,in_size=(),classes=,data_format=,**kwargs):
        super().__init__()
        self.channels =
        self.init_block_channels =
        self.alpha =
        self.in_channels =
        self.in_size =
        self.classes =
        self.data_format =
    def __call__(self,x,training=):
        in_channels =
        x = conv3x3_block(x=,in_channels=,out_channels=,activation=(lambda y: tf.nn.leaky_relu(y,alpha=,name=)),training=,data_format=,name=)
        in_channels =
        for i, channels_per_stage in enumerate():
            for j, out_channels in enumerate():
                if j == 0:
                    x = conv3x3_block(x=,in_channels=,out_channels=,strides=,activation=(lambda y: tf.nn.leaky_relu(y,alpha=,name="")),training=,data_format=,name="")
                else:
                    x = dark_unit(x=,in_channels=,out_channels=,alpha=,training=,data_format=,name="")
                in_channels =
        x = tf.keras.layers.AveragePooling2D(pool_size=,strides=,data_format=,name=)()
        x = flatten(x=,data_format=)
        x = tf.keras.layers.Dense(units=,name=)()
        return x
def get_darknet53(model_name=,pretrained=,root=os.path.join(),**kwargs):
    init_block_channels =
    layers = []
    channels_per_layers = []
    channels = [[] * li for () in zip()]
    net = DarkNet53(channels=,init_block_channels=,**kwargs)
    if pretrained:
        if () or ():
            raise ValueError()
        from .model_store import download_state_dict
        net.state_dict, net.file_path = download_state_dict(model_name=,local_model_store_dir_path=)
    else:
        net.state_dict =
        net.file_path =
    return net
def darknet53():
    return get_darknet53(model_name=, **kwargs)
def _test():
    import numpy as np
    data_format =
    pretrained =
    models = []
    for model in models:
        net = model(pretrained=, data_format=)
        x = tf.placeholder(dtype=,shape=() if is_channels_first() else (),name=)
        y_net = net()
        weight_count = np.sum([np.prod(v.get_shape().as_list()) for v in tf.trainable_variables()])
        with tf.Session() as sess:
            if pretrained:
                from .model_store import init_variables_from_state_dict
                init_variables_from_state_dict(sess=, state_dict=)
            else:
                sess.run(tf.global_variables_initializer())
            x_value = np.zeros(() if is_channels_first() else (), np.float32)
            y = sess.run(y_net, feed_dict={x:})
        tf.reset_default_graph()
if __name__ == "__main__":
    _test()
__all__ = []
import os
import tensorflow as tf
from .common import pre_conv1x1_block, pre_conv3x3_block, is_channels_first, get_channel_axis, flatten
from .preresnet import preres_init_block, preres_activation
def dense_unit(x,in_channels,out_channels,dropout_rate,training,data_format,name=):
    bn_size =
    inc_channels =
    mid_channels =
    identity =
    x = pre_conv1x1_block(x=,in_channels=,out_channels=,training=,data_format=,name=)
    x = pre_conv3x3_block(x=,in_channels=,out_channels=,training=,data_format=,name=)
    use_dropout = (dropout_rate !=)
    if use_dropout:
        x = tf.keras.layers.Dropout(rate=,name=)(inputs=,training=)
    x = tf.concat([], axis=get_channel_axis(), name=)
    return x
def transition_block(x,in_channels,out_channels,training,data_format,name=):
    x = pre_conv1x1_block(x=,in_channels=,out_channels=,training=,data_format=,name=)
    x = tf.keras.layers.AveragePooling2D(pool_size=,strides=,data_format=,name=)()
    return x
class DenseNet():
    def __init__(self,channels,init_block_channels,dropout_rate=,in_channels=,in_size=(),classes=,data_format=,**kwargs):
        super().__init__()
        self.channels =
        self.init_block_channels =
        self.dropout_rate =
        self.in_channels =
        self.in_size =
        self.classes =
        self.data_format =
    def __call__(self,x,training=):
        in_channels =
        x = preres_init_block(x=,in_channels=,out_channels=,training=,data_format=,name=)
        in_channels =
        for i, channels_per_stage in enumerate():
            if i != 0:
                x = transition_block(x=,in_channels=,out_channels=(),training=,data_format=,name="")
                in_channels =
            for j, out_channels in enumerate():
                x = dense_unit(x=,in_channels=,out_channels=,dropout_rate=,training=,data_format=,name="")
                in_channels =
        x = preres_activation(x=,training=,data_format=,name=)
        x = tf.keras.layers.AveragePooling2D(pool_size=,strides=,data_format=,name=)()
        x = flatten(x=,data_format=)
        x = tf.keras.layers.Dense(units=,name=)()
        return x
def get_densenet(blocks,model_name=,pretrained=,root=os.path.join(),**kwargs):
    if blocks == 121:
        init_block_channels =
        growth_rate =
        layers = []
    elif blocks == 161:
        init_block_channels =
        growth_rate =
        layers = []
    elif blocks == 169:
        init_block_channels =
        growth_rate =
        layers = []
    elif blocks == 201:
        init_block_channels =
        growth_rate =
        layers = []
    else:
        raise ValueError()
    from functools import reduce
    channels = reduce(lambda xi, yi:xi + [reduce(lambda xj, yj:xj + [xj[] + yj],[] * yi,[xi[][] // 2])[1:]],layers,[[]])[1:]
    net = DenseNet(channels=,init_block_channels=,**kwargs)
    if pretrained:
        if () or ():
            raise ValueError()
        from .model_store import download_state_dict
        net.state_dict, net.file_path = download_state_dict(model_name=,local_model_store_dir_path=)
    else:
        net.state_dict =
        net.file_path =
    return net
def densenet121():
    return get_densenet(blocks=, model_name=, **kwargs)
def densenet161():
    return get_densenet(blocks=, model_name=, **kwargs)
def densenet169():
    return get_densenet(blocks=, model_name=, **kwargs)
def densenet201():
    return get_densenet(blocks=, model_name=, **kwargs)
def _test():
    import numpy as np
    data_format =
    pretrained =
    models = []
    for model in models:
        net = model(pretrained=, data_format=)
        x = tf.placeholder(dtype=,shape=() if is_channels_first() else (),name=)
        y_net = net()
        weight_count = np.sum([np.prod(v.get_shape().as_list()) for v in tf.trainable_variables()])
        with tf.Session() as sess:
            if pretrained:
                from .model_store import init_variables_from_state_dict
                init_variables_from_state_dict(sess=, state_dict=)
            else:
                sess.run(tf.global_variables_initializer())
            x_value = np.zeros(() if is_channels_first() else (), np.float32)
            y = sess.run(y_net, feed_dict={x:})
        tf.reset_default_graph()
if __name__ == "__main__":
    _test()
__all__ = []
import os
import tensorflow as tf
from .common import conv1x1_block, conv3x3_block, dwconv3x3_block, channel_shuffle, is_channels_first, flatten
def inv_res_unit(x,in_channels,out_channels,strides,expansion,training,data_format,name=):
    residual = (in_channels ==) and (strides ==)
    mid_channels =
    groups =
    if residual:
        identity =
    x = conv1x1_block(x=,in_channels=,out_channels=,groups=,activation=,training=,data_format=,name=)
    x = channel_shuffle(x=,groups=,data_format=)
    x = dwconv3x3_block(x=,in_channels=,out_channels=,strides=,activation=,training=,data_format=,name=)
    x = conv1x1_block(x=,in_channels=,out_channels=,groups=,activation=,training=,data_format=,name=)
    if residual:
        x =
    return x
class IGCV3():
    def __init__(self,channels,init_block_channels,final_block_channels,in_channels=,in_size=(),classes=,data_format=,**kwargs):
        super().__init__()
        self.channels =
        self.init_block_channels =
        self.final_block_channels =
        self.in_channels =
        self.in_size =
        self.classes =
        self.data_format =
    def __call__(self,x,training=):
        in_channels =
        x = conv3x3_block(x=,in_channels=,out_channels=,strides=,activation=,training=,data_format=,name=)
        in_channels =
        for i, channels_per_stage in enumerate():
            for j, out_channels in enumerate():
                strides = 2 if (j ==) and (i !=) else 1
                expansion = (i !=) or (j !=)
                x = inv_res_unit(x=,in_channels=,out_channels=,strides=,expansion=,training=,data_format=,name="")
                in_channels =
        x = conv1x1_block(x=,in_channels=,out_channels=,activation=,training=,data_format=,name=)
        x = tf.keras.layers.AveragePooling2D(pool_size=,strides=,data_format=,name=)()
        x = flatten(x=,data_format=)
        x = tf.keras.layers.Dense(units=,name=)()
        return x
def get_igcv3(width_scale,model_name=,pretrained=,root=os.path.join(),**kwargs):
    init_block_channels =
    final_block_channels =
    layers = []
    downsample = []
    channels_per_layers = []
    from functools import reduce
    channels = reduce(lambda x, y: x + [[y[]] * y[]] if y[] != 0 else x[:] + [x[] + [y[]] * y[]],zip(),[[]])
    if width_scale != 1.0:
        def make_even():
            return x if (x % 2 ==) else x + 1
        channels = [[make_even(int()) for cij in ci] for ci in channels]
        init_block_channels = make_even(int())
        if width_scale > 1.0:
            final_block_channels = make_even(int())
    net = IGCV3(channels=,init_block_channels=,final_block_channels=,**kwargs)
    if pretrained:
        if () or ():
            raise ValueError()
        from .model_store import download_state_dict
        net.state_dict, net.file_path = download_state_dict(model_name=,local_model_store_dir_path=)
    else:
        net.state_dict =
        net.file_path =
    return net
def igcv3_w1():
    return get_igcv3(width_scale=, model_name=, **kwargs)
def igcv3_w3d4():
    return get_igcv3(width_scale=, model_name=, **kwargs)
def igcv3_wd2():
    return get_igcv3(width_scale=, model_name=, **kwargs)
def igcv3_wd4():
    return get_igcv3(width_scale=, model_name=, **kwargs)
def _test():
    import numpy as np
    data_format =
    pretrained =
    models = []
    for model in models:
        net = model(pretrained=, data_format=)
        x = tf.placeholder(dtype=,shape=() if is_channels_first() else (),name=)
        y_net = net()
        weight_count = np.sum([np.prod(v.get_shape().as_list()) for v in tf.trainable_variables()])
        with tf.Session() as sess:
            if pretrained:
                from .model_store import init_variables_from_state_dict
                init_variables_from_state_dict(sess=, state_dict=)
            else:
                sess.run(tf.global_variables_initializer())
            x_value = np.zeros(() if is_channels_first() else (), np.float32)
            y = sess.run(y_net, feed_dict={x:})
        tf.reset_default_graph()
if __name__ == "__main__":
    _test()
import importlib
import numpy as np
import tensorflow as tf
import texar.tf as tx
from utils import model_utils, processor
flags =
FLAGS =
flags.DEFINE_string()
flags.DEFINE_string()
flags.DEFINE_string()
flags.DEFINE_integer()
flags.DEFINE_integer()
flags.DEFINE_integer()
flags.DEFINE_integer()
flags.DEFINE_float()
flags.DEFINE_integer()
flags.DEFINE_boolean()
flags.DEFINE_string()
def main():
    np.random.seed()
    tf.set_random_seed()
    nsamples =
    batch_size =
    max_decoding_length =
    if FLAGS.config_type == "":
        gpt2_config = model_utils.transform_gpt2_to_texar_config()
    elif FLAGS.config_type == "":
        gpt2_config = importlib.import_module()
    else:
        raise ValueError()
    proc = processor.get_encoder()
    context = tf.placeholder(tf.int32, [])
    context_length = tf.placeholder(tf.int32, [])
    end_token = proc.encoder[]
    if FLAGS.is_interactive:
        start_tokens = context[:, 0]
    else:
        start_tokens = tf.fill([], end_token)
    word_embedder = tx.modules.WordEmbedder(vocab_size=,hparams=)
    pos_embedder = tx.modules.PositionEmbedder(position_size=,hparams=)
    def _embedding_fn():
        return word_embedder() + pos_embedder()
    helper = tx.modules.TopKSampleEmbeddingHelper(embedding=,start_tokens=,end_token=,top_k=,softmax_temperature=)
    output_layer = tf.transpose(word_embedder.embedding, ())
    decoder = tx.modules.TransformerDecoder(vocab_size=,output_layer=,hparams=)
    with tf.Session() as sess:
        if FLAGS.is_interactive:
            lm_output, _ = decoder(context=,context_sequence_length=,max_decoding_length=,helper=,mode=)
            if FLAGS.checkpoint:
                saver = tf.train.Saver()
                saver.restore()
            elif FLAGS.pretrain_checkpoint:
                model_utils.init_gpt2_checkpoint()
            while True:
                raw_text = input()
                while not raw_text:
                    raw_text = input()
                context_tokens = proc.encode()
                feed_dict = {context:,context_length:,tx.context.global_mode():}
                generated =
                for _ in range():
                    output = sess.run(lm_output, feed_dict=)
                    sample_id =
                    for i in range():
                        generated +=
                        si = sample_id[][len():]
        else:
            lm_output, _ = decoder(max_decoding_length=,helper=,mode=)
            if FLAGS.checkpoint:
                saver = tf.train.Saver()
                saver.restore()
            elif FLAGS.pretrain_checkpoint:
                model_utils.init_gpt2_checkpoint()
            feed_dict = {tx.context.global_mode():}
            generated =
            while nsamples == 0 or generated < nsamples:
                output = sess.run(lm_output, feed_dict=)
                sample_id =
                for i in range():
                    generated +=
                    text = proc.decode(sample_id[])
if __name__ == "__main__":
    tf.app.run()
__all__ = []
import os
import tensorflow as tf
from .common import conv2d, conv1x1, conv3x3, depthwise_conv3x3, batchnorm, channel_shuffle, maxpool2d, avgpool2d,is_channels_first, get_channel_axis, flatten
def me_unit(x,in_channels,out_channels,side_channels,groups,downsample,ignore_group,training,data_format,name=):
    mid_channels =
    if downsample:
        out_channels -=
    identity =
    x = conv1x1(x=,in_channels=,out_channels=,groups=(),data_format=,name=)
    x = batchnorm(x=,training=,data_format=,name=)
    x = tf.nn.relu(x, name=)
    x = channel_shuffle(x=,groups=,data_format=)
    y = conv1x1(x=,in_channels=,out_channels=,data_format=,name=)
    y = batchnorm(x=,training=,data_format=,name=)
    y = tf.nn.relu(y, name=)
    x = depthwise_conv3x3(x=,channels=,strides=(),data_format=,name=)
    x = batchnorm(x=,training=,data_format=,name=)
    y = conv3x3(x=,in_channels=,out_channels=,strides=(),data_format=,name=)
    y = batchnorm(x=,training=,data_format=,name=)
    y = tf.nn.relu(y, name=)
    y = conv1x1(x=,in_channels=,out_channels=,data_format=,name=)
    y = batchnorm(x=,training=,data_format=,name=)
    y = tf.nn.sigmoid(y, name=)
    x =
    x = conv1x1(x=,in_channels=,out_channels=,groups=,data_format=,name=)
    x = batchnorm(x=,training=,data_format=,name=)
    if downsample:
        identity = avgpool2d(x=,pool_size=,strides=,padding=,data_format=,name=)
        x = tf.concat([], axis=get_channel_axis(), name=)
    else:
        x =
    x = tf.nn.relu(x, name=)
    return x
def me_init_block(x,in_channels,out_channels,training,data_format,name=):
    x = conv2d(x=,in_channels=,out_channels=,kernel_size=,strides=,padding=,use_bias=,data_format=,name=)
    x = batchnorm(x=,training=,data_format=,name=)
    x = tf.nn.relu(x, name=)
    x = maxpool2d(x=,pool_size=,strides=,padding=,data_format=,name=)
    return x
class MENet():
    def __init__(self,channels,init_block_channels,side_channels,groups,in_channels=,in_size=(),classes=,data_format=,**kwargs):
        super().__init__()
        self.channels =
        self.init_block_channels =
        self.side_channels =
        self.groups =
        self.in_channels =
        self.in_size =
        self.classes =
        self.data_format =
    def __call__(self,x,training=):
        in_channels =
        x = me_init_block(x=,in_channels=,out_channels=,training=,data_format=,name=)
        in_channels =
        for i, channels_per_stage in enumerate():
            for j, out_channels in enumerate():
                downsample = (j ==)
                ignore_group = (i ==) and (j ==)
                x = me_unit(x=,in_channels=,out_channels=,side_channels=,groups=,downsample=,ignore_group=,training=,data_format=,name="")
                in_channels =
        x = tf.keras.layers.AveragePooling2D(pool_size=,strides=,data_format=,name=)()
        x = flatten(x=,data_format=)
        x = tf.keras.layers.Dense(units=,name=)()
        return x
def get_menet(first_stage_channels,side_channels,groups,model_name=,pretrained=,root=os.path.join(),**kwargs):
    layers = []
    if first_stage_channels == 108:
        init_block_channels =
        channels_per_layers = []
    elif first_stage_channels == 128:
        init_block_channels =
        channels_per_layers = []
    elif first_stage_channels == 160:
        init_block_channels =
        channels_per_layers = []
    elif first_stage_channels == 228:
        init_block_channels =
        channels_per_layers = []
    elif first_stage_channels == 256:
        init_block_channels =
        channels_per_layers = []
    elif first_stage_channels == 348:
        init_block_channels =
        channels_per_layers = []
    elif first_stage_channels == 352:
        init_block_channels =
        channels_per_layers = []
    elif first_stage_channels == 456:
        init_block_channels =
        channels_per_layers = []
    else:
        raise ValueError()
    channels = [[] * li for () in zip()]
    net = MENet(channels=,init_block_channels=,side_channels=,groups=,**kwargs)
    if pretrained:
        if () or ():
            raise ValueError()
        from .model_store import download_state_dict
        net.state_dict, net.file_path = download_state_dict(model_name=,local_model_store_dir_path=)
    else:
        net.state_dict =
        net.file_path =
    return net
def menet108_8x1_g3():
    return get_menet(first_stage_channels=, side_channels=, groups=, model_name=, **kwargs)
def menet128_8x1_g4():
    return get_menet(first_stage_channels=, side_channels=, groups=, model_name=, **kwargs)
def menet160_8x1_g8():
    return get_menet(first_stage_channels=, side_channels=, groups=, model_name=, **kwargs)
def menet228_12x1_g3():
    return get_menet(first_stage_channels=, side_channels=, groups=, model_name=, **kwargs)
def menet256_12x1_g4():
    return get_menet(first_stage_channels=, side_channels=, groups=, model_name=, **kwargs)
def menet348_12x1_g3():
    return get_menet(first_stage_channels=, side_channels=, groups=, model_name=, **kwargs)
def menet352_12x1_g8():
    return get_menet(first_stage_channels=, side_channels=, groups=, model_name=, **kwargs)
def menet456_24x1_g3():
    return get_menet(first_stage_channels=, side_channels=, groups=, model_name=, **kwargs)
def _test():
    import numpy as np
    data_format =
    pretrained =
    models = []
    for model in models:
        net = model(pretrained=, data_format=)
        x = tf.placeholder(dtype=,shape=() if is_channels_first() else (),name=)
        y_net = net()
        weight_count = np.sum([np.prod(v.get_shape().as_list()) for v in tf.trainable_variables()])
        with tf.Session() as sess:
            if pretrained:
                from .model_store import init_variables_from_state_dict
                init_variables_from_state_dict(sess=, state_dict=)
            else:
                sess.run(tf.global_variables_initializer())
            x_value = np.zeros(() if is_channels_first() else (), np.float32)
            y = sess.run(y_net, feed_dict={x:})
        tf.reset_default_graph()
if __name__ == "__main__":
    _test()
__all__ = []
import os
import tensorflow as tf
from .common import conv1x1_block, conv3x3_block, dwconv3x3_block, is_channels_first, flatten
def dws_conv_block(x,in_channels,out_channels,strides,training,data_format,name=):
    x = dwconv3x3_block(x=,in_channels=,out_channels=,strides=,training=,data_format=,name=)
    x = conv1x1_block(x=,in_channels=,out_channels=,training=,data_format=,name=)
    return x
class MobileNet():
    def __init__(self,channels,first_stage_stride,in_channels=,in_size=(),classes=,data_format=,**kwargs):
        super().__init__()
        self.channels =
        self.first_stage_stride =
        self.in_channels =
        self.in_size =
        self.classes =
        self.data_format =
    def __call__(self,x,training=):
        in_channels =
        init_block_channels = self.channels[][]
        x = conv3x3_block(x=,in_channels=,out_channels=,strides=,training=,data_format=,name=)
        in_channels =
        for i, channels_per_stage in enumerate(self.channels[1:]):
            for j, out_channels in enumerate():
                strides = 2 if (j ==) and ((i !=) or self.first_stage_stride) else 1
                x = dws_conv_block(x=,in_channels=,out_channels=,strides=,training=,data_format=,name="")
                in_channels =
        x = tf.keras.layers.AveragePooling2D(pool_size=,strides=,data_format=,name=)()
        x = flatten(x=,data_format=)
        x = tf.keras.layers.Dense(units=,name=)()
        return x
def get_mobilenet(version,width_scale,model_name=,pretrained=,root=os.path.join(),**kwargs):
    if version == "":
        channels = [[], [], [], [], [], []]
        first_stage_stride =
    elif version == "":
        channels = [[], [], [], [], []]
        first_stage_stride =
    else:
        raise ValueError()
    if width_scale != 1.0:
        channels = [[int() for cij in ci] for ci in channels]
    net = MobileNet(channels=,first_stage_stride=,**kwargs)
    if pretrained:
        if () or ():
            raise ValueError()
        from .model_store import download_state_dict
        net.state_dict, net.file_path = download_state_dict(model_name=,local_model_store_dir_path=)
    else:
        net.state_dict =
        net.file_path =
    return net
def mobilenet_w1():
    return get_mobilenet(version=, width_scale=, model_name=, **kwargs)
def mobilenet_w3d4():
    return get_mobilenet(version=, width_scale=, model_name=, **kwargs)
def mobilenet_wd2():
    return get_mobilenet(version=, width_scale=, model_name=, **kwargs)
def mobilenet_wd4():
    return get_mobilenet(version=, width_scale=, model_name=, **kwargs)
def fdmobilenet_w1():
    return get_mobilenet(version=, width_scale=, model_name=, **kwargs)
def fdmobilenet_w3d4():
    return get_mobilenet(version=, width_scale=, model_name=, **kwargs)
def fdmobilenet_wd2():
    return get_mobilenet(version=, width_scale=, model_name=, **kwargs)
def fdmobilenet_wd4():
    return get_mobilenet(version=, width_scale=, model_name=, **kwargs)
def _test():
    import numpy as np
    data_format =
    pretrained =
    models = []
    for model in models:
        net = model(pretrained=, data_format=)
        x = tf.placeholder(dtype=,shape=() if is_channels_first() else (),name=)
        y_net = net()
        weight_count = np.sum([np.prod(v.get_shape().as_list()) for v in tf.trainable_variables()])
        with tf.Session() as sess:
            if pretrained:
                from .model_store import init_variables_from_state_dict
                init_variables_from_state_dict(sess=, state_dict=)
            else:
                sess.run(tf.global_variables_initializer())
            x_value = np.zeros(() if is_channels_first() else (), np.float32)
            y = sess.run(y_net, feed_dict={x:})
        tf.reset_default_graph()
if __name__ == "__main__":
    _test()
__all__ = []
import os
import tensorflow as tf
from .common import conv1x1, conv1x1_block, conv3x3_block, dwconv3x3_block, is_channels_first, flatten
def linear_bottleneck(x,in_channels,out_channels,strides,expansion,training,data_format,name=):
    residual = (in_channels ==) and (strides ==)
    mid_channels =
    if residual:
        identity =
    x = conv1x1_block(x=,in_channels=,out_channels=,activation=,training=,data_format=,name=)
    x = dwconv3x3_block(x=,in_channels=,out_channels=,strides=,activation=,training=,data_format=,name=)
    x = conv1x1_block(x=,in_channels=,out_channels=,activation=,training=,data_format=,name=)
    if residual:
        x =
    return x
class MobileNetV2():
    def __init__(self,channels,init_block_channels,final_block_channels,in_channels=,in_size=(),classes=,data_format=,**kwargs):
        super().__init__()
        self.channels =
        self.init_block_channels =
        self.final_block_channels =
        self.in_channels =
        self.in_size =
        self.classes =
        self.data_format =
    def __call__(self,x,training=):
        in_channels =
        x = conv3x3_block(x=,in_channels=,out_channels=,strides=,activation=,training=,data_format=,name=)
        in_channels =
        for i, channels_per_stage in enumerate():
            for j, out_channels in enumerate():
                strides = 2 if (j ==) and (i !=) else 1
                expansion = (i !=) or (j !=)
                x = linear_bottleneck(x=,in_channels=,out_channels=,strides=,expansion=,training=,data_format=,name="")
                in_channels =
        x = conv1x1_block(x=,in_channels=,out_channels=,activation=,training=,data_format=,name=)
        in_channels =
        x = tf.keras.layers.AveragePooling2D(pool_size=,strides=,data_format=,name=)()
        x = conv1x1(x=,in_channels=,out_channels=,use_bias=,data_format=,name=)
        x = flatten(x=,data_format=)
        return x
def get_mobilenetv2(width_scale,model_name=,pretrained=,root=os.path.join(),**kwargs):
    init_block_channels =
    final_block_channels =
    layers = []
    downsample = []
    channels_per_layers = []
    from functools import reduce
    channels = reduce(lambda x, y: x + [[y[]] * y[]] if y[] != 0 else x[:] + [x[] + [y[]] * y[]],zip(), [[]])
    if width_scale != 1.0:
        channels = [[int() for cij in ci] for ci in channels]
        init_block_channels = int()
        if width_scale > 1.0:
            final_block_channels = int()
    net = MobileNetV2(channels=,init_block_channels=,final_block_channels=,**kwargs)
    if pretrained:
        if () or ():
            raise ValueError()
        from .model_store import download_state_dict
        net.state_dict, net.file_path = download_state_dict(model_name=,local_model_store_dir_path=)
    else:
        net.state_dict =
        net.file_path =
    return net
def mobilenetv2_w1():
    return get_mobilenetv2(width_scale=, model_name=, **kwargs)
def mobilenetv2_w3d4():
    return get_mobilenetv2(width_scale=, model_name=, **kwargs)
def mobilenetv2_wd2():
    return get_mobilenetv2(width_scale=, model_name=, **kwargs)
def mobilenetv2_wd4():
    return get_mobilenetv2(width_scale=, model_name=, **kwargs)
def _test():
    import numpy as np
    data_format =
    pretrained =
    models = []
    for model in models:
        net = model(pretrained=, data_format=)
        x = tf.placeholder(dtype=,shape=() if is_channels_first() else (),name=)
        y_net = net()
        weight_count = np.sum([np.prod(v.get_shape().as_list()) for v in tf.trainable_variables()])
        with tf.Session() as sess:
            if pretrained:
                from .model_store import init_variables_from_state_dict
                init_variables_from_state_dict(sess=, state_dict=)
            else:
                sess.run(tf.global_variables_initializer())
            x_value = np.zeros(() if is_channels_first() else (), np.float32)
            y = sess.run(y_net, feed_dict={x:})
        tf.reset_default_graph()
if __name__ == "__main__":
    _test()
__all__ = []
import os
import tensorflow as tf
from .common import pre_conv1x1_block, pre_conv3x3_block, conv2d, conv1x1, batchnorm, maxpool2d, is_channels_first,flatten
def preres_block(x,in_channels,out_channels,strides,training,data_format,name=):
    x, x_pre_activ = pre_conv3x3_block(x=,in_channels=,out_channels=,strides=,return_preact=,training=,data_format=,name=)
    x = pre_conv3x3_block(x=,in_channels=,out_channels=,training=,data_format=,name=)
    return x, x_pre_activ
def preres_bottleneck_block(x,in_channels,out_channels,strides,conv1_stride,training,data_format,name=):
    mid_channels =
    x, x_pre_activ = pre_conv1x1_block(x=,in_channels=,out_channels=,strides=(),return_preact=,training=,data_format=,name=)
    x = pre_conv3x3_block(x=,in_channels=,out_channels=,strides=(),training=,data_format=,name=)
    x = pre_conv1x1_block(x=,in_channels=,out_channels=,training=,data_format=,name=)
    return x, x_pre_activ
def preres_unit(x,in_channels,out_channels,strides,bottleneck,conv1_stride,training,data_format,name=):
    identity =
    if bottleneck:
        x, x_pre_activ = preres_bottleneck_block(x=,in_channels=,out_channels=,strides=,conv1_stride=,training=,data_format=,name=)
    else:
        x, x_pre_activ = preres_block(x=,in_channels=,out_channels=,strides=,training=,data_format=,name=)
    resize_identity = (in_channels !=) or (strides !=)
    if resize_identity:
        identity = conv1x1(x=,in_channels=,out_channels=,strides=,data_format=,name=)
    x =
    return x
def preres_init_block(x,in_channels,out_channels,training,data_format,name=):
    x = conv2d(x=,in_channels=,out_channels=,kernel_size=,strides=,padding=,use_bias=,data_format=,name=)
    x = batchnorm(x=,training=,data_format=,name=)
    x = tf.nn.relu(x, name=)
    x = maxpool2d(x=,pool_size=,strides=,padding=,data_format=,name=)
    return x
def preres_activation(x,training,data_format,name=):
    x = batchnorm(x=,training=,data_format=,name=)
    x = tf.nn.relu(x, name=)
    return x
class PreResNet():
    def __init__(self,channels,init_block_channels,bottleneck,conv1_stride,in_channels=,in_size=(),classes=,data_format=,**kwargs):
        super().__init__()
        self.channels =
        self.init_block_channels =
        self.bottleneck =
        self.conv1_stride =
        self.in_channels =
        self.in_size =
        self.classes =
        self.data_format =
    def __call__(self,x,training=):
        in_channels =
        x = preres_init_block(x=,in_channels=,out_channels=,training=,data_format=,name=)
        in_channels =
        for i, channels_per_stage in enumerate():
            for j, out_channels in enumerate():
                strides = 2 if (j ==) and (i !=) else 1
                x = preres_unit(x=,in_channels=,out_channels=,strides=,bottleneck=,conv1_stride=,training=,data_format=,name="")
                in_channels =
        x = preres_activation(x=,training=,data_format=,name=)
        x = tf.keras.layers.AveragePooling2D(pool_size=,strides=,data_format=,name=)()
        x = flatten(x=,data_format=)
        x = tf.keras.layers.Dense(units=,name=)()
        return x
def get_preresnet(blocks,bottleneck=,conv1_stride=,width_scale=,model_name=,pretrained=,root=os.path.join(),**kwargs):
    if bottleneck is None:
        bottleneck = (blocks >=)
    if blocks == 10:
        layers = []
    elif blocks == 12:
        layers = []
    elif blocks == 14 and not bottleneck:
        layers = []
    elif (blocks ==) and bottleneck:
        layers = []
    elif blocks == 16:
        layers = []
    elif blocks == 18:
        layers = []
    elif (blocks ==) and not bottleneck:
        layers = []
    elif (blocks ==) and bottleneck:
        layers = []
    elif blocks == 34:
        layers = []
    elif (blocks ==) and bottleneck:
        layers = []
    elif blocks == 50:
        layers = []
    elif blocks == 101:
        layers = []
    elif blocks == 152:
        layers = []
    elif blocks == 200:
        layers = []
    elif blocks == 269:
        layers = []
    else:
        raise ValueError()
    if bottleneck:
    else:
    init_block_channels =
    channels_per_layers = []
    if bottleneck:
        bottleneck_factor =
        channels_per_layers = []
    channels = [[] * li for () in zip()]
    if width_scale != 1.0:
        channels = [[int() if (i != len() - 1) or (j != len() - 1) else cijfor j, cij in enumerate()] for i, ci in enumerate()]
        init_block_channels = int()
    net = PreResNet(channels=,init_block_channels=,bottleneck=,conv1_stride=,**kwargs)
    if pretrained:
        if () or ():
            raise ValueError()
        from .model_store import download_state_dict
        net.state_dict, net.file_path = download_state_dict(model_name=,local_model_store_dir_path=)
    else:
        net.state_dict =
        net.file_path =
    return net
def preresnet10():
    return get_preresnet(blocks=, model_name=, **kwargs)
def preresnet12():
    return get_preresnet(blocks=, model_name=, **kwargs)
def preresnet14():
    return get_preresnet(blocks=, model_name=, **kwargs)
def preresnetbc14b():
    return get_preresnet(blocks=, bottleneck=, conv1_stride=, model_name=, **kwargs)
def preresnet16():
    return get_preresnet(blocks=, model_name=, **kwargs)
def preresnet18_wd4():
    return get_preresnet(blocks=, width_scale=, model_name=, **kwargs)
def preresnet18_wd2():
    return get_preresnet(blocks=, width_scale=, model_name=, **kwargs)
def preresnet18_w3d4():
    return get_preresnet(blocks=, width_scale=, model_name=, **kwargs)
def preresnet18():
    return get_preresnet(blocks=, model_name=, **kwargs)
def preresnet26():
    return get_preresnet(blocks=, bottleneck=, model_name=, **kwargs)
def preresnetbc26b():
    return get_preresnet(blocks=, bottleneck=, conv1_stride=, model_name=, **kwargs)
def preresnet34():
    return get_preresnet(blocks=, model_name=, **kwargs)
def preresnetbc38b():
    return get_preresnet(blocks=, bottleneck=, conv1_stride=, model_name=, **kwargs)
def preresnet50():
    return get_preresnet(blocks=, model_name=, **kwargs)
def preresnet50b():
    return get_preresnet(blocks=, conv1_stride=, model_name=, **kwargs)
def preresnet101():
    return get_preresnet(blocks=, model_name=, **kwargs)
def preresnet101b():
    return get_preresnet(blocks=, conv1_stride=, model_name=, **kwargs)
def preresnet152():
    return get_preresnet(blocks=, model_name=, **kwargs)
def preresnet152b():
    return get_preresnet(blocks=, conv1_stride=, model_name=, **kwargs)
def preresnet200():
    return get_preresnet(blocks=, model_name=, **kwargs)
def preresnet200b():
    return get_preresnet(blocks=, conv1_stride=, model_name=, **kwargs)
def preresnet269b():
    return get_preresnet(blocks=, conv1_stride=, model_name=, **kwargs)
def _test():
    import numpy as np
    data_format =
    pretrained =
    models = []
    for model in models:
        net = model(pretrained=, data_format=)
        x = tf.placeholder(dtype=,shape=() if is_channels_first() else (),name=)
        y_net = net()
        weight_count = np.sum([np.prod(v.get_shape().as_list()) for v in tf.trainable_variables()])
        with tf.Session() as sess:
            if pretrained:
                from .model_store import init_variables_from_state_dict
                init_variables_from_state_dict(sess=, state_dict=)
            else:
                sess.run(tf.global_variables_initializer())
            x_value = np.zeros(() if is_channels_first() else (), np.float32)
            y = sess.run(y_net, feed_dict={x:})
        tf.reset_default_graph()
if __name__ == "__main__":
    _test()
__all__ = []
import os
import tensorflow as tf
from .common import conv1x1_block, conv3x3_block, conv7x7_block, maxpool2d, is_channels_first, flatten
def res_block(x,in_channels,out_channels,strides,training,data_format,name=):
    x = conv3x3_block(x=,in_channels=,out_channels=,strides=,training=,data_format=,name=)
    x = conv3x3_block(x=,in_channels=,out_channels=,activation=,training=,data_format=,name=)
    return x
def res_bottleneck_block(x,in_channels,out_channels,strides,conv1_stride=,bottleneck_factor=,training=,data_format=,name=):
    mid_channels =
    x = conv1x1_block(x=,in_channels=,out_channels=,strides=(),training=,data_format=,name=)
    x = conv3x3_block(x=,in_channels=,out_channels=,strides=(),training=,data_format=,name=)
    x = conv1x1_block(x=,in_channels=,out_channels=,activation=,training=,data_format=,name=)
    return x
def res_unit(x,in_channels,out_channels,strides,bottleneck,conv1_stride,training,data_format,name=):
    resize_identity = (in_channels !=) or (strides !=)
    if resize_identity:
        identity = conv1x1_block(x=,in_channels=,out_channels=,strides=,activation=,training=,data_format=,name=)
    else:
        identity =
    if bottleneck:
        x = res_bottleneck_block(x=,in_channels=,out_channels=,strides=,conv1_stride=,training=,data_format=,name=)
    else:
        x = res_block(x=,in_channels=,out_channels=,strides=,training=,data_format=,name=)
    x =
    x = tf.nn.relu(x, name=)
    return x
def res_init_block():
    x = conv7x7_block(x=,in_channels=,out_channels=,strides=,training=,data_format=,name=)
    x = maxpool2d(x=,pool_size=,strides=,padding=,data_format=,name=)
    return x
class ResNet():
    def __init__(self,channels,init_block_channels,bottleneck,conv1_stride,in_channels=,in_size=(),classes=,data_format=,**kwargs):
        super().__init__()
        self.channels =
        self.init_block_channels =
        self.bottleneck =
        self.conv1_stride =
        self.in_channels =
        self.in_size =
        self.classes =
        self.data_format =
    def __call__(self,x,training=):
        in_channels =
        x = res_init_block(x=,in_channels=,out_channels=,training=,data_format=,name=)
        in_channels =
        for i, channels_per_stage in enumerate():
            for j, out_channels in enumerate():
                strides = 2 if (j ==) and (i !=) else 1
                x = res_unit(x=,in_channels=,out_channels=,strides=,bottleneck=,conv1_stride=,training=,data_format=,name="")
                in_channels =
        x = tf.keras.layers.AveragePooling2D(pool_size=,strides=,data_format=,name=)()
        x = flatten(x=,data_format=)
        x = tf.keras.layers.Dense(units=,name=)()
        return x
def get_resnet(blocks,bottleneck=,conv1_stride=,width_scale=,model_name=,pretrained=,root=os.path.join(),**kwargs):
    if bottleneck is None:
        bottleneck = (blocks >=)
    if blocks == 10:
        layers = []
    elif blocks == 12:
        layers = []
    elif blocks == 14 and not bottleneck:
        layers = []
    elif (blocks ==) and bottleneck:
        layers = []
    elif blocks == 16:
        layers = []
    elif blocks == 18:
        layers = []
    elif (blocks ==) and not bottleneck:
        layers = []
    elif (blocks ==) and bottleneck:
        layers = []
    elif blocks == 34:
        layers = []
    elif (blocks ==) and bottleneck:
        layers = []
    elif blocks == 50:
        layers = []
    elif blocks == 101:
        layers = []
    elif blocks == 152:
        layers = []
    elif blocks == 200:
        layers = []
    else:
        raise ValueError()
    if bottleneck:
    else:
    init_block_channels =
    channels_per_layers = []
    if bottleneck:
        bottleneck_factor =
        channels_per_layers = []
    channels = [[] * li for () in zip()]
    if width_scale != 1.0:
        channels = [[int() if (i != len() - 1) or (j != len() - 1) else cijfor j, cij in enumerate()] for i, ci in enumerate()]
        init_block_channels = int()
    net = ResNet(channels=,init_block_channels=,bottleneck=,conv1_stride=,**kwargs)
    if pretrained:
        if () or ():
            raise ValueError()
        from .model_store import download_state_dict
        net.state_dict, net.file_path = download_state_dict(model_name=,local_model_store_dir_path=)
    else:
        net.state_dict =
        net.file_path =
    return net
def resnet10():
    return get_resnet(blocks=, model_name=, **kwargs)
def resnet12():
    return get_resnet(blocks=, model_name=, **kwargs)
def resnet14():
    return get_resnet(blocks=, model_name=, **kwargs)
def resnetbc14b():
    return get_resnet(blocks=, bottleneck=, conv1_stride=, model_name=, **kwargs)
def resnet16():
    return get_resnet(blocks=, model_name=, **kwargs)
def resnet18_wd4():
    return get_resnet(blocks=, width_scale=, model_name=, **kwargs)
def resnet18_wd2():
    return get_resnet(blocks=, width_scale=, model_name=, **kwargs)
def resnet18_w3d4():
    return get_resnet(blocks=, width_scale=, model_name=, **kwargs)
def resnet18():
    return get_resnet(blocks=, model_name=, **kwargs)
def resnet26():
    return get_resnet(blocks=, bottleneck=, model_name=, **kwargs)
def resnetbc26b():
    return get_resnet(blocks=, bottleneck=, conv1_stride=, model_name=, **kwargs)
def resnet34():
    return get_resnet(blocks=, model_name=, **kwargs)
def resnetbc38b():
    return get_resnet(blocks=, bottleneck=, conv1_stride=, model_name=, **kwargs)
def resnet50():
    return get_resnet(blocks=, model_name=, **kwargs)
def resnet50b():
    return get_resnet(blocks=, conv1_stride=, model_name=, **kwargs)
def resnet101():
    return get_resnet(blocks=, model_name=, **kwargs)
def resnet101b():
    return get_resnet(blocks=, conv1_stride=, model_name=, **kwargs)
def resnet152():
    return get_resnet(blocks=, model_name=, **kwargs)
def resnet152b():
    return get_resnet(blocks=, conv1_stride=, model_name=, **kwargs)
def resnet200():
    return get_resnet(blocks=, model_name=, **kwargs)
def resnet200b():
    return get_resnet(blocks=, conv1_stride=, model_name=, **kwargs)
def _test():
    import numpy as np
    data_format =
    pretrained =
    models = []
    for model in models:
        net = model(pretrained=, data_format=)
        x = tf.placeholder(dtype=,shape=() if is_channels_first() else (),name=)
        y_net = net()
        weight_count = np.sum([np.prod(v.get_shape().as_list()) for v in tf.trainable_variables()])
        with tf.Session() as sess:
            if pretrained:
                from .model_store import init_variables_from_state_dict
                init_variables_from_state_dict(sess=, state_dict=)
            else:
                sess.run(tf.global_variables_initializer())
            x_value = np.zeros(() if is_channels_first() else (), np.float32)
            y = sess.run(y_net, feed_dict={x:})
        tf.reset_default_graph()
if __name__ == "__main__":
    _test()
__all__ = []
import os
import math
import tensorflow as tf
from .common import conv1x1_block, conv3x3_block, is_channels_first, flatten
from .resnet import res_init_block
def resnext_bottleneck(x,in_channels,out_channels,strides,cardinality,bottleneck_width,bottleneck_factor=,training=,data_format=,name=):
    mid_channels =
    D = int(math.floor(mid_channels * ()))
    group_width =
    x = conv1x1_block(x=,in_channels=,out_channels=,training=,data_format=,name=)
    x = conv3x3_block(x=,in_channels=,out_channels=,strides=,groups=,training=,data_format=,name=)
    x = conv1x1_block(x=,in_channels=,out_channels=,activation=,training=,data_format=,name=)
    return x
def resnext_unit(x,in_channels,out_channels,strides,cardinality,bottleneck_width,training,data_format,name=):
    resize_identity = (in_channels !=) or (strides !=)
    if resize_identity:
        identity = conv1x1_block(x=,in_channels=,out_channels=,strides=,activation=,training=,data_format=,name=)
    else:
        identity =
    x = resnext_bottleneck(x=,in_channels=,out_channels=,strides=,cardinality=,bottleneck_width=,training=,data_format=,name=)
    x =
    x = tf.nn.relu(x, name=)
    return x
class ResNeXt():
    def __init__(self,channels,init_block_channels,cardinality,bottleneck_width,in_channels=,in_size=(),classes=,data_format=,**kwargs):
        super().__init__()
        self.channels =
        self.init_block_channels =
        self.cardinality =
        self.bottleneck_width =
        self.in_channels =
        self.in_size =
        self.classes =
        self.data_format =
    def __call__(self,x,training=):
        in_channels =
        x = res_init_block(x=,in_channels=,out_channels=,training=,data_format=,name=)
        in_channels =
        for i, channels_per_stage in enumerate():
            for j, out_channels in enumerate():
                strides = 2 if (j ==) and (i !=) else 1
                x = resnext_unit(x=,in_channels=,out_channels=,strides=,cardinality=,bottleneck_width=,training=,data_format=,name="")
                in_channels =
        x = tf.keras.layers.AveragePooling2D(pool_size=,strides=,data_format=,name=)()
        x = flatten(x=,data_format=)
        x = tf.keras.layers.Dense(units=,name=)()
        return x
def get_resnext(blocks,cardinality,bottleneck_width,model_name=,pretrained=,root=os.path.join(),**kwargs):
    if blocks == 14:
        layers = []
    elif blocks == 26:
        layers = []
    elif blocks == 38:
        layers = []
    elif blocks == 50:
        layers = []
    elif blocks == 101:
        layers = []
    else:
        raise ValueError()
    init_block_channels =
    channels_per_layers = []
    channels = [[] * li for () in zip()]
    net = ResNeXt(channels=,init_block_channels=,cardinality=,bottleneck_width=,**kwargs)
    if pretrained:
        if () or ():
            raise ValueError()
        from .model_store import download_state_dict
        net.state_dict, net.file_path = download_state_dict(model_name=,local_model_store_dir_path=)
    else:
        net.state_dict =
        net.file_path =
    return net
def resnext14_16x4d():
    return get_resnext(blocks=, cardinality=, bottleneck_width=, model_name=, **kwargs)
def resnext14_32x2d():
    return get_resnext(blocks=, cardinality=, bottleneck_width=, model_name=, **kwargs)
def resnext14_32x4d():
    return get_resnext(blocks=, cardinality=, bottleneck_width=, model_name=, **kwargs)
def resnext26_16x4d():
    return get_resnext(blocks=, cardinality=, bottleneck_width=, model_name=, **kwargs)
def resnext26_32x2d():
    return get_resnext(blocks=, cardinality=, bottleneck_width=, model_name=, **kwargs)
def resnext26_32x4d():
    return get_resnext(blocks=, cardinality=, bottleneck_width=, model_name=, **kwargs)
def resnext38_32x4d():
    return get_resnext(blocks=, cardinality=, bottleneck_width=, model_name=, **kwargs)
def resnext50_32x4d():
    return get_resnext(blocks=, cardinality=, bottleneck_width=, model_name=, **kwargs)
def resnext101_32x4d():
    return get_resnext(blocks=, cardinality=, bottleneck_width=, model_name=, **kwargs)
def resnext101_64x4d():
    return get_resnext(blocks=, cardinality=, bottleneck_width=, model_name=, **kwargs)
def _test():
    import numpy as np
    data_format =
    pretrained =
    models = []
    for model in models:
        net = model(pretrained=, data_format=)
        x = tf.placeholder(dtype=,shape=() if is_channels_first() else (),name=)
        y_net = net()
        weight_count = np.sum([np.prod(v.get_shape().as_list()) for v in tf.trainable_variables()])
        with tf.Session() as sess:
            if pretrained:
                from .model_store import init_variables_from_state_dict
                init_variables_from_state_dict(sess=, state_dict=)
            else:
                sess.run(tf.global_variables_initializer())
            x_value = np.zeros(() if is_channels_first() else (), np.float32)
            y = sess.run(y_net, feed_dict={x:})
        tf.reset_default_graph()
if __name__ == "__main__":
    _test()
__all__ = []
import os
import math
import tensorflow as tf
from .common import conv1x1_block, conv3x3_block, maxpool2d, se_block, is_channels_first, flatten
def senet_bottleneck(x,in_channels,out_channels,strides,cardinality,bottleneck_width,training,data_format,name=):
    mid_channels =
    D = int(math.floor(mid_channels * ()))
    group_width =
    group_width2 =
    x = conv1x1_block(x=,in_channels=,out_channels=,training=,data_format=,name=)
    x = conv3x3_block(x=,in_channels=,out_channels=,strides=,groups=,training=,data_format=,name=)
    x = conv1x1_block(x=,in_channels=,out_channels=,activation=,training=,data_format=,name=)
    return x
def senet_unit(x,in_channels,out_channels,strides,cardinality,bottleneck_width,identity_conv3x3,training,data_format,name=):
    resize_identity = (in_channels !=) or (strides !=)
    if resize_identity:
        if identity_conv3x3:
            identity = conv3x3_block(x=,in_channels=,out_channels=,strides=,activation=,training=,data_format=,name=)
        else:
            identity = conv1x1_block(x=,in_channels=,out_channels=,strides=,activation=,training=,data_format=,name=)
    else:
        identity =
    x = senet_bottleneck(x=,in_channels=,out_channels=,strides=,cardinality=,bottleneck_width=,training=,data_format=,name=)
    x = se_block(x=,channels=,data_format=,name=)
    x =
    x = tf.nn.relu(x, name=)
    return x
def senet_init_block(x,in_channels,out_channels,training,data_format,name=):
    mid_channels =
    x = conv3x3_block(x=,in_channels=,out_channels=,strides=,training=,data_format=,name=)
    x = conv3x3_block(x=,in_channels=,out_channels=,training=,data_format=,name=)
    x = conv3x3_block(x=,in_channels=,out_channels=,training=,data_format=,name=)
    x = maxpool2d(x=,pool_size=,strides=,padding=,data_format=,name=)
    return x
class SENet():
    def __init__(self,channels,init_block_channels,cardinality,bottleneck_width,in_channels=,in_size=(),classes=,data_format=,**kwargs):
        super().__init__()
        self.channels =
        self.init_block_channels =
        self.cardinality =
        self.bottleneck_width =
        self.in_channels =
        self.in_size =
        self.classes =
        self.data_format =
    def __call__(self,x,training=):
        in_channels =
        x = senet_init_block(x=,in_channels=,out_channels=,training=,data_format=,name=)
        in_channels =
        for i, channels_per_stage in enumerate():
            identity_conv3x3 = (i !=)
            for j, out_channels in enumerate():
                strides = 2 if (j ==) and (i !=) else 1
                x = senet_unit(x=,in_channels=,out_channels=,strides=,cardinality=,bottleneck_width=,identity_conv3x3=,training=,data_format=,name="")
                in_channels =
        x = tf.keras.layers.AveragePooling2D(pool_size=,strides=,data_format=,name=)()
        x = flatten(x=,data_format=)
        x = tf.keras.layers.Dropout(rate=,name=)(inputs=,training=)
        x = tf.keras.layers.Dense(units=,name=)()
        return x
def get_senet(blocks,model_name=,pretrained=,root=os.path.join(),**kwargs):
    if blocks == 16:
        layers = []
        cardinality =
    elif blocks == 28:
        layers = []
        cardinality =
    elif blocks == 40:
        layers = []
        cardinality =
    elif blocks == 52:
        layers = []
        cardinality =
    elif blocks == 103:
        layers = []
        cardinality =
    elif blocks == 154:
        layers = []
        cardinality =
    else:
        raise ValueError()
    bottleneck_width =
    init_block_channels =
    channels_per_layers = []
    channels = [[] * li for () in zip()]
    net = SENet(channels=,init_block_channels=,cardinality=,bottleneck_width=,**kwargs)
    if pretrained:
        if () or ():
            raise ValueError()
        from .model_store import download_state_dict
        net.state_dict, net.file_path = download_state_dict(model_name=,local_model_store_dir_path=)
    else:
        net.state_dict =
        net.file_path =
    return net
def senet16():
    return get_senet(blocks=, model_name=, **kwargs)
def senet28():
    return get_senet(blocks=, model_name=, **kwargs)
def senet40():
    return get_senet(blocks=, model_name=, **kwargs)
def senet52():
    return get_senet(blocks=, model_name=, **kwargs)
def senet103():
    return get_senet(blocks=, model_name=, **kwargs)
def senet154():
    return get_senet(blocks=, model_name=, **kwargs)
def _test():
    import numpy as np
    data_format =
    pretrained =
    models = []
    for model in models:
        net = model(pretrained=, data_format=)
        x = tf.placeholder(dtype=,shape=() if is_channels_first() else (),name=)
        y_net = net()
        weight_count = np.sum([np.prod(v.get_shape().as_list()) for v in tf.trainable_variables()])
        with tf.Session() as sess:
            if pretrained:
                from .model_store import init_variables_from_state_dict
                init_variables_from_state_dict(sess=, state_dict=)
            else:
                sess.run(tf.global_variables_initializer())
            x_value = np.zeros(() if is_channels_first() else (), np.float32)
            y = sess.run(y_net, feed_dict={x:})
        tf.reset_default_graph()
if __name__ == "__main__":
    _test()
__all__ = []
import os
import tensorflow as tf
from .common import conv1x1, se_block, is_channels_first, flatten
from .preresnet import preres_block, preres_bottleneck_block, preres_init_block, preres_activation
def sepreres_unit(x,in_channels,out_channels,strides,bottleneck,conv1_stride,training,data_format,name=):
    identity =
    if bottleneck:
        x, x_pre_activ = preres_bottleneck_block(x=,in_channels=,out_channels=,strides=,conv1_stride=,training=,data_format=,name=)
    else:
        x, x_pre_activ = preres_block(x=,in_channels=,out_channels=,strides=,training=,data_format=,name=)
    x = se_block(x=,channels=,data_format=,name=)
    resize_identity = (in_channels !=) or (strides !=)
    if resize_identity:
        identity = conv1x1(x=,in_channels=,out_channels=,strides=,data_format=,name=)
    x =
    return x
class SEPreResNet():
    def __init__(self,channels,init_block_channels,bottleneck,conv1_stride,in_channels=,in_size=(),classes=,data_format=,**kwargs):
        super().__init__()
        self.channels =
        self.init_block_channels =
        self.bottleneck =
        self.conv1_stride =
        self.in_channels =
        self.in_size =
        self.classes =
        self.data_format =
    def __call__(self,x,training=):
        in_channels =
        x = preres_init_block(x=,in_channels=,out_channels=,training=,data_format=,name=)
        in_channels =
        for i, channels_per_stage in enumerate():
            for j, out_channels in enumerate():
                strides = 2 if (j ==) and (i !=) else 1
                x = sepreres_unit(x=,in_channels=,out_channels=,strides=,bottleneck=,conv1_stride=,training=,data_format=,name="")
                in_channels =
        x = preres_activation(x=,training=,data_format=,name=)
        x = tf.keras.layers.AveragePooling2D(pool_size=,strides=,data_format=,name=)()
        x = flatten(x=,data_format=)
        x = tf.keras.layers.Dense(units=,name=)()
        return x
def get_sepreresnet(blocks,bottleneck=,conv1_stride=,model_name=,pretrained=,root=os.path.join(),**kwargs):
    if bottleneck is None:
        bottleneck = (blocks >=)
    if blocks == 10:
        layers = []
    elif blocks == 12:
        layers = []
    elif blocks == 14 and not bottleneck:
        layers = []
    elif (blocks ==) and bottleneck:
        layers = []
    elif blocks == 16:
        layers = []
    elif blocks == 18:
        layers = []
    elif (blocks ==) and not bottleneck:
        layers = []
    elif (blocks ==) and bottleneck:
        layers = []
    elif blocks == 34:
        layers = []
    elif (blocks ==) and bottleneck:
        layers = []
    elif blocks == 50:
        layers = []
    elif blocks == 101:
        layers = []
    elif blocks == 152:
        layers = []
    elif blocks == 200:
        layers = []
    elif blocks == 269:
        layers = []
    else:
        raise ValueError()
    if bottleneck:
    else:
    init_block_channels =
    channels_per_layers = []
    if bottleneck:
        bottleneck_factor =
        channels_per_layers = []
    channels = [[] * li for () in zip()]
    net = SEPreResNet(channels=,init_block_channels=,bottleneck=,conv1_stride=,**kwargs)
    if pretrained:
        if () or ():
            raise ValueError()
        from .model_store import download_state_dict
        net.state_dict, net.file_path = download_state_dict(model_name=,local_model_store_dir_path=)
    else:
        net.state_dict =
        net.file_path =
    return net
def sepreresnet10():
    return get_sepreresnet(blocks=, model_name=, **kwargs)
def sepreresnet12():
    return get_sepreresnet(blocks=, model_name=, **kwargs)
def sepreresnet14():
    return get_sepreresnet(blocks=, model_name=, **kwargs)
def sepreresnet16():
    return get_sepreresnet(blocks=, model_name=, **kwargs)
def sepreresnet18():
    return get_sepreresnet(blocks=, model_name=, **kwargs)
def sepreresnet26():
    return get_sepreresnet(blocks=, model_name=, **kwargs)
def sepreresnetbc26b():
    return get_sepreresnet(blocks=, bottleneck=, conv1_stride=, model_name=, **kwargs)
def sepreresnet34():
    return get_sepreresnet(blocks=, model_name=, **kwargs)
def sepreresnetbc38b():
    return get_sepreresnet(blocks=, bottleneck=, conv1_stride=, model_name=, **kwargs)
def sepreresnet50():
    return get_sepreresnet(blocks=, model_name=, **kwargs)
def sepreresnet50b():
    return get_sepreresnet(blocks=, conv1_stride=, model_name=, **kwargs)
def sepreresnet101():
    return get_sepreresnet(blocks=, model_name=, **kwargs)
def sepreresnet101b():
    return get_sepreresnet(blocks=, conv1_stride=, model_name=, **kwargs)
def sepreresnet152():
    return get_sepreresnet(blocks=, model_name=, **kwargs)
def sepreresnet152b():
    return get_sepreresnet(blocks=, conv1_stride=, model_name=, **kwargs)
def sepreresnet200():
    return get_sepreresnet(blocks=, model_name=, **kwargs)
def sepreresnet200b():
    return get_sepreresnet(blocks=, conv1_stride=, model_name=, **kwargs)
def _test():
    import numpy as np
    data_format =
    pretrained =
    models = []
    for model in models:
        net = model(pretrained=, data_format=)
        x = tf.placeholder(dtype=,shape=() if is_channels_first() else (),name=)
        y_net = net()
        weight_count = np.sum([np.prod(v.get_shape().as_list()) for v in tf.trainable_variables()])
        with tf.Session() as sess:
            if pretrained:
                from .model_store import init_variables_from_state_dict
                init_variables_from_state_dict(sess=, state_dict=)
            else:
                sess.run(tf.global_variables_initializer())
            x_value = np.zeros(() if is_channels_first() else (), np.float32)
            y = sess.run(y_net, feed_dict={x:})
        tf.reset_default_graph()
if __name__ == "__main__":
    _test()
__all__ = []
import os
import tensorflow as tf
from .common import conv1x1_block, se_block, is_channels_first, flatten
from .resnet import res_block, res_bottleneck_block, res_init_block
def seres_unit(x,in_channels,out_channels,strides,bottleneck,conv1_stride,training,data_format,name=):
    resize_identity = (in_channels !=) or (strides !=)
    if resize_identity:
        identity = conv1x1_block(x=,in_channels=,out_channels=,strides=,activation=,training=,data_format=,name=)
    else:
        identity =
    if bottleneck:
        x = res_bottleneck_block(x=,in_channels=,out_channels=,strides=,conv1_stride=,training=,data_format=,name=)
    else:
        x = res_block(x=,in_channels=,out_channels=,strides=,training=,data_format=,name=)
    x = se_block(x=,channels=,data_format=,name=)
    x =
    x = tf.nn.relu(x, name=)
    return x
class SEResNet():
    def __init__(self,channels,init_block_channels,bottleneck,conv1_stride,in_channels=,in_size=(),classes=,data_format=,**kwargs):
        super().__init__()
        self.channels =
        self.init_block_channels =
        self.bottleneck =
        self.conv1_stride =
        self.in_channels =
        self.in_size =
        self.classes =
        self.data_format =
    def __call__(self,x,training=):
        in_channels =
        x = res_init_block(x=,in_channels=,out_channels=,training=,data_format=,name=)
        in_channels =
        for i, channels_per_stage in enumerate():
            for j, out_channels in enumerate():
                strides = 2 if (j ==) and (i !=) else 1
                x = seres_unit(x=,in_channels=,out_channels=,strides=,bottleneck=,conv1_stride=,training=,data_format=,name="")
                in_channels =
        x = tf.keras.layers.AveragePooling2D(pool_size=,strides=,data_format=,name=)()
        x = flatten(x=,data_format=)
        x = tf.keras.layers.Dense(units=,name=)()
        return x
def get_seresnet(blocks,bottleneck=,conv1_stride=,model_name=,pretrained=,root=os.path.join(),**kwargs):
    if bottleneck is None:
        bottleneck = (blocks >=)
    if blocks == 10:
        layers = []
    elif blocks == 12:
        layers = []
    elif blocks == 14 and not bottleneck:
        layers = []
    elif (blocks ==) and bottleneck:
        layers = []
    elif blocks == 16:
        layers = []
    elif blocks == 18:
        layers = []
    elif (blocks ==) and not bottleneck:
        layers = []
    elif (blocks ==) and bottleneck:
        layers = []
    elif blocks == 34:
        layers = []
    elif (blocks ==) and bottleneck:
        layers = []
    elif blocks == 50:
        layers = []
    elif blocks == 101:
        layers = []
    elif blocks == 152:
        layers = []
    elif blocks == 200:
        layers = []
    else:
        raise ValueError()
    if bottleneck:
    else:
    init_block_channels =
    channels_per_layers = []
    if bottleneck:
        bottleneck_factor =
        channels_per_layers = []
    channels = [[] * li for () in zip()]
    net = SEResNet(channels=,init_block_channels=,bottleneck=,conv1_stride=,**kwargs)
    if pretrained:
        if () or ():
            raise ValueError()
        from .model_store import download_state_dict
        net.state_dict, net.file_path = download_state_dict(model_name=,local_model_store_dir_path=)
    else:
        net.state_dict =
        net.file_path =
    return net
def seresnet10():
    return get_seresnet(blocks=, model_name=, **kwargs)
def seresnet12():
    return get_seresnet(blocks=, model_name=, **kwargs)
def seresnet14():
    return get_seresnet(blocks=, model_name=, **kwargs)
def seresnet16():
    return get_seresnet(blocks=, model_name=, **kwargs)
def seresnet18():
    return get_seresnet(blocks=, model_name=, **kwargs)
def seresnet26():
    return get_seresnet(blocks=, bottleneck=, model_name=, **kwargs)
def seresnetbc26b():
    return get_seresnet(blocks=, bottleneck=, conv1_stride=, model_name=, **kwargs)
def seresnet34():
    return get_seresnet(blocks=, model_name=, **kwargs)
def seresnetbc38b():
    return get_seresnet(blocks=, bottleneck=, conv1_stride=, model_name=, **kwargs)
def seresnet50():
    return get_seresnet(blocks=, model_name=, **kwargs)
def seresnet50b():
    return get_seresnet(blocks=, conv1_stride=, model_name=, **kwargs)
def seresnet101():
    return get_seresnet(blocks=, model_name=, **kwargs)
def seresnet101b():
    return get_seresnet(blocks=, conv1_stride=, model_name=, **kwargs)
def seresnet152():
    return get_seresnet(blocks=, model_name=, **kwargs)
def seresnet152b():
    return get_seresnet(blocks=, conv1_stride=, model_name=, **kwargs)
def seresnet200():
    return get_seresnet(blocks=, model_name=, **kwargs)
def seresnet200b():
    return get_seresnet(blocks=, conv1_stride=, model_name=, **kwargs)
def _test():
    import numpy as np
    data_format =
    pretrained =
    models = []
    for model in models:
        net = model(pretrained=, data_format=)
        x = tf.placeholder(dtype=,shape=() if is_channels_first() else (),name=)
        y_net = net()
        weight_count = np.sum([np.prod(v.get_shape().as_list()) for v in tf.trainable_variables()])
        with tf.Session() as sess:
            if pretrained:
                from .model_store import init_variables_from_state_dict
                init_variables_from_state_dict(sess=, state_dict=)
            else:
                sess.run(tf.global_variables_initializer())
            x_value = np.zeros(() if is_channels_first() else (), np.float32)
            y = sess.run(y_net, feed_dict={x:})
        tf.reset_default_graph()
if __name__ == "__main__":
    _test()
__all__ = []
import os
import tensorflow as tf
from .common import conv1x1_block, se_block, is_channels_first, flatten
from .resnet import res_init_block
from .resnext import resnext_bottleneck
def seresnext_unit(x,in_channels,out_channels,strides,cardinality,bottleneck_width,training,data_format,name=):
    resize_identity = (in_channels !=) or (strides !=)
    if resize_identity:
        identity = conv1x1_block(x=,in_channels=,out_channels=,strides=,activation=,training=,data_format=,name=)
    else:
        identity =
    x = resnext_bottleneck(x=,in_channels=,out_channels=,strides=,cardinality=,bottleneck_width=,training=,data_format=,name=)
    x = se_block(x=,channels=,data_format=,name=)
    x =
    x = tf.nn.relu(x, name=)
    return x
class SEResNeXt():
    def __init__(self,channels,init_block_channels,cardinality,bottleneck_width,in_channels=,in_size=(),classes=,data_format=,**kwargs):
        super().__init__()
        self.channels =
        self.init_block_channels =
        self.cardinality =
        self.bottleneck_width =
        self.in_channels =
        self.in_size =
        self.classes =
        self.data_format =
    def __call__(self,x,training=):
        in_channels =
        x = res_init_block(x=,in_channels=,out_channels=,training=,data_format=,name=)
        in_channels =
        for i, channels_per_stage in enumerate():
            for j, out_channels in enumerate():
                strides = 2 if (j ==) and (i !=) else 1
                x = seresnext_unit(x=,in_channels=,out_channels=,strides=,cardinality=,bottleneck_width=,training=,data_format=,name="")
                in_channels =
        x = tf.keras.layers.AveragePooling2D(pool_size=,strides=,data_format=,name=)()
        x = flatten(x=,data_format=)
        x = tf.keras.layers.Dense(units=,name=)()
        return x
def get_seresnext(blocks,cardinality,bottleneck_width,model_name=,pretrained=,root=os.path.join(),**kwargs):
    if blocks == 50:
        layers = []
    elif blocks == 101:
        layers = []
    else:
        raise ValueError()
    init_block_channels =
    channels_per_layers = []
    channels = [[] * li for () in zip()]
    net = SEResNeXt(channels=,init_block_channels=,cardinality=,bottleneck_width=,**kwargs)
    if pretrained:
        if () or ():
            raise ValueError()
        from .model_store import download_state_dict
        net.state_dict, net.file_path = download_state_dict(model_name=,local_model_store_dir_path=)
    else:
        net.state_dict =
        net.file_path =
    return net
def seresnext50_32x4d():
    return get_seresnext(blocks=, cardinality=, bottleneck_width=, model_name=, **kwargs)
def seresnext101_32x4d():
    return get_seresnext(blocks=, cardinality=, bottleneck_width=, model_name=, **kwargs)
def seresnext101_64x4d():
    return get_seresnext(blocks=, cardinality=, bottleneck_width=, model_name=, **kwargs)
def _test():
    import numpy as np
    data_format =
    pretrained =
    models = []
    for model in models:
        net = model(pretrained=, data_format=)
        x = tf.placeholder(dtype=,shape=() if is_channels_first() else (),name=)
        y_net = net()
        weight_count = np.sum([np.prod(v.get_shape().as_list()) for v in tf.trainable_variables()])
        with tf.Session() as sess:
            if pretrained:
                from .model_store import init_variables_from_state_dict
                init_variables_from_state_dict(sess=, state_dict=)
            else:
                sess.run(tf.global_variables_initializer())
            x_value = np.zeros(() if is_channels_first() else (), np.float32)
            y = sess.run(y_net, feed_dict={x:})
        tf.reset_default_graph()
if __name__ == "__main__":
    _test()
import importlib
from io import open
import tensorflow as tf
import texar.tf as tx
import numpy as np
from interpolation_decoder import InterpolationDecoder
from interpolation_helper import InterpolationHelper
from rouge import Rouge
flags =
flags.DEFINE_string()
flags.DEFINE_string()
flags.DEFINE_float()
flags.DEFINE_float()
flags.DEFINE_integer()
flags.DEFINE_string()
FLAGS =
config_model = importlib.import_module()
config_data = importlib.import_module()
FLAGS.lambdas_init = eval()
if not FLAGS.output_dir.endswith():
    FLAGS.output_dir +=
log_dir = FLAGS.output_dir + "" +"" + "" + str(FLAGS.lambdas_init[]) +"" + str(FLAGS.lambdas_init[]) +"" + str(FLAGS.lambdas_init[]) +"" + str() +"" + str() +"" + str() + ""
tx.utils.maybe_create_dir()
def build_model():
    batch_size = tf.shape(batch[])[]
    source_embedder = tx.modules.WordEmbedder(vocab_size=, hparams=)
    encoder = tx.modules.BidirectionalRNNEncoder(hparams=)
    enc_outputs, _ = encoder(source_embedder(batch[]))
    target_embedder = tx.modules.WordEmbedder(vocab_size=, hparams=)
    decoder = InterpolationDecoder(memory=tf.concat(enc_outputs, axis=),memory_sequence_length=batch[],vocab_size=,hparams=)
    start_tokens = tf.ones_like(batch[]) * train_data.target_vocab.bos_token_id
    helper = InterpolationHelper(embedding=,start_tokens=,end_token=,reward_metric=,vocab=,ground_truth=batch[][:, 1:],ground_truth_length=batch[] - 1,lambdas=,)
    training_outputs, _, training_length = decoder(helper=,initial_state=decoder.zero_state(batch_size=, dtype=),max_decoding_length=)
    train_op = tx.core.get_train_op(tx.losses.sequence_sparse_softmax_cross_entropy(labels=,logits=,sequence_length=),hparams=)
    beam_search_outputs, _, _ = tx.modules.beam_search_decode(decoder_or_cell=,embedding=,start_tokens=,end_token=,beam_width=,max_decoding_length=)
    return train_op, beam_search_outputs
def print_stdout_and_file():
def main():
    training_data = tx.data.PairedTextData(hparams=)
    val_data = tx.data.PairedTextData(hparams=)
    test_data = tx.data.PairedTextData(hparams=)
    data_iterator = tx.data.TrainTestDataIterator(train=, val=, test=)
    batch = data_iterator.get_next()
    lambdas_ts = tf.placeholder(shape=[], dtype=)
    train_op, infer_outputs = build_model()
    def _train_epoch():
        data_iterator.switch_to_train_data()
        log_file = open(log_dir + "" + str() + "", "",encoding=)
        step =
        while True:
            try:
                loss = sess.run(train_op, feed_dict={lambdas_ts:})
                if step % config_data.observe_steps == 0:
                log_file.flush()
                step +=
            except tf.errors.OutOfRangeError:
                break
    def _eval_epoch():
        if mode == "":
            data_iterator.switch_to_val_data()
        else:
            data_iterator.switch_to_test_data()
        refs, hypos = [], []
        while True:
            try:
                fetches = [batch[][:, 1:],infer_outputs.predicted_ids[:, :, 0]]
                feed_dict = {tx.global_mode():}
                target_texts_ori, output_ids = sess.run(fetches, feed_dict=)
                target_texts = tx.utils.strip_special_tokens(target_texts_ori.tolist(), is_token_list=)
                target_texts = tx.utils.str_join()
                output_texts = tx.utils.map_ids_to_strs(ids=, vocab=)
                tx.utils.write_paired_text(target_texts, output_texts,log_dir + mode + "" + str() + "",append=, mode=, sep=)
                for hypo, ref in zip():
                    if config_data.eval_metric == "":
                        hypos.append()
                        refs.append([])
                    elif config_data.eval_metric == "":
                        hypos.append(tx.utils.compat_as_text())
                        refs.append(tx.utils.compat_as_text())
            except tf.errors.OutOfRangeError:
                break
        if config_data.eval_metric == "":
            return tx.evals.corpus_bleu_moses(list_of_references=, hypotheses=)
        elif config_data.eval_metric == "":
            rouge = Rouge()
            return rouge.get_scores(hyps=, refs=, avg=)
    def _calc_reward():
        if config_data.eval_metric == "":
            return score
        elif config_data.eval_metric == "":
            return sum([value[] for key, value in score.items()])
    def _anneal():
        def _update_self():
            lambdas[] -=
            lambdas[] +=
            updates.append()
        def _update_rew():
            lambdas[] -=
            lambdas[] +=
            updates.append()
        if updates[-FLAGS.lambda_reward_steps:] == [] * FLAGS.lambda_reward_steps:
            _update_self()
        else:
            _update_rew()
    saver = tf.train.Saver(max_to_keep=)
    with tf.Session() as sess:
        sess.run(tf.global_variables_initializer())
        sess.run(tf.local_variables_initializer())
        sess.run(tf.tables_initializer())
        lambdas =
        updates = [] * FLAGS.lambda_reward_steps
        best_val_score, best_val_score_current_lambdas =, -1.
        scores_file = open(log_dir + "", "", encoding=)
        for i in range():
            _train_epoch()
            saver.save(sess, log_dir + "")
            val_score = _eval_epoch()
            test_score = _eval_epoch()
            if _calc_reward() < best_val_score_current_lambdas:
                _anneal()
                best_val_score_current_lambdas =
                saver.restore(sess, log_dir + "")
            else:
                best_val_score_current_lambdas = _calc_reward()
            best_val_score = max(best_val_score, _calc_reward())
            if config_data.eval_metric == "":
            elif config_data.eval_metric == "":
                for key, value in val_score.items():
                for key, value in test_score.items():
            scores_file.flush()
if __name__ == "__main__":
    main()
__all__ = []
import os
import tensorflow as tf
from .common import conv1x1, conv3x3, depthwise_conv3x3, batchnorm, channel_shuffle, maxpool2d, avgpool2d,is_channels_first, get_channel_axis, flatten
def shuffle_unit(x,in_channels,out_channels,groups,downsample,ignore_group,training,data_format,name=):
    mid_channels =
    if downsample:
        out_channels -=
    identity =
    x = conv1x1(x=,in_channels=,out_channels=,groups=(),data_format=,name=)
    x = batchnorm(x=,training=,data_format=,name=)
    x = tf.nn.relu(x, name=)
    x = channel_shuffle(x=,groups=,data_format=)
    x = depthwise_conv3x3(x=,channels=,strides=(),data_format=,name=)
    x = batchnorm(x=,training=,data_format=,name=)
    x = conv1x1(x=,in_channels=,out_channels=,groups=,data_format=,name=)
    x = batchnorm(x=,training=,data_format=,name=)
    if downsample:
        identity = avgpool2d(x=,pool_size=,strides=,padding=,data_format=,name=)
        x = tf.concat([], axis=get_channel_axis(), name=)
    else:
        x =
    x = tf.nn.relu(x, name=)
    return x
def shuffle_init_block(x,in_channels,out_channels,training,data_format,name=):
    x = conv3x3(x=,in_channels=,out_channels=,strides=,data_format=,name=)
    x = batchnorm(x=,training=,data_format=,name=)
    x = tf.nn.relu(x, name=)
    x = maxpool2d(x=,pool_size=,strides=,padding=,data_format=,name=)
    return x
class ShuffleNet():
    def __init__(self,channels,init_block_channels,groups,in_channels=,in_size=(),classes=,data_format=,**kwargs):
        super().__init__()
        self.channels =
        self.init_block_channels =
        self.groups =
        self.in_channels =
        self.in_size =
        self.classes =
        self.data_format =
    def __call__(self,x,training=):
        in_channels =
        x = shuffle_init_block(x=,in_channels=,out_channels=,training=,data_format=,name=)
        in_channels =
        for i, channels_per_stage in enumerate():
            for j, out_channels in enumerate():
                downsample = (j ==)
                ignore_group = (i ==) and (j ==)
                x = shuffle_unit(x=,in_channels=,out_channels=,groups=,downsample=,ignore_group=,training=,data_format=,name="")
                in_channels =
        x = tf.keras.layers.AveragePooling2D(pool_size=,strides=,data_format=,name=)()
        x = flatten(x=,data_format=)
        x = tf.keras.layers.Dense(units=,name=)()
        return x
def get_shufflenet(groups,width_scale,model_name=,pretrained=,root=os.path.join(),**kwargs):
    init_block_channels =
    layers = []
    if groups == 1:
        channels_per_layers = []
    elif groups == 2:
        channels_per_layers = []
    elif groups == 3:
        channels_per_layers = []
    elif groups == 4:
        channels_per_layers = []
    elif groups == 8:
        channels_per_layers = []
    else:
        raise ValueError()
    channels = [[] * li for () in zip()]
    if width_scale != 1.0:
        channels = [[int() for cij in ci] for ci in channels]
        init_block_channels = int()
    net = ShuffleNet(channels=,init_block_channels=,groups=,**kwargs)
    if pretrained:
        if () or ():
            raise ValueError()
        from .model_store import download_state_dict
        net.state_dict, net.file_path = download_state_dict(model_name=,local_model_store_dir_path=)
    else:
        net.state_dict =
        net.file_path =
    return net
def shufflenet_g1_w1():
    return get_shufflenet(groups=, width_scale=, model_name=, **kwargs)
def shufflenet_g2_w1():
    return get_shufflenet(groups=, width_scale=, model_name=, **kwargs)
def shufflenet_g3_w1():
    return get_shufflenet(groups=, width_scale=, model_name=, **kwargs)
def shufflenet_g4_w1():
    return get_shufflenet(groups=, width_scale=, model_name=, **kwargs)
def shufflenet_g8_w1():
    return get_shufflenet(groups=, width_scale=, model_name=, **kwargs)
def shufflenet_g1_w3d4():
    return get_shufflenet(groups=, width_scale=, model_name=, **kwargs)
def shufflenet_g3_w3d4():
    return get_shufflenet(groups=, width_scale=, model_name=, **kwargs)
def shufflenet_g1_wd2():
    return get_shufflenet(groups=, width_scale=, model_name=, **kwargs)
def shufflenet_g3_wd2():
    return get_shufflenet(groups=, width_scale=, model_name=, **kwargs)
def shufflenet_g1_wd4():
    return get_shufflenet(groups=, width_scale=, model_name=, **kwargs)
def shufflenet_g3_wd4():
    return get_shufflenet(groups=, width_scale=, model_name=, **kwargs)
def _test():
    import numpy as np
    data_format =
    pretrained =
    models = []
    for model in models:
        net = model(pretrained=, data_format=)
        x = tf.placeholder(dtype=,shape=() if is_channels_first() else (),name=)
        y_net = net()
        weight_count = np.sum([np.prod(v.get_shape().as_list()) for v in tf.trainable_variables()])
        with tf.Session() as sess:
            if pretrained:
                from .model_store import init_variables_from_state_dict
                init_variables_from_state_dict(sess=, state_dict=)
            else:
                sess.run(tf.global_variables_initializer())
            x_value = np.zeros(() if is_channels_first() else (), np.float32)
            y = sess.run(y_net, feed_dict={x:})
        tf.reset_default_graph()
if __name__ == "__main__":
    _test()
__all__ = []
import os
import tensorflow as tf
from .common import conv1x1, depthwise_conv3x3, conv1x1_block, conv3x3_block, batchnorm, channel_shuffle, maxpool2d,se_block, is_channels_first, get_channel_axis, flatten
def shuffle_unit(x,in_channels,out_channels,downsample,use_se,use_residual,training,data_format,name=):
    mid_channels =
    if downsample:
        y1 = depthwise_conv3x3(x=,channels=,strides=,data_format=,name=)
        y1 = batchnorm(x=,training=,data_format=,name=)
        y1 = conv1x1(x=,in_channels=,out_channels=,data_format=,name=)
        y1 = batchnorm(x=,training=,data_format=,name=)
        y1 = tf.nn.relu(y1, name=)
        x2 =
    else:
        y1, x2 = tf.split(x, num_or_size_splits=, axis=get_channel_axis())
    y2 = conv1x1(x=,in_channels=(),out_channels=,data_format=,name=)
    y2 = batchnorm(x=,training=,data_format=,name=)
    y2 = tf.nn.relu(y2, name=)
    y2 = depthwise_conv3x3(x=,channels=,strides=(),data_format=,name=)
    y2 = batchnorm(x=,training=,data_format=,name=)
    y2 = conv1x1(x=,in_channels=,out_channels=,data_format=,name=)
    y2 = batchnorm(x=,training=,data_format=,name=)
    y2 = tf.nn.relu(y2, name=)
    if use_se:
        y2 = se_block(x=,channels=,data_format=,name=)
    if use_residual and not downsample:
        y2 =
    x = tf.concat([], axis=get_channel_axis(), name=)
    x = channel_shuffle(x=,groups=,data_format=)
    return x
def shuffle_init_block(x,in_channels,out_channels,training,data_format,name=):
    x = conv3x3_block(x=,in_channels=,out_channels=,strides=,training=,data_format=,name=)
    x = maxpool2d(x=,pool_size=,strides=,padding=,ceil_mode=,data_format=,name=)
    return x
class ShuffleNetV2():
    def __init__(self,channels,init_block_channels,final_block_channels,use_se=,use_residual=,in_channels=,in_size=(),classes=,data_format=,**kwargs):
        super().__init__()
        self.channels =
        self.init_block_channels =
        self.final_block_channels =
        self.use_se =
        self.use_residual =
        self.in_channels =
        self.in_size =
        self.classes =
        self.data_format =
    def __call__(self,x,training=):
        in_channels =
        x = shuffle_init_block(x=,in_channels=,out_channels=,training=,data_format=,name=)
        in_channels =
        for i, channels_per_stage in enumerate():
            for j, out_channels in enumerate():
                downsample = (j ==)
                x = shuffle_unit(x=,in_channels=,out_channels=,downsample=,use_se=,use_residual=,training=,data_format=,name="")
                in_channels =
        x = conv1x1_block(x=,in_channels=,out_channels=,training=,data_format=,name=)
        x = tf.keras.layers.AveragePooling2D(pool_size=,strides=,data_format=,name=)()
        x = flatten(x=,data_format=)
        x = tf.keras.layers.Dense(units=,name=)()
        return x
def get_shufflenetv2(width_scale,model_name=,pretrained=,root=os.path.join(),**kwargs):
    init_block_channels =
    final_block_channels =
    layers = []
    channels_per_layers = []
    channels = [[] * li for () in zip()]
    if width_scale != 1.0:
        channels = [[int() for cij in ci] for ci in channels]
        if width_scale > 1.5:
            final_block_channels = int()
    net = ShuffleNetV2(channels=,init_block_channels=,final_block_channels=,**kwargs)
    if pretrained:
        if () or ():
            raise ValueError()
        from .model_store import download_state_dict
        net.state_dict, net.file_path = download_state_dict(model_name=,local_model_store_dir_path=)
    else:
        net.state_dict =
        net.file_path =
    return net
def shufflenetv2_wd2():
    return get_shufflenetv2(width_scale=(), model_name=, **kwargs)
def shufflenetv2_w1():
    return get_shufflenetv2(width_scale=, model_name=, **kwargs)
def shufflenetv2_w3d2():
    return get_shufflenetv2(width_scale=(), model_name=, **kwargs)
def shufflenetv2_w2():
    return get_shufflenetv2(width_scale=(), model_name=, **kwargs)
def _test():
    import numpy as np
    data_format =
    pretrained =
    models = []
    for model in models:
        net = model(pretrained=, data_format=)
        x = tf.placeholder(dtype=,shape=() if is_channels_first() else (),name=)
        y_net = net()
        weight_count = np.sum([np.prod(v.get_shape().as_list()) for v in tf.trainable_variables()])
        with tf.Session() as sess:
            if pretrained:
                from .model_store import init_variables_from_state_dict
                init_variables_from_state_dict(sess=, state_dict=)
            else:
                sess.run(tf.global_variables_initializer())
            x_value = np.zeros(() if is_channels_first() else (), np.float32)
            y = sess.run(y_net, feed_dict={x:})
        tf.reset_default_graph()
if __name__ == "__main__":
    _test()
__all__ = []
import os
import tensorflow as tf
from .common import conv1x1_block, conv3x3_block, dwconv3x3_block, channel_shuffle, channel_shuffle2, maxpool2d,se_block, is_channels_first, get_channel_axis, flatten
def shuffle_unit(x,in_channels,out_channels,downsample,use_se,use_residual,shuffle_group_first,training,data_format,name=):
    mid_channels =
    in_channels2 =
    if downsample:
        y1 = dwconv3x3_block(x=,in_channels=,out_channels=,strides=,activation=,training=,data_format=,name=)
        y1 = conv1x1_block(x=,in_channels=,out_channels=,training=,data_format=,name=)
        x2 =
    else:
        y1, x2 = tf.split(x, num_or_size_splits=, axis=get_channel_axis())
    y2_in_channels = ()
    y2_out_channels =
    y2 = conv1x1_block(x=,in_channels=,out_channels=,training=,data_format=,name=)
    y2 = dwconv3x3_block(x=,in_channels=,out_channels=,strides=(),activation=,training=,data_format=,name=)
    y2 = conv1x1_block(x=,in_channels=,out_channels=,training=,data_format=,name=)
    if use_se:
        y2 = se_block(x=,channels=,data_format=,name=)
    if use_residual and not downsample:
        y2 =
    x = tf.concat([], axis=get_channel_axis(), name=)
    if shuffle_group_first:
        x = channel_shuffle(x=,groups=,data_format=)
    else:
        x = channel_shuffle2(x=,groups=,data_format=)
    return x
def shuffle_init_block(x,in_channels,out_channels,training,data_format,name=):
    x = conv3x3_block(x=,in_channels=,out_channels=,strides=,training=,data_format=,name=)
    x = maxpool2d(x=,pool_size=,strides=,padding=,ceil_mode=,data_format=,name=)
    return x
class ShuffleNetV2b():
    def __init__(self,channels,init_block_channels,final_block_channels,use_se=,use_residual=,shuffle_group_first=,in_channels=,in_size=(),classes=,data_format=,**kwargs):
        super().__init__()
        self.channels =
        self.init_block_channels =
        self.final_block_channels =
        self.use_se =
        self.use_residual =
        self.shuffle_group_first =
        self.in_channels =
        self.in_size =
        self.classes =
        self.data_format =
    def __call__(self,x,training=):
        in_channels =
        x = shuffle_init_block(x=,in_channels=,out_channels=,training=,data_format=,name=)
        in_channels =
        for i, channels_per_stage in enumerate():
            for j, out_channels in enumerate():
                downsample = (j ==)
                x = shuffle_unit(x=,in_channels=,out_channels=,downsample=,use_se=,use_residual=,shuffle_group_first=,training=,data_format=,name="")
                in_channels =
        x = conv1x1_block(x=,in_channels=,out_channels=,training=,data_format=,name=)
        x = tf.keras.layers.AveragePooling2D(pool_size=,strides=,data_format=,name=)()
        x = flatten(x=,data_format=)
        x = tf.keras.layers.Dense(units=,name=)()
        return x
def get_shufflenetv2b(width_scale,shuffle_group_first=,model_name=,pretrained=,root=os.path.join(),**kwargs):
    init_block_channels =
    final_block_channels =
    layers = []
    channels_per_layers = []
    channels = [[] * li for () in zip()]
    if width_scale != 1.0:
        channels = [[int() for cij in ci] for ci in channels]
        if width_scale > 1.5:
            final_block_channels = int()
    net = ShuffleNetV2b(channels=,init_block_channels=,final_block_channels=,shuffle_group_first=,**kwargs)
    if pretrained:
        if () or ():
            raise ValueError()
        from .model_store import download_state_dict
        net.state_dict, net.file_path = download_state_dict(model_name=,local_model_store_dir_path=)
    else:
        net.state_dict =
        net.file_path =
    return net
def shufflenetv2b_wd2():
    return get_shufflenetv2b(width_scale=(),shuffle_group_first=,model_name=,**kwargs)
def shufflenetv2b_w1():
    return get_shufflenetv2b(width_scale=,shuffle_group_first=,model_name=,**kwargs)
def shufflenetv2b_w3d2():
    return get_shufflenetv2b(width_scale=(),shuffle_group_first=,model_name=,**kwargs)
def shufflenetv2b_w2():
    return get_shufflenetv2b(width_scale=(),shuffle_group_first=,model_name=,**kwargs)
def _test():
    import numpy as np
    data_format =
    pretrained =
    models = []
    for model in models:
        net = model(pretrained=, data_format=)
        x = tf.placeholder(dtype=,shape=() if is_channels_first() else (),name=)
        y_net = net()
        weight_count = np.sum([np.prod(v.get_shape().as_list()) for v in tf.trainable_variables()])
        with tf.Session() as sess:
            if pretrained:
                from .model_store import init_variables_from_state_dict
                init_variables_from_state_dict(sess=, state_dict=)
            else:
                sess.run(tf.global_variables_initializer())
            x_value = np.zeros(() if is_channels_first() else (), np.float32)
            y = sess.run(y_net, feed_dict={x:})
        tf.reset_default_graph()
if __name__ == "__main__":
    _test()
__all__ = []
import os
import tensorflow as tf
from .common import conv2d, maxpool2d, is_channels_first, get_channel_axis, flatten
def fire_conv(x,in_channels,out_channels,kernel_size,padding,data_format,name=):
    x = conv2d(x=,in_channels=,out_channels=,kernel_size=,padding=,use_bias=,data_format=,name=)
    x = tf.nn.relu(x, name=)
    return x
def fire_unit(x,in_channels,squeeze_channels,expand1x1_channels,expand3x3_channels,residual,data_format,name=):
    if residual:
        identity =
    x = fire_conv(x=,in_channels=,out_channels=,kernel_size=,padding=,data_format=,name=)
    y1 = fire_conv(x=,in_channels=,out_channels=,kernel_size=,padding=,data_format=,name=)
    y2 = fire_conv(x=,in_channels=,out_channels=,kernel_size=,padding=,data_format=,name=)
    out = tf.concat([], axis=get_channel_axis(), name=)
    if residual:
        out =
    return out
def squeeze_init_block(x,in_channels,out_channels,kernel_size,data_format,name=):
    x = conv2d(x=,in_channels=,out_channels=,kernel_size=,strides=,use_bias=,data_format=,name=)
    x = tf.nn.relu(x, name=)
    return x
class SqueezeNet():
    def __init__(self,channels,residuals,init_block_kernel_size,init_block_channels,in_channels=,in_size=(),classes=,data_format=,**kwargs):
        super().__init__()
        self.channels =
        self.residuals =
        self.init_block_kernel_size =
        self.init_block_channels =
        self.in_channels =
        self.in_size =
        self.classes =
        self.data_format =
    def __call__(self,x,training=):
        in_channels =
        x = squeeze_init_block(x=,in_channels=,out_channels=,kernel_size=,data_format=,name=)
        in_channels =
        for i, channels_per_stage in enumerate():
            x = maxpool2d(x=,pool_size=,strides=,ceil_mode=,data_format=,name="")
            for j, out_channels in enumerate():
                expand_channels =
                squeeze_channels =
                x = fire_unit(x=,in_channels=,squeeze_channels=,expand1x1_channels=,expand3x3_channels=,residual=(() and (self.residuals[][] ==)),data_format=,name="")
                in_channels =
        x = tf.keras.layers.Dropout(rate=,name=)(inputs=,training=)
        x = conv2d(x=,in_channels=,out_channels=,kernel_size=,data_format=,name=)
        x = tf.nn.relu(x, name=)
        x = tf.keras.layers.AveragePooling2D(pool_size=,strides=,data_format=,name=)()
        x = flatten(x=,data_format=)
        return x
def get_squeezenet(version,residual=,model_name=,pretrained=,root=os.path.join(),**kwargs):
    if version == "":
        channels = [[], [], []]
        residuals = [[], [], []]
        init_block_kernel_size =
        init_block_channels =
    elif version == "":
        channels = [[], [], []]
        residuals = [[], [], []]
        init_block_kernel_size =
        init_block_channels =
    else:
        raise ValueError()
    if not residual:
        residuals =
    net = SqueezeNet(channels=,residuals=,init_block_kernel_size=,init_block_channels=,**kwargs)
    if pretrained:
        if () or ():
            raise ValueError()
        from .model_store import download_state_dict
        net.state_dict, net.file_path = download_state_dict(model_name=,local_model_store_dir_path=)
    else:
        net.state_dict =
        net.file_path =
    return net
def squeezenet_v1_0():
    return get_squeezenet(version=, residual=, model_name=, **kwargs)
def squeezenet_v1_1():
    return get_squeezenet(version=, residual=, model_name=, **kwargs)
def squeezeresnet_v1_0():
    return get_squeezenet(version=, residual=, model_name=, **kwargs)
def squeezeresnet_v1_1():
    return get_squeezenet(version=, residual=, model_name=, **kwargs)
def _test():
    import numpy as np
    data_format =
    pretrained =
    models = []
    for model in models:
        net = model(pretrained=, data_format=)
        x = tf.placeholder(dtype=,shape=() if is_channels_first() else (),name=)
        y_net = net()
        weight_count = np.sum([np.prod(v.get_shape().as_list()) for v in tf.trainable_variables()])
        with tf.Session() as sess:
            if pretrained:
                from .model_store import init_variables_from_state_dict
                init_variables_from_state_dict(sess=, state_dict=)
            else:
                sess.run(tf.global_variables_initializer())
            x_value = np.zeros(() if is_channels_first() else (), np.float32)
            y = sess.run(y_net, feed_dict={x:})
        tf.reset_default_graph()
if __name__ == "__main__":
    _test()
__all__ = []
import os
import tensorflow as tf
from .common import maxpool2d, conv_block, conv1x1_block, conv7x7_block, is_channels_first, flatten
def sqnxt_unit(x,in_channels,out_channels,strides,training,data_format,name=):
    if strides == 2:
        reduction_den =
        resize_identity =
    elif in_channels > out_channels:
        reduction_den =
        resize_identity =
    else:
        reduction_den =
        resize_identity =
    if resize_identity:
        identity = conv1x1_block(x=,in_channels=,out_channels=,strides=,use_bias=,training=,data_format=,name=)
    else:
        identity =
    x = conv1x1_block(x=,in_channels=,out_channels=(),strides=,use_bias=,training=,data_format=,name=)
    x = conv1x1_block(x=,in_channels=(),out_channels=(in_channels // ()),use_bias=,training=,data_format=,name=)
    x = conv_block(x=,in_channels=(in_channels // ()),out_channels=(),kernel_size=(),strides=,padding=(),use_bias=,training=,data_format=,name=)
    x = conv_block(x=,in_channels=(),out_channels=(),kernel_size=(),strides=,padding=(),use_bias=,training=,data_format=,name=)
    x = conv1x1_block(x=,in_channels=(),out_channels=,use_bias=,training=,data_format=,name=)
    x =
    x = tf.nn.relu(x, name=)
    return x
def sqnxt_init_block(x,in_channels,out_channels,training,data_format,name=):
    x = conv7x7_block(x=,in_channels=,out_channels=,strides=,padding=,use_bias=,training=,data_format=,name=)
    x = maxpool2d(x=,pool_size=,strides=,ceil_mode=,data_format=,name=)
    return x
class SqueezeNext():
    def __init__(self,channels,init_block_channels,final_block_channels,in_channels=,in_size=(),classes=,data_format=,**kwargs):
        super().__init__()
        self.channels =
        self.init_block_channels =
        self.final_block_channels =
        self.in_channels =
        self.in_size =
        self.classes =
        self.data_format =
    def __call__(self,x,training=):
        in_channels =
        x = sqnxt_init_block(x=,in_channels=,out_channels=,training=,data_format=,name=)
        in_channels =
        for i, channels_per_stage in enumerate():
            for j, out_channels in enumerate():
                strides = 2 if (j ==) and (i !=) else 1
                x = sqnxt_unit(x=,in_channels=,out_channels=,strides=,training=,data_format=,name="")
                in_channels =
        x = conv1x1_block(x=,in_channels=,out_channels=,use_bias=,training=,data_format=,name=)
        x = tf.keras.layers.AveragePooling2D(pool_size=,strides=,data_format=,name=)()
        x = flatten(x=,data_format=)
        x = tf.keras.layers.Dense(units=,name=)()
        return x
def get_squeezenext(version,width_scale,model_name=,pretrained=,root=os.path.join(),**kwargs):
    init_block_channels =
    final_block_channels =
    channels_per_layers = []
    if version == "":
        layers = []
    elif version == "":
        layers = []
    else:
        raise ValueError()
    channels = [[] * li for () in zip()]
    if width_scale != 1:
        channels = [[int() for cij in ci] for ci in channels]
        init_block_channels = int()
        final_block_channels = int()
    net = SqueezeNext(channels=,init_block_channels=,final_block_channels=,**kwargs)
    if pretrained:
        if () or ():
            raise ValueError()
        from .model_store import download_state_dict
        net.state_dict, net.file_path = download_state_dict(model_name=,local_model_store_dir_path=)
    else:
        net.state_dict =
        net.file_path =
    return net
def sqnxt23_w1():
    return get_squeezenext(version=, width_scale=, model_name=, **kwargs)
def sqnxt23_w3d2():
    return get_squeezenext(version=, width_scale=, model_name=, **kwargs)
def sqnxt23_w2():
    return get_squeezenext(version=, width_scale=, model_name=, **kwargs)
def sqnxt23v5_w1():
    return get_squeezenext(version=, width_scale=, model_name=, **kwargs)
def sqnxt23v5_w3d2():
    return get_squeezenext(version=, width_scale=, model_name=, **kwargs)
def sqnxt23v5_w2():
    return get_squeezenext(version=, width_scale=, model_name=, **kwargs)
def _test():
    import numpy as np
    data_format =
    pretrained =
    models = []
    for model in models:
        net = model(pretrained=, data_format=)
        x = tf.placeholder(dtype=,shape=() if is_channels_first() else (),name=)
        y_net = net()
        weight_count = np.sum([np.prod(v.get_shape().as_list()) for v in tf.trainable_variables()])
        with tf.Session() as sess:
            if pretrained:
                from .model_store import init_variables_from_state_dict
                init_variables_from_state_dict(sess=, state_dict=)
            else:
                sess.run(tf.global_variables_initializer())
            x_value = np.zeros(() if is_channels_first() else (), np.float32)
            y = sess.run(y_net, feed_dict={x:})
        tf.reset_default_graph()
if __name__ == "__main__":
    _test()
__all__ = []
import os
import tensorflow as tf
from .common import conv3x3_block, maxpool2d, is_channels_first, flatten
def vgg_dense(x,in_channels,out_channels,training,name=):
    x = tf.keras.layers.Dense(units=,name=)()
    x = tf.nn.relu(x, name=)
    x = tf.keras.layers.Dropout(rate=,name=)(inputs=,training=)
    return x
def vgg_output_block(x,in_channels,classes,training,name=):
    mid_channels =
    x = vgg_dense(x=,in_channels=,out_channels=,training=,name=)
    x = vgg_dense(x=,in_channels=,out_channels=,training=,name=)
    x = tf.keras.layers.Dense(units=,name=)()
    return x
class VGG():
    def __init__(self,channels,use_bias=,use_bn=,in_channels=,in_size=(),classes=,data_format=,**kwargs):
        super().__init__()
        self.channels =
        self.use_bias =
        self.use_bn =
        self.in_channels =
        self.in_size =
        self.classes =
        self.data_format =
    def __call__(self,x,training=):
        in_channels =
        for i, channels_per_stage in enumerate():
            for j, out_channels in enumerate():
                x = conv3x3_block(x=,in_channels=,out_channels=,use_bias=,use_bn=,training=,data_format=,name="")
                in_channels =
            x = maxpool2d(x=,pool_size=,strides=,padding=,data_format=,name="")
        in_channels =
        x = flatten(x=,data_format=)
        x = vgg_output_block(x=,in_channels=,classes=,training=,name=)
        return x
def get_vgg(blocks,use_bias=,use_bn=,model_name=,pretrained=,root=os.path.join(),**kwargs):
    if blocks == 11:
        layers = []
    elif blocks == 13:
        layers = []
    elif blocks == 16:
        layers = []
    elif blocks == 19:
        layers = []
    else:
        raise ValueError()
    channels_per_layers = []
    channels = [[] * li for () in zip()]
    net = VGG(channels=,use_bias=,use_bn=,**kwargs)
    if pretrained:
        if () or ():
            raise ValueError()
        from .model_store import download_state_dict
        net.state_dict, net.file_path = download_state_dict(model_name=,local_model_store_dir_path=)
    else:
        net.state_dict =
        net.file_path =
    return net
def vgg11():
    return get_vgg(blocks=, model_name=, **kwargs)
def vgg13():
    return get_vgg(blocks=, model_name=, **kwargs)
def vgg16():
    return get_vgg(blocks=, model_name=, **kwargs)
def vgg19():
    return get_vgg(blocks=, model_name=, **kwargs)
def bn_vgg11():
    return get_vgg(blocks=, use_bias=, use_bn=, model_name=, **kwargs)
def bn_vgg13():
    return get_vgg(blocks=, use_bias=, use_bn=, model_name=, **kwargs)
def bn_vgg16():
    return get_vgg(blocks=, use_bias=, use_bn=, model_name=, **kwargs)
def bn_vgg19():
    return get_vgg(blocks=, use_bias=, use_bn=, model_name=, **kwargs)
def bn_vgg11b():
    return get_vgg(blocks=, use_bias=, use_bn=, model_name=, **kwargs)
def bn_vgg13b():
    return get_vgg(blocks=, use_bias=, use_bn=, model_name=, **kwargs)
def bn_vgg16b():
    return get_vgg(blocks=, use_bias=, use_bn=, model_name=, **kwargs)
def bn_vgg19b():
    return get_vgg(blocks=, use_bias=, use_bn=, model_name=, **kwargs)
def _test():
    import numpy as np
    data_format =
    pretrained =
    models = []
    for model in models:
        net = model(pretrained=, data_format=)
        x = tf.placeholder(dtype=,shape=() if is_channels_first() else (),name=)
        y_net = net()
        weight_count = np.sum([np.prod(v.get_shape().as_list()) for v in tf.trainable_variables()])
        with tf.Session() as sess:
            if pretrained:
                from .model_store import init_variables_from_state_dict
                init_variables_from_state_dict(sess=, state_dict=)
            else:
                sess.run(tf.global_variables_initializer())
            x_value = np.zeros(() if is_channels_first() else (), np.float32)
            y = sess.run(y_net, feed_dict={x:})
        tf.reset_default_graph()
if __name__ == "__main__":
    _test()
__all__ = []
import os
import tensorflow as tf
from .common import is_channels_first
from .alexnet import AlexNet
def get_zfnet(version=,model_name=,pretrained=,root=os.path.join(),**kwargs):
    if version == "":
        channels = [[], [], []]
        kernel_sizes = [[], [], []]
        strides = [[], [], []]
        paddings = [[], [], []]
        use_lrn =
    elif version == "":
        channels = [[], [], []]
        kernel_sizes = [[], [], []]
        strides = [[], [], []]
        paddings = [[], [], []]
        use_lrn =
    else:
        raise ValueError()
    net = AlexNet(channels=,kernel_sizes=,strides=,paddings=,use_lrn=,**kwargs)
    if pretrained:
        if () or ():
            raise ValueError()
        from .model_store import download_state_dict
        net.state_dict, net.file_path = download_state_dict(model_name=,local_model_store_dir_path=)
    else:
        net.state_dict =
        net.file_path =
    return net
def zfnet():
    return get_zfnet(model_name=, **kwargs)
def zfnetb():
    return get_zfnet(version=, model_name=, **kwargs)
def _test():
    import numpy as np
    data_format =
    pretrained =
    models = []
    for model in models:
        net = model(pretrained=, data_format=)
        x = tf.placeholder(dtype=,shape=() if is_channels_first() else (),name=)
        y_net = net()
        weight_count = np.sum([np.prod(v.get_shape().as_list()) for v in tf.trainable_variables()])
        with tf.Session() as sess:
            if pretrained:
                from .model_store import init_variables_from_state_dict
                init_variables_from_state_dict(sess=, state_dict=)
            else:
                sess.run(tf.global_variables_initializer())
            x_value = np.zeros(() if is_channels_first() else (), np.float32)
            y = sess.run(y_net, feed_dict={x:})
        tf.reset_default_graph()
if __name__ == "__main__":
    _test()
from __future__ import absolute_import
from __future__ import print_function
from __future__ import division
import os
import time
import tensorflow as tf
from six.moves import range
import numpy as np
import zhusuan as zs
from examples import conf
from examples.utils import dataset
def build_gen():
    bn = zs.BayesianNet()
    z_logits = tf.zeros([])
    z = bn.bernoulli("", z_logits, group_ndims=, n_samples=,dtype=)
    h = tf.layers.dense(z, 500, use_bias=)
    h = tf.layers.batch_normalization(h, training=)
    h = tf.nn.relu()
    h = tf.layers.dense(h, 500, use_bias=)
    h = tf.layers.batch_normalization(h, training=)
    h = tf.nn.relu()
    x_logits = tf.layers.dense()
    bn.bernoulli("", x_logits, group_ndims=)
    return bn
def build_q_net():
    bn = zs.BayesianNet()
    h = tf.layers.dense(tf.cast(), 500, use_bias=)
    h = tf.layers.batch_normalization(h, training=)
    h = tf.nn.relu()
    h = tf.layers.dense(h, 500, use_bias=)
    h = tf.layers.batch_normalization(h, training=)
    h = tf.nn.relu()
    z_logits = tf.layers.dense()
    bn.bernoulli("", z_logits, group_ndims=, n_samples=,dtype=)
    return bn
def baseline_net():
    lc_x = tf.layers.dense(tf.cast(), 100, activation=)
    lc_x = tf.layers.dense()
    lc_x = tf.squeeze()
    return lc_x
def main():
    data_path = os.path.join()
    x_train, t_train, x_valid, t_valid, x_test, t_test = dataset.load_mnist_realval()
    x_train = np.vstack([])
    x_test = np.random.binomial(1, x_test, size=)
    x_dim = x_train.shape[]
    z_dim =
    is_training = tf.placeholder(tf.bool, shape=[], name=)
    n_particles = tf.placeholder(tf.int32, shape=[], name=)
    x_input = tf.placeholder(tf.float32, shape=[], name=)
    x = tf.cast(tf.less(tf.random_uniform(tf.shape()), x_input),tf.int32)
    n = tf.shape()[]
    model = build_gen()
    variational = build_q_net()
    cx = tf.expand_dims(baseline_net(), 0)
    lower_bound = zs.variational.elbo(model, {"x":}, variational=, axis=)
    cost, baseline_cost = lower_bound.reinforce(baseline=)
    cost = tf.reduce_mean()
    lower_bound = tf.reduce_mean()
    is_log_likelihood = tf.reduce_mean(zs.is_loglikelihood(model, {'x':}, proposal=, axis=))
    optimizer = tf.train.AdamOptimizer(learning_rate=)
    update_ops = tf.get_collection()
    with tf.control_dependencies():
        infer_op = optimizer.minimize()
    epochs =
    batch_size =
    iters = x_train.shape[] // batch_size
    test_freq =
    test_batch_size =
    test_iters = x_test.shape[] // test_batch_size
    with tf.Session() as sess:
        sess.run(tf.global_variables_initializer())
        for epoch in range():
            time_epoch = -time.time()
            np.random.shuffle()
            lbs = []
            for t in range():
                x_batch = x_train[t * batch_size:() * batch_size]
                _, lb = sess.run([],feed_dict={x_input:,is_training:,n_particles:})
                lbs.append()
            time_epoch += time.time()
            if epoch % test_freq == 0:
                time_test = -time.time()
                test_lbs = []
                for t in range():
                    test_x_batch = x_test[t * test_batch_size:() * test_batch_size]
                    test_lb = sess.run(lower_bound,feed_dict={x:,is_training:,n_particles:})
                    test_lbs.append()
                time_test += time.time()
if __name__ == "__main__":
    main()
from __future__ import absolute_import
from __future__ import print_function
from __future__ import division
import os
import tensorflow as tf
from six.moves import range, zip
import numpy as np
import zhusuan as zs
from examples import conf
from examples.utils import dataset
def build_bnn():
    bn = zs.BayesianNet()
    h = tf.tile(x[], [])
    for i, () in enumerate(zip(layer_sizes[:], layer_sizes[1:])):
        w = bn.normal("" + str(), tf.zeros([]), std=,group_ndims=, n_samples=)
        h = tf.concat([h, tf.ones(tf.shape()[:])[]], -1)
        h = tf.einsum() / tf.sqrt(tf.cast(tf.shape()[], tf.float32))
        if i < len() - 2:
            h = tf.nn.relu()
    y_mean = bn.deterministic("", tf.squeeze())
    y_logstd = tf.get_variable("", shape=[],initializer=tf.constant_initializer())
    bn.normal("", y_mean, logstd=)
    return bn
def build_mean_field_variational():
    bn = zs.BayesianNet()
    for i, () in enumerate(zip(layer_sizes[:], layer_sizes[1:])):
        w_mean = tf.get_variable("" + str(), shape=[],initializer=tf.constant_initializer())
        w_logstd = tf.get_variable("" + str(), shape=[],initializer=tf.constant_initializer())
        bn.normal("" + str(), w_mean, logstd=,n_samples=, group_ndims=)
    return bn
def main():
    tf.set_random_seed()
    np.random.seed()
    data_path = os.path.join()
    x_train, y_train, x_valid, y_valid, x_test, y_test = dataset.load_uci_boston_housing()
    x_train = np.vstack([])
    y_train = np.hstack([])
    n_train, x_dim =
    x_train, x_test, _, _ = dataset.standardize()
    y_train, y_test, mean_y_train, std_y_train = dataset.standardize()
    n_hiddens = []
    n_particles = tf.placeholder(tf.int32, shape=[], name=)
    x = tf.placeholder(tf.float32, shape=[])
    y = tf.placeholder(tf.float32, shape=[])
    layer_sizes = [] + n_hiddens + []
    w_names = ["" + str() for i in range(len() - 1)]
    model = build_bnn()
    variational = build_mean_field_variational()
    def log_joint():
        log_pws = bn.cond_log_prob()
        log_py_xw = bn.cond_log_prob()
        return tf.add_n() + tf.reduce_mean() * n_train
    model.log_joint =
    lower_bound = zs.variational.elbo(model, {'y':}, variational=, axis=)
    cost = lower_bound.sgvb()
    optimizer = tf.train.AdamOptimizer(learning_rate=)
    infer_op = optimizer.minimize()
    y_mean = lower_bound.bn[]
    y_pred = tf.reduce_mean()
    rmse = tf.sqrt(tf.reduce_mean(() ** 2)) * std_y_train
    log_py_xw = lower_bound.bn.cond_log_prob()
    log_likelihood = tf.reduce_mean(zs.log_mean_exp()) - tf.log()
    lb_samples =
    ll_samples =
    epochs =
    batch_size =
    iters = () // batch_size + 1
    test_freq =
    with tf.Session() as sess:
        sess.run(tf.global_variables_initializer())
        for epoch in range():
            perm = np.random.permutation(x_train.shape[])
            x_train = x_train[perm, :]
            y_train = y_train[]
            lbs = []
            for t in range():
                x_batch = x_train[t * batch_size:() * batch_size]
                y_batch = y_train[t * batch_size:() * batch_size]
                _, lb = sess.run([],feed_dict={n_particles:,x:, y:})
                lbs.append()
            if epoch % test_freq == 0:
                test_rmse, test_ll = sess.run([],feed_dict={n_particles:,x:, y:})
if __name__ == "__main__":
    main()
from __future__ import absolute_import
from __future__ import print_function
from __future__ import division
import os
import time
import tensorflow as tf
from six.moves import range
import numpy as np
import zhusuan as zs
from examples import conf
from examples.utils import dataset
def build_gen():
    bn = zs.BayesianNet()
    z_mean = tf.zeros([])
    z = bn.normal("", z_mean, std=, group_ndims=, n_samples=)
    h = tf.layers.dense(z, 500, activation=)
    h = tf.layers.dense(h, 500, activation=)
    x_logits = tf.layers.dense()
    bn.bernoulli("", x_logits, group_ndims=)
    return bn
def build_q_net():
    bn = zs.BayesianNet()
    h = tf.layers.dense(tf.cast(), 500, activation=)
    h = tf.layers.dense(h, 500, activation=)
    z_mean = tf.layers.dense()
    z_logstd = tf.layers.dense()
    bn.normal("", z_mean, logstd=, group_ndims=,n_samples=)
    return bn
def main():
    tf.set_random_seed()
    np.random.seed()
    data_path = os.path.join()
    x_train, t_train, x_valid, t_valid, x_test, t_test = dataset.load_mnist_realval()
    x_train = np.vstack([])
    x_test = np.random.binomial(1, x_test, size=)
    x_dim = x_train.shape[]
    z_dim =
    n_particles = tf.placeholder(tf.int32, shape=[], name=)
    x_input = tf.placeholder(tf.float32, shape=[], name=)
    x = tf.cast(tf.less(tf.random_uniform(tf.shape()), x_input),tf.int32)
    n = tf.placeholder(tf.int32, shape=[], name=)
    model = build_gen()
    variational = build_q_net()
    lower_bound = zs.variational.importance_weighted_objective(model, {'x':}, variational=, axis=)
    cost = tf.reduce_mean(lower_bound.sgvb())
    lower_bound = tf.reduce_mean()
    optimizer = tf.train.AdamOptimizer(learning_rate=)
    infer_op = optimizer.minimize()
    lb_samples =
    epochs =
    batch_size =
    iters = x_train.shape[] // batch_size
    test_freq =
    test_batch_size =
    test_iters = x_test.shape[] // test_batch_size
    with tf.Session() as sess:
        sess.run(tf.global_variables_initializer())
        for epoch in range():
            time_epoch = -time.time()
            np.random.shuffle()
            lbs = []
            for t in range():
                x_batch = x_train[t * batch_size:() * batch_size]
                _, lb = sess.run([],feed_dict={x_input:,n_particles:,n:})
                lbs.append()
            time_epoch += time.time()
            if epoch % test_freq == 0:
                time_test = -time.time()
                test_lbs = []
                for t in range():
                    test_x_batch = x_test[t * test_batch_size:() * test_batch_size]
                    test_lb = sess.run(lower_bound,feed_dict={x:,n_particles:,n:})
                    test_lbs.append()
                time_test += time.time()
if __name__ == "__main__":
    main()
import importlib
import numpy as np
import tensorflow as tf
import texar.tf as tx
from ptb_reader import prepare_data
from ptb_reader import ptb_iterator_memnet as ptb_iterator
flags =
flags.DEFINE_string()
FLAGS =
config = importlib.import_module()
def _main():
    batch_size =
    memory_size =
    terminating_learning_rate =
    data = prepare_data()
    vocab_size = data[]
    inputs = tf.placeholder(tf.int32, [], name=)
    targets = tf.placeholder(tf.int32, [], name=)
    initializer = tf.random_normal_initializer(stddev=)
    with tf.variable_scope("", initializer=):
        memnet = tx.modules.MemNetRNNLike(raw_memory_dim=,hparams=)
        queries = tf.fill([tf.shape()[], config.dim],config.query_constant)
        logits = memnet()
    mle_loss = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=, logits=)
    mle_loss = tf.reduce_sum()
    lr = config.opt[][][]
    learning_rate = tf.placeholder(tf.float32, [], name=)
    global_step = tf.Variable(0, dtype=, name=)
    increment_global_step = tf.assign_add()
    train_op = tx.core.get_train_op(mle_loss,learning_rate=,global_step=,increment_global_step=,hparams=)
    def _run_epoch(sess, data_iter, epoch, is_train=):
        loss =
        iters =
        fetches = {"mle_loss":}
        if is_train:
            fetches[] =
        mode = ()
        for _, () in enumerate():
            batch_size = x.shape[]
            feed_dict = {inputs:, targets:, learning_rate:,tx.global_mode():,}
            rets = sess.run()
            loss += rets[]
            iters +=
        ppl = np.exp()
        return ppl
    saver = tf.train.Saver()
    with tf.Session() as sess:
        sess.run(tf.global_variables_initializer())
        sess.run(tf.local_variables_initializer())
        sess.run(tf.tables_initializer())
        try:
            saver.restore()
        except BaseException:
        last_valid_ppl =
        heuristic_lr_decay = (hasattr()and config.heuristic_lr_decay)
        while True:
            if lr < terminating_learning_rate:
                break
            epoch = sess.run()
            if epoch >= config.num_epochs:
                break
            train_data_iter = ptb_iterator(data[], batch_size, memory_size)
            train_ppl = _run_epoch(sess, train_data_iter, epoch, is_train=)
            sess.run()
            if epoch % 5 == 0:
                try:
                    saver.save()
                except BaseException:
            valid_data_iter = ptb_iterator(data[], batch_size, memory_size)
            valid_ppl = _run_epoch()
            if last_valid_ppl:
                if heuristic_lr_decay:
                    if valid_ppl > last_valid_ppl * config.heuristic_threshold:
                        lr /= 1. + () * config.heuristic_rate
                    last_valid_ppl = last_valid_ppl * () + valid_ppl * config.heuristic_smooth_rate
                else:
                    if valid_ppl > last_valid_ppl:
                        lr /=
                    last_valid_ppl =
            else:
                last_valid_ppl =
        epoch = sess.run()
        test_data_iter = ptb_iterator(data[], 1, memory_size)
        test_ppl = _run_epoch()
if __name__ == "__main__":
    tf.app.run(main=)
from __future__ import absolute_import
from __future__ import print_function
from __future__ import division
import sys
import os
import time
import tensorflow as tf
from six.moves import range, zip
from copy import copy
import numpy as np
import zhusuan as zs
from zhusuan.evaluation import AIS
from examples import conf
from examples.utils import dataset
log_delta =
def lntm():
    bn = zs.BayesianNet()
    eta_mean = tf.tile(tf.expand_dims(), [])
    eta = bn.normal("", eta_mean, logstd=, n_samples=,group_ndims=)
    theta = tf.nn.softmax()
    beta = bn.normal("", tf.zeros([]),logstd=, group_ndims=)
    phi = tf.nn.softmax()
    doc_word = tf.matmul(tf.reshape(theta, []), phi)
    doc_word = tf.reshape(doc_word, [])
    bn.unnormalized_multinomial("", tf.log(), normalize_logits=,dtype=)
    return bn
if __name__ == "__main__":
    tf.set_random_seed()
    data_name =
    data_path = os.path.join()
    X, vocab = dataset.load_uci_bow()
    training_size =
    X_train = X[:, :]
    X_test = X[training_size:, :]
    batch_size =
    n_topics =
    n_vocab = X_train.shape[]
    n_chains =
    num_e_steps =
    hmc = zs.HMC(step_size=, n_leapfrogs=, adapt_step_size=,target_acceptance_rate=)
    epochs =
    learning_rate_0 =
    t0 =
    rem = batch_size - X_train.shape[] % batch_size
    if rem < batch_size:
        X_train = np.vstack((X_train, np.zeros(())))
    iters = X_train.shape[] // batch_size
    Eta = np.zeros((n_chains, X_train.shape[], n_topics), dtype=)
    Eta_mean = np.zeros(n_topics, dtype=)
    Eta_logstd = np.zeros(n_topics, dtype=)
    x = tf.placeholder(tf.float32, shape=[], name=)
    eta_mean = tf.placeholder(tf.float32, shape=[], name=)
    eta_logstd = tf.placeholder(tf.float32, shape=[],name=)
    eta = tf.Variable(tf.zeros([]), name=)
    eta_ph = tf.placeholder(tf.float32, shape=[],name=)
    beta = tf.Variable(tf.zeros([]), name=)
    phi = tf.nn.softmax()
    init_eta_ph = tf.assign()
    def e_obj():
        return bn.cond_log_prob() + bn.cond_log_prob()
    model = lntm()
    model.log_joint =
    sample_op, hmc_info = hmc.sample(model,observed={'x':, 'beta':},latent={'eta':})
    bn = model.observe(eta=, x=, beta=)
    log_p_beta, log_px = bn.cond_log_prob([])
    log_p_beta = tf.reduce_sum()
    log_px = tf.reduce_sum(tf.reduce_mean(log_px, axis=))
    log_joint_beta =
    learning_rate_ph = tf.placeholder(tf.float32, shape=[], name=)
    optimizer = tf.train.AdamOptimizer()
    infer = optimizer.minimize(-log_joint_beta, var_list=[])
    n_docs_test = X_test.shape[]
    _n_chains =
    _n_temperatures =
    _x = tf.placeholder(tf.float32, shape=[], name=)
    _eta = tf.Variable(tf.zeros([]),name=)
    _model = lntm()
    _model.log_joint =
    proposal_model = copy()
    def log_prior():
        return bn.cond_log_prob()
    proposal_model.log_joint =
    _hmc = zs.HMC(step_size=, n_leapfrogs=, adapt_step_size=,target_acceptance_rate=)
    ais = AIS(_model, proposal_model, _hmc,observed={'x':, 'beta':},latent={'eta':},n_temperatures=)
    with tf.Session() as sess:
        sess.run(tf.global_variables_initializer())
        for epoch in range():
            time_epoch = -time.time()
            learning_rate = learning_rate_0 * (t0 / ())**2
            perm = list(range(X_train.shape[]))
            np.random.shuffle()
            X_train = X_train[perm, :]
            Eta = Eta[:, perm, :]
            lls = []
            accs = []
            for t in range():
                x_batch = X_train[t*batch_size: ()*batch_size]
                old_eta = Eta[:, t*batch_size: ()*batch_size, :]
                sess.run(init_eta_ph, feed_dict={eta_ph:})
                for j in range():
                    _, new_eta, acc = sess.run([sample_op, hmc_info.samples[],hmc_info.acceptance_rate],feed_dict={x:,eta_mean:,eta_logstd:})
                    accs.append()
                    if j + 1 == num_e_steps:
                        Eta[:, t*batch_size: ()*batch_size, :] =
                _, ll = sess.run([],feed_dict={x:,eta_mean:,eta_logstd:,learning_rate_ph:})
                lls.append()
            Eta_mean = np.mean(Eta, axis=())
            Eta_logstd = np.log(np.std(Eta, axis=()) + 1e-6)
            time_epoch += time.time()
        p = sess.run()
        for k in range():
            rank = list(zip(list(p[k, :]), range()))
            rank.sort()
            rank.reverse()
            sys.stdout.write(""))
            for i in range():
                sys.stdout.write(vocab[rank[][]] + "")
            sys.stdout.write()
        time_ais = -time.time()
        ll_lb = ais.run(sess, feed_dict={_x:,eta_mean:,eta_logstd:})
        time_ais += time.time()
from __future__ import absolute_import
from __future__ import print_function
from __future__ import division
import os
import time
import tensorflow as tf
from six.moves import range
import numpy as np
import zhusuan as zs
from examples import conf
from examples.utils import dataset
def build_sbn():
    bn = zs.BayesianNet()
    h3_logits = tf.zeros([])
    h3 = bn.bernoulli("", h3_logits, group_ndims=, n_samples=,dtype=)
    h2_logits = tf.layers.dense()
    h2 = bn.bernoulli("", h2_logits, group_ndims=, dtype=)
    h1_logits = tf.layers.dense()
    h1 = bn.bernoulli("", h1_logits, group_ndims=, dtype=)
    x_logits = tf.layers.dense()
    bn.bernoulli("", x_logits, group_ndims=)
    return bn
def build_proposal():
    bn = zs.BayesianNet()
    h1_logits = tf.layers.dense(tf.cast(), h_dim)
    h1 = bn.bernoulli("", h1_logits, group_ndims=,n_samples=, dtype=)
    h2_logits = tf.layers.dense()
    h2 = bn.bernoulli("", h2_logits, group_ndims=, dtype=)
    h3_logits = tf.layers.dense()
    bn.bernoulli("", h3_logits, group_ndims=, dtype=)
    return bn
def main():
    tf.set_random_seed()
    np.random.seed()
    data_path = os.path.join()
    x_train, t_train, x_valid, t_valid, x_test, t_test = dataset.load_mnist_realval()
    x_train = np.vstack([])
    x_test = np.random.binomial(1, x_test, size=)
    x_dim = x_train.shape[]
    h_dim =
    n_particles = tf.placeholder(tf.int32, shape=[], name=)
    x_input = tf.placeholder(tf.float32, shape=[], name=)
    x = tf.cast(tf.less(tf.random_uniform(tf.shape()), x_input),tf.int32)
    n = tf.placeholder(tf.int32, shape=[], name=)
    model = build_sbn()
    proposal = build_proposal()
    optimizer = tf.train.AdamOptimizer(learning_rate=, epsilon=)
    lower_bound = tf.reduce_mean(zs.variational.importance_weighted_objective(model, observed={"x":}, variational=, axis=))
    model_params = tf.trainable_variables(scope=)
    model_grads = optimizer.compute_gradients()
    klpq_obj = zs.variational.klpq(model, observed={"x":}, variational=, axis=)
    klpq_cost = tf.reduce_mean(klpq_obj.importance())
    proposal_params = tf.trainable_variables(scope=)
    klpq_grads = optimizer.compute_gradients()
    infer_op = optimizer.apply_gradients()
    lb_samples =
    ll_samples =
    epochs =
    batch_size =
    iters = x_train.shape[] // batch_size
    test_freq =
    test_batch_size =
    test_iters = x_test.shape[] // test_batch_size
    with tf.Session() as sess:
        sess.run(tf.global_variables_initializer())
        for epoch in range():
            time_epoch = -time.time()
            np.random.shuffle()
            lbs = []
            for t in range():
                x_batch = x_train[t * batch_size:() * batch_size]
                _, lb = sess.run([],feed_dict={x_input:,n_particles:,n:})
                lbs.append()
            time_epoch += time.time()
            if epoch % test_freq == 0:
                time_test = -time.time()
                test_lbs = []
                test_lls = []
                for t in range():
                    test_x_batch = x_test[t * test_batch_size: () * test_batch_size]
                    test_lb = sess.run(lower_bound,feed_dict={x:,n_particles:,n:})
                    test_ll = sess.run(lower_bound,feed_dict={x:,n_particles:,n:})
                    test_lbs.append()
                    test_lls.append()
                time_test += time.time()
if __name__ == "__main__":
    main()
from __future__ import absolute_import
from __future__ import print_function
from __future__ import division
import os
import time
import tensorflow as tf
from six.moves import range
import numpy as np
import zhusuan as zs
from examples import conf
from examples.utils import dataset
def build_sbn():
    bn = zs.BayesianNet()
    h3_logits = tf.zeros([])
    h3 = bn.bernoulli("", h3_logits, group_ndims=, n_samples=,dtype=)
    h2_logits = tf.layers.dense()
    h2 = bn.bernoulli("", h2_logits, group_ndims=, dtype=)
    h1_logits = tf.layers.dense()
    h1 = bn.bernoulli("", h1_logits, group_ndims=, dtype=)
    x_logits = tf.layers.dense()
    bn.bernoulli("", x_logits, group_ndims=)
    return bn
def build_q_net():
    bn = zs.BayesianNet()
    h1_logits = tf.layers.dense(tf.cast(), h_dim)
    h1 = bn.bernoulli("", h1_logits, group_ndims=,n_samples=, dtype=)
    h2_logits = tf.layers.dense()
    h2 = bn.bernoulli("", h2_logits, group_ndims=, dtype=)
    h3_logits = tf.layers.dense()
    bn.bernoulli("", h3_logits, group_ndims=, dtype=)
    return bn
def main():
    tf.set_random_seed()
    np.random.seed()
    data_path = os.path.join()
    x_train, t_train, x_valid, t_valid, x_test, t_test = dataset.load_mnist_realval()
    x_train = np.vstack([])
    x_test = np.random.binomial(1, x_test, size=)
    x_dim = x_train.shape[]
    h_dim =
    n_particles = tf.placeholder(tf.int32, shape=[], name=)
    x_input = tf.placeholder(tf.float32, shape=[], name=)
    x = tf.cast(tf.less(tf.random_uniform(tf.shape()), x_input),tf.int32)
    n = tf.placeholder(tf.int32, shape=[], name=)
    model = build_sbn()
    variational = build_q_net()
    lower_bound = zs.variational.importance_weighted_objective(model, observed={"x":}, variational=, axis=)
    cost = tf.reduce_mean(lower_bound.vimco())
    lower_bound = tf.reduce_mean()
    optimizer = tf.train.AdamOptimizer(learning_rate=, epsilon=)
    infer_op = optimizer.minimize()
    lb_samples =
    ll_samples =
    epochs =
    batch_size =
    iters = x_train.shape[] // batch_size
    test_freq =
    test_batch_size =
    test_iters = x_test.shape[] // test_batch_size
    with tf.Session() as sess:
        sess.run(tf.global_variables_initializer())
        for epoch in range():
            time_epoch = -time.time()
            np.random.shuffle()
            lbs = []
            for t in range():
                x_batch = x_train[t * batch_size:() * batch_size]
                _, lb = sess.run([],feed_dict={x_input:,n_particles:,n:})
                lbs.append()
            time_epoch += time.time()
            if epoch % test_freq == 0:
                time_test = -time.time()
                test_lbs = []
                test_lls = []
                for t in range():
                    test_x_batch = x_test[t * test_batch_size: () * test_batch_size]
                    test_lb = sess.run(lower_bound,feed_dict={x:,n_particles:,n:})
                    test_ll = sess.run(lower_bound,feed_dict={x:,n_particles:,n:})
                    test_lbs.append()
                    test_lls.append()
                time_test += time.time()
if __name__ == "__main__":
    main()
from __future__ import absolute_import
from __future__ import print_function
from __future__ import division
import os
import argparse
import numpy as np
from six.moves import range
import tensorflow as tf
import zhusuan as zs
from examples import conf
from examples.utils import dataset
from examples.gaussian_process.utils import gp_conditional, RBFKernel
parser = argparse.ArgumentParser()
parser.add_argument("", default=, type=)
parser.add_argument("", default=, type=)
parser.add_argument("", default=, type=)
parser.add_argument("", default=, type=)
parser.add_argument("", default=, type=)
parser.add_argument("", default=, type=,choices=[])
parser.add_argument("", default=, type=,choices=[])
parser.add_argument("", default=, type=)
def build_model(hps, kernel, z_pos, x, n_particles, full_cov=):
    bn = zs.BayesianNet()
    Kzz_chol = tf.cholesky(kernel())
    fz = bn.multivariate_normal_cholesky("", tf.zeros([], dtype=), Kzz_chol,n_samples=)
    fx_given_fz = bn.stochastic("", gp_conditional())
    noise_level = tf.get_variable("", shape=[], dtype=,initializer=tf.constant_initializer())
    noise_level = tf.nn.softplus()
    bn.normal("", mean=, std=, group_ndims=)
    return bn
def build_variational():
    bn = zs.BayesianNet()
    z_mean = tf.get_variable("", [], hps.dtype, tf.zeros_initializer())
    z_cov_raw = tf.get_variable("", initializer=tf.eye(hps.n_z, dtype=))
    z_cov_tril = tf.matrix_set_diag(tf.matrix_band_part(),tf.nn.softplus(tf.matrix_diag_part()))
    fz = bn.multivariate_normal_cholesky("", z_mean, z_cov_tril, n_samples=)
    bn.stochastic("", gp_conditional())
    return bn
def main():
    hps = parser.parse_args()
    data_path = os.path.join()
    data_func = getattr()
    x_train, y_train, x_valid, y_valid, x_test, y_test = data_func()
    x_train = np.vstack([])
    y_train = np.hstack([])
    n_train, n_covariates =
    hps.dtype = getattr()
    x_train, x_test, _, _ = dataset.standardize()
    y_train, y_test, mean_y_train, std_y_train = dataset.standardize()
    kernel = RBFKernel()
    x_ph = tf.placeholder(hps.dtype, [], "")
    y_ph = tf.placeholder(hps.dtype, [], "")
    z_pos = tf.get_variable("", [], hps.dtype,initializer=tf.random_uniform_initializer())
    n_particles_ph = n_particles_ph = tf.placeholder(tf.int32, [], "")
    batch_size = tf.cast(tf.shape()[], hps.dtype)
    model = build_model()
    variational = build_variational()
    def log_joint():
        prior, log_py_given_fx = bn.cond_log_prob([])
        return prior + log_py_given_fx / batch_size * n_train
    model.log_joint =
    [] = variational.query([], outputs=, local_log_prob=)
    var_fx = (var_fx[], tf.zeros_like(var_fx[]))
    lower_bound = zs.variational.elbo(model,observed={'y':},latent={'fz':, 'fx':},axis=)
    cost = lower_bound.sgvb()
    optimizer = tf.train.AdamOptimizer(learning_rate=)
    infer_op = optimizer.minimize()
    model = model.observe(fx=var_fx[], y=)
    log_likelihood = model.cond_log_prob()
    std_y_train = tf.cast()
    log_likelihood = zs.log_mean_exp() / batch_size - tf.log()
    y_pred_mean = tf.reduce_mean(model[].distribution.mean, axis=)
    pred_mse = tf.reduce_mean(() ** 2) * std_y_train ** 2
    def infer_step():
        fd = {x_ph:,y_ph:,n_particles_ph:}
        return sess.run([], fd)[]
    def predict_step():
        fd = {x_ph:,y_ph:,n_particles_ph:}
        return sess.run([], fd)
    iters = int(np.ceil(x_train.shape[] / float()))
    test_freq =
    with tf.Session() as sess:
        sess.run(tf.global_variables_initializer())
        for epoch in range():
            lbs = []
            indices = np.arange(x_train.shape[])
            np.random.shuffle()
            x_train = x_train[]
            y_train = y_train[]
            for t in range():
                lb = infer_step(sess,x_train[t * hps.batch_size: () * hps.batch_size],y_train[t * hps.batch_size: () * hps.batch_size])
                lbs.append()
            if 10 * epoch % test_freq == 0:
            if epoch % test_freq == 0:
                test_lls = []
                test_mses = []
                for t in range(0, x_test.shape[], hps.batch_size):
                    ll, mse = predict_step(sess,x_test[t:],y_test[t:])
                    test_lls.append()
                    test_mses.append()
if __name__ == "__main__":
    main()
from __future__ import absolute_import
from __future__ import print_function
from __future__ import division
from six.moves import range
import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
import zhusuan as zs
def build_toy2d_intractable():
    bn = zs.BayesianNet()
    z2 = bn.normal("", 0., std=, n_samples=)
    bn.normal("", 0., logstd=)
    return bn
def build_mean_field_variational():
    bn = zs.BayesianNet()
    for name in []:
        z_mean = bn.deterministic(name + "", tf.Variable())
        z_logstd = bn.deterministic(name + "", tf.Variable())
        bn.normal(name, z_mean, logstd=, n_samples=)
    return bn
if __name__ == "__main__":
    n_particles = tf.placeholder(tf.int32, shape=[])
    model = build_toy2d_intractable()
    variational = build_mean_field_variational()
    lower_bound = zs.variational.elbo(model, {}, variational=, axis=)
    cost = lower_bound.sgvb()
    optimizer = tf.train.AdamOptimizer(learning_rate=)
    infer_op = optimizer.minimize()
    fig = plt.figure(figsize=(), facecolor=)
    ax = fig.add_subplot(111, frameon=)
    plt.ion()
    plt.show(block=)
    def plot_isocontours(ax, func, xlimits, ylimits, numticks=):
        x = np.linspace(*xlimits, num=)
        y = np.linspace(*ylimits, num=)
        xx, yy = np.meshgrid()
        z = func(np.concatenate([np.atleast_2d(xx.ravel()),np.atleast_2d(yy.ravel())]).T)
        z = z.reshape()
        ax.contour()
    def draw():
        from scipy import stats
        plt.cla()
        xlimits = []
        ylimits = []
        def log_prob():
            z1, z2 = z[:, 0], z[:, 1]
            return stats.norm.logpdf() + stats.norm.logpdf(z1, 0, np.exp())
        plot_isocontours(ax, lambda z: np.exp(log_prob()), xlimits, ylimits)
        def variational_contour():
            return stats.multivariate_normal.pdf(z, vmean, np.diag(np.exp()))
        plot_isocontours()
        plt.draw()
        plt.pause()
    z_mean = tf.stack(variational.get([]))
    z_logstd = tf.stack(variational.get([]))
    iters =
    with tf.Session() as sess:
        sess.run(tf.global_variables_initializer())
        for t in range():
            _, lb, vmean, vlogstd = sess.run([],feed_dict={n_particles:})
            draw()
from __future__ import absolute_import
from __future__ import print_function
from __future__ import division
import os
import time
import tensorflow as tf
from six.moves import range
import numpy as np
import zhusuan as zs
from examples import conf
from examples.utils import dataset, save_image_collections
def build_gen(x_dim, z_dim, n, n_particles=):
    bn = zs.BayesianNet()
    z_mean = tf.zeros([])
    z = bn.normal("", z_mean, std=, group_ndims=, n_samples=)
    h = tf.layers.dense(z, 500, activation=)
    h = tf.layers.dense(h, 500, activation=)
    x_logits = tf.layers.dense()
    bn.deterministic("", tf.sigmoid())
    bn.bernoulli("", x_logits, group_ndims=)
    return bn
def build_q_net():
    bn = zs.BayesianNet()
    h = tf.layers.dense(tf.cast(), 500, activation=)
    h = tf.layers.dense(h, 500, activation=)
    z_mean = tf.layers.dense()
    z_logstd = tf.layers.dense()
    bn.normal("", z_mean, logstd=, group_ndims=, n_samples=)
    return bn
def main():
    data_path = os.path.join()
    x_train, t_train, x_valid, t_valid, x_test, t_test = dataset.load_mnist_realval()
    x_train = np.vstack([])
    x_test = np.random.binomial(1, x_test, size=)
    x_dim = x_train.shape[]
    z_dim =
    n_particles = tf.placeholder(tf.int32, shape=[], name=)
    x_input = tf.placeholder(tf.float32, shape=[], name=)
    x = tf.cast(tf.less(tf.random_uniform(tf.shape()), x_input),tf.int32)
    n = tf.placeholder(tf.int32, shape=[], name=)
    model = build_gen()
    variational = build_q_net()
    lower_bound = zs.variational.elbo(model, {"x":}, variational=, axis=)
    cost = tf.reduce_mean(lower_bound.sgvb())
    lower_bound = tf.reduce_mean()
    is_log_likelihood = tf.reduce_mean(zs.is_loglikelihood(model, {"x":}, proposal=, axis=))
    optimizer = tf.train.AdamOptimizer(learning_rate=)
    infer_op = optimizer.minimize()
    x_gen = tf.reshape(model.observe()[], [])
    epochs =
    batch_size =
    iters = x_train.shape[] // batch_size
    save_freq =
    test_freq =
    test_batch_size =
    test_iters = x_test.shape[] // test_batch_size
    result_path =
    with tf.Session() as sess:
        sess.run(tf.global_variables_initializer())
        for epoch in range():
            time_epoch = -time.time()
            np.random.shuffle()
            lbs = []
            for t in range():
                x_batch = x_train[t * batch_size:() * batch_size]
                _, lb = sess.run([],feed_dict={x_input:,n_particles:,n:})
                lbs.append()
            time_epoch += time.time()
            if epoch % test_freq == 0:
                time_test = -time.time()
                test_lbs, test_lls = [], []
                for t in range():
                    test_x_batch = x_test[t * test_batch_size:() * test_batch_size]
                    test_lb = sess.run(lower_bound,feed_dict={x:,n_particles:,n:})
                    test_ll = sess.run(is_log_likelihood,feed_dict={x:,n_particles:,n:})
                    test_lbs.append()
                    test_lls.append()
                time_test += time.time()
            if epoch % save_freq == 0:
                images = sess.run(x_gen, feed_dict={n:, n_particles:})
                name = os.path.join(result_path,"")
                save_image_collections()
if __name__ == "__main__":
    main()
from __future__ import absolute_import
from __future__ import print_function
from __future__ import division
import os
import time
import tensorflow as tf
from six.moves import range
import numpy as np
import zhusuan as zs
from examples import conf
from examples.utils import dataset
from examples.utils import save_image_collections, conv2d_transpose
def deconv_resnet_block(input_, out_shape, resize=):
    if not resize:
        lx_z = conv2d_transpose(input_, out_shape, kernel_size=(),stride=())
        lx_z = conv2d_transpose(lx_z, out_shape, kernel_size=(),stride=(), activation_fn=)
        lx_z +=
    else:
        lx_z = conv2d_transpose(input_, input_.get_shape().as_list()[1:],kernel_size=(), stride=())
        lx_z = conv2d_transpose(lx_z, out_shape, kernel_size=(),stride=(), activation_fn=)
        residual = conv2d_transpose(input_, out_shape, kernel_size=(),stride=(), activation_fn=)
        lx_z +=
    lx_z = tf.nn.relu()
    return lx_z
def conv_resnet_block(input_, out_channel, resize=):
    if not resize:
        lz_x = tf.layers.conv2d(input_, out_channel, 3, padding=,activation=)
        lz_x = tf.layers.conv2d(lz_x, out_channel, 3, padding=)
        lz_x +=
    else:
        lz_x = tf.layers.conv2d(input_, out_channel, 3, strides=(),padding=, activation=)
        lz_x = tf.layers.conv2d(lz_x, out_channel, 3, padding=)
        residual = tf.layers.conv2d(input_, out_channel, 3, strides=(),padding=)
        lz_x +=
    lz_x = tf.nn.relu()
    return lz_x
def build_gen(n, x_dim, z_dim, n_particles, nf=):
    bn = zs.BayesianNet()
    z_mean = tf.zeros([])
    z = bn.normal("", z_mean, std=, group_ndims=, n_samples=)
    lx_z = tf.layers.dense(z, 7 * 7 * nf * 2, activation=)
    lx_z = tf.reshape(lx_z, [])
    lx_z = deconv_resnet_block(lx_z, [])
    lx_z = deconv_resnet_block(lx_z, [], resize=)
    lx_z = deconv_resnet_block(lx_z, [])
    lx_z = deconv_resnet_block(lx_z, [], resize=)
    lx_z = deconv_resnet_block(lx_z, [])
    lx_z = conv2d_transpose(lx_z, [], kernel_size=(),stride=(), activation_fn=)
    x_logits = tf.reshape(lx_z, [])
    bn.deterministic("", tf.sigmoid())
    bn.bernoulli("", x_logits, group_ndims=)
    return bn
def build_q_net(x, z_dim, n_particles, nf=):
    bn = zs.BayesianNet()
    lz_x = 2 * tf.cast() - 1
    lz_x = tf.reshape(lz_x, [])
    lz_x = tf.layers.conv2d(lz_x, nf, 3, padding=, activation=)
    lz_x = conv_resnet_block()
    lz_x = conv_resnet_block(lz_x, nf * 2, resize=)
    lz_x = conv_resnet_block()
    lz_x = conv_resnet_block(lz_x, nf * 2, resize=)
    lz_x = conv_resnet_block()
    lz_x = tf.layers.flatten()
    lz_x = tf.layers.dense(lz_x, 500, activation=)
    z_mean = tf.layers.dense()
    z_logstd = tf.layers.dense()
    bn.normal("", z_mean, logstd=, group_ndims=,n_samples=)
    return bn
def main():
    tf.set_random_seed()
    np.random.seed()
    data_path = os.path.join()
    x_train, t_train, x_valid, t_valid, x_test, t_test = dataset.load_mnist_realval()
    x_train = np.vstack([])
    x_test = np.random.binomial(1, x_test, size=)
    x_dim = x_train.shape[]
    z_dim =
    n_particles = tf.placeholder(tf.int32, shape=[], name=)
    x_input = tf.placeholder(tf.float32, shape=[])
    x = tf.cast(tf.random_uniform(tf.shape()) <=, tf.int32)
    n = tf.placeholder(tf.int32, shape=[], name=)
    model = build_gen()
    variational = build_q_net()
    lower_bound = zs.variational.elbo(model, {"x":}, variational=, axis=)
    cost = tf.reduce_mean(lower_bound.sgvb())
    lower_bound = tf.reduce_mean()
    optimizer = tf.train.AdamOptimizer(learning_rate=, beta1=)
    infer_op = optimizer.minimize()
    x_gen = tf.reshape(model.observe()[], [])
    epochs =
    batch_size =
    iters = x_train.shape[] // batch_size
    save_freq =
    test_freq =
    test_batch_size =
    test_iters = x_test.shape[] // test_batch_size
    result_path =
    with tf.Session() as sess:
        sess.run(tf.global_variables_initializer())
        for epoch in range():
            time_epoch = -time.time()
            np.random.shuffle()
            lbs = []
            for t in range():
                x_batch = x_train[t * batch_size:() * batch_size]
                _, lb = sess.run([],feed_dict={x_input:,n_particles:,n:})
                lbs.append()
            time_epoch += time.time()
            if epoch % test_freq == 0:
                time_test = -time.time()
                test_lbs = []
                for t in range():
                    test_x_batch = x_test[t * test_batch_size: () * test_batch_size]
                    test_lb = sess.run(lower_bound,feed_dict={x:,n_particles:,n:})
                    test_lbs.append()
                time_test += time.time()
            if epoch % save_freq == 0:
                images = sess.run(x_gen, feed_dict={n:, n_particles:})
                name = os.path.join(result_path,"")
                save_image_collections()
if __name__ == "__main__":
    main()
from __future__ import absolute_import
from __future__ import print_function
from __future__ import division
import os
import time
import tensorflow as tf
from six.moves import range
import numpy as np
import zhusuan as zs
from examples import conf
from examples.utils import dataset
def build_gen():
    bn = zs.BayesianNet()
    z_mean = tf.zeros([])
    z = bn.normal("", z_mean, std=, group_ndims=, n_samples=)
    h = tf.layers.dense(z, 500, activation=)
    h = tf.layers.dense(h, 500, activation=)
    x_logits = tf.layers.dense()
    bn.bernoulli("", x_logits, group_ndims=)
    return bn
def build_q_net():
    bn = zs.BayesianNet()
    h = tf.layers.dense(tf.cast(), 500, activation=)
    h = tf.layers.dense(h, 500, activation=)
    z_mean = tf.layers.dense()
    z_logstd = tf.layers.dense()
    bn.normal("", z_mean, logstd=, group_ndims=,n_samples=)
    return bn
def main():
    tf.set_random_seed()
    np.random.seed()
    data_path = os.path.join()
    x_train, t_train, x_valid, t_valid, x_test, t_test = dataset.load_mnist_realval()
    x_train = np.vstack([])
    x_test = np.random.binomial(1, x_test, size=)
    x_dim = x_train.shape[]
    z_dim =
    n_planar_flows =
    n_particles = tf.placeholder(tf.int32, shape=[], name=)
    x_input = tf.placeholder(tf.float32, shape=[], name=)
    x = tf.cast(tf.less(tf.random_uniform(tf.shape()), x_input),tf.int32)
    n = tf.placeholder(tf.int32, shape=[], name=)
    model = build_gen()
    q_net = build_q_net()
    qz_samples, log_qz = q_net.query("", outputs=, local_log_prob=)
    qz_samples, log_qz = zs.planar_normalizing_flow(qz_samples, log_qz,n_iters=)
    qz_samples, log_qz = zs.planar_normalizing_flow(qz_samples, log_qz,n_iters=)
    lower_bound = zs.variational.elbo(model,observed={"x":},latent={"z":},axis=)
    cost = tf.reduce_mean(lower_bound.sgvb())
    lower_bound = tf.reduce_mean()
    is_log_likelihood = tf.reduce_mean(zs.is_loglikelihood(model, {'x':},{'z':}, axis=))
    optimizer = tf.train.AdamOptimizer(learning_rate=)
    infer_op = optimizer.minimize()
    epochs =
    batch_size =
    iters = x_train.shape[] // batch_size
    test_freq =
    test_batch_size =
    test_iters = x_test.shape[] // test_batch_size
    with tf.Session() as sess:
        sess.run(tf.global_variables_initializer())
        for epoch in range():
            time_epoch = -time.time()
            np.random.shuffle()
            lbs = []
            for t in range():
                x_batch = x_train[t * batch_size:() * batch_size]
                _, lb = sess.run([],feed_dict={x_input:,n_particles:,n:})
                lbs.append()
            time_epoch += time.time()
            if epoch % test_freq == 0:
                time_test = -time.time()
                test_lbs = []
                test_lls = []
                for t in range():
                    test_x_batch = x_test[t * test_batch_size:() * test_batch_size]
                    test_lb = sess.run(lower_bound,feed_dict={x:,n_particles:,n:})
                    test_ll = sess.run(is_log_likelihood,feed_dict={x:,n_particles:,n:})
                    test_lbs.append()
                    test_lls.append()
                time_test += time.time()
if __name__ == "__main__":
    main()
from __future__ import absolute_import
from __future__ import print_function
from __future__ import division
import os
import time
import tensorflow as tf
from six.moves import range
import numpy as np
import zhusuan as zs
from examples import conf
from examples.utils import dataset
def build_gen():
    bn = zs.BayesianNet()
    z_mean = tf.zeros([])
    z = bn.normal("", z_mean, std=, group_ndims=, n_samples=)
    h_from_z = tf.layers.dense()
    y_logits = tf.zeros([])
    y = bn.onehot_categorical()
    h_from_y = tf.layers.dense(tf.cast(), 500)
    h = tf.nn.relu()
    h = tf.layers.dense(h, 500, activation=)
    x_logits = tf.layers.dense()
    bn.bernoulli("", x_logits, group_ndims=)
    return bn
def qz_xy():
    bn = zs.BayesianNet()
    h = tf.layers.dense(tf.cast(tf.concat([], -1), tf.float32), 500,activation=)
    h = tf.layers.dense(h, 500, activation=)
    z_mean = tf.layers.dense()
    z_logstd = tf.layers.dense()
    bn.normal("", z_mean, logstd=, group_ndims=,n_samples=)
    return bn
def qy_x():
    h = tf.layers.dense(tf.cast(), 500, activation=)
    h = tf.layers.dense(h, 500, activation=)
    y_logits = tf.layers.dense()
    return y_logits
def main():
    tf.set_random_seed()
    np.random.seed()
    data_path = os.path.join()
    x_labeled, t_labeled, x_unlabeled, x_test, t_test = dataset.load_mnist_semi_supervised(data_path, one_hot=)
    x_test = np.random.binomial(1, x_test, size=)
    n_labeled, x_dim =
    n_class =
    z_dim =
    lb_samples =
    beta =
    epochs =
    batch_size =
    test_batch_size =
    iters = x_unlabeled.shape[] // batch_size
    test_iters = x_test.shape[] // test_batch_size
    test_freq =
    n = tf.placeholder(tf.int32, shape=[], name=)
    n_particles = tf.placeholder(tf.int32, shape=[], name=)
    model = build_gen()
    x_labeled_ph = tf.placeholder(tf.float32, shape=[], name=)
    x_labeled = tf.cast(tf.less(tf.random_uniform(tf.shape()), x_labeled_ph),tf.int32)
    y_labeled_ph = tf.placeholder(tf.int32, shape=[], name=)
    variational = qz_xy()
    labeled_lower_bound = tf.reduce_mean(zs.variational.elbo(model,observed={"x":, "y":},variational=,axis=))
    x_unlabeled_ph = tf.placeholder(tf.float32, shape=[],name=)
    x_unlabeled = tf.cast(tf.less(tf.random_uniform(tf.shape()), x_unlabeled_ph),tf.int32)
    y_diag = tf.eye(n_class, dtype=)
    y_u = tf.reshape(tf.tile(y_diag[], []), [])
    x_u = tf.reshape(tf.tile(x_unlabeled[:, None, ...], []),[])
    variational = qz_xy()
    lb_z = zs.variational.elbo(model,observed={"x":, "y":},variational=,axis=)
    lb_z = tf.reshape(lb_z, [])
    qy_logits_u = qy_x()
    qy_u = tf.nn.softmax() + 1e-8
    qy_u /= tf.reduce_sum(qy_u, 1, keepdims=)
    log_qy_u = tf.log()
    unlabeled_lower_bound = tf.reduce_mean(tf.reduce_sum(qy_u * (), 1))
    qy_logits_l = qy_x()
    qy_l = tf.nn.softmax()
    pred_y = tf.argmax()
    acc = tf.reduce_sum(tf.cast(tf.equal(pred_y, tf.argmax()), tf.float32) /tf.cast(tf.shape()[], tf.float32))
    onehot_cat = zs.distributions.OnehotCategorical()
    log_qy_x = onehot_cat.log_prob()
    classifier_cost = -beta * tf.reduce_mean()
    cost = -() / 2.
    optimizer = tf.train.AdamOptimizer(learning_rate=)
    grads = optimizer.compute_gradients()
    infer_op = optimizer.apply_gradients()
    with tf.Session() as sess:
        sess.run(tf.global_variables_initializer())
        for epoch in range():
            time_epoch = -time.time()
            np.random.shuffle()
            lbs_labeled, lbs_unlabeled, train_accs = [], [], []
            for t in range():
                labeled_indices = np.random.randint(0, n_labeled,size=)
                x_labeled_batch = x_labeled[]
                y_labeled_batch = t_labeled[]
                x_unlabeled_batch = x_unlabeled[t * batch_size:() * batch_size]
                _, lb_labeled, lb_unlabeled, train_acc = sess.run([],feed_dict={x_labeled_ph:,y_labeled_ph:,x_unlabeled_ph:,n_particles:,n:})
                lbs_labeled.append()
                lbs_unlabeled.append()
                train_accs.append()
            time_epoch += time.time()
            if epoch % test_freq == 0:
                time_test = -time.time()
                test_lls_labeled, test_lls_unlabeled, test_accs = [], [], []
                for t in range():
                    test_x_batch = x_test[t * test_batch_size: () * test_batch_size]
                    test_y_batch = t_test[t * test_batch_size: () * test_batch_size]
                    test_ll_labeled, test_ll_unlabeled, test_acc = sess.run([],feed_dict={x_labeled:,y_labeled_ph:,x_unlabeled:,n_particles:,n:})
                    test_lls_labeled.append()
                    test_lls_unlabeled.append()
                    test_accs.append()
                time_test += time.time()
if __name__ == "__main__":
    main()
from __future__ import absolute_import
from __future__ import print_function
from __future__ import division
import os
import time
import tensorflow as tf
from six.moves import range
import numpy as np
import zhusuan as zs
from examples import conf
from examples.utils import dataset
def build_gen():
    bn = zs.BayesianNet()
    z_mean = tf.zeros([])
    z = bn.normal("", z_mean, std=, group_ndims=, n_samples=)
    h_from_z = tf.layers.dense()
    y_logits = tf.zeros([])
    y = bn.onehot_categorical()
    h_from_y = tf.layers.dense(tf.cast(), 500)
    h = tf.nn.relu()
    h = tf.layers.dense(h, 500, activation=)
    x_logits = tf.layers.dense()
    bn.bernoulli("", x_logits, group_ndims=)
    return bn
def qz_xy():
    h = tf.layers.dense(tf.cast(tf.concat([], -1), tf.float32), 500,activation=)
    h = tf.layers.dense(h, 500, activation=)
    z_mean = tf.layers.dense()
    z_logstd = tf.layers.dense()
    return z_mean, z_logstd
def qy_x():
    h = tf.layers.dense(tf.cast(), 500, activation=)
    h = tf.layers.dense(h, 500, activation=)
    y_logits = tf.layers.dense()
    return y_logits
def labeled_proposal():
    bn = zs.BayesianNet()
    z_mean, z_logstd = qz_xy()
    bn.normal("", z_mean, logstd=, n_samples=,group_ndims=, is_reparameterized=)
    return bn
def unlabeled_proposal():
    bn = zs.BayesianNet()
    y_logits = qy_x()
    y = bn.onehot_categorical()
    z_mean, z_logstd = qz_xy()
    bn.normal("", z_mean, logstd=, group_ndims=,is_reparameterized=, n_samples=)
    return bn
def main():
    tf.set_random_seed()
    np.random.seed()
    data_path = os.path.join()
    x_labeled, t_labeled, x_unlabeled, x_test, t_test = dataset.load_mnist_semi_supervised(data_path, one_hot=)
    x_test = np.random.binomial(1, x_test, size=)
    n_labeled, x_dim =
    n_class =
    z_dim =
    beta =
    n = tf.placeholder(tf.int32, shape=[], name=)
    n_particles = tf.placeholder(tf.int32, shape=[], name=)
    model = build_gen()
    x_labeled_ph = tf.placeholder(tf.float32, shape=[], name=)
    x_labeled = tf.cast(tf.less(tf.random_uniform(tf.shape()), x_labeled_ph),tf.int32)
    y_labeled_ph = tf.placeholder(tf.int32, shape=[], name=)
    proposal = labeled_proposal()
    labeled_klpq_obj = zs.variational.klpq(model,observed={"x":, "y":},variational=,axis=)
    labeled_q_cost = tf.reduce_mean(labeled_klpq_obj.importance())
    labeled_lower_bound = tf.reduce_mean(zs.variational.importance_weighted_objective(model, observed={'x':, 'y':},variational=, axis=))
    x_unlabeled_ph = tf.placeholder(tf.float32, shape=[],name=)
    x_unlabeled = tf.cast(tf.less(tf.random_uniform(tf.shape()), x_unlabeled_ph),tf.int32)
    proposal = unlabeled_proposal()
    unlabeled_klpq_obj = zs.variational.klpq(model,observed={'x':},variational=,axis=)
    unlabeled_q_cost = tf.reduce_mean(unlabeled_klpq_obj.importance())
    unlabeled_lower_bound = tf.reduce_mean(zs.variational.importance_weighted_objective(model, observed={'x':}, variational=,axis=))
    qy_logits_l = qy_x()
    qy_l = tf.nn.softmax()
    pred_y = tf.argmax()
    acc = tf.reduce_sum(tf.cast(tf.equal(pred_y, tf.argmax()), tf.float32) /tf.cast(tf.shape()[], tf.float32))
    onehot_cat = zs.distributions.OnehotCategorical()
    log_qy_x = onehot_cat.log_prob()
    classifier_cost = -beta * tf.reduce_mean()
    proposal_cost =
    model_cost =
    optimizer = tf.train.AdamOptimizer(learning_rate=)
    model_params = tf.trainable_variables(scope=)
    model_grads = optimizer.compute_gradients(model_cost,var_list=)
    proposal_params = (tf.trainable_variables(scope=) +tf.trainable_variables(scope=))
    proposal_grads = optimizer.compute_gradients(proposal_cost,var_list=)
    infer_op = optimizer.apply_gradients()
    ll_samples =
    epochs =
    batch_size =
    iters = x_unlabeled.shape[] // batch_size
    test_freq =
    test_batch_size =
    test_iters = x_test.shape[] // test_batch_size
    with tf.Session() as sess:
        sess.run(tf.global_variables_initializer())
        for epoch in range():
            time_epoch = -time.time()
            np.random.shuffle()
            lbs_labeled, lbs_unlabeled, train_accs = [], [], []
            for t in range():
                labeled_indices = np.random.randint(0, n_labeled,size=)
                x_labeled_batch = x_labeled[]
                y_labeled_batch = t_labeled[]
                x_unlabeled_batch = x_unlabeled[t * batch_size:() * batch_size]
                _, lb_labeled, lb_unlabeled, train_acc = sess.run([],feed_dict={x_labeled_ph:,y_labeled_ph:,x_unlabeled_ph:,n_particles:,n:})
                lbs_labeled.append()
                lbs_unlabeled.append()
                train_accs.append()
            time_epoch += time.time()
            if epoch % test_freq == 0:
                time_test = -time.time()
                test_lls_labeled, test_lls_unlabeled, test_accs = [], [], []
                for t in range():
                    test_x_batch = x_test[t * test_batch_size: () * test_batch_size]
                    test_y_batch = t_test[t * test_batch_size: () * test_batch_size]
                    test_ll_labeled, test_ll_unlabeled, test_acc = sess.run([],feed_dict={x_labeled:,y_labeled_ph:,x_unlabeled:,n_particles:,n:})
                    test_lls_labeled.append()
                    test_lls_unlabeled.append()
                    test_accs.append()
                time_test += time.time()
if __name__ == "__main__":
    main()
import os
import importlib
import numpy as np
import tensorflow as tf
import texar.tf as tx
from ctrl_gen_model import CtrlGenModel
flags =
flags.DEFINE_string()
FLAGS =
config = importlib.import_module()
def _main():
    train_data = tx.data.MultiAlignedData()
    val_data = tx.data.MultiAlignedData()
    test_data = tx.data.MultiAlignedData()
    vocab = train_data.vocab()
    iterator = tx.data.FeedableDataIterator({'train_g':, 'train_d':,'val':, 'test':})
    batch = iterator.get_next()
    gamma = tf.placeholder(dtype=, shape=[], name=)
    lambda_g = tf.placeholder(dtype=, shape=[], name=)
    model = CtrlGenModel()
    def _train_epoch(sess, gamma_, lambda_g_, epoch, verbose=):
        avg_meters_d = tx.utils.AverageRecorder(size=)
        avg_meters_g = tx.utils.AverageRecorder(size=)
        step =
        while True:
            try:
                step +=
                feed_dict = {iterator.handle:,gamma:,lambda_g:}
                vals_d = sess.run(model.fetches_train_d, feed_dict=)
                avg_meters_d.add()
                feed_dict = {iterator.handle:,gamma:,lambda_g:}
                vals_g = sess.run(model.fetches_train_g, feed_dict=)
                avg_meters_g.add()
                if verbose and (step == 1 or step % config.display ==):
                if verbose and step % config.display_eval == 0:
                    iterator.restart_dataset()
                    _eval_epoch()
            except tf.errors.OutOfRangeError:
                break
    def _eval_epoch(sess, gamma_, lambda_g_, epoch, val_or_test=):
        avg_meters = tx.utils.AverageRecorder()
        while True:
            try:
                feed_dict = {iterator.handle:,gamma:,lambda_g:,tx.context.global_mode():}
                vals = sess.run(model.fetches_eval, feed_dict=)
                batch_size = vals.pop()
                samples = tx.utils.dict_pop(vals, list(model.samples.keys()))
                hyps = tx.utils.map_ids_to_strs(samples[], vocab)
                refs = tx.utils.map_ids_to_strs(samples[], vocab)
                refs = np.expand_dims(refs, axis=)
                bleu = tx.evals.corpus_bleu_moses()
                vals[] =
                avg_meters.add(vals, weight=)
                tx.utils.write_paired_text(refs.squeeze(), hyps,os.path.join(),append=, mode=)
            except tf.errors.OutOfRangeError:
                break
        return avg_meters.avg()
    tf.gfile.MakeDirs()
    tf.gfile.MakeDirs()
    with tf.Session() as sess:
        sess.run(tf.global_variables_initializer())
        sess.run(tf.local_variables_initializer())
        sess.run(tf.tables_initializer())
        saver = tf.train.Saver(max_to_keep=)
        if config.restore:
            saver.restore()
        iterator.initialize_dataset()
        gamma_ =
        lambda_g_ =
        for epoch in range():
            if epoch > config.pretrain_nepochs:
                gamma_ = max()
                lambda_g_ =
            iterator.restart_dataset(sess, [])
            _train_epoch()
            iterator.restart_dataset()
            _eval_epoch()
            saver.save(sess, os.path.join(), epoch)
            iterator.restart_dataset()
            _eval_epoch()
if __name__ == "__main__":
    tf.app.run(main=)
from __future__ import absolute_import
from __future__ import print_function
from __future__ import division
import os
import time
import tensorflow as tf
import tensorflow.contrib.layers as layers
from six.moves import range, zip
import numpy as np
import zhusuan as zs
from examples import conf
from examples.utils import dataset
def var_dropout():
    normalizer_params = {'is_training':,'updates_collections':}
    bn = zs.BayesianNet()
    h =
    for i, [] in enumerate(zip(net_size[:], net_size[1:])):
        eps_mean = tf.ones([])
        eps = bn.normal("" + str() + "", eps_mean, std=,n_samples=, group_ndims=)
        h = layers.fully_connected(h * eps, n_out, normalizer_fn=,normalizer_params=)
        if i < len() - 2:
            h = tf.nn.relu()
    y = bn.categorical()
    bn.deterministic()
    return bn
def q():
    bn = zs.BayesianNet()
    for i, [] in enumerate(zip(net_size[:], net_size[1:])):
        with tf.variable_scope("" + str()):
            logit_alpha = tf.get_variable("", [])
        std = tf.sqrt(tf.nn.sigmoid() + 1e-10)
        std = tf.tile(tf.expand_dims(), [])
        eps = bn.normal("" + str() + "",1., std=,n_samples=, group_ndims=)
    return bn
if __name__ == "__main__":
    tf.set_random_seed()
    np.random.seed()
    data_path = os.path.join()
    x_train, y_train, x_valid, y_valid, x_test, y_test = dataset.load_mnist_realval(data_path, one_hot=)
    x_train = np.vstack([]).astype()
    y_train = np.concatenate([]).astype()
    x_train, x_test, _, _ = dataset.standardize()
    n_x = x_train.shape[]
    epochs =
    batch_size =
    lb_samples =
    ll_samples =
    iters = int(np.floor(x_train.shape[] / float()))
    test_freq =
    learning_rate =
    anneal_lr_freq =
    anneal_lr_rate =
    n_particles = tf.placeholder(tf.int32, shape=[], name=)
    is_training = tf.placeholder(tf.bool, shape=[], name=)
    x = tf.placeholder(tf.float32, shape=())
    y = tf.placeholder(tf.int32, shape=())
    n = tf.shape()[]
    net_size = []
    e_names = ["" + str() + "" for i in range(len() - 1)]
    x_obs = tf.tile(tf.expand_dims(), [])
    y_obs = tf.tile(tf.expand_dims(), [])
    model = var_dropout()
    variational = q()
    def log_joint():
        log_pe = bn.cond_log_prob()
        log_py_xe = bn.cond_log_prob()
        return tf.add_n() + log_py_xe * x_train.shape[]
    model.log_joint =
    lower_bound = zs.variational.elbo(model, {'y':},variational=, axis=)
    y_logit = lower_bound.bn[]
    h_pred = tf.reduce_mean(tf.nn.softmax(), 0)
    y_pred = tf.argmax(h_pred, 1, output_type=)
    acc = tf.reduce_mean(tf.cast(tf.equal(), tf.float32))
    cost = tf.reduce_mean(lower_bound.sgvb()) / x_train.shape[]
    learning_rate_ph = tf.placeholder(tf.float32, shape=())
    optimizer = tf.train.AdamOptimizer(learning_rate_ph, epsilon=)
    infer = optimizer.minimize()
    lower_bound = tf.reduce_mean() / x_train.shape[]
    params = tf.trainable_variables()
    for i in params:
    with tf.Session() as sess:
        sess.run(tf.global_variables_initializer())
        for epoch in range():
            if epoch % anneal_lr_freq == 0:
                learning_rate *=
            time_epoch = -time.time()
            indices = np.random.permutation(x_train.shape[])
            x_train = x_train[]
            y_train = y_train[]
            lbs = []
            for t in range():
                x_batch = x_train[t * batch_size:() * batch_size]
                y_batch = y_train[t * batch_size:() * batch_size]
                _, lb = sess.run([],feed_dict={n_particles:,is_training:,learning_rate_ph:,x:, y:})
                lbs.append()
            time_epoch += time.time()
            if epoch % test_freq == 0:
                time_test = -time.time()
                test_lbs = []
                test_accs = []
                for t in range():
                    x_batch = x_test[t * 1000:() * 1000]
                    y_batch = y_test[t * 1000:() * 1000]
                    lb, acc1 = sess.run([],feed_dict={n_particles:,is_training:,x:, y:})
                    test_lbs.append()
                    test_accs.append()
                time_test += time.time()
import tensorflow as tf
import vgg19_trainable as vgg19
import utils
img1 = utils.load_image()
img1_true_result = [1 if i == 292 else 0 for i in range()]
batch1 = img1.reshape(())
with tf.device('/cpu:):
    sess = tf.Session()
    images = tf.placeholder(tf.float32, [])
    true_out = tf.placeholder(tf.float32, [])
    train_mode = tf.placeholder()
    vgg = vgg19.Vgg19()
    vgg.build()
    sess.run(tf.global_variables_initializer())
    prob = sess.run(vgg.prob, feed_dict={images:, train_mode:})
    utils.print_prob(prob[], "")
    cost = tf.reduce_sum(() ** 2)
    train = tf.train.GradientDescentOptimizer().minimize()
    sess.run(train, feed_dict={images:, true_out:, train_mode:})
    prob = sess.run(vgg.prob, feed_dict={images:, train_mode:})
    utils.print_prob(prob[], "")
    vgg.save_npy()
import tensorflow as tf
import numpy as np
from PIL import Image
from cnnlib.network import CNN
import json
class Recognizer():
    def __init__():
        super().__init__()
        self.g = tf.Graph()
        self.sess = tf.Session(graph=)
        with self.g.as_default():
            self.X = tf.placeholder(tf.float32, [])
            self.Y = tf.placeholder(tf.float32, [])
            self.keep_prob = tf.placeholder()
            self.y_predict = self.model()
            self.predict = tf.argmax(tf.reshape(self.y_predict, []), 2)
            saver = tf.train.Saver()
            with self.sess.as_default() as sess:
                saver.restore()
    def rec_image():
        img_array = np.array()
        test_image = self.convert2gray()
        test_image = test_image.flatten() / 255
        with self.g.as_default():
            with self.sess.as_default() as sess:
                text_list = sess.run(self.predict, feed_dict={self.X:, self.keep_prob:})
        predict_text = text_list[].tolist()
        p_text =
        for p in predict_text:
            p_text += str(self.char_set[])
        return p_text
def main():
    with open("", "", encoding=) as f:
        sample_conf = json.load()
    image_height = sample_conf[]
    image_width = sample_conf[]
    max_captcha = sample_conf[]
    char_set = sample_conf[]
    model_save_dir = sample_conf[]
    R = Recognizer()
    r_img = Image.open()
    t = R.rec_image()
if __name__ == "__main__":
    main()
import os
import sys
import inspect
import importlib
import imp
import numpy as np
from collections import OrderedDict
import tensorflow as tf
def run():
    return tf.get_default_session().run()
def is_tf_expression():
    return isinstance() or isinstance() or isinstance()
def shape_to_list():
    return []
def flatten():
    with tf.name_scope():
        return tf.reshape(x, [])
def log2():
    with tf.name_scope():
        return tf.log() * np.float32(1.0 / np.log())
def exp2():
    with tf.name_scope():
        return tf.exp(x * np.float32(np.log()))
def lerp():
    with tf.name_scope():
        return a + () * t
def lerp_clip():
    with tf.name_scope():
        return a + () * tf.clip_by_value()
def absolute_name_scope():
    return tf.name_scope()
def init_tf(config_dict=dict()):
    if tf.get_default_session() is None:
        tf.set_random_seed(np.random.randint())
        create_session(config_dict, force_as_default=)
def create_session(config_dict=dict(), force_as_default=):
    config = tf.ConfigProto()
    for key, value in config_dict.items():
        fields = key.split()
        obj =
        for field in fields[:]:
            obj = getattr()
        setattr(obj, fields[], value)
    session = tf.Session(config=)
    if force_as_default:
        session._default_session = session.as_default()
        session._default_session.enforce_nesting =
        session._default_session.__enter__()
    return session
def init_uninited_vars(vars=):
    if vars is None: vars = tf.global_variables()
    test_vars = []; test_ops = []
    with tf.control_dependencies():
        for var in vars:
            try:
                tf.get_default_graph().get_tensor_by_name(var.name.replace(""/IsVariableInitialized:))
            except KeyError:
                test_vars.append()
                with absolute_name_scope(var.name.split(':)[]):
                    test_ops.append(tf.is_variable_initialized())
    init_vars = [var for var, inited in zip(test_vars, run()) if not inited]
    run([])
def set_vars():
    ops = []
    feed_dict = {}
    for var, value in var_to_value_dict.items():
        try:
            setter = tf.get_default_graph().get_tensor_by_name(var.name.replace(""/setter:))
        except KeyError:
            with absolute_name_scope(var.name.split(':)[]):
                with tf.control_dependencies():
                    setter = tf.assign(var, tf.placeholder(), name=)
        ops.append()
        feed_dict[setter.op.inputs[]] =
    run()
_autosummary_vars = OrderedDict()
_autosummary_immediate = OrderedDict()
_autosummary_finalized =
def autosummary():
    id = name.replace()
    if is_tf_expression():
        with tf.name_scope(), tf.device():
            update_op = _create_autosummary_var()
            with tf.control_dependencies([]):
                return tf.identity()
    else:
        if name not in _autosummary_immediate:
            with absolute_name_scope(), tf.device(), tf.control_dependencies():
                update_value = tf.placeholder()
                update_op = _create_autosummary_var()
                _autosummary_immediate[] =, update_value
        update_op, update_value = _autosummary_immediate[]
        run(update_op, {update_value:})
        return value
def finalize_autosummaries():
    global _autosummary_finalized
    if _autosummary_finalized:
        return
    _autosummary_finalized =
    init_uninited_vars([var for vars in _autosummary_vars.values() for var in vars])
    with tf.device(), tf.control_dependencies():
        for name, vars in _autosummary_vars.items():
            id = name.replace()
            with absolute_name_scope():
                sum = tf.add_n()
                avg = sum[] / sum[]
                with tf.control_dependencies([]):
                    reset_ops = [tf.assign(var, tf.zeros()) for var in vars]
                    with tf.name_scope(), tf.control_dependencies():
                        tf.summary.scalar()
def _create_autosummary_var():
    v = tf.cast()
    if v.shape.ndims is 0:
        v = [v, np.float32()]
    elif v.shape.ndims is 1:
        v = [tf.reduce_sum(), tf.cast(tf.shape()[], tf.float32)]
    else:
        v = [tf.reduce_sum(), tf.reduce_prod(tf.cast(tf.shape(), tf.float32))]
    v = tf.cond(tf.is_finite(v[]), lambda: tf.stack(), lambda: tf.zeros())
    with tf.control_dependencies():
        var = tf.Variable(tf.zeros())
    update_op = tf.cond(tf.is_variable_initialized(), lambda: tf.assign_add(), lambda: tf.assign())
    if name in _autosummary_vars:
        _autosummary_vars[].append()
    else:
        _autosummary_vars[] = []
    return update_op
_summary_merge_op =
def save_summaries(filewriter, global_step=):
    global _summary_merge_op
    if _summary_merge_op is None:
        finalize_autosummaries()
        with tf.device(), tf.control_dependencies():
            _summary_merge_op = tf.summary.merge_all()
    filewriter.add_summary(_summary_merge_op.eval(), global_step)
def import_module():
    parts = module_or_obj_name.split()
    parts[] = {'np':, 'tf':}.get(parts[], parts[])
    for i in range(len(), 0, -1):
        try:
            module = importlib.import_module("".join(parts[:]))
            relative_obj_name = "".join(parts[i:])
            return module, relative_obj_name
        except ImportError:
            pass
    raise ImportError()
def find_obj_in_module():
    obj =
    for part in relative_obj_name.split():
        obj = getattr()
    return obj
def import_obj():
    module, relative_obj_name = import_module()
    return find_obj_in_module()
def call_func_by_name(*args, func=, **kwargs):
    return import_obj()()
class Optimizer:
    def __init__(self,name                =,tf_optimizer        =,learning_rate       =,use_loss_scaling    =,loss_scaling_init   =,loss_scaling_inc    =,loss_scaling_dec    =,**kwargs):
        self.name               =
        self.learning_rate      = tf.convert_to_tensor()
        self.id                 = self.name.replace()
        self.scope              = tf.get_default_graph().unique_name()
        self.optimizer_class    = import_obj()
        self.optimizer_kwargs   = dict()
        self.use_loss_scaling   =
        self.loss_scaling_init  =
        self.loss_scaling_inc   =
        self.loss_scaling_dec   =
        self._grad_shapes       =
        self._dev_opt           = OrderedDict()
        self._dev_grads         = OrderedDict()
        self._dev_ls_var        = OrderedDict()
        self._updates_applied   =
    def register_gradients():
        if isinstance():
            vars = list(vars.values())
        if self._grad_shapes is None:
            self._grad_shapes = [shape_to_list() for var in vars]
        dev =
        with tf.name_scope(), tf.device():
            if dev not in self._dev_opt:
                opt_name = self.scope.replace() + "")
                self._dev_opt[] = self.optimizer_class(name=, learning_rate=, **self.optimizer_kwargs)
                self._dev_grads[] = []
            loss = self.apply_loss_scaling(tf.cast())
            grads = self._dev_opt[].compute_gradients(loss, vars, gate_gradients=)
            grads = [() if g is not None else (tf.zeros_like(), v) for g, v in grads]
            self._dev_grads[].append()
    def apply_updates():
        self._updates_applied =
        devices = list(self._dev_grads.keys())
        total_grads = sum(len() for grads in self._dev_grads.values())
        ops = []
        with absolute_name_scope():
            dev_grads = OrderedDict()
            for dev_idx, dev in enumerate():
                with tf.name_scope(), tf.device():
                    sums = []
                    for gv in zip(*self._dev_grads[]):
                        g = [tf.cast() for g, v in gv]
                        g = g[] if len() == 1 else tf.add_n()
                        sums.append((g, gv[][]))
                    dev_grads[] =
            if len() > 1:
                with tf.name_scope(), tf.device():
                    for var_idx, grad_shape in enumerate():
                        g = [dev_grads[][][] for dev in devices]
                        if np.prod():
                            g = tf.contrib.nccl.all_sum()
                        for dev, gg in zip():
                            dev_grads[][] = (gg, dev_grads[][][])
            for dev_idx, () in enumerate(dev_grads.items()):
                with tf.name_scope(), tf.device():
                    if self.use_loss_scaling or total_grads > 1:
                        with tf.name_scope():
                            coef = tf.constant(np.float32(), name=)
                            coef = self.undo_loss_scaling()
                            grads = [() for g, v in grads]
                    with tf.name_scope():
                        grad_ok = tf.reduce_all(tf.stack([tf.reduce_all(tf.is_finite()) for g, v in grads]))
                    with tf.name_scope():
                        opt = self._dev_opt[]
                        ls_var = self.get_loss_scaling_var()
                        if not self.use_loss_scaling:
                            ops.append(tf.cond(grad_ok, lambda: opt.apply_gradients(), tf.no_op))
                        else:
                            ops.append(tf.cond(grad_ok,lambda: tf.group(tf.assign_add(), opt.apply_gradients()),lambda: tf.group(tf.assign_sub())))
                    if dev == devices[]:
                        with tf.name_scope():
                            ops.append(autosummary())
                            ops.append(autosummary(self.id + "", tf.where()))
                            if self.use_loss_scaling:
                                ops.append(autosummary())
            self.reset_optimizer_state()
            init_uninited_vars(list(self._dev_ls_var.values()))
            return tf.group(*ops, name=)
    def reset_optimizer_state():
        run([var.initializer for opt in self._dev_opt.values() for var in opt.variables()])
    def get_loss_scaling_var():
        if not self.use_loss_scaling:
            return None
        if device not in self._dev_ls_var:
            with absolute_name_scope(), tf.control_dependencies():
                self._dev_ls_var[] = tf.Variable(np.float32(), name=)
        return self._dev_ls_var[]
    def apply_loss_scaling():
        if not self.use_loss_scaling:
            return value
        return value * exp2(self.get_loss_scaling_var())
    def undo_loss_scaling():
        if not self.use_loss_scaling:
            return value
        return value * exp2(-self.get_loss_scaling_var())
network_import_handlers = []
_network_import_modules = []
class Network:
    def __init__(self,name=,func=,**static_kwargs):
        self._init_fields()
        self.name =
        self.static_kwargs = dict()
        module, self._build_func_name = import_module()
        self._build_module_src = inspect.getsource()
        self._build_func = find_obj_in_module()
        self._init_graph()
        self.reset_vars()
    def _init_fields():
        self.name               =
        self.scope              =
        self.static_kwargs      = dict()
        self.num_inputs         =
        self.num_outputs        =
        self.input_shapes       = [[]]
        self.output_shapes      = [[]]
        self.input_shape        = []
        self.output_shape       = []
        self.input_templates    = []
        self.output_templates   = []
        self.input_names        = []
        self.output_names       = []
        self.vars               = OrderedDict()
        self.trainables         = OrderedDict()
        self._build_func        =
        self._build_func_name   =
        self._build_module_src  =
        self._run_cache         = dict()
    def _init_graph():
        self.input_names = []
        for param in inspect.signature().parameters.values():
            if param.kind == param.POSITIONAL_OR_KEYWORD and param.default is param.empty:
                self.input_names.append()
        self.num_inputs = len()
        if self.name is None:
            self.name =
        self.scope = tf.get_default_graph().unique_name(self.name.replace(), mark_as_used=)
        with tf.variable_scope(self.scope, reuse=):
            with absolute_name_scope():
                with tf.control_dependencies():
                    self.input_templates = [tf.placeholder(tf.float32, name=) for name in self.input_names]
                    out_expr = self._build_func(*self.input_templates, is_template_graph=, **self.static_kwargs)
        self.output_templates = [] if is_tf_expression() else list()
        self.output_names = [t.name.split()[].split(':)[] for t in self.output_templates]
        self.num_outputs = len()
        self.input_shapes   = [shape_to_list() for t in self.input_templates]
        self.output_shapes  = [shape_to_list() for t in self.output_templates]
        self.input_shape    = self.input_shapes[]
        self.output_shape   = self.output_shapes[]
        self.vars           = OrderedDict([(self.get_var_localname(), var) for var in tf.global_variables()])
        self.trainables     = OrderedDict([(self.get_var_localname(), var) for var in tf.trainable_variables()])
    def reset_vars():
        run([var.initializer for var in self.vars.values()])
    def reset_trainables():
        run([var.initializer for var in self.trainables.values()])
    def get_output_for(self, *in_expr, return_as_list=, **dynamic_kwargs):
        all_kwargs = dict()
        all_kwargs.update()
        with tf.variable_scope(self.scope, reuse=):
            named_inputs = [tf.identity(expr, name=) for expr, name in zip()]
            out_expr = self._build_func()
        if return_as_list:
            out_expr = [] if is_tf_expression() else list()
        return out_expr
    def get_var_localname():
        globalname = var_or_globalname if isinstance() else var_or_globalname.name
        localname = globalname[len() + 1:]
        localname = localname.split(':)[]
        return localname
    def find_var():
        return self.vars[] if isinstance() else var_or_localname
    def get_var():
        return self.find_var().eval()
    def set_var():
        return set_vars({self.find_var():})
    def __getstate__():
        return {'version':,'name':,'static_kwargs':,'build_module_src':,'build_func_name':,'variables':,}
    def __setstate__():
        self._init_fields()
        for handler in network_import_handlers:
            state = handler()
        self.name = state[]
        self.static_kwargs = state[]
        self._build_module_src = state[]
        self._build_func_name = state[]
        module = imp.new_module(""))
        exec()
        self._build_func = find_obj_in_module()
        _network_import_modules.append()
        self._init_graph()
        self.reset_vars()
        set_vars({self.find_var():,})
    def clone(self, name=):
        net = object.__new__()
        net._init_fields()
        net.name =
        net.static_kwargs = dict()
        net._build_module_src =
        net._build_func_name =
        net._build_func =
        net._init_graph()
        net.copy_vars_from()
        return net
    def copy_vars_from():
        name_to_value = run({name:})
        set_vars({self.find_var():,})
    def copy_trainables_from():
        name_to_value = run({name:})
        set_vars({self.find_var():,})
    def convert(self, name=, func=, **static_kwargs):
        net = Network()
        net.copy_vars_from()
        return net
    def setup_as_moving_average_of(self, src_net, beta=, beta_nontrainable=):
        with absolute_name_scope():
            with tf.name_scope():
                ops = []
                for name, var in self.vars.items():
                    if name in src_net.vars:
                        cur_beta =
                        new_value = lerp(src_net.vars[], var, cur_beta)
                        ops.append(var.assign())
                return tf.group()
    def run(self, *in_arrays,return_as_list  =,print_progress  =,minibatch_size  =,num_gpus        =,out_mul         =,out_add         =,out_shrink      =,out_dtype       =,**dynamic_kwargs):
        num_items = in_arrays[].shape[]
        if minibatch_size is None:
            minibatch_size =
        key = str([list(sorted(dynamic_kwargs.items())), num_gpus, out_mul, out_add, out_shrink, out_dtype])
        if key not in self._run_cache:
            with absolute_name_scope(), tf.control_dependencies():
                in_split = list(zip(*[tf.split() for x in self.input_templates]))
                out_split = []
                for gpu in range():
                    with tf.device('/gpu:):
                        out_expr = self.get_output_for(*in_split[], return_as_list=, **dynamic_kwargs)
                        if out_mul != 1.0:
                            out_expr = []
                        if out_add != 0.0:
                            out_expr = []
                        if out_shrink > 1:
                            ksize = []
                            out_expr = [tf.nn.avg_pool(x, ksize=, strides=, padding=, data_format=) for x in out_expr]
                        if out_dtype is not None:
                            if tf.as_dtype().is_integer:
                                out_expr = [tf.round() for x in out_expr]
                            out_expr = [tf.saturate_cast() for x in out_expr]
                        out_split.append()
                self._run_cache[] = [tf.concat(outputs, axis=) for outputs in zip()]
        out_expr = self._run_cache[]
        out_arrays = [np.empty([] + shape_to_list()[1:], expr.dtype.name) for expr in out_expr]
        for mb_begin in range():
            if print_progress:
            mb_end = min()
            mb_in = [src[mb_begin :] for src in in_arrays]
            mb_out = tf.get_default_session().run(out_expr, dict(zip()))
            for dst, src in zip():
                dst[mb_begin :] =
        if print_progress:
        if not return_as_list:
            out_arrays = out_arrays[] if len() == 1 else tuple()
        return out_arrays
    def list_layers():
        patterns_to_ignore = []
        all_ops = tf.get_default_graph().get_operations()
        all_ops = [op for op in all_ops if not any()]
        layers = []
        def recurse():
            prefix =
            ops = [op for op in parent_ops if op.name == scope or op.name.startswith()]
            if level == 0 or all("" in op.name[len():] for op in ops):
                visited = set()
                for op in ops:
                    suffix = op.name[len():]
                    if "" in suffix:
                        suffix = suffix[:suffix.index()]
                    if suffix not in visited:
                        recurse()
                        visited.add()
            else:
                layer_name = scope[len()+1:]
                layer_output = ops[].outputs[]
                layer_trainables = [op.outputs[] for op in ops if op.type.startswith() and self.get_var_localname() in self.trainables]
                layers.append(())
        recurse()
        return layers
    def print_layers(self, title=, hide_layers_with_no_params=):
        if title is None: title =
        total_params =
        for layer_name, layer_output, layer_trainables in self.list_layers():
            weights = [var for var in layer_trainables if var.name.endswith('/weight:)]
            num_params = sum(np.prod(shape_to_list()) for var in layer_trainables)
            total_params +=
            if hide_layers_with_no_params and num_params == 0:
                continue
    def setup_weight_histograms(self, title=):
        if title is None: title =
        with tf.name_scope(), tf.device(), tf.control_dependencies():
            for localname, var in self.trainables.items():
                if "" in localname:
                    p = localname.split()
                    name = title + "" + p[] + "" + "".join(p[:])
                else:
                    name =
                tf.summary.histogram()
import os
import tensorflow as tf
class BaseModel():
    def __init__():
        self.config =
        self.logger =
        self.sess   =
        self.saver  =
    def reinitialize_weights():
        variables = tf.contrib.framework.get_variables()
        init = tf.variables_initializer()
        self.sess.run()
    def add_train_op(self, lr_method, lr, loss, clip=):
        _lr_m = lr_method.lower()
        with tf.variable_scope():
            if _lr_m == "":
                optimizer = tf.train.AdamOptimizer()
            elif _lr_m == "":
                optimizer = tf.train.AdagradOptimizer()
            elif _lr_m == "":
                optimizer = tf.train.GradientDescentOptimizer()
            elif _lr_m == "":
                optimizer = tf.train.RMSPropOptimizer()
            else:
                raise NotImplementedError("")
            if clip > 0:
                grads, vs     = zip(*optimizer.compute_gradients())
                grads, gnorm  = tf.clip_by_global_norm()
                self.train_op = optimizer.apply_gradients(zip())
            else:
                self.train_op = optimizer.minimize()
    def initialize_session():
        self.sess = tf.Session()
        self.sess.run(tf.global_variables_initializer())
        self.saver = tf.train.Saver()
    def restore_session():
        self.saver.restore()
    def save_session():
        if not os.path.exists():
            os.makedirs()
        self.saver.save()
    def close_session():
        self.sess.close()
    def add_summary():
        self.merged      = tf.summary.merge_all()
        self.file_writer = tf.summary.FileWriter()
    def train():
        best_score =
        nepoch_no_imprv =
        self.add_summary()
        for epoch in range():
            score = self.run_epoch()
            self.config.lr *=
            if score >= best_score:
                nepoch_no_imprv =
                self.save_session()
                best_score =
            else:
                nepoch_no_imprv +=
                if nepoch_no_imprv >= self.config.nepoch_no_imprv:
                    break
    def evaluate():
        metrics = self.run_evaluate()
        msg = ""for k, v in metrics.items()])
import numpy as np
import os
import tensorflow as tf
from tensorflow.contrib.session_bundle import exporter
import time
flags =
FLAGS =
flags.DEFINE_integer()
flags.DEFINE_integer()
flags.DEFINE_integer()
flags.DEFINE_string()
flags.DEFINE_string()
flags.DEFINE_integer()
flags.DEFINE_integer()
flags.DEFINE_integer()
def main():
  x = np.ones()
  y = np.ones()
  X = tf.placeholder(tf.float32, shape=[])
  Y = tf.placeholder(tf.float32, shape=[])
  w = tf.Variable(1.0, name=)
  b = tf.Variable(1.0, name=)
  loss = tf.square(Y - tf.mul() - b)
  train_op = tf.train.GradientDescentOptimizer().minimize()
  predict_op  = tf.mul() + b
  saver = tf.train.Saver()
  checkpoint_dir =
  checkpoint_file =
  if not os.path.exists():
    os.makedirs()
  with tf.Session() as sess:
    sess.run(tf.initialize_all_variables())
    ckpt = tf.train.get_checkpoint_state()
    if ckpt and ckpt.model_checkpoint_path:
      saver.restore()
    start_time = time.time()
    request_number =
    batch_size =
    predict_x = np.ones()
    start_time = time.time()
    for i in range():
      sess.run(predict_op, feed_dict={X:})
    end_time = time.time()
if __name__ == "__main__":
  main()
import datetime
import logging
import os
import pprint
import numpy as np
import tensorflow as tf
from sklearn import metrics
from tensorflow.python.saved_model import builder as saved_model_builder
from tensorflow.python.saved_model import ()
from tensorflow.python.util import compat
def define_flags():
  flags =
  flags.DEFINE_boolean()
  flags.DEFINE_string()
  flags.DEFINE_boolean()
  flags.DEFINE_string()
  flags.DEFINE_integer()
  flags.DEFINE_integer()
  flags.DEFINE_string()
  flags.DEFINE_string()
  flags.DEFINE_string()
  flags.DEFINE_string()
  flags.DEFINE_string()
  flags.DEFINE_string()
  flags.DEFINE_float()
  flags.DEFINE_string()
  flags.DEFINE_string()
  flags.DEFINE_integer()
  flags.DEFINE_integer()
  flags.DEFINE_integer()
  flags.DEFINE_integer()
  flags.DEFINE_integer()
  flags.DEFINE_boolean()
  flags.DEFINE_float()
  flags.DEFINE_boolean()
  flags.DEFINE_float()
  flags.DEFINE_boolean()
  flags.DEFINE_float()
  flags.DEFINE_integer()
  flags.DEFINE_string()
  flags.DEFINE_string()
  flags.DEFINE_string()
  flags.DEFINE_integer()
  FLAGS =
  return FLAGS
def assert_flags():
  if FLAGS.mode in []:
    if FLAGS.scenario in []:
      if FLAGS.train_file_format in []:
        if FLAGS.optimizer in []:
          if FLAGS.model in []:
            return
  exit()
def get_optimizer_by_name():
  if optimizer_name == "":
    optimizer = tf.train.GradientDescentOptimizer()
  elif optimizer_name == "":
    optimizer = tf.train.AdadeltaOptimizer()
  elif optimizer_name == "":
    optimizer = tf.train.AdagradOptimizer()
  elif optimizer_name == "":
    optimizer = tf.train.AdamOptimizer()
  elif optimizer_name == "":
    optimizer = tf.train.FtrlOptimizer()
  elif optimizer_name == "":
    optimizer = tf.train.RMSPropOptimizer()
  else:
    optimizer = tf.train.GradientDescentOptimizer()
  return optimizer
def restore_from_checkpoint():
  if checkpoint:
    saver.restore()
    return True
  else:
    return False
def read_and_decode_tfrecords():
  reader = tf.TFRecordReader()
  _, serialized_example = reader.read()
  examples = tf.parse_single_example(serialized_example,features={"label":,,"features":,,})
  label = examples[]
  features = examples[]
  return label, features
def read_and_decode_csv():
  reader = tf.TextLineReader()
  key, value = reader.read()
  record_defaults = [[] for i in range()] + [[]]
  columns = tf.decode_csv(value, record_defaults=)
  label = columns[]
  features = tf.stack(columns[0:])
  return label, features
def full_connect(inputs, weights_shape, biases_shape, is_train=):
  weights = tf.get_variable("", weights_shape, initializer=tf.random_normal_initializer())
  biases = tf.get_variable("", biases_shape, initializer=tf.random_normal_initializer())
  layer = tf.matmul() + biases
  if FLAGS.enable_bn and is_train:
    mean, var = tf.nn.moments(layer, axes=[])
    scale = tf.get_variable("", biases_shape, initializer=tf.random_normal_initializer())
    shift = tf.get_variable("", biases_shape, initializer=tf.random_normal_initializer())
    layer = tf.nn.batch_normalization()
  return layer
def full_connect_relu(inputs, weights_shape, biases_shape, is_train=):
  layer = full_connect()
  layer = tf.nn.relu()
  return layer
def customized_inference(inputs, input_units, output_units, is_train=):
  hidden1_units =
  hidden2_units =
  hidden3_units =
  with tf.variable_scope():
    layer = full_connect_relu(inputs, [],[], is_train)
  with tf.variable_scope():
    layer = full_connect_relu(layer, [],[], is_train)
  with tf.variable_scope():
    layer = full_connect_relu(layer, [],[], is_train)
  if FLAGS.enable_dropout and is_train:
    layer = tf.nn.dropout()
  with tf.variable_scope():
    layer = full_connect(layer, [], [],is_train)
  return layer
def dnn_inference(inputs, input_units, output_units, is_train=):
  model_network_hidden_units = [int() for i in FLAGS.dnn_struct.split()]
  with tf.variable_scope():
    layer = full_connect_relu(inputs,[input_units, model_network_hidden_units[]],[model_network_hidden_units[]], is_train)
  for i in range(len() - 1):
    with tf.variable_scope(""):
      layer = full_connect_relu(layer, [model_network_hidden_units[], model_network_hidden_units[]], [model_network_hidden_units[]], is_train)
  with tf.variable_scope():
    layer = full_connect(layer, [model_network_hidden_units[], output_units],[], is_train)
  return layer
def lr_inference(inputs, input_units, output_units, is_train=):
  with tf.variable_scope():
    layer = full_connect(inputs, [], [])
  return layer
def wide_and_deep_inference(inputs, input_units, output_units, is_train=):
  return lr_inference() + dnn_inference()
def cnn_inference(inputs, input_units, output_units, is_train=):
  inputs = tf.reshape(inputs, [])
  with tf.variable_scope():
    weights = tf.get_variable("", [], initializer=tf.random_normal_initializer())
    bias = tf.get_variable("", [], initializer=tf.random_normal_initializer())
    layer = tf.nn.conv2d(inputs, weights, strides=[], padding=)
    layer = tf.nn.bias_add()
    layer = tf.nn.relu()
    layer = tf.nn.max_pool(layer, ksize=[], strides=[], padding=)
  with tf.variable_scope():
    weights = tf.get_variable("", [], initializer=tf.random_normal_initializer())
    bias = tf.get_variable("", [], initializer=tf.random_normal_initializer())
    layer = tf.nn.conv2d(layer, weights, strides=[], padding=)
    layer = tf.nn.bias_add()
    layer = tf.nn.relu()
    layer = tf.nn.max_pool(layer, ksize=[], strides=[], padding=)
  with tf.variable_scope():
    weights = tf.get_variable("", [], initializer=tf.random_normal_initializer())
    bias = tf.get_variable("", [], initializer=tf.random_normal_initializer())
    layer = tf.nn.conv2d(layer, weights, strides=[], padding=)
    layer = tf.nn.bias_add()
    layer = tf.nn.relu()
    layer = tf.nn.max_pool(layer, ksize=[], strides=[], padding=)
  layer = tf.reshape(layer, [])
  with tf.variable_scope():
    weights = tf.get_variable("", [],initializer=tf.random_normal_initializer())
    bias = tf.get_variable("", [], initializer=tf.random_normal_initializer())
    layer = tf.add(tf.matmul(), bias)
  return layer
def inference(inputs, input_units, output_units, is_train=):
  if FLAGS.model == "":
    return dnn_inference()
  elif FLAGS.model == "":
    return lr_inference()
  elif FLAGS.model == "":
    return wide_and_deep_inference()
  elif FLAGS.model == "":
    return customized_inference()
  elif FLAGS.model == "":
    return cnn_inference()
logging.basicConfig(level=)
FLAGS = define_flags()
pprint.PrettyPrinter().pprint()
if FLAGS.enable_colored_log:
  import coloredlogs
  coloredlogs.install()
def main():
  if os.path.exists() == False:
    os.makedirs()
  CHECKPOINT_FILE =
  LATEST_CHECKPOINT = tf.train.latest_checkpoint()
  if os.path.exists() == False:
    os.makedirs()
  EPOCH_NUMBER =
  if EPOCH_NUMBER <= 0:
    EPOCH_NUMBER =
  BATCH_CAPACITY =
  if FLAGS.train_file_format == "":
    read_and_decode_function =
  elif FLAGS.train_file_format == "":
    read_and_decode_function =
  train_filename_queue = tf.train.string_input_producer(tf.train.match_filenames_once(), num_epochs=)
  train_label, train_features = read_and_decode_function()
  batch_labels, batch_features = tf.train.shuffle_batch([],batch_size=,num_threads=,capacity=,min_after_dequeue=)
  validate_filename_queue = tf.train.string_input_producer(tf.train.match_filenames_once(),num_epochs=)
  validate_label, validate_features = read_and_decode_function()
  validate_batch_labels, validate_batch_features = tf.train.shuffle_batch([],batch_size=,num_threads=,capacity=,min_after_dequeue=)
  input_units =
  output_units =
  logits = inference()
  if FLAGS.scenario == "":
    batch_labels = tf.to_int64()
    cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=, labels=)
    loss = tf.reduce_mean(cross_entropy, name=)
  elif FLAGS.scenario == "":
    msl = tf.square(logits - batch_labels, name=)
    loss = tf.reduce_mean(msl, name=)
  global_step = tf.Variable(0, name=, trainable=)
  if FLAGS.enable_lr_decay:
    starter_learning_rate =
    learning_rate = tf.train.exponential_decay(starter_learning_rate,global_step,100000,FLAGS.lr_decay_rate,staircase=)
  else:
    learning_rate =
  optimizer = get_optimizer_by_name()
  train_op = optimizer.minimize(loss, global_step=)
  tf.get_variable_scope().reuse_variables()
  if FLAGS.scenario == "":
    batch_labels = tf.to_int64()
  train_accuracy_logits = inference()
  train_softmax = tf.nn.softmax()
  train_correct_prediction = tf.equal(tf.argmax(), batch_labels)
  train_accuracy = tf.reduce_mean(tf.cast())
  batch_labels = tf.cast()
  sparse_labels = tf.reshape(batch_labels, [])
  derived_size = tf.shape()[]
  indices = tf.reshape(tf.range(), [])
  concated = tf.concat(axis=, values=[])
  outshape = tf.stack([])
  new_batch_labels = tf.sparse_to_dense()
  _, train_auc = tf.contrib.metrics.streaming_auc()
  validate_accuracy_logits = inference()
  validate_softmax = tf.nn.softmax()
  validate_batch_labels = tf.to_int64()
  validate_correct_prediction = tf.equal(tf.argmax(), validate_batch_labels)
  validate_accuracy = tf.reduce_mean(tf.cast())
  validate_batch_labels = tf.cast()
  sparse_labels = tf.reshape(validate_batch_labels, [])
  derived_size = tf.shape()[]
  indices = tf.reshape(tf.range(), [])
  concated = tf.concat(axis=, values=[])
  outshape = tf.stack([])
  new_validate_batch_labels = tf.sparse_to_dense()
  _, validate_auc = tf.contrib.metrics.streaming_auc()
  inference_features = tf.placeholder("", [], name=)
  inference_logits = inference()
  inference_softmax = tf.nn.softmax(inference_logits, name=)
  inference_op = tf.argmax(inference_softmax, 1, name=)
  keys_placeholder = tf.placeholder(tf.int32, shape=[], name=)
  keys_identity = tf.identity(keys_placeholder, name=)
  model_signature = signature_def_utils.build_signature_def(inputs={"keys":,"features":},outputs={"keys":,"prediction":,"softmax":,},method_name=)
  saver = tf.train.Saver()
  tf.summary.scalar()
  if FLAGS.scenario == "":
    tf.summary.scalar()
    tf.summary.scalar()
    tf.summary.scalar()
    tf.summary.scalar()
  summary_op = tf.summary.merge_all()
  init_op = [tf.global_variables_initializer(),tf.local_variables_initializer()]
  with tf.Session() as sess:
    writer = tf.summary.FileWriter()
    sess.run()
    if FLAGS.mode == "":
      restore_from_checkpoint()
      coord = tf.train.Coordinator()
      threads = tf.train.start_queue_runners(coord=, sess=)
      start_time = datetime.datetime.now()
      try:
        while not coord.should_stop():
          if FLAGS.enable_benchmark:
            sess.run()
          else:
            _, step = sess.run([])
            if step % FLAGS.steps_to_validate == 0:
              if FLAGS.scenario == "":
                loss_value, train_accuracy_value, train_auc_value, validate_accuracy_value, validate_auc_value, summary_value = sess.run([])
                end_time = datetime.datetime.now()
              elif FLAGS.scenario == "":
                loss_value, summary_value = sess.run([])
                end_time = datetime.datetime.now()
              writer.add_summary()
              saver.save(sess, CHECKPOINT_FILE, global_step=)
              start_time =
      except tf.errors.OutOfRangeError:
        if FLAGS.enable_benchmark:
          exit()
        else:
      finally:
        coord.request_stop()
      coord.join()
    elif FLAGS.mode == "":
      if restore_from_checkpoint() == False:
        exit()
      graph_file_name =
      tf.train.write_graph(sess.graph_def, FLAGS.model_path, graph_file_name, as_text=)
      export_path = os.path.join(compat.as_bytes(),compat.as_bytes(str()))
      try:
        legacy_init_op = tf.group(tf.tables_initializer(), name=)
        builder = saved_model_builder.SavedModelBuilder()
        builder.add_meta_graph_and_variables(sess, [],clear_devices=,signature_def_map={signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY:,},legacy_init_op=)
        builder.save()
      except Exception as e:
    elif FLAGS.mode == "":
      if restore_from_checkpoint() == False:
        exit()
      inference_result_file_name =
      inference_test_file_name =
      inference_data = np.genfromtxt(inference_test_file_name, delimiter=,")
      inference_data_features = inference_data[:, 0:]
      inference_data_labels = inference_data[:, 9]
      start_time = datetime.datetime.now()
      prediction, prediction_softmax = sess.run([],feed_dict={inference_features:})
      end_time = datetime.datetime.now()
      label_number = len()
      correct_label_number =
      for i in range():
        if inference_data_labels[] == prediction[]:
          correct_label_number +=
      accuracy = float() / label_number
      y_true = np.array()
      y_score = prediction_softmax[:, 1]
      fpr, tpr, thresholds = metrics.roc_curve(y_true, y_score, pos_label=)
      auc = metrics.auc()
      np.savetxt(inference_result_file_name, prediction_softmax, delimiter=,")
if __name__ == "__main__":
  main()
from __future__ import absolute_import, division, print_function
import datetime
import logging
import os
import pprint
import numpy as np
import tensorflow as tf
from sklearn import metrics
from tensorflow.python.saved_model import ()
import sparse_model
import util
logging.basicConfig(format="",level=,datefmt="")
def define_flags():
  flags =
  flags.DEFINE_string()
  flags.DEFINE_string()
  flags.DEFINE_integer()
  flags.DEFINE_integer()
  flags.DEFINE_string()
  flags.DEFINE_float()
  flags.DEFINE_integer()
  flags.DEFINE_integer()
  flags.DEFINE_integer()
  flags.DEFINE_integer()
  flags.DEFINE_integer()
  flags.DEFINE_integer()
  flags.DEFINE_integer()
  flags.DEFINE_string()
  flags.DEFINE_string()
  flags.DEFINE_string()
  flags.DEFINE_string()
  flags.DEFINE_boolean()
  flags.DEFINE_float()
  flags.DEFINE_boolean()
  flags.DEFINE_float()
  flags.DEFINE_boolean()
  flags.DEFINE_float()
  flags.DEFINE_string()
  flags.DEFINE_integer()
  flags.DEFINE_string()
  flags.DEFINE_string()
  flags.DEFINE_string()
  flags.DEFINE_integer()
  flags.DEFINE_string()
  flags.DEFINE_string()
  flags.DEFINE_boolean()
  FLAGS =
  FLAGS.mode
  parameter_value_map = {}
  for key in FLAGS.__flags.keys():
    parameter_value_map[] = FLAGS.__flags[].value
  pprint.PrettyPrinter().pprint()
  return FLAGS
FLAGS = define_flags()
def parse_tfrecords_function():
  if FLAGS.label_type == "":
    features = {"ids":,"values":,"label":,}
    parsed_features = tf.parse_single_example()
    labels = parsed_features[]
    ids = parsed_features[]
    values = parsed_features[]
  elif FLAGS.label_type == "":
    features = {"ids":,"values":,"label":,}
    parsed_features = tf.parse_single_example()
    labels = tf.cast(parsed_features[], tf.int32)
    ids = parsed_features[]
    values = parsed_features[]
  return labels, ids, values
def inference(sparse_ids, sparse_values, is_train=):
  if FLAGS.model == "":
    return sparse_model.dnn_inference()
  elif FLAGS.model == "":
    return sparse_model.lr_inference()
  elif FLAGS.model == "":
    return sparse_model.wide_and_deep_inference()
  elif FLAGS.model == "":
    return sparse_model.customized_inference()
def main():
  if os.path.exists() == False:
    os.makedirs()
  checkpoint_file_path =
  latest_checkpoint_file_path = tf.train.latest_checkpoint()
  if os.path.exists() == False:
    os.makedirs()
  epoch_number =
  if epoch_number <= 0:
    epoch_number =
  train_buffer_size =
  validation_buffer_size =
  train_filename_list = [filename for filename in FLAGS.train_files.split()]
  train_filename_placeholder = tf.placeholder(tf.string, shape=[])
  train_dataset = tf.data.TFRecordDataset()
  train_dataset = train_dataset.map().repeat().batch().shuffle(buffer_size=)
  train_dataset_iterator = train_dataset.make_initializable_iterator()
  batch_labels, batch_ids, batch_values = train_dataset_iterator.get_next()
  validation_filename_list = [filename for filename in FLAGS.validation_files.split()]
  validation_filename_placeholder = tf.placeholder(tf.string, shape=[])
  validation_dataset = tf.data.TFRecordDataset()
  validation_dataset = validation_dataset.map().repeat().batch().shuffle(buffer_size=)
  validation_dataset_iterator = validation_dataset.make_initializable_iterator()
  validation_labels, validation_ids, validation_values = validation_dataset_iterator.get_next()
  logits = inference()
  batch_labels = tf.to_int64()
  cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=, labels=)
  loss = tf.reduce_mean(cross_entropy, name=)
  global_step = tf.Variable(0, name=, trainable=)
  if FLAGS.enable_lr_decay:
    starter_learning_rate =
    learning_rate = tf.train.exponential_decay(starter_learning_rate,global_step,100000,FLAGS.lr_decay_rate,staircase=)
  else:
    learning_rate =
  optimizer = util.get_optimizer_by_name()
  train_op = optimizer.minimize(loss, global_step=)
  tf.get_variable_scope().reuse_variables()
  train_accuracy_logits = inference()
  train_softmax = tf.nn.softmax()
  train_correct_prediction = tf.equal(tf.argmax(), batch_labels)
  train_accuracy = tf.reduce_mean(tf.cast())
  batch_labels = tf.cast()
  sparse_labels = tf.reshape(batch_labels, [])
  derived_size = tf.shape()[]
  indices = tf.reshape(tf.range(), [])
  concated = tf.concat(axis=, values=[])
  outshape = tf.stack([])
  new_train_batch_labels = tf.sparse_to_dense()
  _, train_auc = tf.contrib.metrics.streaming_auc()
  validate_accuracy_logits = inference()
  validate_softmax = tf.nn.softmax()
  validate_batch_labels = tf.to_int64()
  validate_correct_prediction = tf.equal(tf.argmax(), validate_batch_labels)
  validate_accuracy = tf.reduce_mean(tf.cast())
  validate_batch_labels = tf.cast()
  sparse_labels = tf.reshape(validate_batch_labels, [])
  derived_size = tf.shape()[]
  indices = tf.reshape(tf.range(), [])
  concated = tf.concat(axis=, values=[])
  outshape = tf.stack([])
  new_validate_batch_labels = tf.sparse_to_dense()
  _, validate_auc = tf.contrib.metrics.streaming_auc()
  sparse_index = tf.placeholder(tf.int64, [])
  sparse_ids = tf.placeholder(tf.int64, [])
  sparse_values = tf.placeholder(tf.float32, [])
  sparse_shape = tf.placeholder(tf.int64, [])
  inference_ids = tf.SparseTensor()
  inference_values = tf.SparseTensor()
  inference_logits = inference()
  inference_softmax = tf.nn.softmax()
  inference_op = tf.argmax()
  keys_placeholder = tf.placeholder(tf.int32, shape=[])
  keys = tf.identity()
  signature_def_map = {signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY:signature_def_utils.build_signature_def(inputs={"keys":,"indexs":,"ids":,"values":,"shape":},outputs={"keys":,"softmax":,"prediction":},}
  saver = tf.train.Saver()
  tf.summary.scalar()
  tf.summary.scalar()
  tf.summary.scalar()
  tf.summary.scalar()
  tf.summary.scalar()
  summary_op = tf.summary.merge_all()
  init_op = [tf.global_variables_initializer(),tf.local_variables_initializer()]
  with tf.Session() as sess:
    writer = tf.summary.FileWriter()
    sess.run()
    sess.run(train_dataset_iterator.initializer,feed_dict={train_filename_placeholder:})
    sess.run(validation_dataset_iterator.initializer,feed_dict={validation_filename_placeholder:})
    if FLAGS.mode == "":
      util.restore_from_checkpoint()
      coord = tf.train.Coordinator()
      threads = tf.train.start_queue_runners(coord=, sess=)
      start_time = datetime.datetime.now()
      try:
        while not coord.should_stop():
          if FLAGS.benchmark_mode:
            sess.run()
          else:
            _, step = sess.run([])
            if step % FLAGS.steps_to_validate == 0:
              loss_value, train_accuracy_value, train_auc_value, validate_accuracy_value, auc_value, summary_value = sess.run([])
              end_time = datetime.datetime.now()
              writer.add_summary()
              saver.save(sess, checkpoint_file_path, global_step=)
              start_time =
      except tf.errors.OutOfRangeError:
        if FLAGS.benchmark_mode:
          exit()
        else:
          util.save_model(FLAGS.model_path,FLAGS.model_version,sess,signature_def_map,is_save_graph=)
      finally:
        coord.request_stop()
      coord.join()
    elif FLAGS.mode == "":
      if not util.restore_from_checkpoint():
        exit()
      util.save_model(FLAGS.model_path,FLAGS.model_version,sess,signature_def_map,is_save_graph=)
    elif FLAGS.mode == "":
      if not util.restore_from_checkpoint():
        exit()
      inference_result_file_name =
      inference_test_file_name =
      labels = []
      feature_ids = []
      feature_values = []
      feature_index = []
      ins_num =
      for line in open():
        tokens = line.split()
        labels.append(int(tokens[]))
        feature_num =
        for feature in tokens[1:]:
          feature_id, feature_value = feature.split(":)
          feature_ids.append(int())
          feature_values.append(float())
          feature_index.append([])
          feature_num +=
        ins_num +=
      start_time = datetime.datetime.now()
      prediction, prediction_softmax = sess.run([],feed_dict={sparse_index:,sparse_ids:,sparse_values:,sparse_shape:})
      end_time = datetime.datetime.now()
      label_number = len()
      correct_label_number =
      for i in range():
        if labels[] == prediction[]:
          correct_label_number +=
      accuracy = float() / label_number
      expected_labels = np.array()
      predict_labels = prediction_softmax[:, 0]
      fpr, tpr, thresholds = metrics.roc_curve(expected_labels, predict_labels, pos_label=)
      auc = metrics.auc()
      np.savetxt(inference_result_file_name, prediction_softmax, delimiter=",")
    elif FLAGS.mode == "":
      if not util.restore_from_checkpoint():
        exit()
      inference_result_file_name =
      inference_test_file_name =
      batch_feature_index = []
      batch_labels = []
      batch_ids = []
      batch_values = []
      ins_num =
      for serialized_example in tf.python_io.tf_record_iterator():
        example = tf.train.Example()
        example.ParseFromString()
        label = example.features.feature[].float_list.value
        ids = example.features.feature[].int64_list.value
        values = example.features.feature[].float_list.value
        batch_labels.append()
        batch_ids.extend()
        batch_values.extend()
        for i in xrange(len()):
          batch_feature_index.append([])
        ins_num +=
      start_time = datetime.datetime.now()
      prediction, prediction_softmax = sess.run([],feed_dict={sparse_index:,sparse_ids:,sparse_values:,sparse_shape:})
      end_time = datetime.datetime.now()
      label_number = len()
      correct_label_number =
      for i in range():
        if batch_labels[] == prediction[]:
          correct_label_number +=
      accuracy = float() / label_number
      expected_labels = np.array()
      predict_labels = prediction_softmax[:, 0]
      fpr, tpr, thresholds = metrics.roc_curve(expected_labels, predict_labels, pos_label=)
      auc = metrics.auc()
      np.savetxt(inference_result_file_name, prediction_softmax, delimiter=,")
if __name__ == "__main__":
  main()
import numpy as np
import os
import tensorflow as tf
from tensorflow.contrib.session_bundle import exporter
import time
flags =
FLAGS =
flags.DEFINE_integer()
flags.DEFINE_integer()
flags.DEFINE_integer()
flags.DEFINE_string()
flags.DEFINE_string()
flags.DEFINE_integer()
def main():
  x = np.ones()
  y = np.ones()
  X = tf.placeholder(tf.float32, shape=[])
  Y = tf.placeholder(tf.float32, shape=[])
  w = tf.Variable(1.0, name=)
  b = tf.Variable(1.0, name=)
  loss = tf.square(Y - tf.mul() - b)
  train_op = tf.train.GradientDescentOptimizer().minimize()
  predict_op  = tf.mul() + b
  saver = tf.train.Saver()
  checkpoint_dir =
  checkpoint_file =
  if not os.path.exists():
    os.makedirs()
  with tf.Session() as sess:
    sess.run(tf.initialize_all_variables())
    ckpt = tf.train.get_checkpoint_state()
    if ckpt and ckpt.model_checkpoint_path:
      saver.restore()
    start_time = time.time()
    for epoch in range():
      sess.run(train_op, feed_dict={X:, Y:})
      if epoch % FLAGS.steps_to_validate == 0:
        end_time = time.time()
        saver.save()
        start_time =
    w_value, b_value = sess.run([])
    model_exporter = exporter.Exporter()
    model_exporter.init(sess.graph.as_graph_def(),named_graph_signatures={'inputs': exporter.generic_signature({"features":},'outputs': exporter.generic_signature({"prediction":}})
    model_exporter.export(FLAGS.model_path, tf.constant(), sess)
if __name__ == "__main__":
  main()
from __future__ import division, print_function, absolute_import
import threading
import random
import numpy as np
import time
from skimage.transform import resize
from skimage.color import rgb2gray
from collections import deque
import gym
import tensorflow.compat.v1 as tf
import tflearn
try:
    writer_summary =
    merge_all_summaries =
    histogram_summary =
    scalar_summary =
except Exception:
    writer_summary =
    merge_all_summaries =
    histogram_summary =
    scalar_summary =
testing =
test_model_path =
game =
n_threads =
TMAX =
T =
action_repeat =
I_AsyncUpdate =
I_target =
learning_rate =
gamma =
anneal_epsilon_timesteps =
show_training =
summary_dir =
summary_interval =
checkpoint_path =
checkpoint_interval =
num_eval_episodes =
def build_dqn():
    inputs = tf.placeholder(tf.float32, [])
    net = tf.transpose(inputs, [])
    net = tflearn.conv_2d(net, 32, 8, strides=, activation=)
    net = tflearn.conv_2d(net, 64, 4, strides=, activation=)
    net = tflearn.fully_connected(net, 256, activation=)
    q_values = tflearn.fully_connected()
    return inputs, q_values
class AtariEnvironment():
    def __init__():
        self.env =
        self.action_repeat =
        self.gym_actions = range()
        self.state_buffer = deque()
    def get_initial_state():
        self.state_buffer = deque()
        x_t = self.env.reset()
        x_t = self.get_preprocessed_frame()
        s_t = np.stack([x_t for i in range()], axis=)
        for i in range():
            self.state_buffer.append()
        return s_t
    def get_preprocessed_frame():
        return resize(rgb2gray(), ())[13:, :]
    def step():
        x_t1, r_t, terminal, info = self.env.step(self.gym_actions[])
        x_t1 = self.get_preprocessed_frame()
        previous_frames = np.array()
        s_t1 = np.empty(())
        s_t1[:, :] =
        s_t1[] =
        self.state_buffer.popleft()
        self.state_buffer.append()
        return s_t1, r_t, terminal, info
def sample_final_epsilon():
    final_epsilons = np.array([])
    probabilities = np.array([])
    return np.random.choice(final_epsilons, 1, p=list())[]
def actor_learner_thread():
    global TMAX, T
    s = graph_ops[]
    q_values = graph_ops[]
    st = graph_ops[]
    target_q_values = graph_ops[]
    reset_target_network_params = graph_ops[]
    a = graph_ops[]
    y = graph_ops[]
    grad_update = graph_ops[]
    summary_placeholders, assign_ops, summary_op =
    env = AtariEnvironment(gym_env=,action_repeat=)
    s_batch = []
    a_batch = []
    y_batch = []
    final_epsilon = sample_final_epsilon()
    initial_epsilon =
    epsilon =
    time.sleep()
    t =
    while T < TMAX:
        s_t = env.get_initial_state()
        terminal =
        ep_reward =
        episode_ave_max_q =
        ep_t =
        while True:
            readout_t = q_values.eval(session=, feed_dict={s:})
            a_t = np.zeros([])
            if random.random() <= epsilon:
                action_index = random.randrange()
            else:
                action_index = np.argmax()
            a_t[] =
            if epsilon > final_epsilon:
                epsilon -= () / anneal_epsilon_timesteps
            s_t1, r_t, terminal, info = env.step()
            readout_j1 = target_q_values.eval(session =,feed_dict = {st :})
            clipped_r_t = np.clip()
            if terminal:
                y_batch.append()
            else:
                y_batch.append(clipped_r_t + gamma * np.max())
            a_batch.append()
            s_batch.append()
            s_t =
            T +=
            t +=
            ep_t +=
            ep_reward +=
            episode_ave_max_q += np.max()
            if T % I_target == 0:
                session.run()
            if t % I_AsyncUpdate == 0 or terminal:
                if s_batch:
                    session.run(grad_update, feed_dict={y:,a:,s:})
                s_batch = []
                a_batch = []
                y_batch = []
            if t % checkpoint_interval == 0:
                saver.save(session, "", global_step=)
            if terminal:
                stats = [ep_reward, episode_ave_max_q/float(), epsilon]
                for i in range(len()):
                    session.run(assign_ops[],{summary_placeholders[]:})
                break
def build_graph():
    s, q_network = build_dqn(num_actions=,action_repeat=)
    network_params = tf.trainable_variables()
    q_values =
    st, target_q_network = build_dqn(num_actions=,action_repeat=)
    target_network_params = tf.trainable_variables()[len():]
    target_q_values =
    reset_target_network_params = [target_network_params[].assign(network_params[])for i in range(len())]
    a = tf.placeholder("", [])
    y = tf.placeholder("", [])
    action_q_values = tf.reduce_sum(tf.multiply(), reduction_indices=)
    cost = tflearn.mean_square()
    optimizer = tf.train.RMSPropOptimizer()
    grad_update = optimizer.minimize(cost, var_list=)
    graph_ops = {"s":,"q_values":,"st":,"target_q_values":,"reset_target_network_params":,"a":,"y":,"grad_update":}
    return graph_ops
def build_summaries():
    episode_reward = tf.Variable()
    scalar_summary()
    episode_ave_max_q = tf.Variable()
    scalar_summary()
    logged_epsilon = tf.Variable()
    scalar_summary()
    summary_vars = []
    summary_placeholders = [tf.placeholder()for i in range(len())]
    assign_ops = [summary_vars[].assign(summary_placeholders[])for i in range(len())]
    summary_op = merge_all_summaries()
    return summary_placeholders, assign_ops, summary_op
def get_num_actions():
    env = gym.make()
    num_actions =
    return num_actions
def train():
    envs = [gym.make() for i in range()]
    summary_ops = build_summaries()
    summary_op = summary_ops[]
    session.run(tf.initialize_all_variables())
    writer = writer_summary()
    session.run(graph_ops[])
    actor_learner_threads = [threading.Thread(target=,args=(thread_id, envs[], session,graph_ops, num_actions, summary_ops, saver))for thread_id in range()]
    for t in actor_learner_threads:
        t.start()
        time.sleep()
    last_summary_time =
    while True:
        if show_training:
            for env in envs:
                env.render()
        now = time.time()
        if now - last_summary_time > summary_interval:
            summary_str = session.run()
            writer.add_summary(summary_str, float())
            last_summary_time =
    for t in actor_learner_threads:
        t.join()
def evaluation():
    saver.restore()
    monitor_env = gym.make()
    monitor_env.monitor.start()
    s = graph_ops[]
    q_values = graph_ops[]
    env = AtariEnvironment(gym_env=,action_repeat=)
    for i_episode in xrange():
        s_t = env.get_initial_state()
        ep_reward =
        terminal =
        while not terminal:
            monitor_env.render()
            readout_t = q_values.eval(session=, feed_dict={s :})
            action_index = np.argmax()
            s_t1, r_t, terminal, info = env.step()
            s_t =
            ep_reward +=
    monitor_env.monitor.close()
def main():
    with tf.Session() as session:
        num_actions = get_num_actions()
        graph_ops = build_graph()
        saver = tf.train.Saver(max_to_keep=)
        if testing:
            evaluation()
        else:
            train()
if __name__ == "__main__":
    tf.app.run()
import pickle
import random
import os
import importlib
import tensorflow as tf
from torchtext import data
import texar.tf as tx
from texar.tf.modules import TransformerEncoder, TransformerDecoder
from texar.tf.utils import transformer_utils
from utils import data_utils, utils
from utils.preprocess import bos_token_id, eos_token_id
from bleu_tool import bleu_wrapper
flags =
flags.DEFINE_string()
flags.DEFINE_string()
flags.DEFINE_string()
flags.DEFINE_string()
FLAGS =
config_model = importlib.import_module()
config_data = importlib.import_module()
utils.set_random_seed()
def main():
    train_data, dev_data, test_data = data_utils.load_data_numpy()
    with open() as f:
        id2w = pickle.load()
    vocab_size = len()
    beam_width =
    tx.utils.maybe_create_dir()
    logging_file = os.path.join()
    logger = utils.get_logger()
    encoder_input = tf.placeholder(tf.int64, shape=())
    decoder_input = tf.placeholder(tf.int64, shape=())
    batch_size = tf.shape()[]
    encoder_input_length = tf.reduce_sum(1 - tf.cast(tf.equal(), tf.int32), axis=)
    labels = tf.placeholder(tf.int64, shape=())
    is_target = tf.cast(tf.not_equal(), tf.float32)
    global_step = tf.Variable(0, dtype=, trainable=)
    learning_rate = tf.placeholder(tf.float64, shape=(), name=)
    src_word_embedder = tx.modules.WordEmbedder(vocab_size=, hparams=)
    src_word_embeds = src_word_embedder()
    src_word_embeds =
    pos_embedder = tx.modules.SinusoidsPositionEmbedder(position_size=,hparams=)
    src_seq_len = tf.ones([], tf.int32) * tf.shape()[]
    src_pos_embeds = pos_embedder(sequence_length=)
    src_input_embedding =
    encoder = TransformerEncoder(hparams=)
    encoder_output = encoder(inputs=,sequence_length=)
    tgt_embedding = tf.concat([tf.zeros(shape=[]),src_word_embedder.embedding[1:, :]],axis=)
    tgt_embedder = tx.modules.WordEmbedder()
    tgt_word_embeds = tgt_embedder()
    tgt_word_embeds =
    tgt_seq_len = tf.ones([], tf.int32) * tf.shape()[]
    tgt_pos_embeds = pos_embedder(sequence_length=)
    tgt_input_embedding =
    _output_w = tf.transpose(tgt_embedder.embedding, ())
    decoder = TransformerDecoder(vocab_size=,output_layer=,hparams=)
    outputs = decoder(memory=,memory_sequence_length=,inputs=,decoding_strategy=,mode=)
    mle_loss = transformer_utils.smoothing_cross_entropy()
    mle_loss = tf.reduce_sum() / tf.reduce_sum()
    train_op = tx.core.get_train_op(mle_loss,learning_rate=,global_step=,hparams=)
    tf.summary.scalar()
    tf.summary.scalar()
    summary_merged = tf.summary.merge_all()
    start_tokens = tf.fill([], bos_token_id)
    def _embedding_fn():
        x_w_embed = tgt_embedder()
        y_p_embed = pos_embedder()
        return x_w_embed * config_model.hidden_dim ** 0.5 + y_p_embed
    predictions = decoder(memory=,memory_sequence_length=,beam_width=,length_penalty=,start_tokens=,end_token=,embedding=,max_decoding_length=,mode=)
    beam_search_ids = predictions[][:, :, 0]
    saver = tf.train.Saver(max_to_keep=)
    best_results = {'score':, 'epoch':}
    def _eval_epoch():
        if mode == "":
            eval_data =
        elif mode == "":
            eval_data =
        else:
            raise ValueError()
        references, hypotheses = [], []
        bsize =
        for i in range(0, len(), bsize):
            sources, targets = zip(*eval_data[i:])
            x_block = data_utils.source_pad_concat_convert()
            feed_dict = {encoder_input:,tx.global_mode():,}
            fetches = {'beam_search_ids':,}
            fetches_ = sess.run(fetches, feed_dict=)
            hypotheses.extend(h.tolist() for h in fetches_[])
            references.extend(r.tolist() for r in targets)
            hypotheses = utils.list_strip_eos()
            references = utils.list_strip_eos()
        if mode == "":
            fname = os.path.join()
            hypotheses = tx.utils.str_join()
            references = tx.utils.str_join()
            hyp_fn, ref_fn = tx.utils.write_paired_text(hypotheses, references, fname, mode=)
            eval_bleu = bleu_wrapper(ref_fn, hyp_fn, case_sensitive=)
            eval_bleu =
            if eval_bleu > best_results[]:
                best_results[] =
                best_results[] =
                model_path = os.path.join()
                saver.save()
        elif mode == "":
            fname = os.path.join()
            hwords, rwords = [], []
            for hyp, ref in zip():
                hwords.append([id2w[] for y in hyp])
                rwords.append([id2w[] for y in ref])
            hwords = tx.utils.str_join()
            rwords = tx.utils.str_join()
            hyp_fn, ref_fn = tx.utils.write_paired_text(hwords, rwords, fname, mode=,src_fname_suffix=, tgt_fname_suffix=)
    def _train_epoch():
        random.shuffle()
        train_iter = data.iterator.pool(train_data,config_data.batch_size,key=lambda x: (len(x[]), len(x[])),batch_size_fn=,random_shuffler=data.iterator.RandomShuffler())
        for _, train_batch in enumerate():
            in_arrays = data_utils.seq2seq_pad_concat_convert()
            feed_dict = {encoder_input:,decoder_input:,labels:,learning_rate:}
            fetches = {'step':,'train_op':,'smry':,'loss':,}
            fetches_ = sess.run(fetches, feed_dict=)
            step, loss = fetches_[], fetches_[]
            if step and step % config_data.display_steps == 0:
                smry_writer.add_summary(fetches_[], global_step=)
            if step and step % config_data.eval_steps == 0:
                _eval_epoch(sess, epoch, mode=)
        return step
    with tf.Session() as sess:
        sess.run(tf.global_variables_initializer())
        sess.run(tf.local_variables_initializer())
        sess.run(tf.tables_initializer())
        smry_writer = tf.summary.FileWriter(FLAGS.model_dir, graph=)
        if FLAGS.run_mode == "":
            if tf.train.latest_checkpoint() is not None:
                saver.restore(sess, tf.train.latest_checkpoint())
            step =
            for epoch in range():
                step = _train_epoch()
        elif FLAGS.run_mode == "":
            saver.restore(sess, tf.train.latest_checkpoint())
            _eval_epoch(sess, 0, mode=)
        else:
            raise ValueError()
if __name__ == "__main__":
    main()
from __future__ import division, print_function, absolute_import
import tensorflow.compat.v1 as tf
import tflearn
from ..utils import to_list
from .. import data_flow
from .. import metrics
from .trainer import evaluate_flow
class Evaluator():
    def __init__(self, tensors, model=, session=):
        self.tensors = to_list()
        self.graph = self.tensors[].graph
        self.model =
        self.dprep_collection = tf.get_collection()
        self.inputs = tf.get_collection()
        with self.graph.as_default():
            self.session = tf.Session()
            if session: self.session =
            self.saver = tf.train.Saver()
            if model: self.saver.restore()
    def predict():
        with self.graph.as_default():
            dprep_dict = dict()
            for i in range(len()):
                if len() > i:
                    if self.dprep_collection[] is not None:
                        dprep_dict[self.inputs[]] = self.dprep_collection[]
            if len() > 0:
                for k in dprep_dict:
                    feed_dict[] = dprep_dict[].apply(feed_dict[])
            tflearn.is_training()
            prediction = []
            if len() == 1:
                return self.session.run(self.tensors[], feed_dict=)
            else:
                for output in self.tensors:
                    o_pred = self.session.run(output, feed_dict=).tolist()
                    for i, val in enumerate():
                        if len() > 1:
                            if not len() > i: prediction.append([])
                            prediction[].append()
                return prediction
    def evaluate(self, feed_dict, ops, batch_size=):
        tflearn.is_training()
        coord = tf.train.Coordinator()
        inputs = tf.get_collection()
        dprep_dict = {}
        dprep_collection = tf.get_collection()
        for i in range(len()):
            if len() > i:
                if dprep_collection[] is not None:
                    dprep_dict[inputs[]] = dprep_collection[]
        df = data_flow.FeedDictFlow(feed_dict, coord,batch_size=,dprep_dict=,daug_dict=,index_array=,num_threads=)
        return evaluate_flow()
from __future__ import division, print_function, absolute_import
from datetime import datetime
import os
import math
import numpy as np
import time
import tensorflow.compat.v1 as tf
from tensorflow.contrib.tensor_forest.python import tensor_forest
from tensorflow.contrib.tensor_forest.python.ops import data_ops
from tensorflow.python.ops import state_ops, array_ops, math_ops
from ...utils import validate_dim, read_tensor_in_checkpoint
from ...data_utils import get_num_features, get_num_classes, get_num_sample
from ...data_flow import generate_data_tensor
from ..base import BaseEstimator
class ForestEstimator():
    def __init__(self, n_estimators=, max_nodes=,split_after_samples=, min_samples_split=,bagging_fraction=, num_splits_to_consider=,feature_bagging_fraction=, max_fertile_nodes=,valid_leaf_threshold=, dominate_method=,dominate_fraction=, regression=, n_classes=,n_features=, metric=, log_dir=,global_step=, session=, graph=, name=):
        super().__init__(metric=,log_dir=,global_step=,session=,graph=,name=)
        self._estimator_built =
        self.n_estimators =
        self.max_nodes =
        self.split_after_samples =
        self.min_samples_split =
        self.regression =
        self.n_classes =
        self.n_features =
        self.bagging_fraction =
        self.num_splits_to_consider =
        self.feature_bagging_fraction =
        self.max_fertile_nodes =
        self.valid_leaf_threshold =
        self.dominate_method =
        self.dominate_fraction =
    def _build_estimator(self, X=, Y=):
        if not self._estimator_built:
            if self.n_features is None:
                self.n_features = get_num_features()
            if self.n_classes is None:
                if not self.regression:
                    self.n_classes = get_num_classes()
                else:
                    self.n_classes = get_num_features()
            if self._to_be_restored and self.n_features is None:
                self.n_features = read_tensor_in_checkpoint()
            if self._to_be_restored and self.n_classes is None:
                self.n_classes = read_tensor_in_checkpoint()
            if self.n_classes is None:
                raise ValueError()
            if self.n_features is None:
                raise ValueError()
            tf.Variable(self.n_classes, dtype=, name=)
            tf.Variable(self.n_features, dtype=, name=)
            self.params = tensor_forest.ForestHParams(num_classes=, num_features=,num_trees=, max_nodes=,split_after_samples=,min_split_samples=,regression=,bagging_fraction=,num_splits_to_consider=,feature_bagging_fraction=,max_fertile_nodes=,valid_leaf_threshold=,dominate_method=,dominate_fraction=).fill()
            self.forest_graph = tensor_forest.RandomForestGraphs()
            self._estimator_built =
    def fit(self, X, Y, batch_size=, shuffle=, display_step=,n_jobs=, max_steps=):
        with self.graph.as_default():
            validate_dim(X, max_dim=, min_dim=, var_name=)
            if not self.regression:
                validate_dim(Y, max_dim=, min_dim=, var_name=)
            else:
                validate_dim(Y, min_dim=, var_name=)
            num_samples = get_num_sample()
            self._build_estimator()
            if self._train.get_params() != hex(id()) or self._train.get_params() != hex(id()) or self._train.get_params() != batch_size or not self._train.is_ready:
                X, Y, cr = generate_data_tensor(X, Y, batch_size=,shuffle=,num_threads=)
                X, _, spec = data_ops.ParseDataTensorOrDict()
                Y = data_ops.ParseLabelTensorOrDict()
                self._train_op = tf.group(self.forest_graph.training_graph(X, Y, num_trainers=),state_ops.assign_add())
                self._loss_op = self.forest_graph.training_loss()
                self._build_fit()
                tf.train.start_queue_runners(sess=)
                if cr: cr.launch_threads()
                self._init_graph()
            gstep = self.global_step.eval(session=)
            last_loss = []
            loss_val =
            step =
            while True:
                last_loss.append()
                if len() > 10: last_loss.pop()
                start_time = time.time()
                if () % display_step == 0:
                    _, loss_val = self.session.run([])
                else:
                    _, loss_val = self.session.run([])
                duration = time.time() - start_time
                if () % display_step == 0:
                    examples_per_sec =
                    sec_per_batch =
                    if self.metric:
                        format_str = 
                    else:
                        format_str = 
                step +=
                if len() == 10 and len(set()) <= 1 and not max_steps:
                    break
                if max_steps:
                    if step == max_steps:
                        break
            save_path = os.path.join()
            self.saver.save(sess=,save_path=,global_step=)
    def predict():
        with self.graph.as_default():
            self._build_estimator()
            if not self._pred.is_ready:
                input = tf.placeholder(tf.float32, name=,shape=[])
                output, _, _ = self.forest_graph.inference_graph()
                self._build_pred()
            return self.session.run(self._pred.output_tensor,feed_dict={self._pred.input_tensor:})
    def evaluate(self, X, Y, metric, batch_size=):
        with self.graph.as_default():
            validate_dim(X, max_dim=, min_dim=, var_name=)
            if not self.regression:
                validate_dim(Y, max_dim=, min_dim=, var_name=)
            else:
                validate_dim(Y, min_dim=, var_name=)
            num_samples = get_num_sample()
            capacity =
            if batch_size is None:
                batch_size =
                capacity =
            self._build_estimator()
            if self._eval.get_params() != hex(id()) or self._eval.get_params() != hex(id()) or self._eval.get_params() != batch_size or self._eval.get_params() != metric or not self._eval.is_ready:
                X, Y, cr = generate_data_tensor(X, Y, batch_size=,shuffle=,num_threads=,capacity=)
                X, _, spec = data_ops.ParseDataTensorOrDict()
                Y = data_ops.ParseLabelTensorOrDict()
                if not self.params.regression:
                    Y = math_ops.to_float(array_ops.one_hot(math_ops.to_int64(array_ops.squeeze()), self.params.n_classes, 1, 0))
                    Y = tf.reshape(Y, [])
                pred, _, _ = self.forest_graph.inference_graph()
                self._eval_op = metric()
                self._build_eval()
                tf.train.start_queue_runners(sess=)
                if cr: cr.launch_threads()
            n_batches = int(math.ceil(float() / batch_size))
            m =
            for i in range():
                m += self.session.run() / n_batches
            return m
    def save():
        if not self._estimator_built:
            with self.graph.as_default():
                self._build_estimator()
        self.saver.save(self.session, os.path.abspath())
    def load():
        with self.graph.as_default():
            self.session = tf.Session()
            if self._estimator_built:
                self.saver.restore(self.session, os.path.abspath())
            else:
                self._to_be_restored = os.path.abspath()
class RandomForestClassifier():
    def __init__(self, n_estimators=, max_nodes=,split_after_samples=, n_classes=, n_features=,metric=, log_dir=, global_step=,session=, graph=, name=):
        super().__init__(n_estimators=, max_nodes=,split_after_samples=, regression=,n_classes=, n_features=, metric=,log_dir=, global_step=, session=,graph=, name=)
    def predict():
        sc = super()
        return np.argmax(sc.predict(), axis=)
    def predict_proba():
        sc = super()
        return sc.predict()
    def predict_log_proba():
        return np.log(self.predict_proba())
class RandomForestRegressor():
    def __init__(self, n_estimators=, max_nodes=,split_after_samples=, n_features=, num_output=,metric=, log_dir=, global_step=,session=, graph=, name=):
        super().__init__(n_estimators=, max_nodes=,split_after_samples=, regression=,n_classes=, n_features=, metric=,log_dir=, global_step=, session=,graph=, name=)
from __future__ import division, print_function, absolute_import
from datetime import datetime
import os
import math
import numpy as np
import time
import tensorflow.compat.v1 as tf
from tensorflow.contrib.factorization.python.ops import clustering_ops as c_ops
from tensorflow.contrib.tensor_forest.python.ops import data_ops
from tensorflow.python.ops import state_ops, array_ops, math_ops
from ...utils import validate_dim, read_tensor_in_checkpoint, prepare_X
from ...data_utils import get_num_features, get_num_sample
from ...data_flow import generate_data_tensor
from ...distances import euclidean, cosine
from ..base import BaseEstimator
class KMeansBase():
    def __init__(self, n_clusters, max_iter=, init=,distance=,metric=, num_features=, log_dir=,global_step=, session=, graph=, name=):
        super().__init__(metric=, log_dir=, global_step=,session=, graph=, name=)
        self._estimator_built =
        self.n_clusters =
        self.max_iter =
        self.init =
        self.distance =
        self.num_features =
        self.use_mini_batch =
    def _build_estimator(self, X=):
        if not self._estimator_built:
            if self.num_features is None:
                self.num_features = get_num_features()
            if self._to_be_restored and self.num_features is None:
                self.num_features = read_tensor_in_checkpoint()
            if self._to_be_restored and self.num_classes is None:
                self.num_classes = read_tensor_in_checkpoint()
            if self.num_features is None:
                raise ValueError()
            tf.Variable(self.num_features, dtype=, name=)
            self._kmeans = c_ops.KMeans(X, self.n_clusters,initial_clusters=,distance_metric=,use_mini_batch=)
            () = self._kmeans.training_graph()
            self._cluster_idx = self._cluster_idx[]
            self.avg_distance = tf.reduce_mean()
            self._estimator_built =
            self._init_graph()
    def cluster_centers_vars():
        if self._estimator_built:
            return self.session.run()
        else:
            return None
    def cluster_idx():
        if self._estimator_built:
            return self.session.run()
        else:
            return None
    def scores():
        if self._estimator_built:
            return self.session.run()
        else:
            return None
    def all_scores():
        if self._estimator_built:
            return self.session.run()
        else:
            return None
    def cluster_centers_():
        return self.cluster_centers_vars
    def labels_():
        return self.cluster_idx
    def distances_():
        return self.session.run()
    def all_distances_():
        return self.session.run()
    def _init_graph():
        super()._init_graph()
        self.session.run()
    def fit(self, X, shuffle=, display_step=,n_jobs=, max_steps=, verbose=, **kwargs):
        with self.graph.as_default():
            validate_dim(X, max_dim=, min_dim=, var_name=)
            num_samples = get_num_sample()
            if "" in kwargs.keys():
                batch_size = kwargs[]
            else:
                batch_size =
            self._build_estimator()
            if self._train.get_params() != hex(id()) or self._train.get_params() != batch_size or not self._train.is_ready:
                X, _, cr = generate_data_tensor(X, X, batch_size=,shuffle=,num_threads=)
                X, _, spec = data_ops.ParseDataTensorOrDict()
                self._train_op = tf.group(self._train_op,state_ops.assign_add())
                self._loss_op =
                self._build_fit()
                tf.train.start_queue_runners(sess=)
                if cr: cr.launch_threads()
            gstep = self.global_step.eval(session=)
            last_loss = []
            loss_val =
            step =
            while True:
                if loss_val: last_loss.append()
                if len() > 10: last_loss.pop()
                start_time = time.time()
                if () % display_step == 0:
                    _, loss_val, idx = self.session.run([])
                else:
                    _, loss_val, idx = self.session.run([])
                duration = time.time() - start_time
                if () % display_step == 0:
                    examples_per_sec =
                    sec_per_batch =
                    if self.metric:
                        format_str = 
                    else:
                        format_str = 
                step +=
                if len() == 10 and np.var() <= 0.01 and not max_steps:
                    break
                if max_steps:
                    if step == max_steps:
                        break
    def predict(self, X, with_distances=):
        X, orig_ndim = prepare_X(X, 2, max_dim=, min_dim=, debug_msg=)
        with self.graph.as_default():
            self._build_estimator()
            if not self._pred.is_ready:
                input = tf.placeholder(tf.float32, name=,shape=[])
                output = c_ops.nearest_neighbors(input, self._cluster_centers_vars, k=)
                self._build_pred()
            indices, distances = self.session.run(self._pred.output_tensor,feed_dict={self._pred.input_tensor:})
            indices = indices[]
            distances = distances[]
            if orig_ndim == 1:
                indices = indices[]
                distances = distances[]
            if with_distances:
                return indices, distances
            return indices
    def transform():
        X, orig_ndim = prepare_X(X, 2, max_dim=, min_dim=, debug_msg=)
        with self.graph.as_default():
            self._build_estimator()
            if not self._transform.is_ready:
                input = tf.placeholder(tf.float32, name=,shape=[])
                centers =
                centers = tf.reshape(centers, shape=[])
                if self.distance == c_ops.SQUARED_EUCLIDEAN_DISTANCE:
                    dist_fn =
                elif self.distance == c_ops.COSINE_DISTANCE:
                    dist_fn =
                else:
                    raise Exception()
                output = tf.map_fn(lambda x: tf.map_fn(lambda y: dist_fn(),centers),input)
                self._build_transform()
            distances = self.session.run(self._transform.output_tensor,feed_dict={self._transform.input_tensor:})
            if orig_ndim == 1:
                distances = distances[]
            return distances
    def save():
        if not self._estimator_built:
            with self.graph.as_default():
                self._build_estimator()
        self.saver.save(self.session, os.path.abspath())
    def load():
        with self.graph.as_default():
            self.session = tf.Session()
            if self._estimator_built:
                self.saver.restore(self.session, os.path.abspath())
            else:
                self._to_be_restored = os.path.abspath()
class KMeans():
    def __init__(self, n_clusters, max_iter=, init=,distance=,metric=, num_features=, log_dir=,global_step=, session=, graph=, name=):
        super().__init__(n_clusters, max_iter=, init=, distance=,metric=, num_features=, log_dir=,global_step=, session=, graph=,name=)
    def fit(self, X, shuffle=, display_step=, n_jobs=,max_steps=):
        super().fit(X, shuffle=, display_step=,n_jobs=, max_steps=)
class MiniBatchKMeans():
    def __init__(self, n_clusters, max_iter=, init=,distance=,metric=, num_features=, log_dir=,global_step=, session=, graph=, name=):
        super().__init__(n_clusters, max_iter=, init=, distance=,metric=, num_features=, log_dir=,global_step=, session=, graph=,name=)
        self.use_mini_batch =
    def fit(self, X, batch_size=, shuffle=, display_step=,n_jobs=, max_steps=):
        super().fit(X, shuffle=, display_step=,n_jobs=, max_steps=,batch_size=)
from __future__ import print_function
import tensorflow.compat.v1 as tf
import tflearn
import tflearn.datasets.mnist as mnist
mnist_data = mnist.read_data_sets(one_hot=)
with tf.Graph().as_default():
    X = tf.placeholder(shape=(), dtype=)
    Y = tf.placeholder(shape=(), dtype=)
    net = tf.reshape(X, [])
    net = tflearn.conv_2d(net, 32, 3, activation=)
    net = tflearn.max_pool_2d()
    net = tflearn.local_response_normalization()
    net = tflearn.dropout()
    net = tflearn.conv_2d(net, 64, 3, activation=)
    net = tflearn.max_pool_2d()
    net = tflearn.local_response_normalization()
    net = tflearn.dropout()
    net = tflearn.fully_connected(net, 128, activation=)
    net = tflearn.dropout()
    net = tflearn.fully_connected(net, 256, activation=)
    net = tflearn.dropout()
    net = tflearn.fully_connected(net, 10, activation=)
    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=, labels=))
    optimizer = tf.train.AdamOptimizer(learning_rate=).minimize()
    init = tf.global_variables_initializer()
    with tf.Session() as sess:
        sess.run()
        batch_size =
        for epoch in range():
            avg_cost =
            total_batch = int()
            for i in range():
                batch_xs, batch_ys = mnist_data.train.next_batch()
                sess.run(optimizer, feed_dict={X:, Y:})
                cost = sess.run(loss, feed_dict={X:, Y:})
                avg_cost +=
                if i % 20 == 0:
from __future__ import division, print_function, absolute_import
import re
import os
import numpy as np
import tensorflow.compat.v1 as tf
from tensorflow.python.training import optimizer as tf_optimizer
import tflearn
from .. import callbacks as tf_callbacks
from ..config import init_training_mode
from ..utils import to_list, id_generator, check_dir_name, standarize_dict, get_dict_first_element, make_batches, slice_array, check_scope_path, check_restore_tensor
from .. import data_flow
from .. import variables
from .. import utils
from .summarizer import summaries, summarize, summarize_gradients, summarize_variables, summarize_activations
try:
    writer_summary =
    merge_summary =
except Exception:
    writer_summary =
    merge_summary =
class Trainer():
    def __init__(self, train_ops, graph=, clip_gradients=,tensorboard_dir=,tensorboard_verbose=, checkpoint_path=, best_checkpoint_path=,max_checkpoints=,keep_checkpoint_every_n_hours=, random_seed=,session=, best_val_accuracy=):
        self.graph = tf.get_default_graph()
        self.summ_writer =
        if graph:
            self.graph =
        with self.graph.as_default():
            init_training_mode()
            train_ops = to_list()
            duplicate_identical_ops()
            if random_seed:
                tf.set_random_seed()
            self.restored =
            self.tensorboard_dir = check_dir_name()
            self.training_state = TrainingState()
            self.train_ops = to_list()
            self.validate_trainop_names()
            self.global_step = tf.Variable(0., name=,trainable=)
            self.incr_global_step = tf.assign(self.global_step,tf.add())
            self.best_val_accuracy =
            self.best_checkpoint_path =
            config =
            tflearn_conf = tf.get_collection()
            if tflearn_conf:
                config = tflearn_conf[]
            if not session:
                self.session = tf.Session(config=)
            else:
                self.session =
                self.restored =
            self.coord = tf.train.Coordinator()
            for i, train_op in enumerate():
                if len() == 1:
                    train_op.scope_name =
                train_op.initialize_training_ops()
            self.saver = tf.train.Saver(max_to_keep=,keep_checkpoint_every_n_hours=,allow_empty=)
            if self.best_checkpoint_path:
                self.val_saver = tf.train.Saver(max_to_keep=,keep_checkpoint_every_n_hours=,allow_empty=)
            all_vars = variables.get_all_variables()
            excl_vars = tf.get_collection()
            to_restore = [item for item in all_varsif check_restore_tensor()]
            self.restorer = tf.train.Saver(var_list=,max_to_keep=,keep_checkpoint_every_n_hours=,allow_empty=)
            to_restore_trainvars = [item for item in tf.trainable_variables()if check_restore_tensor()]
            self.restorer_trainvars = tf.train.Saver(var_list=,max_to_keep=,keep_checkpoint_every_n_hours=,allow_empty=)
            self.to_restore =
            self.to_restore_trainvars =
            self.checkpoint_path =
            if not self.restored:
                try:
                    init = tf.group(tf.global_variables_initializer(),tf.local_variables_initializer())
                    self.session.run(tf.variables_initializer(tf.get_collection_ref()))
                except Exception as e:
                    init = tf.initialize_all_variables()
                self.session.run()
    def fit(self, feed_dicts, n_epoch=, val_feed_dicts=, show_metric=,snapshot_step=, snapshot_epoch=, shuffle_all=,dprep_dict=, daug_dict=, excl_trainops=, run_id=,callbacks=[]):
        if not run_id:
            run_id = id_generator()
        original_train_ops = list()
        if excl_trainops:
            self.train_ops = list(filter(lambda a:, self.train_ops))
        if isinstance():
            for t in self.train_ops: t.shuffle =
        with self.graph.as_default():
            obj_lists = utils.fix_saver()
            if self.summ_writer:
                try:
                    self.summ_writer.reopen()
                except:
                    self.summ_writer = writer_summary()
            else:
                try:
                    self.summ_writer = writer_summary()
                except Exception:
                    self.summ_writer = writer_summary()
            utils.fix_saver()
            feed_dicts = to_list()
            for d in feed_dicts: standarize_dict()
            val_feed_dicts = to_list()
            if val_feed_dicts:
                [standarize_dict() for d in val_feed_dicts if notisinstance()]
            termlogger = tf_callbacks.TermLogger()
            modelsaver = tf_callbacks.ModelSaver()
            for i, train_op in enumerate():
                vd = val_feed_dicts[] if val_feed_dicts else None
                train_op.initialize_fit(feed_dicts[], vd, dprep_dict,daug_dict, show_metric,self.summ_writer, self.coord)
                metric_term_name =
                if train_op.metric is not None:
                    if hasattr():
                        metric_term_name =
                    else:
                        metric_term_name = train_op.metric.name.split(':)[]
                termlogger.add(train_op.n_train_samples,val_size=,metric_name=,name=)
            max_batches_len = np.max([])
            caller = tf_callbacks.ChainCallback(callbacks=[])
            callbacks = to_list()
            if callbacks:
                [caller.add() for cb in callbacks]
            caller.on_train_begin()
            train_ops_count = len()
            snapshot =
            try:
                for epoch in range():
                    self.training_state.increaseEpoch()
                    caller.on_epoch_begin()
                    for batch_step in range():
                        self.training_state.increaseStep()
                        self.training_state.resetGlobal()
                        caller.on_batch_begin()
                        for i, train_op in enumerate():
                            caller.on_sub_batch_begin()
                            snapshot = train_op._train(self.training_state.step,(bool() | snapshot_epoch),snapshot_step,show_metric)
                            self.training_state.update()
                            caller.on_sub_batch_end()
                        self.session.run()
                        caller.on_batch_end()
                    caller.on_epoch_end()
            finally:
                caller.on_train_end()
                for t in self.train_ops:
                    t.train_dflow.interrupt()
                self.train_ops =
        self.summ_writer.close()
    def fit_batch(self, feed_dicts, dprep_dict=, daug_dict=):
        feed_dicts = to_list()
        for d in feed_dicts: standarize_dict()
        val_loss = []
        for train_op in self.train_ops:
            if daug_dict:
                for k in daug_dict:
                    feed_dicts[] = daug_dict.apply(feed_dicts[])
            if dprep_dict:
                for k in dprep_dict:
                    feed_dicts[] = dprep_dict.apply(feed_dicts[])
        for d in feed_dicts:
            val_loss.append(train_op._train_batch())
        if len() == 1: val_loss = val_loss[]
        return val_loss
    def save(self, model_file, global_step=, use_val_saver=):
        obj_lists = utils.fix_saver()
        if not os.path.isabs():
            model_file = os.path.abspath(os.path.join(os.getcwd(), model_file))
        if use_val_saver:
            self.val_saver.save(self.session, model_file, global_step=)
        else:
            self.saver.save(self.session, model_file, global_step=)
        utils.fix_saver()
    def restore(self, model_file, trainable_variable_only=, variable_name_map=, scope_for_restore=,create_new_session=, verbose=):
        if not os.path.isabs():
            model_file = os.path.abspath(os.path.join(os.getcwd(), model_file))
        if create_new_session:
            self.close_session()
            config =
            tflearn_conf = tf.get_collection()
            if tflearn_conf:
                config = tflearn_conf[]
            self.session = tf.Session(config=)
            try:
                self.session.run([tf.global_variables_initializer(),tf.local_variables_initializer()])
            except Exception:
                self.session.run(tf.initialize_all_variables())
        if scope_for_restore is not None:
            sname =
            def vn_map_func():
                if not existing_name.startswith():
                    return None
                name_in_file = re.sub()
                if verbose:
                return name_in_file
            variable_name_map =
        if variable_name_map is not None:
            if type()==tuple:
                () =
                def vn_map_func():
                    name_in_file = re.sub()
                    if verbose:
                    return name_in_file
            else:
                vn_map_func =
            if trainable_variable_only:
                to_restore =
            else:
                to_restore =
            renamed_to_restore = {vn_map_func():}
            if None in renamed_to_restore:
                renamed_to_restore.pop()
            restorer = tf.train.Saver(var_list=)
            restorer.restore()
        elif not trainable_variable_only:
            self.restorer.restore()
        else:
            self.restorer_trainvars.restore()
        for o in self.train_ops:
            o.session =
        self.restored =
        self.training_state.step = int(self.global_step.eval())
    def close_session():
        self.session.close()
    def validate_trainop_names():
        t_len = len()
        for i in range():
            if not self.train_ops[].name:
                self.train_ops[].name =
                self.train_ops[].scope_name =
        for i in range():
            dupl =
            for j in range():
                if not self.train_ops[].name:
                    break
                if self.train_ops[].name == self.train_ops[].name:
                    if dupl == 0:
                        self.train_ops[].name += "" + str()
                        self.train_ops[].scope_name = self.train_ops[].name
                    dupl +=
                    self.train_ops[].name += "" + str()
                    self.train_ops[].scope_name = self.train_ops[].name
class TrainOp():
    def __init__(self, loss, optimizer, metric=, batch_size=, ema=,trainable_vars=, shuffle=, step_tensor=,validation_monitors=, validation_batch_size=,name=, graph=):
        self.graph = tf.get_default_graph()
        if graph:
            self.graph =
        self.name =
        self.scope_name =
        self.loss =
        self.optimizer =
        self.metric =
        self.metric_summ_name =
        if metric is not None:
            self.metric_summ_name = metric.name.split()[]
        if isinstance():
            validation_monitors = []
        self.validation_monitors = validation_monitors or []
        self.grad =
        self.apply_grad =
        self.summ_op =
        self.val_summary_op =
        self.train_vars =
        self.shuffle =
        self.batch_size =
        self.validation_batch_size =
        self.n_batches =
        self.ema =
        self.feed_dict =
        self.val_feed_dict =
        self.loss_value =
        self.val_loss =
        self.acc_value =
        self.val_acc =
        if step_tensor is None:
            with self.graph.as_default():
                self.training_steps = tf.Variable(0., name=,trainable=)
        else:
            self.training_steps =
        if not isinstance():
            raise ValueError()
        if not isinstance():
            raise ValueError()
        if self.train_vars is None:
            self.train_vars = tf.trainable_variables()
        else:
            self.train_var = to_list()
        self.train =
    def initialize_training_ops():
        self.session =
        self.val_loss_T = tf.Variable(0., name=, trainable=)
        self.val_acc_T = tf.Variable(0., name=, trainable=)
        self.validation_monitors_T = [tf.Variable(0., name="", 1)[], trainable=) for v in self.validation_monitors]
        self.val_loss_P = tf.placeholder(dtype=, name="")[])
        self.val_acc_P = tf.placeholder(dtype=, name="")[])
        self.val_monitors_P = [tf.placeholder(dtype=, name="")[]) for v in self.validation_monitors_T]
        self.val_loss_assign = tf.assign(self.val_loss_T, self.val_loss_P,name="")[])
        self.val_acc_assign = tf.assign(self.val_acc_T, self.val_acc_P,name="")[])
        self.val_monitors_assign = [tf.assign(vmt, vmp, name="", vmp inzip()]
        if self.metric is not None:
            self.acc_averages = tf.train.ExponentialMovingAverage(0.9, self.training_steps,name=)
            acc_avg_op = self.acc_averages.apply([])
        else:
            acc_avg_op = tf.no_op()
        with tf.name_scope():
            lss = [] + tf.get_collection()
            total_loss = tf.add_n(lss, name=)
            loss_avg_op = summaries.add_loss_summaries(total_loss,self.loss,regul_losses_collection_key=,name_prefix=,summaries_collection_key=,exp_moving_avg=,ema_num_updates=)
            with tf.control_dependencies([]):
                self.grad = tf.gradients()
                if clip_gradients > 0.0:
                    self.grad, self.grad_norm = tf.clip_by_global_norm()
            self.grad = list(zip())
            self.apply_grad = self.optimizer.apply_gradients(grads_and_vars=,global_step=,name="" + str())
            self.create_summaries()
            if self.ema > 0.:
                var_averages = tf.train.ExponentialMovingAverage()
                var_averages_op = var_averages.apply()
                with tf.control_dependencies([]):
                    with tf.control_dependencies([]):
                        self.train = tf.no_op(name="" + str())
            else:
                with tf.control_dependencies([]):
                    self.train = tf.no_op(name="" + str())
    def initialize_fit():
        self.summary_writer =
        self.feed_dict =
        self.val_feed_dict =
        self.n_train_samples = len(get_dict_first_element())
        self.index_array = np.arange()
        self.n_val_samples =
        if isinstance():
            split_at = int(self.n_train_samples * ())
            np.random.shuffle()
            self.val_index_array = self.index_array[split_at:]
            self.index_array = self.index_array[:]
            self.n_train_samples = len()
            self.n_val_samples = len()
            val_feed_dict =
        elif val_feed_dict is not None:
            self.val_index_array =
            self.n_val_samples = len(get_dict_first_element())
        if dprep_dict:
            for k in dprep_dict:
                dprep_dict[].initialize(feed_dict[], self.session)
        self.train_dflow = data_flow.FeedDictFlow(feed_dict, coord,continuous=,batch_size=,dprep_dict=,daug_dict=,index_array=,num_threads=,shuffle=)
        self.n_batches = len()
        self.train_dflow.start()
        if val_feed_dict:
            self.test_dflow = data_flow.FeedDictFlow(val_feed_dict, coord,batch_size=,dprep_dict=,daug_dict=,index_array=,num_threads=)
        self.create_testing_summaries()
    def _train():
        self.loss_value, self.acc_value =, None
        self.val_loss, self.val_acc =, None
        train_summ_str, test_summ_str =, None
        snapshot =
        epoch =
        feed_batch = self.train_dflow.next()
        tflearn.is_training(True, session=)
        _, train_summ_str = self.session.run([],feed_batch)
        sname =
        self.loss_value = summaries.get_value_from_summary_string()
        if show_metric and self.metric is not None:
            sname =
            self.acc_value = summaries.get_value_from_summary_string()
        if epoch != self.train_dflow.data_status.epoch:
            if snapshot_epoch:
                snapshot =
        if snapshot_step:
            if training_step % snapshot_step == 0:
                snapshot =
        if snapshot and self.val_feed_dict:
            tflearn.is_training(False, session=)
            eval_ops = [] + self.validation_monitors
            if show_metric and self.metric is not None:
                eval_ops.append()
            e = evaluate_flow()
            self.val_loss = e[]
            if show_metric and self.metric is not None:
                self.validation_monitor_values = e[1:]
                self.val_acc = e[]
            else:
                self.validation_monitor_values = e[1:]
            update_val_op = []
            update_val_feed = {self.val_loss_P:}
            if show_metric:
                update_val_op.append()
                update_val_feed[] =
            if self.validation_monitors:
                update_val_op.append()
                for vmp, vmv in zip():
                    update_val_feed[] =
            self.session.run(update_val_op, feed_dict=)
            test_summ_str = self.session.run()
        n_step = self.training_steps.eval(session=)
        if n_step > 1:
            if train_summ_str:
                self.summary_writer.add_summary()
            if test_summ_str:
                self.summary_writer.add_summary()
        return snapshot
    def _train_batch():
        tflearn.is_training(True, session=)
        _, loss, _ = self.session.run([],feed_dict=)
        tflearn.is_training(False, session=)
        return loss
    def duplicate():
        return TrainOp(self.loss, optimizer=,batch_size=, ema=,metric=,trainable_vars=,shuffle=)
    def create_summaries(self, verbose=):
        summ_collection =
        if verbose in []:
            activations = tf.get_collection()
            summarize_activations()
        if verbose in []:
            summarize_variables()
        if verbose in []:
            summarize_gradients()
        self.summ_op = merge_summary(tf.get_collection())
    def create_testing_summaries(self, show_metric=,metric_name=, validation_set=):
        tr_summ_collection =
        te_summ_collection =
        mn = metric_name.replace("")
        if show_metric and self.metric is not None:
            sname = mn + "" + self.scope_name
            summarize()
            sname =
            self.summ_op = summarize(self.acc_averages.average(),"", sname, tr_summ_collection)
        if validation_set is not None:
            loss_val_name =
            loss_val_name = check_scope_path()
            self.val_summary_op = summarize()
            if show_metric and self.metric is not None:
                acc_val_name =
                acc_val_name = check_scope_path()
                self.val_summary_op = summarize()
            if self.validation_monitors:
                for vm_op in self.validation_monitors_T:
                    vm_name =
                    vm_name = check_scope_path()
                    self.val_summary_op = summarize()
def duplicate_identical_ops():
    for i in range(len()):
        for j in range(i+1, len()):
            if ops[] == ops[]:
                ops[] = ops[].duplicate()
def get_current_batch_size():
    if hasattr():
        iterator =
    else:
        iterator =
    for k, v in iterator():
        if k.get_shape()[].value == None:
            if type() is list:
              return len()
            else:
              return int(v.shape[])
    return dataflow.batch_size
def evaluate_flow():
        if not isinstance():
            ops_to_evaluate = []
        tflearn.is_training()
        dataflow.reset()
        dataflow.start()
        res = []
        feed_batch = dataflow.next()
        while feed_batch:
            r = session.run()
            current_batch_size = get_current_batch_size()
            for i in range(len()):
                res[] += r[] * current_batch_size
            feed_batch = dataflow.next()
        res = []
        return res
def evaluate():
        tflearn.is_training()
        n_test_samples = len(get_dict_first_element())
        batches = make_batches()
        index_array = np.arange()
        avg =
        for i, () in enumerate():
            batch_ids = index_array[batch_start:]
            feed_batch = {}
            for key in feed_dict:
                if np.ndim(feed_dict[]) > 0:
                    feed_batch[] = slice_array(feed_dict[], batch_ids)
                else:
                    feed_batch[] = feed_dict[]
            avg += session.run() / len()
        return avg
class TrainingState():
    def __init__():
        self.epoch =
        self.step =
        self.current_iter =
        self.step_time =
        self.acc_value =
        self.loss_value =
        self.val_acc =
        self.val_loss =
        self.best_accuracy =
        self.global_acc =
        self.global_loss =
    def update(self, train_op, train_ops_count =):
        data_status =
        self.acc_value =
        self.loss_value =
        self.val_acc =
        self.val_loss =
        self.current_iter =
        if self.val_acc is not None and self.val_acc > self.best_accuracy:
            self.best_accuracy =
        self.global_loss +=
        if self.acc_value and self.global_acc:
            self.global_acc +=
        else:
            self.global_acc =
    def increaseEpoch():
        self.epoch +=
    def increaseStep():
        self.step +=
    def resetGlobal():
        self.global_acc =
        self.global_loss =
import time
import numpy as np
import tensorflow as tf
from models import GAT
from utils import process
checkpt_file =
dataset =
batch_size =
nb_epochs =
patience =
lr =
l2_coef =
hid_units = []
n_heads = []
residual =
nonlinearity =
model =
adj, features, y_train, y_val, y_test, train_mask, val_mask, test_mask = process.load_data()
features, spars = process.preprocess_features()
nb_nodes = features.shape[]
ft_size = features.shape[]
nb_classes = y_train.shape[]
adj = adj.todense()
features = features[]
adj = adj[]
y_train = y_train[]
y_val = y_val[]
y_test = y_test[]
train_mask = train_mask[]
val_mask = val_mask[]
test_mask = test_mask[]
biases = process.adj_to_bias(adj, [], nhood=)
with tf.Graph().as_default():
    with tf.name_scope():
        ftr_in = tf.placeholder(dtype=, shape=())
        bias_in = tf.placeholder(dtype=, shape=())
        lbl_in = tf.placeholder(dtype=, shape=())
        msk_in = tf.placeholder(dtype=, shape=())
        attn_drop = tf.placeholder(dtype=, shape=())
        ffd_drop = tf.placeholder(dtype=, shape=())
        is_train = tf.placeholder(dtype=, shape=())
    logits = model.inference(ftr_in, nb_classes, nb_nodes, is_train,attn_drop, ffd_drop,bias_mat=,hid_units=, n_heads=,residual=, activation=)
    log_resh = tf.reshape(logits, [])
    lab_resh = tf.reshape(lbl_in, [])
    msk_resh = tf.reshape(msk_in, [])
    loss = model.masked_softmax_cross_entropy()
    accuracy = model.masked_accuracy()
    train_op = model.training()
    saver = tf.train.Saver()
    init_op = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer())
    vlss_mn =
    vacc_mx =
    curr_step =
    with tf.Session() as sess:
        sess.run()
        train_loss_avg =
        train_acc_avg =
        val_loss_avg =
        val_acc_avg =
        for epoch in range():
            tr_step =
            tr_size = features.shape[]
            while tr_step * batch_size < tr_size:
                _, loss_value_tr, acc_tr = sess.run([],feed_dict={ftr_in: features[tr_step*batch_size:,bias_in: biases[tr_step*batch_size:,lbl_in: y_train[tr_step*batch_size:,msk_in: train_mask[tr_step*batch_size:,is_train:,attn_drop:, ffd_drop:})
                train_loss_avg +=
                train_acc_avg +=
                tr_step +=
            vl_step =
            vl_size = features.shape[]
            while vl_step * batch_size < vl_size:
                loss_value_vl, acc_vl = sess.run([],feed_dict={ftr_in: features[vl_step*batch_size:,bias_in: biases[vl_step*batch_size:,lbl_in: y_val[vl_step*batch_size:,msk_in: val_mask[vl_step*batch_size:,is_train:,attn_drop:, ffd_drop:})
                val_loss_avg +=
                val_acc_avg +=
                vl_step +=
            if val_acc_avg/vl_step >= vacc_mx or val_loss_avg/vl_step <= vlss_mn:
                if val_acc_avg/vl_step >= vacc_mx and val_loss_avg/vl_step <= vlss_mn:
                    vacc_early_model =
                    vlss_early_model =
                    saver.save()
                vacc_mx = np.max(())
                vlss_mn = np.min(())
                curr_step =
            else:
                curr_step +=
                if curr_step == patience:
                    break
            train_loss_avg =
            train_acc_avg =
            val_loss_avg =
            val_acc_avg =
        saver.restore()
        ts_size = features.shape[]
        ts_step =
        ts_loss =
        ts_acc =
        while ts_step * batch_size < ts_size:
            loss_value_ts, acc_ts = sess.run([],feed_dict={ftr_in: features[ts_step*batch_size:,bias_in: biases[ts_step*batch_size:,lbl_in: y_test[ts_step*batch_size:,msk_in: test_mask[ts_step*batch_size:,is_train:,attn_drop:, ffd_drop:})
            ts_loss +=
            ts_acc +=
            ts_step +=
        sess.close()
import time
import scipy.sparse as sp
import numpy as np
import tensorflow as tf
import argparse
from models import GAT
from models import SpGAT
from utils import process
checkpt_file =
dataset =
batch_size =
nb_epochs =
patience =
lr =
l2_coef =
hid_units = []
n_heads = []
residual =
nonlinearity =
model =
sparse =
adj, features, y_train, y_val, y_test, train_mask, val_mask, test_mask = process.load_data()
features, spars = process.preprocess_features()
nb_nodes = features.shape[]
ft_size = features.shape[]
nb_classes = y_train.shape[]
features = features[]
y_train = y_train[]
y_val = y_val[]
y_test = y_test[]
train_mask = train_mask[]
val_mask = val_mask[]
test_mask = test_mask[]
if sparse:
    biases = process.preprocess_adj_bias()
else:
    adj = adj.todense()
    adj = adj[]
    biases = process.adj_to_bias(adj, [], nhood=)
with tf.Graph().as_default():
    with tf.name_scope():
        ftr_in = tf.placeholder(dtype=, shape=())
        if sparse:
            bias_in = tf.sparse_placeholder(dtype=)
        else:
            bias_in = tf.placeholder(dtype=, shape=())
        lbl_in = tf.placeholder(dtype=, shape=())
        msk_in = tf.placeholder(dtype=, shape=())
        attn_drop = tf.placeholder(dtype=, shape=())
        ffd_drop = tf.placeholder(dtype=, shape=())
        is_train = tf.placeholder(dtype=, shape=())
    logits = model.inference(ftr_in, nb_classes, nb_nodes, is_train,attn_drop, ffd_drop,bias_mat=,hid_units=, n_heads=,residual=, activation=)
    log_resh = tf.reshape(logits, [])
    lab_resh = tf.reshape(lbl_in, [])
    msk_resh = tf.reshape(msk_in, [])
    loss = model.masked_softmax_cross_entropy()
    accuracy = model.masked_accuracy()
    train_op = model.training()
    saver = tf.train.Saver()
    init_op = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer())
    vlss_mn =
    vacc_mx =
    curr_step =
    with tf.Session() as sess:
        sess.run()
        train_loss_avg =
        train_acc_avg =
        val_loss_avg =
        val_acc_avg =
        for epoch in range():
            tr_step =
            tr_size = features.shape[]
            while tr_step * batch_size < tr_size:
                if sparse:
                    bbias =
                else:
                    bbias = biases[tr_step*batch_size:()*batch_size]
                _, loss_value_tr, acc_tr = sess.run([],feed_dict={ftr_in: features[tr_step*batch_size:,bias_in:,lbl_in: y_train[tr_step*batch_size:,msk_in: train_mask[tr_step*batch_size:,is_train:,attn_drop:, ffd_drop:})
                train_loss_avg +=
                train_acc_avg +=
                tr_step +=
            vl_step =
            vl_size = features.shape[]
            while vl_step * batch_size < vl_size:
                if sparse:
                    bbias =
                else:
                    bbias = biases[vl_step*batch_size:()*batch_size]
                loss_value_vl, acc_vl = sess.run([],feed_dict={ftr_in: features[vl_step*batch_size:,bias_in:,lbl_in: y_val[vl_step*batch_size:,msk_in: val_mask[vl_step*batch_size:,is_train:,attn_drop:, ffd_drop:})
                val_loss_avg +=
                val_acc_avg +=
                vl_step +=
            if val_acc_avg/vl_step >= vacc_mx or val_loss_avg/vl_step <= vlss_mn:
                if val_acc_avg/vl_step >= vacc_mx and val_loss_avg/vl_step <= vlss_mn:
                    vacc_early_model =
                    vlss_early_model =
                    saver.save()
                vacc_mx = np.max(())
                vlss_mn = np.min(())
                curr_step =
            else:
                curr_step +=
                if curr_step == patience:
                    break
            train_loss_avg =
            train_acc_avg =
            val_loss_avg =
            val_acc_avg =
        saver.restore()
        ts_size = features.shape[]
        ts_step =
        ts_loss =
        ts_acc =
        while ts_step * batch_size < ts_size:
            if sparse:
                bbias =
            else:
                bbias = biases[ts_step*batch_size:()*batch_size]
            loss_value_ts, acc_ts = sess.run([],feed_dict={ftr_in: features[ts_step*batch_size:,bias_in:,lbl_in: y_test[ts_step*batch_size:,msk_in: test_mask[ts_step*batch_size:,is_train:,attn_drop:, ffd_drop:})
            ts_loss +=
            ts_acc +=
            ts_step +=
        sess.close()
from __future__ import absolute_import
from __future__ import division
from __future__ import print_function
import logging
import random
import time
import numpy as np
import six
import tensorflow as tf
from tensorflow_fold.public import loom
tf.flags.DEFINE_integer()
tf.flags.DEFINE_integer()
tf.flags.DEFINE_integer()
tf.flags.DEFINE_integer()
tf.flags.DEFINE_boolean()
tf.flags.DEFINE_string()
tf.flags.DEFINE_boolean()
tf.flags.DEFINE_boolean()
tf.flags.DEFINE_boolean()
tf.flags.DEFINE_boolean()
tf.flags.DEFINE_boolean()
FLAGS =
logging.basicConfig()
_logger = logging.getLogger()
_logger.setLevel()
def make_random_tree():
  if size <= 1:
    return 0
  r = random.randint()
  return (make_random_tree(), make_random_tree())
def make_sequence_tree():
  if size <= 1:
    return 0
  return (make_sequence_tree(), 0)
def make_balanced_tree():
  if size <= 1:
    return 0
  return (make_balanced_tree(), make_balanced_tree())
def make_input_tree():
  if FLAGS.tree_type == "":
    return make_sequence_tree()
  elif FLAGS.tree_type == "":
    return make_balanced_tree()
  elif FLAGS.tree_type == "":
    return make_random_tree()
  raise ValueError()
def index_type():
  return loom.TypeShape("", ())
def vector_type():
  return loom.TypeShape("", ())
class LeafOp():
  def __init__():
    super().__init__([index_type()],[vector_type()])
    self._embedding_size =
    self._embedding =
    self._vscope =
  def instantiate_batch():
    return [self()]
  def __call__():
    if self._embedding is None:
      with tf.variable_scope():
        self._embedding = (tf.get_variable("",[],initializer=tf.random_uniform_initializer()))
    return tf.gather()
class NonTerminalOp():
  def __init__():
    super().__init__([vector_type(), vector_type()],[vector_type()])
    self._weights =
    self._bias =
    self._vscope =
  def instantiate_batch():
    return [self()]
  def tree_fc():
    if self._weights is None:
      with tf.variable_scope():
        self._weights = tf.get_variable("", [],initializer=tf.uniform_unit_scaling_initializer())
        self._bias = tf.get_variable("", [],initializer=tf.zeros_initializer())
    x = tf.concat([], 1)
    result = tf.add(tf.matmul(), self._bias)
    return tf.nn.relu()
  def tree_lstm():
    if self._weights is None:
      with tf.variable_scope():
        self._weights_0 = tf.get_variable("", [],initializer=tf.uniform_unit_scaling_initializer())
        self._bias_0 = tf.get_variable("", [],initializer=tf.zeros_initializer())
        self._weights = tf.get_variable("", [],initializer=tf.uniform_unit_scaling_initializer())
        self._bias = tf.get_variable("", [],initializer=tf.zeros_initializer())
    x = tf.concat([], 1)
    h0 = tf.nn.relu(tf.add(tf.matmul(), self._bias_0))
    h1 = tf.add(tf.matmul(), self._bias)
    () = tf.split(h1, 4, axis=)
    fl = tf.nn.sigmoid()
    fr = tf.nn.sigmoid()
    i = tf.nn.sigmoid()
    g = tf.nn.tanh()
    ylr = tf.add(tf.multiply(), tf.multiply())
    ygi = tf.multiply()
    y = tf.add()
    return y
  def __call__():
    if FLAGS.tree_lstm:
      return self.tree_lstm()
    else:
      return self.tree_fc()
class ModelBase():
  def __init__():
    self._embedding_size =
    self.batch_size =
    self._leaf_op = LeafOp()
    self._non_terminal_op = NonTerminalOp()
    self.elapsed_times = []
    self.elapsed_fd_times = []
  def random_index():
    return random.randint()
  def name():
    return ""
  def build_model():
    pass
  def build_model_loss():
    self.build_model()
    if FLAGS.train_with_loss:
      self._loss = tf.nn.l2_loss()
      optr = tf.train.GradientDescentOptimizer()
      self._train = optr.minimize()
    else:
      self._loss = tf.reduce_sum()
      self._train = tf.constant()
  def build_feed_dict():
    return {}
  def evaluate():
    for i in six.moves.xrange():
      fd = self.build_feed_dict()
      sess.run([], feed_dict=)
    batch_size =
    if batch_size < 32:
      num_batches = int() * FLAGS.num_repeats
    else:
      num_batches =
    for batch in six.moves.xrange():
      start_time_fd = time.time()
      fd = self.build_feed_dict()
      end_time_fd = time.time()
      elapsed_fd =
      self.elapsed_fd_times.append()
      start_time = time.time()
      [] = sess.run([], feed_dict=)
      end_time = time.time()
      elapsed =
      self.elapsed_times.append()
  def run():
    with tf.Graph().as_default():
      self.build_model_loss()
      config = tf.ConfigProto(log_device_placement=)
      with tf.Session(config=) as sess:
        sess.run(tf.global_variables_initializer())
        self.evaluate()
class TfModel():
  def __init__():
    super().__init__()
    self._placeholders = []
  def name():
    return ""
  def build_model():
    tree = make_input_tree()
    self._output = self.build_graph()
  def build_graph():
    if isinstance():
      left = self.build_graph(root[])
      right = self.build_graph(root[])
      return self._non_terminal_op()
    else:
      indices = tf.placeholder(dtype=, shape=[])
      self._placeholders.append()
      return self._leaf_op()
  def build_feed_dict():
    def rand_indices():
      return np.array([self.random_index() for _ in six.moves.xrange()],dtype=)
    return {p:}
class LoomModel():
  def __init__():
    super().__init__()
    self._proper_batching =
  def name():
    return ""
  def build_model():
    named_tensors = {}
    named_ops = {"leaf":,"non_terminal":}
    self._tree = make_input_tree()
    if not self._proper_batching:
    self._loom = loom.Loom(named_tensors=,named_ops=,direct_feed_dict=)
    self._output = self._loom.output_tensor(vector_type())
  def get_input_tree():
    if self._proper_batching:
      return make_input_tree()
    else:
      return self._tree
  def build_feed_dict():
    if FLAGS.serialize_and_merge:
      return self.build_feed_dict_with_serialize_and_merge()
    weaver = self._loom.make_weaver()
    for _ in six.moves.xrange():
      root = self.traverse_tree(self.get_input_tree(), weaver)
      weaver.add_output()
    if FLAGS.direct_feed_dict:
    else:
    return weaver.build_feed_dict()
  def build_feed_dict_with_serialize_and_merge():
    if FLAGS.direct_feed_dict:
      raise RuntimeError()
    serialized_trees = []
    for _ in six.moves.xrange():
      weaver = self._loom.make_weaver()
      root = self.traverse_tree(self.get_input_tree(), weaver)
      weaver.add_output()
      serialized_trees.append(weaver.serialize())
    return {self._loom.input_tensor:}
  def traverse_tree():
    if isinstance():
      left = self.traverse_tree(node[], weaver)
      right = self.traverse_tree(node[], weaver)
      return weaver.non_terminal()
    else:
      idx = weaver(np.array(self.random_index(), dtype=))
      return weaver.leaf()
def test_model():
  test_results = {}
  if FLAGS.quick_run:
    batch_size_list = []
  else:
    batch_size_list = []
  for batch_size in batch_size_list:
    test_results[] = ([], [])
    for _ in six.moves.xrange():
      model = model_class()
      model.run()
      test_results[][].extend()
      test_results[][].extend()
  return test_results
def print_results():
  def avg():
    return sum()/len()
  result_list = list(six.iteritems())
  for () in sorted(result_list, reverse=):
    () =
    tree_times = []
    tree_times_fd = []
def compare_results():
  def avg():
    return sum()/len()
  rs1 = sorted(list(six.iteritems()), reverse=)
  rs2 = sorted(list(six.iteritems()), reverse=)
  for r in zip():
    ((b, ()), (_, ())) =
def compare_total_speedup():
  def avg():
    return sum()/len()
  baseline_tree_time = avg(baseline[])
  result_list = list(six.iteritems())
  for () in sorted(result_list, reverse=):
    () =
    tree_times = []
    avg_time = avg()
def main():
  tf.logging.set_verbosity()
  tf_results = test_model()
  loom_results = test_model()
  loom_results_proper = test_model()
  if FLAGS.tree_lstm:
    model_type =
  else:
    model_type =
  compare_results()
  compare_total_speedup(loom_results, tf_results[])
if __name__ == "__main__":
  tf.app.run()
from fnc_libs import *
from keras import optimizers as op
from util import *
import random
import keras.backend as K
from keras.preprocessing import sequence
from keras.models import Sequential, Model
from keras.layers import Dense, Layer, Dropout, Activation, Input, Merge, Multiply
from keras.layers import Embedding
from keras.layers import Conv1D, GlobalMaxPooling1D
from keras.utils.np_utils import to_categorical
import numpy as np
import pandas as pd
from keras import regularizers
from utils.score import report_score, LABELS, score_submission
file_train_instances =
file_train_bodies =
file_test_instances =
file_test_bodies =
file_head =
file_body =
test_dh,test_db,test_stances = load_data()
new_test_stances = []
for i in test_stances:
    if i == "":
        new_test_stances.append()
    elif i == "":
        new_test_stances.append()
    elif i == "":
        new_test_stances.append()
    else:
        new_test_stances.append()
r = random.Random()
lim_unigram =
target_size =
hidden_size =
train_keep_prob =
l2_alpha =
learn_rate =
clip_ratio =
batch_size_train =
epochs =
reg =
raw_train = FNCData()
raw_test = FNCData()
n_train = len()
train_set, train_stances, bow_vectorizer, tfreq_vectorizer, tfidf_vectorizer = pipeline_train(raw_train, raw_test, lim_unigram=)
feature_size = len(train_set[])
test_set = pipeline_test()
model = Sequential()
model.add(Dense(500, input_dim=, activation=,kernel_regularizer=regularizers.l2()))
model.add(Dropout())
model.add(Dense(100, activation=,kernel_regularizer=regularizers.l2()))
model.add(Dropout())
model.add(Dense(4, activation=))
opt = op.Adam(lr=, beta_1=, beta_2=, epsilon=, decay=, clipvalue=)
model.compile( loss=,optimizer=,metrics=[])
Y_train = to_categorical()
Y_test = to_categorical()
train_set = np.array()
test_set = np.array()
model.fit(train_set,Y_train, batch_size=, epochs=, verbose=)
predictions = model.predict()
predictions = [i.argmax()for i in predictions]
predictions = np.array()
string_predicted = []
for i,j in enumerate():
    if j == 3:
        string_predicted.append()
    elif j == 0:
        string_predicted.append()
    elif j == 1:
        string_predicted.append()
    elif j == 2:
        string_predicted.append()
report_score()
features_pl = tf.placeholder(tf.float32, [], "")
stances_pl = tf.placeholder(tf.int64, [], "")
keep_prob_pl = tf.placeholder()
batch_size = tf.shape()[]
hidden_layer = tf.nn.dropout(tf.nn.relu(tf.contrib.layers.linear()), keep_prob=)
logits_flat = tf.nn.dropout(tf.contrib.layers.linear(), keep_prob=)
logits = tf.reshape(logits_flat, [])
tf_vars = tf.trainable_variables()
l2_loss = tf.add_n([tf.nn.l2_loss() for v in tf_vars if "" not in v.name]) * l2_alpha
loss = tf.reduce_sum(tf.nn.sparse_softmax_cross_entropy_with_logits() + l2_loss)
softmaxed_logits = tf.nn.softmax()
predict = tf.arg_max()
if mode == "":
    with tf.Session() as sess:
        load_model()
        test_feed_dict = {features_pl:, keep_prob_pl:}
        test_pred = sess.run(predict, feed_dict=)
if mode == "":
    opt_func = tf.train.AdamOptimizer()
    grads, _ = tf.clip_by_global_norm(tf.gradients(), clip_ratio)
    opt_op = opt_func.apply_gradients(zip())
    with tf.Session() as sess:
        sess.run(tf.global_variables_initializer())
        for epoch in range():
            total_loss =
            indices = list(range())
            r.shuffle()
            for i in range():
                batch_indices = indices[i * batch_size_train: () * batch_size_train]
                batch_features = [train_set[] for i in batch_indices]
                batch_stances = [train_stances[] for i in batch_indices]
                batch_feed_dict = {features_pl:, stances_pl:, keep_prob_pl:}
                _, current_loss = sess.run([], feed_dict=)
                total_loss +=
        test_feed_dict = {features_pl:, keep_prob_pl:}
        test_pred = sess.run(predict, feed_dict=)
save_predictions()
import numpy as np
import tensorflow as tf
from sklearn.base import BaseEstimator, TransformerMixin
from sklearn.metrics import roc_auc_score
from time import time
from tensorflow.contrib.layers.python.layers import batch_norm as batch_norm
from yellowfin import YFOptimizer
class DeepFM():
    def __init__(self, feature_size, field_size,embedding_size=, dropout_fm=[],deep_layers=[], dropout_deep=[],deep_layers_activation=,epoch=, batch_size=,learning_rate=, optimizer_type=,batch_norm=, batch_norm_decay=,verbose=, random_seed=,use_fm=, use_deep=,loss_type=, eval_metric=,l2_reg=, greater_is_better=):
        self.feature_size =
        self.field_size =
        self.embedding_size =
        self.dropout_fm =
        self.deep_layers =
        self.dropout_deep =
        self.deep_layers_activation =
        self.use_fm =
        self.use_deep =
        self.l2_reg =
        self.epoch =
        self.batch_size =
        self.learning_rate =
        self.optimizer_type =
        self.batch_norm =
        self.batch_norm_decay =
        self.verbose =
        self.random_seed =
        self.loss_type =
        self.eval_metric =
        self.greater_is_better =
        self.train_result, self.valid_result = [], []
        self._init_graph()
    def _init_graph():
        self.graph = tf.Graph()
        with self.graph.as_default():
            tf.set_random_seed()
            self.feat_index = tf.placeholder(tf.int32, shape=[],name=)
            self.feat_value = tf.placeholder(tf.float32, shape=[],name=)
            self.label = tf.placeholder(tf.float32, shape=[], name=)
            self.dropout_keep_fm = tf.placeholder(tf.float32, shape=[], name=)
            self.dropout_keep_deep = tf.placeholder(tf.float32, shape=[], name=)
            self.train_phase = tf.placeholder(tf.bool, name=)
            self.weights = self._initialize_weights()
            self.embeddings = tf.nn.embedding_lookup(self.weights[],self.feat_index)
            feat_value = tf.reshape(self.feat_value, shape=[])
            self.embeddings = tf.multiply()
            self.y_first_order = tf.nn.embedding_lookup(self.weights[], self.feat_index)
            self.y_first_order = tf.reduce_sum(tf.multiply(), 2)
            self.y_first_order = tf.nn.dropout(self.y_first_order, self.dropout_keep_fm[])
            self.summed_features_emb = tf.reduce_sum()
            self.summed_features_emb_square = tf.square()
            self.squared_features_emb = tf.square()
            self.squared_sum_features_emb = tf.reduce_sum()
            self.y_second_order = 0.5 * tf.subtract()
            self.y_second_order = tf.nn.dropout(self.y_second_order, self.dropout_keep_fm[])
            self.y_deep = tf.reshape(self.embeddings, shape=[])
            self.y_deep = tf.nn.dropout(self.y_deep, self.dropout_keep_deep[])
            for i in range(0, len()):
                self.y_deep = tf.add(tf.matmul(self.y_deep, self.weights[]), self.weights[])
                if self.batch_norm:
                    self.y_deep = self.batch_norm_layer(self.y_deep, train_phase=, scope_bn=)
                self.y_deep = self.deep_layers_activation()
                self.y_deep = tf.nn.dropout(self.y_deep, self.dropout_keep_deep[])
            if self.use_fm and self.use_deep:
                concat_input = tf.concat([], axis=)
            elif self.use_fm:
                concat_input = tf.concat([], axis=)
            elif self.use_deep:
                concat_input =
            self.out = tf.add(tf.matmul(concat_input, self.weights[]), self.weights[])
            if self.loss_type == "":
                self.out = tf.nn.sigmoid()
                self.loss = tf.losses.log_loss()
            elif self.loss_type == "":
                self.loss = tf.nn.l2_loss(tf.subtract())
            if self.l2_reg > 0:
                self.loss += tf.contrib.layers.l2_regularizer()(self.weights[])
                if self.use_deep:
                    for i in range(len()):
                        self.loss += tf.contrib.layers.l2_regularizer()(self.weights[])
            if self.optimizer_type == "":
                self.optimizer = tf.train.AdamOptimizer(learning_rate=, beta1=, beta2=,epsilon=).minimize()
            elif self.optimizer_type == "":
                self.optimizer = tf.train.AdagradOptimizer(learning_rate=,initial_accumulator_value=).minimize()
            elif self.optimizer_type == "":
                self.optimizer = tf.train.GradientDescentOptimizer(learning_rate=).minimize()
            elif self.optimizer_type == "":
                self.optimizer = tf.train.MomentumOptimizer(learning_rate=, momentum=).minimize()
            elif self.optimizer_type == "":
                self.optimizer = YFOptimizer(learning_rate=, momentum=).minimize()
            self.saver = tf.train.Saver()
            init = tf.global_variables_initializer()
            self.sess = self._init_session()
            self.sess.run()
            total_parameters =
            for variable in self.weights.values():
                shape = variable.get_shape()
                variable_parameters =
                for dim in shape:
                    variable_parameters *=
                total_parameters +=
            if self.verbose > 0:
    def _init_session():
        config = tf.ConfigProto(device_count={"gpu":})
        config.gpu_options.allow_growth =
        return tf.Session(config=)
    def _initialize_weights():
        weights = dict()
        weights[] = tf.Variable(tf.random_normal([], 0.0, 0.01),name=)
        weights[] = tf.Variable(tf.random_uniform([], 0.0, 1.0), name=)
        num_layer = len()
        input_size =
        glorot = np.sqrt(2.0 / (input_size + self.deep_layers[]))
        weights[] = tf.Variable(np.random.normal(loc=, scale=, size=(input_size, self.deep_layers[])), dtype=)
        weights[] = tf.Variable(np.random.normal(loc=, scale=, size=(1, self.deep_layers[])),dtype=)
        for i in range():
            glorot = np.sqrt(2.0 / (self.deep_layers[] + self.deep_layers[]))
            weights[] = tf.Variable(np.random.normal(loc=, scale=, size=(self.deep_layers[], self.deep_layers[])),dtype=)
            weights[] = tf.Variable(np.random.normal(loc=, scale=, size=(1, self.deep_layers[])),dtype=)
        if self.use_fm and self.use_deep:
            input_size = self.field_size + self.embedding_size + self.deep_layers[]
        elif self.use_fm:
            input_size =
        elif self.use_deep:
            input_size = self.deep_layers[]
        glorot = np.sqrt(2.0 / ())
        weights[] = tf.Variable(np.random.normal(loc=, scale=, size=()),dtype=)
        weights[] = tf.Variable(tf.constant(), dtype=)
        return weights
    def batch_norm_layer():
        bn_train = batch_norm(x, decay=, center=, scale=, updates_collections=,is_training=, reuse=, trainable=, scope=)
        bn_inference = batch_norm(x, decay=, center=, scale=, updates_collections=,is_training=, reuse=, trainable=, scope=)
        z = tf.cond(train_phase, lambda:, lambda:)
        return z
    def get_batch():
        start =
        end = () * batch_size
        end = end if end < len() else len()
        return Xi[start:], Xv[start:], [[] for y_ in y[start:]]
    def shuffle_in_unison_scary():
        rng_state = np.random.get_state()
        np.random.shuffle()
        np.random.set_state()
        np.random.shuffle()
        np.random.set_state()
        np.random.shuffle()
    def fit_on_batch():
        feed_dict = {self.feat_index:,self.feat_value:,self.label:,self.dropout_keep_fm:,self.dropout_keep_deep:,self.train_phase:}
        loss, opt = self.sess.run((), feed_dict=)
        return loss
    def fit(self, Xi_train, Xv_train, y_train,Xi_valid=, Xv_valid=, y_valid=,early_stopping=, refit=):
        has_valid =
        for epoch in range():
            t1 = time()
            self.shuffle_in_unison_scary()
            total_batch = int(len() / self.batch_size)
            for i in range():
                Xi_batch, Xv_batch, y_batch = self.get_batch()
                self.fit_on_batch()
            train_result = self.evaluate()
            self.train_result.append()
            if has_valid:
                valid_result = self.evaluate()
                self.valid_result.append()
            if self.verbose > 0 and epoch % self.verbose == 0:
                if has_valid:
                else:
            if has_valid and early_stopping and self.training_termination():
                break
        if has_valid and refit:
            if self.greater_is_better:
                best_valid_score = max()
            else:
                best_valid_score = min()
            best_epoch = self.valid_result.index()
            best_train_score = self.train_result[]
            Xi_train =
            Xv_train =
            y_train =
            for epoch in range():
                self.shuffle_in_unison_scary()
                total_batch = int(len() / self.batch_size)
                for i in range():
                    Xi_batch, Xv_batch, y_batch = self.get_batch()
                    self.fit_on_batch()
                train_result = self.evaluate()
                if abs() < 0.001 or () or (() and train_result < best_train_score):
                    break
    def training_termination():
        if len() > 5:
            if self.greater_is_better:
                if valid_result[] < valid_result[] and valid_result[] < valid_result[] and valid_result[] < valid_result[] and valid_result[] < valid_result[]:
                    return True
            else:
                if valid_result[] > valid_result[] and valid_result[] > valid_result[] and valid_result[] > valid_result[] and valid_result[] > valid_result[]:
                    return True
        return False
    def predict():
        dummy_y = [] * len()
        batch_index =
        Xi_batch, Xv_batch, y_batch = self.get_batch()
        y_pred =
        while len() > 0:
            num_batch = len()
            feed_dict = {self.feat_index:,self.feat_value:,self.label:,self.dropout_keep_fm:,self.dropout_keep_deep:,self.train_phase:}
            batch_out = self.sess.run(self.out, feed_dict=)
            if batch_index == 0:
                y_pred = np.reshape(batch_out, ())
            else:
                y_pred = np.concatenate((y_pred, np.reshape(batch_out, ())))
            batch_index +=
            Xi_batch, Xv_batch, y_batch = self.get_batch()
        return y_pred
    def evaluate():
        y_pred = self.predict()
        return self.eval_metric()
import os
import sys
import time
import importlib
from io import open
import numpy as np
import tensorflow as tf
import tensorflow_probability as tfp
import texar.tf as tx
tfd =
flags =
flags.DEFINE_string()
flags.DEFINE_string()
flags.DEFINE_string()
flags.DEFINE_string()
FLAGS =
config = importlib.import_module()
def kl_dvg():
    kl_cost = -0.5 * (logvars - tf.square() -tf.exp() + 1.0)
    kl_cost = tf.reduce_mean()
    return tf.reduce_sum()
def _main():
    train_data = tx.data.MonoTextData()
    val_data = tx.data.MonoTextData()
    test_data = tx.data.MonoTextData()
    iterator = tx.data.TrainTestDataIterator(train=,val=,test=)
    data_batch = iterator.get_next()
    opt_vars = {'learning_rate':,'best_valid_nll':,'steps_not_improved':,'kl_weight':}
    decay_cnt =
    max_decay = config.lr_decay_hparams[]
    decay_factor = config.lr_decay_hparams[]
    decay_ts = config.lr_decay_hparams[]
    save_dir =
    if not os.path.exists():
        os.makedirs()
    suffix = ""
    save_path = os.path.join()
    anneal_r = 1.0 / (config.kl_anneal_hparams[] *(train_data.dataset_size() / config.batch_size))
    encoder_w_embedder = tx.modules.WordEmbedder(vocab_size=, hparams=)
    input_embed = encoder_w_embedder(data_batch[])
    encoder = tx.modules.UnidirectionalRNNEncoder(hparams={"rnn_cell":})
    decoder_w_embedder = tx.modules.WordEmbedder(vocab_size=, hparams=)
    output_w_embed = decoder_w_embedder(data_batch[][:, :])
    if config.decoder_type == "":
        output_embed =
        decoder = tx.modules.BasicRNNDecoder(vocab_size=,hparams={"rnn_cell":})
        decoder_initial_state_size =
    elif config.decoder_type == "":
        decoder_p_embedder = tx.modules.SinusoidsPositionEmbedder(position_size=, hparams=)
        batch_size = tf.shape(data_batch[])[]
        max_seq_len = tf.shape(data_batch[])[] - 1
        batch_max_seq_len = tf.ones([], tf.int32) * max_seq_len
        output_p_embed = decoder_p_embedder(sequence_length=)
        output_w_embed =
        output_embed =
        decoder = tx.modules.TransformerDecoder(output_layer=tf.transpose(decoder_w_embedder.embedding, ()),hparams=)
        decoder_initial_state_size = tf.TensorShape([1, config.dec_emb_hparams[]])
    else:
        raise NotImplementedError
    connector_mlp = tx.modules.MLPTransformConnector()
    connector_stoch = tx.modules.ReparameterizedStochasticConnector()
    _, ecdr_states = encoder(input_embed,sequence_length=data_batch[])
    mean_logvar = connector_mlp()
    mean, logvar = tf.split()
    kl_loss = kl_dvg()
    dst = tfd.MultivariateNormalDiag(loc=,scale_diag=tf.exp())
    dcdr_states, latent_z = connector_stoch()
    if config.decoder_type == "":
        latent_z = tf.expand_dims(latent_z, axis=)
        latent_z = tf.tile(latent_z, [1, tf.shape()[], 1])
        output_embed = tf.concat([], axis=)
        outputs, _, _ = decoder(initial_state=,decoding_strategy=,inputs=,sequence_length=data_batch[] - 1)
    else:
        outputs = decoder(inputs=,memory=,memory_sequence_length=tf.ones(tf.shape()[]))
    logits =
    seq_lengths = data_batch[] - 1
    rc_loss = tx.losses.sequence_sparse_softmax_cross_entropy(labels=data_batch[][:, 1:],logits=,sequence_length=data_batch[] - 1)
    kl_weight = tf.placeholder(tf.float32, shape=())
    nll =
    learning_rate = tf.placeholder(dtype=, shape=(),name=)
    train_op = tx.core.get_train_op(nll, learning_rate=,hparams=)
    def _run_epoch(sess, epoch, mode_string, display=):
        if mode_string == "":
            iterator.switch_to_train_data()
        elif mode_string == "":
            iterator.switch_to_val_data()
        elif mode_string == "":
            iterator.switch_to_test_data()
        step =
        start_time = time.time()
        num_words = num_sents =
        nll_ =
        kl_loss_ = rc_loss_ =
        while True:
            try:
                fetches = {"nll":,"kl_loss":,"rc_loss":,"lengths":}
                if mode_string == "":
                    fetches[] =
                    opt_vars[] = min(1.0, opt_vars[] + anneal_r)
                    kl_weight_ = opt_vars[]
                else:
                    kl_weight_ =
                mode = (tf.estimator.ModeKeys.TRAIN if mode_string ==)
                feed = {tx.global_mode():,kl_weight:,learning_rate:}
                fetches_ = sess.run(fetches, feed_dict=)
                batch_size_ = len(fetches_[])
                num_sents +=
                num_words += sum(fetches_[])
                nll_ += fetches_[] * batch_size_
                kl_loss_ += fetches_[] * batch_size_
                rc_loss_ += fetches_[] * batch_size_
                if step % display == 0 and mode_string == 'train':
                    sys.stdout.flush()
                step +=
            except tf.errors.OutOfRangeError:
                break
        return nll_ / num_sents, np.exp()
    def _generate(sess, saver, fname=):
        if tf.train.checkpoint_exists():
            saver.restore()
        else:
            raise ValueError()
        batch_size =
        dst = tfd.MultivariateNormalDiag(loc=tf.zeros([]),scale_diag=tf.ones([]))
        dcdr_states, latent_z = connector_stoch()
        vocab =
        start_tokens = tf.ones() * vocab.bos_token_id
        end_token =
        if config.decoder_type == "":
            def _cat_embedder():
                embedding = decoder_w_embedder()
                return tf.concat([], axis=)
            outputs, _, _ = decoder(initial_state=,decoding_strategy=,embedding=,max_decoding_length=,start_tokens=,end_token=)
        else:
            def _embedding_fn():
                w_embed = decoder_w_embedder()
                p_embed = decoder_p_embedder()
                return w_embed * config.hidden_size ** 0.5 + p_embed
            outputs, _ = decoder(memory=,decoding_strategy=,memory_sequence_length=tf.ones(tf.shape()[]),embedding=,max_decoding_length=,start_tokens=,end_token=)
        sample_tokens = vocab.map_ids_to_tokens()
        sess.run(tf.tables_initializer())
        feed = {tx.global_mode():}
        sample_tokens_ = sess.run(sample_tokens, feed_dict=)
        if fname is None:
            fh =
        else:
            fh = open(fname, "", encoding=)
        for sent in sample_tokens_:
            sent = tx.utils.compat_as_text(list())
            end_id = len()
            if vocab.eos_token in sent:
                end_id = sent.index()
            fh.write("".join(sent[:]) + "")
        fh.close()
    saver = tf.train.Saver()
    with tf.Session() as sess:
        if FLAGS.mode == "":
            _generate()
            return
        sess.run(tf.global_variables_initializer())
        sess.run(tf.local_variables_initializer())
        sess.run(tf.tables_initializer())
        total_parameters =
        for variable in tf.trainable_variables():
            shape = variable.get_shape()
            variable_parameters =
            for dim in shape:
                variable_parameters *=
            total_parameters +=
        best_nll = best_ppl =
        for epoch in range():
            _, _ = _run_epoch(sess, epoch, "", display=)
            val_nll, _ = _run_epoch()
            test_nll, test_ppl = _run_epoch()
            if val_nll < opt_vars[]:
                opt_vars[] =
                opt_vars[] =
                best_nll =
                best_ppl =
                saver.save()
            else:
                opt_vars[] +=
                if opt_vars[] == decay_ts:
                    old_lr = opt_vars[]
                    opt_vars[] *=
                    opt_vars[] =
                    new_lr = opt_vars[]
                    saver.restore()
                    decay_cnt +=
                    if decay_cnt == max_decay:
                        break
if __name__ == "__main__":
    tf.app.run(main=)
from __future__ import print_function, division, absolute_import, unicode_literals
import os
import shutil
import numpy as np
from collections import OrderedDict
import logging
import tensorflow as tf
from tf_unet import util
from tf_unet.layers import ()
logging.basicConfig(level=, format="")
def create_conv_net(x, keep_prob, channels, n_class, layers=, features_root=, filter_size=, pool_size=,summaries=):
    with tf.name_scope():
        nx = tf.shape()[]
        ny = tf.shape()[]
        x_image = tf.reshape(x, tf.stack([]))
        in_node =
        batch_size = tf.shape()[]
    weights = []
    biases = []
    convs = []
    pools = OrderedDict()
    deconv = OrderedDict()
    dw_h_convs = OrderedDict()
    up_h_convs = OrderedDict()
    in_size =
    size =
    for layer in range():
        with tf.name_scope("")):
            features =
            stddev = np.sqrt(2 / ())
            if layer == 0:
                w1 = weight_variable([], stddev, name=)
            else:
                w1 = weight_variable([], stddev, name=)
            w2 = weight_variable([], stddev, name=)
            b1 = bias_variable([], name=)
            b2 = bias_variable([], name=)
            conv1 = conv2d()
            tmp_h_conv = tf.nn.relu()
            conv2 = conv2d()
            dw_h_convs[] = tf.nn.relu()
            weights.append(())
            biases.append(())
            convs.append(())
            size -= 2 * 2 * ()
            if layer < layers - 1:
                pools[] = max_pool(dw_h_convs[], pool_size)
                in_node = pools[]
                size /=
    in_node = dw_h_convs[]
    for layer in range():
        with tf.name_scope("")):
            features = 2 ** () * features_root
            stddev = np.sqrt(2 / ())
            wd = weight_variable_devonc([], stddev, name=)
            bd = bias_variable([], name=)
            h_deconv = tf.nn.relu(deconv2d() + bd)
            h_deconv_concat = crop_and_concat(dw_h_convs[], h_deconv)
            deconv[] =
            w1 = weight_variable([], stddev, name=)
            w2 = weight_variable([], stddev, name=)
            b1 = bias_variable([], name=)
            b2 = bias_variable([], name=)
            conv1 = conv2d()
            h_conv = tf.nn.relu()
            conv2 = conv2d()
            in_node = tf.nn.relu()
            up_h_convs[] =
            weights.append(())
            biases.append(())
            convs.append(())
            size *=
            size -= 2 * 2 * ()
    with tf.name_scope():
        weight = weight_variable([], stddev)
        bias = bias_variable([], name=)
        conv = conv2d(in_node, weight, bias, tf.constant())
        output_map = tf.nn.relu()
        up_h_convs[] =
    if summaries:
        with tf.name_scope():
            for i, () in enumerate():
                tf.summary.image("", get_image_summary())
                tf.summary.image("", get_image_summary())
            for k in pools.keys():
                tf.summary.image("", get_image_summary(pools[]))
            for k in deconv.keys():
                tf.summary.image("", get_image_summary(deconv[]))
            for k in dw_h_convs.keys():
                tf.summary.histogram("", dw_h_convs[])
            for k in up_h_convs.keys():
                tf.summary.histogram("", up_h_convs[])
    variables = []
    for w1, w2 in weights:
        variables.append()
        variables.append()
    for b1, b2 in biases:
        variables.append()
        variables.append()
    return output_map, variables, int()
class Unet():
    def __init__(self, channels, n_class, cost=, cost_kwargs={}, **kwargs):
        tf.reset_default_graph()
        self.n_class =
        self.summaries = kwargs.get()
        self.x = tf.placeholder("", shape=[], name=)
        self.y = tf.placeholder("", shape=[], name=)
        self.keep_prob = tf.placeholder(tf.float32, name=)
        logits, self.variables, self.offset = create_conv_net()
        self.cost = self._get_cost()
        self.gradients_node = tf.gradients()
        with tf.name_scope():
            self.cross_entropy = cross_entropy(tf.reshape(self.y, []),tf.reshape(pixel_wise_softmax(), []))
        with tf.name_scope():
            self.predicter = pixel_wise_softmax()
            self.correct_pred = tf.equal(tf.argmax(), tf.argmax())
            self.accuracy = tf.reduce_mean(tf.cast())
    def _get_cost():
        with tf.name_scope():
            flat_logits = tf.reshape(logits, [])
            flat_labels = tf.reshape(self.y, [])
            if cost_name == "":
                class_weights = cost_kwargs.pop()
                if class_weights is not None:
                    class_weights = tf.constant(np.array(class_weights, dtype=))
                    weight_map = tf.multiply()
                    weight_map = tf.reduce_sum(weight_map, axis=)
                    loss_map = tf.nn.softmax_cross_entropy_with_logits_v2(logits=,labels=)
                    weighted_loss = tf.multiply()
                    loss = tf.reduce_mean()
                else:
                    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=,labels=))
            elif cost_name == "":
                eps =
                prediction = pixel_wise_softmax()
                intersection = tf.reduce_sum()
                union = eps + tf.reduce_sum() + tf.reduce_sum()
                loss = -(2 * intersection / ())
            else:
                raise ValueError()
            regularizer = cost_kwargs.pop()
            if regularizer is not None:
                regularizers = sum([tf.nn.l2_loss() for variable in self.variables])
                loss += ()
            return loss
    def predict():
        init = tf.global_variables_initializer()
        with tf.Session() as sess:
            sess.run()
            self.restore()
            y_dummy = np.empty((x_test.shape[], x_test.shape[], x_test.shape[], self.n_class))
            prediction = sess.run(self.predicter, feed_dict={self.x:, self.y:, self.keep_prob:})
        return prediction
    def save():
        saver = tf.train.Saver()
        save_path = saver.save()
        return save_path
    def restore():
        saver = tf.train.Saver()
        saver.restore()
class Trainer():
    def __init__(self, net, batch_size=, verification_batch_size =, norm_grads=, optimizer=, opt_kwargs={}):
        self.net =
        self.batch_size =
        self.verification_batch_size =
        self.norm_grads =
        self.optimizer =
        self.opt_kwargs =
    def _get_optimizer():
        if self.optimizer == "":
            learning_rate = self.opt_kwargs.pop()
            decay_rate = self.opt_kwargs.pop()
            momentum = self.opt_kwargs.pop()
            self.learning_rate_node = tf.train.exponential_decay(learning_rate=,global_step=,decay_steps=,decay_rate=,staircase=)
            optimizer = tf.train.MomentumOptimizer(learning_rate=, momentum=,**self.opt_kwargs).minimize(self.net.cost,global_step=)
        elif self.optimizer == "":
            learning_rate = self.opt_kwargs.pop()
            self.learning_rate_node = tf.Variable(learning_rate, name=)
            optimizer = tf.train.AdamOptimizer(learning_rate=,**self.opt_kwargs).minimize(self.net.cost,global_step=)
        return optimizer
    def _initialize():
        global_step = tf.Variable(0, name=)
        self.norm_gradients_node = tf.Variable(tf.constant(0.0, shape=[len()]), name=)
        if self.net.summaries and self.norm_grads:
            tf.summary.histogram()
        tf.summary.scalar()
        tf.summary.scalar()
        tf.summary.scalar()
        self.optimizer = self._get_optimizer()
        tf.summary.scalar()
        self.summary_op = tf.summary.merge_all()
        init = tf.global_variables_initializer()
        self.prediction_path =
        abs_prediction_path = os.path.abspath()
        output_path = os.path.abspath()
        if not restore:
            shutil.rmtree(abs_prediction_path, ignore_errors=)
            shutil.rmtree(output_path, ignore_errors=)
        if not os.path.exists():
            os.makedirs()
        if not os.path.exists():
            os.makedirs()
        return init
    def train(self, data_provider, output_path, training_iters=, epochs=, dropout=, display_step=,restore=, write_graph=, prediction_path=):
        save_path = os.path.join()
        if epochs == 0:
            return save_path
        init = self._initialize()
        with tf.Session() as sess:
            if write_graph:
                tf.train.write_graph()
            sess.run()
            if restore:
                ckpt = tf.train.get_checkpoint_state()
                if ckpt and ckpt.model_checkpoint_path:
                    self.net.restore()
            test_x, test_y = data_provider()
            pred_shape = self.store_prediction()
            summary_writer = tf.summary.FileWriter(output_path, graph=)
            avg_gradients =
            for epoch in range():
                total_loss =
                for step in range((), (() * training_iters)):
                    batch_x, batch_y = data_provider()
                    _, loss, lr, gradients = sess.run((),feed_dict={self.net.x:,self.net.y:,self.net.keep_prob:})
                    if self.net.summaries and self.norm_grads:
                        avg_gradients = _update_avg_gradients()
                        norm_gradients = [np.linalg.norm() for gradient in avg_gradients]
                        self.norm_gradients_node.assign().eval()
                    if step % display_step == 0:
                        self.output_minibatch_stats(sess, summary_writer, step, batch_x,util.crop_to_shape())
                    total_loss +=
                self.output_epoch_stats()
                self.store_prediction()
                save_path = self.net.save()
            return save_path
    def store_prediction():
        prediction = sess.run(self.net.predicter, feed_dict={self.net.x:,self.net.y:,self.net.keep_prob:})
        pred_shape =
        loss = sess.run(self.net.cost, feed_dict={self.net.x:,self.net.y:,self.net.keep_prob:})
        img = util.combine_img_prediction()
        util.save_image(img, "")
        return pred_shape
    def output_epoch_stats():
    def output_minibatch_stats():
        summary_str, loss, acc, predictions = sess.run([],feed_dict={self.net.x:,self.net.y:,self.net.keep_prob:})
        summary_writer.add_summary()
        summary_writer.flush()
def _update_avg_gradients():
    if avg_gradients is None:
        avg_gradients = [np.zeros_like() for gradient in gradients]
    for i in range(len()):
        avg_gradients[] = (avg_gradients[] * (1.0 - (1.0 / ()))) + (gradients[] / ())
    return avg_gradients
def error_rate():
    return 100.0 - (100.0 *np.sum(np.argmax() == np.argmax()) /(predictions.shape[] * predictions.shape[] * predictions.shape[]))
def get_image_summary(img, idx=):
    V = tf.slice(img, (), ())
    V -= tf.reduce_min()
    V /= tf.reduce_max()
    V *=
    img_w = tf.shape()[]
    img_h = tf.shape()[]
    V = tf.reshape(V, tf.stack(()))
    V = tf.transpose(V, ())
    V = tf.reshape(V, tf.stack(()))
    return V
from __future__ import absolute_import
from __future__ import division
from __future__ import print_function
import logging
import math
import tempfile
import tensorflow as tf
from tensorflow.examples.tutorials.mnist import input_data
logger = logging.getLogger()
FLAGS =
class MnistNetwork():
    def __init__(self,channel_1_num =,channel_2_num =,conv_size =,hidden_size =,pool_size =,learning_rate =,x_dim =,y_dim =):
        self.channel_1_num =
        self.channel_2_num =
        self.conv_size =
        self.hidden_size =
        self.pool_size =
        self.learning_rate =
        self.x_dim =
        self.y_dim =
    def build_network():
        self.x = tf.placeholder(tf.float32, [], name =)
        self.y = tf.placeholder(tf.float32, [], name =)
        self.keep_prob = tf.placeholder(tf.float32, name =)
        with tf.name_scope():
            try:
                input_dim = int(math.sqrt())
            except:
                raise
            x_image = tf.reshape(self.x, [])
        with tf.name_scope():
            W_conv1 = weight_variable([])
            b_conv1 = bias_variable([])
            h_conv1 = tf.nn.relu(conv2d() + b_conv1)
        with tf.name_scope():
            h_pool1 = max_pool()
        with tf.name_scope():
            W_conv2 = weight_variable([])
            b_conv2 = bias_variable([])
            h_conv2 = tf.nn.relu(conv2d() + b_conv2)
        with tf.name_scope():
            h_pool2 = max_pool()
        last_dim = int(input_dim / ())
        with tf.name_scope():
            W_fc1 = weight_variable([])
            b_fc1 = bias_variable([])
        h_pool2_flat = tf.reshape(h_pool2, [])
        h_fc1 = tf.nn.relu(tf.matmul() + b_fc1)
        with tf.name_scope():
            h_fc1_drop = tf.nn.dropout()
        with tf.name_scope():
            W_fc2 = weight_variable([])
            b_fc2 = bias_variable([])
            y_conv = tf.matmul() + b_fc2
        with tf.name_scope():
            cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels =, logits =))
        with tf.name_scope():
            self.train_step = tf.train.AdamOptimizer().minimize()
        with tf.name_scope():
            correct_prediction = tf.equal(tf.argmax(), tf.argmax())
            self.accuracy = tf.reduce_mean(tf.cast())
        return
def conv2d():
    return tf.nn.conv2d(x, W, strides=[], padding=)
def max_pool():
    return tf.nn.max_pool(x, ksize=[],strides=[], padding=)
def avg_pool():
    return tf.nn.avg_pool(x, ksize=[],strides=[], padding=)
def weight_variable():
    initial = tf.truncated_normal(shape, stddev=)
    return tf.Variable()
def bias_variable():
    initial = tf.constant(0.1, shape=)
    return tf.Variable()
def main():
    data_dir=
    mnist = input_data.read_data_sets(data_dir, one_hot=)
    mnist_network = MnistNetwork()
    mnist_network.build_network()
    graph_location = tempfile.mkdtemp()
    train_writer = tf.summary.FileWriter()
    train_writer.add_graph(tf.get_default_graph())
    test_acc =
    with tf.Session() as sess:
        sess.run(tf.global_variables_initializer())
        batch_num=
        for i in range():
            batch_size=
            batch = mnist.train.next_batch()
            dropout_rate=
            mnist_network.train_step.run(feed_dict={mnist_network.x:, mnist_network.y:, mnist_network.keep_prob:})
            if i % 100 == 0:
                test_acc = mnist_network.accuracy.eval(feed_dict={mnist_network.x:, mnist_network.y:, mnist_network.keep_prob:})
        test_acc = mnist_network.accuracy.eval(feed_dict={mnist_network.x:, mnist_network.y:, mnist_network.keep_prob:})
def generate_default_params():
    params = {'data_dir':,'dropout_rate':,'channel_1_num':,'channel_2_num':,'conv_size':,'pool_size':,'hidden_size':,'batch_size':,'batch_num':,'learning_rate':}
    return params
if __name__ == "__main__":
    try:
        params = generate_default_params()
        main()
    except:
        raise
import argparse
import logging
import math
import tempfile
import time
import tensorflow as tf
from tensorflow.examples.tutorials.mnist import input_data
FLAGS =
logger = logging.getLogger()
class MnistNetwork():
    def __init__(self,channel_1_num,channel_2_num,conv_size,hidden_size,pool_size,learning_rate,x_dim=,y_dim=):
        self.channel_1_num =
        self.channel_2_num =
        self.conv_size =
        self.hidden_size =
        self.pool_size =
        self.learning_rate =
        self.x_dim =
        self.y_dim =
        self.images = tf.placeholder(tf.float32, [], name=)
        self.labels = tf.placeholder(tf.float32, [], name=)
        self.keep_prob = tf.placeholder(tf.float32, name=)
        self.train_step =
        self.accuracy =
    def build_network():
        with tf.name_scope():
            try:
                input_dim = int(math.sqrt())
            except:
                raise
            x_image = tf.reshape(self.images, [])
        with tf.name_scope():
            w_conv1 = weight_variable([])
            b_conv1 = bias_variable([])
            h_conv1 = tf.nn.relu(conv2d() + b_conv1)
        with tf.name_scope():
            h_pool1 = max_pool()
        with tf.name_scope():
            w_conv2 = weight_variable([])
            b_conv2 = bias_variable([])
            h_conv2 = tf.nn.relu(conv2d() + b_conv2)
        with tf.name_scope():
            h_pool2 = max_pool()
        last_dim = int(input_dim / ())
        with tf.name_scope():
            w_fc1 = weight_variable([])
            b_fc1 = bias_variable([])
        h_pool2_flat = tf.reshape(h_pool2, [])
        h_fc1 = tf.nn.relu(tf.matmul() + b_fc1)
        with tf.name_scope():
            h_fc1_drop = tf.nn.dropout()
        with tf.name_scope():
            w_fc2 = weight_variable([])
            b_fc2 = bias_variable([])
            y_conv = tf.matmul() + b_fc2
        with tf.name_scope():
            cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=, logits=))
        with tf.name_scope():
            self.train_step = tf.train.AdamOptimizer().minimize()
        with tf.name_scope():
            correct_prediction = tf.equal(tf.argmax(), tf.argmax())
            self.accuracy = tf.reduce_mean(tf.cast())
def conv2d():
    return tf.nn.conv2d(x_input, w_matrix, strides=[], padding=)
def max_pool():
    return tf.nn.max_pool(x_input, ksize=[],strides=[], padding=)
def weight_variable():
    initial = tf.truncated_normal(shape, stddev=)
    return tf.Variable()
def bias_variable():
    initial = tf.constant(0.1, shape=)
    return tf.Variable()
def download_mnist_retry(data_dir, max_num_retries=):
    for _ in range():
        try:
            return input_data.read_data_sets(data_dir, one_hot=)
        except tf.errors.AlreadyExistsError:
            time.sleep()
    raise Exception()
def main():
    mnist = download_mnist_retry(params[])
    mnist_network = MnistNetwork(channel_1_num=params[],channel_2_num=params[],conv_size=params[],hidden_size=params[],pool_size=params[],learning_rate=params[])
    mnist_network.build_network()
    graph_location = tempfile.mkdtemp()
    train_writer = tf.summary.FileWriter()
    train_writer.add_graph(tf.get_default_graph())
    test_acc =
    with tf.Session() as sess:
        sess.run(tf.global_variables_initializer())
        for i in range(params[]):
            batch = mnist.train.next_batch(params[])
            mnist_network.train_step.run(feed_dict={mnist_network.images:,mnist_network.labels:,mnist_network.keep_prob:})
            if i % 100 == 0:
                test_acc = mnist_network.accuracy.eval(feed_dict={mnist_network.images:,mnist_network.labels:,mnist_network.keep_prob:})
        test_acc = mnist_network.accuracy.eval(feed_dict={mnist_network.images:,mnist_network.labels:,mnist_network.keep_prob:})
def get_params():
    parser = argparse.ArgumentParser()
    parser.add_argument("", type=, default=, help=)
    parser.add_argument("", type=, default=, help=)
    parser.add_argument("", type=, default=)
    parser.add_argument("", type=, default=)
    parser.add_argument("", type=, default=)
    parser.add_argument("", type=, default=)
    parser.add_argument("", type=, default=)
    parser.add_argument("", type=, default=)
    parser.add_argument("", type=, default=)
    parser.add_argument("", type=, default=)
    args, _ = parser.parse_known_args()
    return args
if __name__ == "__main__":
    try:
        params = vars(get_params())
        main()
    except Exception as exception:
        raise
import logging
import math
import tempfile
import time
import tensorflow as tf
from tensorflow.examples.tutorials.mnist import input_data
import nni
FLAGS =
logger = logging.getLogger()
class MnistNetwork():
    def __init__(self, channel_1_num, channel_2_num, conv_size, hidden_size,pool_size, learning_rate, x_dim=, y_dim=):
        self.channel_1_num =
        self.channel_2_num =
        self.conv_size = nni.choice(2, 3, 5, 7, name=)
        self.hidden_size = nni.choice(124, 512, 1024, name=)
        self.pool_size =
        self.learning_rate = nni.uniform(0.0001, 0.1, name=)
        self.x_dim =
        self.y_dim =
        self.images = tf.placeholder(tf.float32, [], name=)
        self.labels = tf.placeholder(tf.float32, [], name=)
        self.keep_prob = tf.placeholder(tf.float32, name=)
        self.train_step =
        self.accuracy =
    def build_network():
        with tf.name_scope():
            try:
                input_dim = int(math.sqrt())
            except:
                raise
            x_image = tf.reshape(self.images, [])
        with tf.name_scope():
            w_conv1 = weight_variable([])
            b_conv1 = bias_variable([])
            h_conv1 = nni.function_choice(lambda : tf.nn.relu(conv2d() + b_conv1), lambda : tf.nn.sigmoid(conv2d() + b_conv1), lambda : tf.nn.tanh(conv2d() + b_conv1), name=)
        with tf.name_scope():
            h_pool1 = nni.function_choice(lambda : max_pool(), lambda : avg_pool(),name=)
        with tf.name_scope():
            w_conv2 = weight_variable([])
            b_conv2 = bias_variable([])
            h_conv2 = tf.nn.relu(conv2d() + b_conv2)
        with tf.name_scope():
            h_pool2 = max_pool()
        last_dim = int(input_dim / ())
        with tf.name_scope():
            w_fc1 = weight_variable([])
            b_fc1 = bias_variable([])
        h_pool2_flat = tf.reshape(h_pool2, [])
        h_fc1 = tf.nn.relu(tf.matmul() + b_fc1)
        with tf.name_scope():
            h_fc1_drop = tf.nn.dropout()
        with tf.name_scope():
            w_fc2 = weight_variable([])
            b_fc2 = bias_variable([])
            y_conv = tf.matmul() + b_fc2
        with tf.name_scope():
            cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=,logits=))
        with tf.name_scope():
            self.train_step = tf.train.AdamOptimizer().minimize()
        with tf.name_scope():
            correct_prediction = tf.equal(tf.argmax(), tf.argmax())
            self.accuracy = tf.reduce_mean(tf.cast())
def conv2d():
    return tf.nn.conv2d(x_input, w_matrix, strides=[], padding=)
def max_pool():
    return tf.nn.max_pool(x_input, ksize=[],strides=[], padding=)
def avg_pool():
    return tf.nn.avg_pool(x_input, ksize=[],strides=[], padding=)
def weight_variable():
    initial = tf.truncated_normal(shape, stddev=)
    return tf.Variable()
def bias_variable():
    initial = tf.constant(0.1, shape=)
    return tf.Variable()
def download_mnist_retry(data_dir, max_num_retries=):
    for _ in range():
        try:
            return input_data.read_data_sets(data_dir, one_hot=)
        except tf.errors.AlreadyExistsError:
            time.sleep()
    raise Exception()
def main():
def main():
    mnist = download_mnist_retry(params[])
    mnist_network = MnistNetwork(channel_1_num=params[],channel_2_num=params[], conv_size=params[], hidden_size=params[], pool_size=params[],learning_rate=params[])
    mnist_network.build_network()
    graph_location = tempfile.mkdtemp()
    train_writer = tf.summary.FileWriter()
    train_writer.add_graph(tf.get_default_graph())
    test_acc =
    with tf.Session() as sess:
        sess.run(tf.global_variables_initializer())
        batch_num = nni.choice(50, 250, 500, name=)
        for i in range():
            batch = mnist.train.next_batch()
            dropout_rate = nni.choice(1, 5, name=)
            mnist_network.train_step.run(feed_dict={mnist_network.images:, mnist_network.labels:, mnist_network.keep_prob:})
            if i % 100 == 0:
                test_acc = mnist_network.accuracy.eval(feed_dict={mnist_network.images:, mnist_network.labels:, mnist_network.keep_prob:})
                nni.report_intermediate_result()
        test_acc = mnist_network.accuracy.eval(feed_dict={mnist_network.images:, mnist_network.labels:, mnist_network.keep_prob:})
        nni.report_final_result()
def generate_defualt_params():
    params = {'data_dir':,'dropout_rate':, 'channel_1_num':, 'channel_2_num':,'conv_size':, 'pool_size':, 'hidden_size':,'learning_rate':, 'batch_num':}
    return params
if __name__ == "__main__":
    try:
        main(generate_defualt_params())
    except Exception as exception:
        raise
import logging
import math
import tempfile
import time
import tensorflow as tf
from tensorflow.examples.tutorials.mnist import input_data
import nni
FLAGS =
logger = logging.getLogger()
class MnistNetwork():
    def __init__(self,channel_1_num,channel_2_num,pool_size,learning_rate,x_dim=,y_dim=):
        self.channel_1_num =
        self.channel_2_num =
        self.conv_size = nni.choice(2, 3, 5, 7, name=)
        self.hidden_size = nni.choice()
        self.pool_size =
        self.learning_rate = nni.uniform(0.0001, 0.1, name=)
        self.x_dim =
        self.y_dim =
        self.images = tf.placeholder(tf.float32, [], name=)
        self.labels = tf.placeholder(tf.float32, [], name=)
        self.keep_prob = tf.placeholder(tf.float32, name=)
        self.train_step =
        self.accuracy =
    def build_network():
        with tf.name_scope():
            try:
                input_dim = int(math.sqrt())
            except:
                raise
            x_image = tf.reshape(self.images, [])
        with tf.name_scope():
            w_conv1 = weight_variable([])
            b_conv1 = bias_variable([])
            h_conv1 = nni.function_choice(lambda: tf.nn.relu(conv2d() + b_conv1),lambda: tf.nn.sigmoid(conv2d() + b_conv1),lambda: tf.nn.tanh(conv2d() + b_conv1))
        with tf.name_scope():
            h_pool1 = max_pool()
            h_pool1 = nni.function_choice(lambda: max_pool(),lambda: avg_pool(),name=)
        with tf.name_scope():
            w_conv2 = weight_variable([])
            b_conv2 = bias_variable([])
            h_conv2 = tf.nn.relu(conv2d() + b_conv2)
        with tf.name_scope():
            h_pool2 = max_pool()
        last_dim = int(input_dim / ())
        with tf.name_scope():
            w_fc1 = weight_variable([])
            b_fc1 = bias_variable([])
        h_pool2_flat = tf.reshape(h_pool2, [])
        h_fc1 = tf.nn.relu(tf.matmul() + b_fc1)
        with tf.name_scope():
            h_fc1_drop = tf.nn.dropout()
        with tf.name_scope():
            w_fc2 = weight_variable([])
            b_fc2 = bias_variable([])
            y_conv = tf.matmul() + b_fc2
        with tf.name_scope():
            cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=, logits=))
        with tf.name_scope():
            self.train_step = tf.train.AdamOptimizer().minimize()
        with tf.name_scope():
            correct_prediction = tf.equal(tf.argmax(), tf.argmax())
            self.accuracy = tf.reduce_mean(tf.cast())
def conv2d():
    return tf.nn.conv2d(x_input, w_matrix, strides=[], padding=)
def max_pool():
    return tf.nn.max_pool(x_input, ksize=[],strides=[], padding=)
def avg_pool():
    return tf.nn.avg_pool(x_input, ksize=[],strides=[], padding=)
def weight_variable():
    initial = tf.truncated_normal(shape, stddev=)
    return tf.Variable()
def bias_variable():
    initial = tf.constant(0.1, shape=)
    return tf.Variable()
def download_mnist_retry(data_dir, max_num_retries=):
    for _ in range():
        try:
            return input_data.read_data_sets(data_dir, one_hot=)
        except tf.errors.AlreadyExistsError:
            time.sleep()
    raise Exception()
def main():
    mnist = download_mnist_retry(params[])
    mnist_network = MnistNetwork(channel_1_num=params[],channel_2_num=params[],pool_size=params[])
    mnist_network.build_network()
    graph_location = tempfile.mkdtemp()
    train_writer = tf.summary.FileWriter()
    train_writer.add_graph(tf.get_default_graph())
    test_acc =
    with tf.Session() as sess:
        sess.run(tf.global_variables_initializer())
        batch_num = nni.choice(50, 250, 500, name=)
        for i in range():
            batch = mnist.train.next_batch()
            dropout_rate = nni.choice(1, 5, name=)
            mnist_network.train_step.run(feed_dict={mnist_network.images:,mnist_network.labels:,mnist_network.keep_prob:})
            if i % 100 == 0:
                test_acc = mnist_network.accuracy.eval(feed_dict={mnist_network.images:,mnist_network.labels:,mnist_network.keep_prob:})
                nni.report_intermediate_result()
        test_acc = mnist_network.accuracy.eval(feed_dict={mnist_network.images:,mnist_network.labels:,mnist_network.keep_prob:})
        nni.report_final_result()
def generate_defualt_params():
    params = {'data_dir':,'channel_1_num':,'channel_2_num':,'pool_size':}
    return params
if __name__ == "__main__":
    try:
        main(generate_defualt_params())
    except Exception as exception:
        raise
import logging
import math
import tempfile
import time
import tensorflow as tf
from tensorflow.examples.tutorials.mnist import input_data
FLAGS =
logger = logging.getLogger()
class MnistNetwork():
    def __init__(self,channel_1_num,channel_2_num,conv_size,hidden_size,pool_size,learning_rate,x_dim=,y_dim=):
        self.channel_1_num =
        self.channel_2_num =
        self.conv_size =
        self.hidden_size =
        self.pool_size =
        self.learning_rate =
        self.x_dim =
        self.y_dim =
        self.images = tf.placeholder(tf.float32, [], name=)
        self.labels = tf.placeholder(tf.float32, [], name=)
        self.keep_prob = tf.placeholder(tf.float32, name=)
        self.train_step =
        self.accuracy =
    def build_network():
        with tf.name_scope():
            try:
                input_dim = int(math.sqrt())
            except:
                raise
            x_image = tf.reshape(self.images, [])
        with tf.name_scope():
            w_conv1 = weight_variable([])
            b_conv1 = bias_variable([])
            h_conv1 = tf.nn.relu(conv2d() + b_conv1)
        with tf.name_scope():
            h_pool1 = max_pool()
        with tf.name_scope():
            w_conv2 = weight_variable([])
            b_conv2 = bias_variable([])
            h_conv2 = tf.nn.relu(conv2d() + b_conv2)
        with tf.name_scope():
            h_pool2 = max_pool()
        last_dim = int(input_dim / ())
        with tf.name_scope():
            w_fc1 = weight_variable([])
            b_fc1 = bias_variable([])
        h_pool2_flat = tf.reshape(h_pool2, [])
        h_fc1 = tf.nn.relu(tf.matmul() + b_fc1)
        with tf.name_scope():
            h_fc1_drop = tf.nn.dropout()
        with tf.name_scope():
            w_fc2 = weight_variable([])
            b_fc2 = bias_variable([])
            y_conv = tf.matmul() + b_fc2
        with tf.name_scope():
            cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=, logits=))
        with tf.name_scope():
            self.train_step = tf.train.AdamOptimizer().minimize()
        with tf.name_scope():
            correct_prediction = tf.equal(tf.argmax(), tf.argmax())
            self.accuracy = tf.reduce_mean(tf.cast())
def conv2d():
    return tf.nn.conv2d(x_input, w_matrix, strides=[], padding=)
def max_pool():
    return tf.nn.max_pool(x_input, ksize=[],strides=[], padding=)
def avg_pool():
    return tf.nn.avg_pool(x_input, ksize=[],strides=[], padding=)
def weight_variable():
    initial = tf.truncated_normal(shape, stddev=)
    return tf.Variable()
def bias_variable():
    initial = tf.constant(0.1, shape=)
    return tf.Variable()
def download_mnist_retry(data_dir, max_num_retries=):
    for _ in range():
        try:
            return input_data.read_data_sets(data_dir, one_hot=)
        except tf.errors.AlreadyExistsError:
            time.sleep()
    raise Exception()
def main():
    mnist = download_mnist_retry(params[])
    mnist_network = MnistNetwork(channel_1_num=params[],channel_2_num=params[],conv_size=params[],hidden_size=params[],pool_size=params[],learning_rate=params[])
    mnist_network.build_network()
    graph_location = tempfile.mkdtemp()
    train_writer = tf.summary.FileWriter()
    train_writer.add_graph(tf.get_default_graph())
    test_acc =
    with tf.Session() as sess:
        sess.run(tf.global_variables_initializer())
        batch_num = params[]
        for i in range():
            batch = mnist.train.next_batch()
            dropout_rate = params[]
            mnist_network.train_step.run(feed_dict={mnist_network.images:,mnist_network.labels:,mnist_network.keep_prob:})
            if i % 100 == 0:
                test_acc = mnist_network.accuracy.eval(feed_dict={mnist_network.images:,mnist_network.labels:,mnist_network.keep_prob:})
        test_acc = mnist_network.accuracy.eval(feed_dict={mnist_network.images:,mnist_network.labels:,mnist_network.keep_prob:})
def generate_defualt_params():
    params = {'data_dir':,'dropout_rate':,'channel_1_num':,'channel_2_num':,'conv_size':,'pool_size':,'hidden_size':,'learning_rate':,'batch_num':}
    return params
if __name__ == "__main__":
    try:
        main(generate_defualt_params())
    except Exception as exception:
        raise
import numpy as np
import cv2
import tensorflow as tf
import time
import sys
class YOLO_TF:
	fromfile =
	tofile_img =
	tofile_txt =
	imshow =
	filewrite_img =
	filewrite_txt =
	disp_console =
	weights_file =
	alpha =
	threshold =
	iou_threshold =
	num_class =
	num_box =
	grid_size =
	classes =  []
	w_img =
	h_img =
	def __init__(self,argvs = []):
		self.argv_parser()
		self.build_networks()
		if self.fromfile is not None: self.detect_from_file()
	def argv_parser():
		for i in range(1,len(),2):
			if argvs[] == "" : self.fromfile = argvs[]
			if argvs[] == "" : self.tofile_img = argvs[] ; self.filewrite_img =
			if argvs[] == "" : self.tofile_txt = argvs[] ; self.filewrite_txt =
			if argvs[] == "" :
				if argvs[] == "" :self.imshow =
				else : self.imshow =
			if argvs[] == "" :
				if argvs[] == "" :self.disp_console =
				else : self.disp_console =
	def build_networks():
		if self.disp_console :
		self.x = tf.placeholder("",[])
		self.conv_1 = self.conv_layer()
		self.pool_2 = self.pooling_layer()
		self.conv_3 = self.conv_layer()
		self.pool_4 = self.pooling_layer()
		self.conv_5 = self.conv_layer()
		self.pool_6 = self.pooling_layer()
		self.conv_7 = self.conv_layer()
		self.pool_8 = self.pooling_layer()
		self.conv_9 = self.conv_layer()
		self.pool_10 = self.pooling_layer()
		self.conv_11 = self.conv_layer()
		self.pool_12 = self.pooling_layer()
		self.conv_13 = self.conv_layer()
		self.conv_14 = self.conv_layer()
		self.conv_15 = self.conv_layer()
		self.fc_16 = self.fc_layer(16,self.conv_15,256,flat=,linear=)
		self.fc_17 = self.fc_layer(17,self.fc_16,4096,flat=,linear=)
		self.fc_19 = self.fc_layer(19,self.fc_17,1331,flat=,linear=)
		self.sess = tf.Session()
		self.sess.run(tf.initialize_all_variables())
		self.saver = tf.train.Saver()
		self.saver.restore()
		if self.disp_console :
	def conv_layer():
		channels = inputs.get_shape()[]
		weight = tf.Variable(tf.truncated_normal([size,size,int(),filters], stddev=))
		biases = tf.Variable(tf.constant(0.1, shape=[]))
		pad_size =
		pad_mat = np.array([[],[],[],[]])
		inputs_pad = tf.pad()
		conv = tf.nn.conv2d(inputs_pad, weight, strides=[], padding=,name=str()+"")
		conv_biased = tf.add(conv,biases,name=str()+"")
		if self.disp_console : print "",size,size,stride,filters,int())
		return tf.maximum(self.alpha*conv_biased,conv_biased,name=str()+"")
	def pooling_layer():
		if self.disp_console : print ""
		return tf.nn.max_pool(inputs, ksize=[],strides=[], padding=,name=str()+"")
	def fc_layer(self,idx,inputs,hiddens,flat =,linear =):
		input_shape = inputs.get_shape().as_list()
		if flat:
			dim = input_shape[]*input_shape[]*input_shape[]
			inputs_transposed = tf.transpose(inputs,())
			inputs_processed = tf.reshape(inputs_transposed, [])
		else:
			dim = input_shape[]
			inputs_processed =
		weight = tf.Variable(tf.truncated_normal([], stddev=))
		biases = tf.Variable(tf.constant(0.1, shape=[]))
		if self.disp_console : print "",hiddens,int(),int(),1-int())
		if linear : return tf.add(tf.matmul(),biases,name=str()+"")
		ip = tf.add(tf.matmul(),biases)
		return tf.maximum(self.alpha*ip,ip,name=str()+"")
	def detect_from_cvmat():
		s = time.time()
		self.h_img,self.w_img,_ =
		img_resized = cv2.resize(img, ())
		img_RGB = cv2.cvtColor()
		img_resized_np = np.asarray()
		inputs = np.zeros((),dtype=)
		inputs[] = ()*2.0-1.0
		in_dict = {self.x:}
		net_output = self.sess.run(self.fc_19,feed_dict=)
		self.result = self.interpret_output(net_output[])
		self.show_results()
		strtime = str(time.time()-s)
		if self.disp_console : print 'Elapsed time :
	def detect_from_file():
		if self.disp_console :
		img = cv2.imread()
		self.detect_from_cvmat()
	def detect_from_crop_sample():
		self.w_img =
		self.h_img =
		f = np.array(open().readlines(),dtype=)
		inputs = np.zeros((),dtype=)
		for c in range():
			for y in range():
				for x in range():
					inputs[] = f[]
		in_dict = {self.x:}
		net_output = self.sess.run(self.fc_19,feed_dict=)
		self.boxes, self.probs = self.interpret_output(net_output[])
		img = cv2.imread()
		self.show_results()
	def interpret_output():
		prob_range = []
		scales_range = [prob_range[],prob_range[]+self.grid_size*self.grid_size*self.num_box]
		boxes_range = [scales_range[],scales_range[]+self.grid_size*self.grid_size*self.num_box*4]
		probs = np.zeros(())
		class_probs = np.reshape(output[0:prob_range[]],())
		scales = np.reshape(output[scales_range[]:scales_range[]],())
		boxes = np.reshape(output[boxes_range[]:],())
		offset = np.transpose(np.reshape(np.array([np.arange()]*()),()),())
		boxes[:,:,:,0] +=
		boxes[:,:,:,1] += np.transpose(offset,())
		boxes[:,:,:,0:] = boxes[:,:,:,0:] / float()
		boxes[:,:,:,2] = np.multiply(boxes[:,:,:,2],boxes[:,:,:,2])
		boxes[:,:,:,3] = np.multiply(boxes[:,:,:,3],boxes[:,:,:,3])
		boxes[:,:,:,0] *=
		boxes[:,:,:,1] *=
		boxes[:,:,:,2] *=
		boxes[:,:,:,3] *=
		for i in range():
			for j in range():
				probs[:,:,i,j] = np.multiply(class_probs[:,:,j],scales[:,:,i])
		filter_mat_probs = np.array(probs>=,dtype=)
		filter_mat_boxes = np.nonzero()
		boxes_filtered = boxes[filter_mat_boxes[],filter_mat_boxes[],filter_mat_boxes[]]
		probs_filtered = probs[]
		classes_num_filtered = np.argmax(filter_mat_probs,axis=)[filter_mat_boxes[],filter_mat_boxes[],filter_mat_boxes[]]
		argsort = np.array(np.argsort())[::]
		boxes_filtered = boxes_filtered[]
		probs_filtered = probs_filtered[]
		classes_num_filtered = classes_num_filtered[]
		for i in range(len()):
			if probs_filtered[] == 0 :
			for j in range(i+1,len()):
				if self.iou(boxes_filtered[],boxes_filtered[]) > self.iou_threshold :
					probs_filtered[] =
		filter_iou = np.array(probs_filtered>0.0,dtype=)
		boxes_filtered = boxes_filtered[]
		probs_filtered = probs_filtered[]
		classes_num_filtered = classes_num_filtered[]
		result = []
		for i in range(len()):
			result.append([self.classes[classes_num_filtered[]],boxes_filtered[][],boxes_filtered[][],boxes_filtered[][],boxes_filtered[][],probs_filtered[]])
		return result
	def show_results():
		img_cp = img.copy()
		if self.filewrite_txt :
			ftxt = open()
		for i in range(len()):
			x = int(results[][])
			y = int(results[][])
			w = int(results[][])//2
			h = int(results[][])//2
			if self.disp_console : print "" + results[][] + ' , []=[' + str() + "" + str() + "" + str(int(results[][])) + "" + str(int(results[][]))+'], Confidence = ' + str(results[][])
			if self.filewrite_img or self.imshow:
				cv2.rectangle(img_cp,(),(),(),2)
				cv2.rectangle(img_cp,(),(),(),-1)
				cv2.putText(img_cp,results[][] + "",(),cv2.FONT_HERSHEY_SIMPLEX,0.5,(),1)
			if self.filewrite_txt :
				ftxt.write(results[][] + "" + str() + "" + str() + "" + str() + "" + str()+"" + str(results[][]) + "")
		if self.filewrite_img :
			if self.disp_console : print '    image file writed :
			cv2.imwrite()
		if self.imshow :
			cv2.imshow()
			cv2.waitKey()
		if self.filewrite_txt :
			if self.disp_console : print '    txt file writed :
			ftxt.close()
	def iou():
		tb = min(box1[]+0.5*box1[],box2[]+0.5*box2[])-max(box1[]-0.5*box1[],box2[]-0.5*box2[])
		lr = min(box1[]+0.5*box1[],box2[]+0.5*box2[])-max(box1[]-0.5*box1[],box2[]-0.5*box2[])
		if tb < 0 or lr < 0 : intersection =
		else : intersection =
		return intersection / (box1[]*box1[] + box2[]*box2[] - intersection)
	def training():
		return None
def main():
	yolo = YOLO_TF()
	cv2.waitKey()
if __name__=="":
	main()
import numpy as np
import cv2
import tensorflow as tf
import time
import sys
import os
class YOLO_TF:
	fromfile =
	tofile_img =
	tofile_txt =
	imshow =
	filewrite_img =
	filewrite_txt =
	disp_console =
	weights_file =
	alpha =
	threshold =
	iou_threshold =
	num_class =
	num_box =
	grid_size =
	classes =  []
	w_img =
	h_img =
	def __init__(self,argvs = []):
		self.detected =
		self.overall_pics =
		self.argv_parser()
		self.build_networks()
		if self.fromfile is not None: self.detect_from_file()
		if self.fromfolder is not None:
			filename_list = os.listdir()
			for filename in filename_list:
				self.overall_pics+=
				self.detect_from_file()
	def argv_parser():
		for i in range(1,len(),2):
			if argvs[] == "" : self.fromfile = argvs[]
			if argvs[] == "" :
				self.fromfolder = argvs[]
			else:
				self.fromfolder =
			if argvs[] == "" : self.tofile_img = argvs[] ; self.filewrite_img =
			if argvs[] == "" : self.tofile_txt = argvs[] ; self.filewrite_txt =
			if argvs[] == "" :
				if argvs[] == "" :self.imshow =
				else : self.imshow =
			if argvs[] == "" :
				if argvs[] == "" :self.disp_console =
				else : self.disp_console =
	def build_networks():
		if self.disp_console :
		self.x = tf.placeholder("",[])
		self.conv_1 = self.conv_layer()
		self.pool_2 = self.pooling_layer()
		self.conv_3 = self.conv_layer()
		self.pool_4 = self.pooling_layer()
		self.conv_5 = self.conv_layer()
		self.conv_6 = self.conv_layer()
		self.conv_7 = self.conv_layer()
		self.conv_8 = self.conv_layer()
		self.pool_9 = self.pooling_layer()
		self.conv_10 = self.conv_layer()
		self.conv_11 = self.conv_layer()
		self.conv_12 = self.conv_layer()
		self.conv_13 = self.conv_layer()
		self.conv_14 = self.conv_layer()
		self.conv_15 = self.conv_layer()
		self.conv_16 = self.conv_layer()
		self.conv_17 = self.conv_layer()
		self.conv_18 = self.conv_layer()
		self.conv_19 = self.conv_layer()
		self.pool_20 = self.pooling_layer()
		self.conv_21 = self.conv_layer()
		self.conv_22 = self.conv_layer()
		self.conv_23 = self.conv_layer()
		self.conv_24 = self.conv_layer()
		self.conv_25 = self.conv_layer()
		self.conv_26 = self.conv_layer()
		self.conv_27 = self.conv_layer()
		self.conv_28 = self.conv_layer()
		self.fc_29 = self.fc_layer(29,self.conv_28,512,flat=,linear=)
		self.fc_30 = self.fc_layer(30,self.fc_29,4096,flat=,linear=)
		self.fc_32 = self.fc_layer(32,self.fc_30,1470,flat=,linear=)
		self.sess = tf.Session()
		self.sess.run(tf.initialize_all_variables())
		self.saver = tf.train.Saver()
		self.saver.restore()
		if self.disp_console :
	def conv_layer():
		channels = inputs.get_shape()[]
		weight = tf.Variable(tf.truncated_normal([size,size,int(),filters], stddev=))
		biases = tf.Variable(tf.constant(0.1, shape=[]))
		pad_size =
		pad_mat = np.array([[],[],[],[]])
		inputs_pad = tf.pad()
		conv = tf.nn.conv2d(inputs_pad, weight, strides=[], padding=,name=str()+"")
		conv_biased = tf.add(conv,biases,name=str()+"")
		if self.disp_console : print "",size,size,stride,filters,int())
		return tf.maximum(self.alpha*conv_biased,conv_biased,name=str()+"")
	def pooling_layer():
		if self.disp_console : print ""
		return tf.nn.max_pool(inputs, ksize=[],strides=[], padding=,name=str()+"")
	def fc_layer(self,idx,inputs,hiddens,flat =,linear =):
		input_shape = inputs.get_shape().as_list()
		if flat:
			dim = input_shape[]*input_shape[]*input_shape[]
			inputs_transposed = tf.transpose(inputs,())
			inputs_processed = tf.reshape(inputs_transposed, [])
		else:
			dim = input_shape[]
			inputs_processed =
		weight = tf.Variable(tf.truncated_normal([], stddev=))
		biases = tf.Variable(tf.constant(0.1, shape=[]))
		if self.disp_console : print "",hiddens,int(),int(),1-int())
		if linear : return tf.add(tf.matmul(),biases,name=str()+"")
		ip = tf.add(tf.matmul(),biases)
		return tf.maximum(self.alpha*ip,ip,name=str()+"")
	def detect_from_cvmat():
		s = time.time()
		self.h_img,self.w_img,_ =
		img_resized = cv2.resize(img, ())
		img_RGB = cv2.cvtColor()
		img_resized_np = np.asarray()
		inputs = np.zeros((),dtype=)
		inputs[] = ()*2.0-1.0
		in_dict = {self.x:}
		net_output = self.sess.run(self.fc_32,feed_dict=)
		self.result = self.interpret_output(net_output[])
		self.show_results()
		strtime = str(time.time()-s)
		if self.disp_console : print 'Elapsed time :
	def detect_from_file():
		if self.disp_console :
		img = cv2.imread()
		self.detect_from_cvmat()
	def detect_from_crop_sample():
		self.w_img =
		self.h_img =
		f = np.array(open().readlines(),dtype=)
		inputs = np.zeros((),dtype=)
		for c in range():
			for y in range():
				for x in range():
					inputs[] = f[]
		in_dict = {self.x:}
		net_output = self.sess.run(self.fc_32,feed_dict=)
		self.boxes, self.probs = self.interpret_output(net_output[])
		img = cv2.imread()
		self.show_results()
	def interpret_output():
		probs = np.zeros(())
		class_probs = np.reshape(output[0:],())
		scales = np.reshape(output[980:],())
		boxes = np.reshape(output[1078:],())
		offset = np.transpose(np.reshape(np.array([np.arange()]*14),()),())
		boxes[:,:,:,0] +=
		boxes[:,:,:,1] += np.transpose(offset,())
		boxes[:,:,:,0:] = boxes[:,:,:,0:] / 7.0
		boxes[:,:,:,2] = np.multiply(boxes[:,:,:,2],boxes[:,:,:,2])
		boxes[:,:,:,3] = np.multiply(boxes[:,:,:,3],boxes[:,:,:,3])
		boxes[:,:,:,0] *=
		boxes[:,:,:,1] *=
		boxes[:,:,:,2] *=
		boxes[:,:,:,3] *=
		for i in range():
			for j in range():
				probs[:,:,i,j] = np.multiply(class_probs[:,:,j],scales[:,:,i])
		filter_mat_probs = np.array(probs>=,dtype=)
		filter_mat_boxes = np.nonzero()
		boxes_filtered = boxes[filter_mat_boxes[],filter_mat_boxes[],filter_mat_boxes[]]
		probs_filtered = probs[]
		classes_num_filtered = np.argmax(filter_mat_probs,axis=)[filter_mat_boxes[],filter_mat_boxes[],filter_mat_boxes[]]
		argsort = np.array(np.argsort())[::]
		boxes_filtered = boxes_filtered[]
		probs_filtered = probs_filtered[]
		classes_num_filtered = classes_num_filtered[]
		for i in range(len()):
			if probs_filtered[] == 0 :
			for j in range(i+1,len()):
				if self.iou(boxes_filtered[],boxes_filtered[]) > self.iou_threshold :
					probs_filtered[] =
		filter_iou = np.array(probs_filtered>0.0,dtype=)
		boxes_filtered = boxes_filtered[]
		probs_filtered = probs_filtered[]
		classes_num_filtered = classes_num_filtered[]
		result = []
		for i in range(len()):
			result.append([self.classes[classes_num_filtered[]],boxes_filtered[][],boxes_filtered[][],boxes_filtered[][],boxes_filtered[][],probs_filtered[]])
		return result
	def show_results():
		img_cp = img.copy()
		if self.filewrite_txt :
			ftxt = open()
		class_results_set = set()
		for i in range(len()):
			x = int(results[][])
			y = int(results[][])
			w = int(results[][])//2
			h = int(results[][])//2
			class_results_set.add(results[][])
			if self.disp_console : print "" + results[][] + ' , []=[' + str() + "" + str() + "" + str(int(results[][])) + "" + str(int(results[][]))+'], Confidence = ' + str(results[][])
			if self.filewrite_img or self.imshow:
				cv2.rectangle(img_cp,(),(),(),2)
				cv2.rectangle(img_cp,(),(),(),-1)
				cv2.putText(img_cp,results[][] + "",(),cv2.FONT_HERSHEY_SIMPLEX,0.5,(),1)
			if self.filewrite_txt :
				ftxt.write(results[][] + "" + str() + "" + str() + "" + str() + "" + str()+"" + str(results[][]) + "")
		if "" in class_results_set:
			self.detected+=
		if self.filewrite_img :
			if self.disp_console : print '    image file writed :
			is_saved = cv2.imwrite()
			if is_saved == True:
			else:
		if self.imshow :
			cv2.imshow()
			cv2.waitKey()
		if self.filewrite_txt :
			if self.disp_console : print '    txt file writed :
			ftxt.close()
	def iou():
		tb = min(box1[]+0.5*box1[],box2[]+0.5*box2[])-max(box1[]-0.5*box1[],box2[]-0.5*box2[])
		lr = min(box1[]+0.5*box1[],box2[]+0.5*box2[])-max(box1[]-0.5*box1[],box2[]-0.5*box2[])
		if tb < 0 or lr < 0 : intersection =
		else : intersection =
		return intersection / (box1[]*box1[] + box2[]*box2[] - intersection)
	def training():
		return None
def main():
	yolo = YOLO_TF()
	cv2.waitKey()
if __name__=="":
	main()
import numpy as np
import cv2
import tensorflow as tf
import time
import sys
import os
import pdb
class YOLO_TF:
	fromfile =
	tofile_img =
	tofile_txt =
	imshow =
	filewrite_img =
	filewrite_txt =
	disp_console =
	weights_file =
	alpha =
	threshold =
	iou_threshold =
	num_class =
	num_box =
	grid_size =
	classes =  []
	w_img =
	h_img =
	def __init__(self,argvs = []):
		self.detected =
		self.overall_pics =
		self.argv_parser()
		self.build_networks()
		if self.fromfile is not None: self.detect_from_file()
		if self.fromfolder is not None:
			filename_list = os.listdir()
			for filename in filename_list:
				self.overall_pics+=
				self.detect_from_file()
	def argv_parser():
		for i in range(1,len(),2):
			if argvs[] == "" : self.fromfile = argvs[]
			if argvs[] == "" :
				self.fromfolder = argvs[]
			else:
				self.fromfolder =
			if argvs[] == "" : self.tofile_img = argvs[] ; self.filewrite_img =
			if argvs[] == "" : self.tofile_txt = argvs[] ; self.filewrite_txt =
			if argvs[] == "" :
				if argvs[] == "" :self.imshow =
				else : self.imshow =
			if argvs[] == "" :
				if argvs[] == "" :self.disp_console =
				else : self.disp_console =
	def build_networks():
		if self.disp_console :
		self.x = tf.placeholder("",[])
		self.conv_1 = self.conv_layer()
		self.pool_2 = self.pooling_layer()
		self.conv_3 = self.conv_layer()
		self.pool_4 = self.pooling_layer()
		self.conv_5 = self.conv_layer()
		self.pool_6 = self.pooling_layer()
		self.conv_7 = self.conv_layer()
		self.pool_8 = self.pooling_layer()
		self.conv_9 = self.conv_layer()
		self.pool_10 = self.pooling_layer()
		self.conv_11 = self.conv_layer()
		self.pool_12 = self.pooling_layer()
		self.conv_13 = self.conv_layer()
		self.conv_14 = self.conv_layer()
		self.conv_15 = self.conv_layer()
		self.fc_16 = self.fc_layer(16,self.conv_15,256,flat=,linear=)
		self.fc_17 = self.fc_layer(17,self.fc_16,4096,flat=,linear=)
		self.fc_19 = self.fc_layer(19,self.fc_17,1470,flat=,linear=)
		self.sess = tf.Session()
		self.sess.run(tf.initialize_all_variables())
		self.saver = tf.train.Saver()
		self.saver.restore()
		if self.disp_console :
	def conv_layer():
		channels = inputs.get_shape()[]
		weight = tf.Variable(tf.truncated_normal([size,size,int(),filters], stddev=))
		biases = tf.Variable(tf.constant(0.1, shape=[]))
		pad_size =
		pad_mat = np.array([[],[],[],[]])
		inputs_pad = tf.pad()
		conv = tf.nn.conv2d(inputs_pad, weight, strides=[], padding=,name=str()+"")
		conv_biased = tf.add(conv,biases,name=str()+"")
		if self.disp_console : print "",size,size,stride,filters,int())
		return tf.maximum(self.alpha*conv_biased,conv_biased,name=str()+"")
	def pooling_layer():
		if self.disp_console : print ""
		return tf.nn.max_pool(inputs, ksize=[],strides=[], padding=,name=str()+"")
	def fc_layer(self,idx,inputs,hiddens,flat =,linear =):
		input_shape = inputs.get_shape().as_list()
		if flat:
			dim = input_shape[]*input_shape[]*input_shape[]
			inputs_transposed = tf.transpose(inputs,())
			inputs_processed = tf.reshape(inputs_transposed, [])
		else:
			dim = input_shape[]
			inputs_processed =
		weight = tf.Variable(tf.truncated_normal([], stddev=))
		biases = tf.Variable(tf.constant(0.1, shape=[]))
		if self.disp_console : print "",hiddens,int(),int(),1-int())
		if linear : return tf.add(tf.matmul(),biases,name=str()+"")
		ip = tf.add(tf.matmul(),biases)
		return tf.maximum(self.alpha*ip,ip,name=str()+"")
	def detect_from_cvmat():
		s = time.time()
		self.h_img,self.w_img,_ =
		img_resized = cv2.resize(img, ())
		img_RGB = cv2.cvtColor()
		img_resized_np = np.asarray()
		inputs = np.zeros((),dtype=)
		inputs[] = ()*2.0-1.0
		in_dict = {self.x:}
		net_output = self.sess.run(self.fc_19,feed_dict=)
		self.result = self.interpret_output(net_output[])
		self.show_results()
		strtime = str(time.time()-s)
		if self.disp_console : print 'Elapsed time :
	def detect_from_file():
		if self.disp_console :
		img = cv2.imread()
		self.detect_from_cvmat()
	def detect_from_crop_sample():
		self.w_img =
		self.h_img =
		f = np.array(open().readlines(),dtype=)
		inputs = np.zeros((),dtype=)
		for c in range():
			for y in range():
				for x in range():
					inputs[] = f[]
		in_dict = {self.x:}
		net_output = self.sess.run(self.fc_19,feed_dict=)
		self.boxes, self.probs = self.interpret_output(net_output[])
		img = cv2.imread()
		self.show_results()
	def interpret_output():
		probs = np.zeros(())
		class_probs = np.reshape(output[0:],())
		scales = np.reshape(output[980:],())
		boxes = np.reshape(output[1078:],())
		offset = np.transpose(np.reshape(np.array([np.arange()]*14),()),())
		boxes[:,:,:,0] +=
		boxes[:,:,:,1] += np.transpose(offset,())
		boxes[:,:,:,0:] = boxes[:,:,:,0:] / 7.0
		boxes[:,:,:,2] = np.multiply(boxes[:,:,:,2],boxes[:,:,:,2])
		boxes[:,:,:,3] = np.multiply(boxes[:,:,:,3],boxes[:,:,:,3])
		boxes[:,:,:,0] *=
		boxes[:,:,:,1] *=
		boxes[:,:,:,2] *=
		boxes[:,:,:,3] *=
		for i in range():
			for j in range():
				probs[:,:,i,j] = np.multiply(class_probs[:,:,j],scales[:,:,i])
		filter_mat_probs = np.array(probs>=,dtype=)
		filter_mat_boxes = np.nonzero()
		boxes_filtered = boxes[filter_mat_boxes[],filter_mat_boxes[],filter_mat_boxes[]]
		probs_filtered = probs[]
		classes_num_filtered = np.argmax(filter_mat_probs,axis=)[filter_mat_boxes[],filter_mat_boxes[],filter_mat_boxes[]]
		argsort = np.array(np.argsort())[::]
		boxes_filtered = boxes_filtered[]
		probs_filtered = probs_filtered[]
		classes_num_filtered = classes_num_filtered[]
		for i in range(len()):
			if probs_filtered[] == 0 :
			for j in range(i+1,len()):
				if self.iou(boxes_filtered[],boxes_filtered[]) > self.iou_threshold :
					probs_filtered[] =
		filter_iou = np.array(probs_filtered>0.0,dtype=)
		boxes_filtered = boxes_filtered[]
		probs_filtered = probs_filtered[]
		classes_num_filtered = classes_num_filtered[]
		result = []
		for i in range(len()):
			result.append([self.classes[classes_num_filtered[]],boxes_filtered[][],boxes_filtered[][],boxes_filtered[][],boxes_filtered[][],probs_filtered[]])
		return result
	def show_results():
		img_cp = img.copy()
		if self.filewrite_txt :
			ftxt = open()
		class_results_set = set()
		for i in range(len()):
			x = int(results[][])
			y = int(results[][])
			w = int(results[][])//2
			h = int(results[][])//2
			class_results_set.add(results[][])
			if self.disp_console : print "" + results[][] + ' , []=[' + str() + "" + str() + "" + str(int(results[][])) + "" + str(int(results[][]))+'], Confidence = ' + str(results[][])
			if self.filewrite_img or self.imshow:
				cv2.rectangle(img_cp,(),(),(),2)
				cv2.rectangle(img_cp,(),(),(),-1)
				cv2.putText(img_cp,results[][] + "",(),cv2.FONT_HERSHEY_SIMPLEX,0.5,(),1)
			if self.filewrite_txt :
				ftxt.write(results[][] + "" + str() + "" + str() + "" + str() + "" + str()+"" + str(results[][]) + "")
		if "" in class_results_set:
			self.detected+=
		if self.filewrite_img :
			if self.disp_console : print '    image file writed :
			is_saved = cv2.imwrite()
			if is_saved == True:
			else:
		if self.imshow :
			cv2.imshow()
			cv2.waitKey()
		if self.filewrite_txt :
			if self.disp_console : print '    txt file writed :
			ftxt.close()
	def iou():
		tb = min(box1[]+0.5*box1[],box2[]+0.5*box2[])-max(box1[]-0.5*box1[],box2[]-0.5*box2[])
		lr = min(box1[]+0.5*box1[],box2[]+0.5*box2[])-max(box1[]-0.5*box1[],box2[]-0.5*box2[])
		if tb < 0 or lr < 0 : intersection =
		else : intersection =
		return intersection / (box1[]*box1[] + box2[]*box2[] - intersection)
	def training():
		return None
def main():
	yolo = YOLO_TF()
	cv2.waitKey()
if __name__=="":
	main()
import tensorflow as tf
from tensorflow.python.framework import ops
from tensorflow.python.framework import dtypes
import os, sys
import numpy as np
import math
from datetime import datetime
import time
from PIL import Image
from math import ceil
from tensorflow.python.ops import gen_nn_ops
from Utils import _variable_with_weight_decay, _variable_on_cpu, _add_loss_summaries, _activation_summary, print_hist_summery, get_hist, per_class_acc, writeImage
from Inputs import *
MOVING_AVERAGE_DECAY =
NUM_EPOCHS_PER_DECAY =
LEARNING_RATE_DECAY_FACTOR =
INITIAL_LEARNING_RATE =
EVAL_BATCH_SIZE =
BATCH_SIZE =
IMAGE_HEIGHT =
IMAGE_WIDTH =
IMAGE_DEPTH =
NUM_CLASSES =
NUM_EXAMPLES_PER_EPOCH_FOR_TRAIN =
NUM_EXAMPLES_PER_EPOCH_FOR_TEST =
NUM_EXAMPLES_PER_EPOCH_FOR_EVAL =
TEST_ITER =
def msra_initializer():
    stddev = math.sqrt(2. / ())
    return tf.truncated_normal_initializer(stddev=)
def orthogonal_initializer(scale =):
    def _initializer(shape, dtype=, partition_info=):
      flat_shape = (shape[], np.prod(shape[1:]))
      a = np.random.normal()
      u, _, v = np.linalg.svd(a, full_matrices=)
      q = u if u.shape ==
      q = q.reshape()
      return tf.constant(scale * q[:shape[], :shape[]], dtype=)
    return _initializer
def loss():
  logits = tf.reshape(logits, ())
  labels = tf.reshape(labels, [])
  cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=, labels=, name=)
  cross_entropy_mean = tf.reduce_mean(cross_entropy, name=)
  tf.add_to_collection()
  return tf.add_n(tf.get_collection(), name=)
def weighted_loss(logits, labels, num_classes, head=):
    with tf.name_scope():
        logits = tf.reshape(logits, ())
        epsilon = tf.constant(value=)
        logits =
        label_flat = tf.reshape(labels, ())
        labels = tf.reshape(tf.one_hot(label_flat, depth=), ())
        softmax = tf.nn.softmax()
        cross_entropy = -tf.reduce_sum(tf.multiply(labels * tf.log(), head), axis=[])
        cross_entropy_mean = tf.reduce_mean(cross_entropy, name=)
        tf.add_to_collection()
        loss = tf.add_n(tf.get_collection(), name=)
    return loss
def cal_loss():
    loss_weight = np.array([])
    labels = tf.cast()
    return weighted_loss(logits, labels, num_classes=, head=)
def conv_layer_with_bn(inputT, shape, train_phase, activation=, name=):
    in_channel = shape[]
    out_channel = shape[]
    k_size = shape[]
    with tf.variable_scope() as scope:
      kernel = _variable_with_weight_decay("", shape=, initializer=orthogonal_initializer(), wd=)
      conv = tf.nn.conv2d(inputT, kernel, [], padding=)
      biases = _variable_on_cpu("", [], tf.constant_initializer())
      bias = tf.nn.bias_add()
      if activation is True:
        conv_out = tf.nn.relu(batch_norm_layer())
      else:
        conv_out = batch_norm_layer()
    return conv_out
def get_deconv_filter():
  width = f_shape[]
  heigh = f_shape[]
  f = ceil()
  c = () / ()
  bilinear = np.zeros([f_shape[], f_shape[]])
  for x in range():
      for y in range():
          value = (1 - abs()) * (1 - abs())
          bilinear[] =
  weights = np.zeros()
  for i in range(f_shape[]):
      weights[:, :, i, i] =
  init = tf.constant_initializer(value=,dtype=)
  return tf.get_variable(name=, initializer=,shape=)
def deconv_layer(inputT, f_shape, output_shape, stride=, name=):
  sess_temp = tf.global_variables_initializer()
  strides = []
  with tf.variable_scope():
    weights = get_deconv_filter()
    deconv = tf.nn.conv2d_transpose(inputT, weights, output_shape,strides=, padding=)
  return deconv
def batch_norm_layer():
  return tf.cond(is_training,lambda: tf.contrib.layers.batch_norm(inputT, is_training=,center=, updates_collections=, scope=),lambda: tf.contrib.layers.batch_norm(inputT, is_training=,updates_collections=, center=, scope=, reuse =))
def inference():
    norm1 = tf.nn.lrn(images, depth_radius=, bias=, alpha=, beta=,name=)
    conv1 = conv_layer_with_bn(norm1, [7, 7, images.get_shape().as_list()[], 64], phase_train, name=)
    pool1, pool1_indices = tf.nn.max_pool_with_argmax(conv1, ksize=[], strides=[],padding=, name=)
    conv2 = conv_layer_with_bn(pool1, [], phase_train, name=)
    pool2, pool2_indices = tf.nn.max_pool_with_argmax(conv2, ksize=[],strides=[], padding=, name=)
    conv3 = conv_layer_with_bn(pool2, [], phase_train, name=)
    pool3, pool3_indices = tf.nn.max_pool_with_argmax(conv3, ksize=[],strides=[], padding=, name=)
    conv4 = conv_layer_with_bn(pool3, [], phase_train, name=)
    pool4, pool4_indices = tf.nn.max_pool_with_argmax(conv4, ksize=[],strides=[], padding=, name=)
    upsample4 = deconv_layer(pool4, [], [], 2, "")
    conv_decode4 = conv_layer_with_bn(upsample4, [], phase_train, False, name=)
    upsample3= deconv_layer(conv_decode4, [], [], 2, "")
    conv_decode3 = conv_layer_with_bn(upsample3, [], phase_train, False, name=)
    upsample2= deconv_layer(conv_decode3, [], [], 2, "")
    conv_decode2 = conv_layer_with_bn(upsample2, [], phase_train, False, name=)
    upsample1= deconv_layer(conv_decode2, [], [], 2, "")
    conv_decode1 = conv_layer_with_bn(upsample1, [], phase_train, False, name=)
    with tf.variable_scope() as scope:
      kernel = _variable_with_weight_decay("",shape=[],initializer=msra_initializer(),wd=)
      conv = tf.nn.conv2d(conv_decode1, kernel, [], padding=)
      biases = _variable_on_cpu("", [], tf.constant_initializer())
      conv_classifier = tf.nn.bias_add(conv, biases, name=)
    logit =
    loss = cal_loss()
    return loss, logit
def train():
    total_sample =
    num_batches_per_epoch =
    lr =
    loss_averages_op = _add_loss_summaries()
    with tf.control_dependencies([]):
      opt = tf.train.AdamOptimizer()
      grads = opt.compute_gradients()
    apply_gradient_op = opt.apply_gradients(grads, global_step=)
    for var in tf.trainable_variables():
      tf.summary.histogram()
    for grad, var in grads:
      if grad is not None:
        tf.summary.histogram()
    variable_averages = tf.train.ExponentialMovingAverage()
    variables_averages_op = variable_averages.apply(tf.trainable_variables())
    with tf.control_dependencies([]):
      train_op = tf.no_op(name=)
    return train_op
def test():
  max_steps =
  batch_size =
  train_dir =
  test_dir =
  test_ckpt =
  image_w =
  image_h =
  image_c =
  batch_size =
  image_filenames, label_filenames = get_filename_list()
  test_data_node = tf.placeholder(tf.float32,shape=[])
  test_labels_node = tf.placeholder(tf.int64, shape=[])
  phase_train = tf.placeholder(tf.bool, name=)
  loss, logits = inference()
  pred = tf.argmax(logits, axis=)
  variable_averages = tf.train.ExponentialMovingAverage()
  variables_to_restore = variable_averages.variables_to_restore()
  saver = tf.train.Saver()
  with tf.Session() as sess:
    saver.restore()
    images, labels = get_all_test_data()
    threads = tf.train.start_queue_runners(sess=)
    hist = np.zeros(())
    for image_batch, label_batch  in zip():
      feed_dict = {test_data_node:,test_labels_node:,phase_train:}
      dense_prediction, im = sess.run([], feed_dict=)
      if ():
          writeImage(im[], "")
      hist += get_hist()
    acc_total = np.diag().sum() / hist.sum()
    iu = np.diag() / (hist.sum() + hist.sum() - np.diag())
def training(FLAGS, is_finetune=):
  max_steps =
  batch_size =
  train_dir =
  image_dir =
  val_dir =
  finetune_ckpt =
  image_w =
  image_h =
  image_c =
  startstep = 0 if not is_finetune else int(FLAGS.finetune.split()[])
  image_filenames, label_filenames = get_filename_list()
  val_image_filenames, val_label_filenames = get_filename_list()
  with tf.Graph().as_default():
    train_data_node = tf.placeholder( tf.float32, shape=[])
    train_labels_node = tf.placeholder(tf.int64, shape=[])
    phase_train = tf.placeholder(tf.bool, name=)
    global_step = tf.Variable(0, trainable=)
    images, labels = CamVidInputs()
    val_images, val_labels = CamVidInputs()
    loss, eval_prediction = inference()
    train_op = train()
    saver = tf.train.Saver(tf.global_variables())
    summary_op = tf.summary.merge_all()
    with tf.Session() as sess:
      if (is_finetune ==):
          saver.restore()
      else:
          init = tf.global_variables_initializer()
          sess.run()
      coord = tf.train.Coordinator()
      threads = tf.train.start_queue_runners(sess=, coord=)
      summary_writer = tf.summary.FileWriter()
      average_pl = tf.placeholder()
      acc_pl = tf.placeholder()
      iu_pl = tf.placeholder()
      average_summary = tf.summary.scalar()
      acc_summary = tf.summary.scalar()
      iu_summary = tf.summary.scalar()
      for step in range():
        image_batch ,label_batch = sess.run([])
        feed_dict = {train_data_node:,train_labels_node:,phase_train:}
        start_time = time.time()
        _, loss_value = sess.run([], feed_dict=)
        duration = time.time() - start_time
        if step % 10 == 0:
          num_examples_per_step =
          examples_per_sec =
          sec_per_batch = float()
          format_str =
          pred = sess.run(eval_prediction, feed_dict=)
          per_class_acc()
        if step % 100 == 0:
          total_val_loss =
          hist = np.zeros(())
          for test_step in range(int()):
            val_images_batch, val_labels_batch = sess.run([])
            _val_loss, _val_pred = sess.run([], feed_dict={train_data_node:,train_labels_node:,phase_train:})
            total_val_loss +=
            hist += get_hist()
          acc_total = np.diag().sum() / hist.sum()
          iu = np.diag() / (hist.sum() + hist.sum() - np.diag())
          test_summary_str = sess.run(average_summary, feed_dict={average_pl:})
          acc_summary_str = sess.run(acc_summary, feed_dict={acc_pl:})
          iu_summary_str = sess.run(iu_summary, feed_dict={iu_pl:})
          summary_str = sess.run(summary_op, feed_dict=)
          summary_writer.add_summary()
          summary_writer.add_summary()
          summary_writer.add_summary()
          summary_writer.add_summary()
        if step % 1000 == 0 or () == max_steps:
          checkpoint_path = os.path.join()
          saver.save(sess, checkpoint_path, global_step=)
      coord.request_stop()
      coord.join()